Args in experiment:
Namespace(model='TimeMixer', task_name='long_term_forecast', seed=2021, data='custom', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', train_prop=1.0, seq_len=96, label_len=0, pred_len=96, seasonal_patterns='Monthly', inverse=False, enc_in=21, dec_in=21, c_out=21, decomp_method='moving_avg', top_k=5, moving_avg=25, d_model=16, d_ff=32, e_layers=3, dropout=0.1, embed='timeF', channel_independence=1, use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', use_future_temporal_feature=0, output_attention=False, num_workers=4, train_epochs=20, batch_size=128, patience=10, delta=0.0, learning_rate=0.01, des='test', loss='MSE', lradj='type1', pct_start=0.2, use_amp=False, comment='none', use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', save_dir='./checkpoints/baseline/reproduction/weather_96_96', save_last=False, break_at=0)
Use GPU: cuda:0
train 36696
val 5175
test 10444
	iters: 100, epoch: 1 | loss: 0.4355873
	speed: 0.0376s/iter; left time: 211.0757s
	iters: 200, epoch: 1 | loss: 0.4396277
	speed: 0.0305s/iter; left time: 168.4298s
Epoch: 1 cost time: 9.224709510803223
Epoch: 1, Steps: 286 | Train Loss: 0.5531578 Vali Loss: 0.4660015
Updating learning rate to 0.01
Validation loss decreased (inf --> 0.4660).  Saving model state dict ...
	iters: 100, epoch: 2 | loss: 0.4472249
	speed: 0.0649s/iter; left time: 346.2744s
	iters: 200, epoch: 2 | loss: 0.2905309
	speed: 0.0306s/iter; left time: 160.4219s
Epoch: 2 cost time: 8.87204623222351
Epoch: 2, Steps: 286 | Train Loss: 0.4452973 Vali Loss: 0.4071642
Updating learning rate to 0.005
Validation loss decreased (0.4660 --> 0.4072).  Saving model state dict ...
	iters: 100, epoch: 3 | loss: 0.3528395
	speed: 0.0651s/iter; left time: 328.5921s
	iters: 200, epoch: 3 | loss: 0.5787734
	speed: 0.0312s/iter; left time: 154.5298s
Epoch: 3 cost time: 8.905048608779907
Epoch: 3, Steps: 286 | Train Loss: 0.4189072 Vali Loss: 0.4052887
Updating learning rate to 0.0025
Validation loss decreased (0.4072 --> 0.4053).  Saving model state dict ...
	iters: 100, epoch: 4 | loss: 0.3468698
	speed: 0.0648s/iter; left time: 308.5580s
	iters: 200, epoch: 4 | loss: 0.3679119
	speed: 0.0307s/iter; left time: 143.3275s
Epoch: 4 cost time: 8.894591569900513
Epoch: 4, Steps: 286 | Train Loss: 0.4162435 Vali Loss: 0.4018634
Updating learning rate to 0.00125
Validation loss decreased (0.4053 --> 0.4019).  Saving model state dict ...
	iters: 100, epoch: 5 | loss: 0.2769315
	speed: 0.0647s/iter; left time: 289.6411s
	iters: 200, epoch: 5 | loss: 0.5986452
	speed: 0.0317s/iter; left time: 138.9038s
Epoch: 5 cost time: 9.052955865859985
Epoch: 5, Steps: 286 | Train Loss: 0.4092417 Vali Loss: 0.4027010
Updating learning rate to 0.000625
EarlyStopping counter: 1 out of 10
	iters: 100, epoch: 6 | loss: 0.3004520
	speed: 0.0667s/iter; left time: 279.5035s
	iters: 200, epoch: 6 | loss: 0.4528692
	speed: 0.0305s/iter; left time: 124.7801s
Epoch: 6 cost time: 8.93323302268982
Epoch: 6, Steps: 286 | Train Loss: 0.4062839 Vali Loss: 0.4021712
Updating learning rate to 0.0003125
EarlyStopping counter: 2 out of 10
	iters: 100, epoch: 7 | loss: 0.3785998
	speed: 0.0646s/iter; left time: 252.2477s
	iters: 200, epoch: 7 | loss: 0.3665995
	speed: 0.0304s/iter; left time: 115.7564s
Epoch: 7 cost time: 8.897047758102417
Epoch: 7, Steps: 286 | Train Loss: 0.4041734 Vali Loss: 0.4012352
Updating learning rate to 0.00015625
Validation loss decreased (0.4019 --> 0.4012).  Saving model state dict ...
	iters: 100, epoch: 8 | loss: 0.5670211
	speed: 0.0651s/iter; left time: 235.6846s
	iters: 200, epoch: 8 | loss: 0.3749869
	speed: 0.0313s/iter; left time: 110.1970s
Epoch: 8 cost time: 8.96864128112793
Epoch: 8, Steps: 286 | Train Loss: 0.4027648 Vali Loss: 0.4022683
Updating learning rate to 7.8125e-05
EarlyStopping counter: 1 out of 10
	iters: 100, epoch: 9 | loss: 0.3269604
	speed: 0.0655s/iter; left time: 218.3071s
	iters: 200, epoch: 9 | loss: 0.3727298
	speed: 0.0309s/iter; left time: 99.9843s
Epoch: 9 cost time: 9.023969650268555
Epoch: 9, Steps: 286 | Train Loss: 0.4032026 Vali Loss: 0.4013126
Updating learning rate to 3.90625e-05
EarlyStopping counter: 2 out of 10
	iters: 100, epoch: 10 | loss: 0.3410225
	speed: 0.0664s/iter; left time: 202.2735s
	iters: 200, epoch: 10 | loss: 0.3172105
	speed: 0.0312s/iter; left time: 91.8588s
Epoch: 10 cost time: 8.95082426071167
Epoch: 10, Steps: 286 | Train Loss: 0.4028584 Vali Loss: 0.4015148
Updating learning rate to 1.953125e-05
EarlyStopping counter: 3 out of 10
	iters: 100, epoch: 11 | loss: 0.6044744
	speed: 0.0644s/iter; left time: 177.8690s
	iters: 200, epoch: 11 | loss: 0.4504779
	speed: 0.0306s/iter; left time: 81.4980s
Epoch: 11 cost time: 8.878230094909668
Epoch: 11, Steps: 286 | Train Loss: 0.4029057 Vali Loss: 0.4012864
Updating learning rate to 9.765625e-06
EarlyStopping counter: 4 out of 10
	iters: 100, epoch: 12 | loss: 0.3758189
	speed: 0.0655s/iter; left time: 162.1816s
	iters: 200, epoch: 12 | loss: 0.3838036
	speed: 0.0312s/iter; left time: 74.0905s
Epoch: 12 cost time: 8.989174842834473
Epoch: 12, Steps: 286 | Train Loss: 0.4019699 Vali Loss: 0.4013357
Updating learning rate to 4.8828125e-06
EarlyStopping counter: 5 out of 10
	iters: 100, epoch: 13 | loss: 0.6102924
	speed: 0.0658s/iter; left time: 144.1285s
	iters: 200, epoch: 13 | loss: 0.3889488
	speed: 0.0311s/iter; left time: 64.9420s
Epoch: 13 cost time: 8.951412677764893
Epoch: 13, Steps: 286 | Train Loss: 0.4016131 Vali Loss: 0.4013536
Updating learning rate to 2.44140625e-06
EarlyStopping counter: 6 out of 10
	iters: 100, epoch: 14 | loss: 0.3741007
	speed: 0.0647s/iter; left time: 123.0739s
	iters: 200, epoch: 14 | loss: 0.4848427
	speed: 0.0314s/iter; left time: 56.5289s
Epoch: 14 cost time: 9.0080726146698
Epoch: 14, Steps: 286 | Train Loss: 0.4024934 Vali Loss: 0.4013184
Updating learning rate to 1.220703125e-06
EarlyStopping counter: 7 out of 10
	iters: 100, epoch: 15 | loss: 0.2894784
	speed: 0.0654s/iter; left time: 105.7050s
	iters: 200, epoch: 15 | loss: 0.5993491
	speed: 0.0307s/iter; left time: 46.5226s
Epoch: 15 cost time: 8.934211015701294
Epoch: 15, Steps: 286 | Train Loss: 0.4024517 Vali Loss: 0.4013287
Updating learning rate to 6.103515625e-07
EarlyStopping counter: 8 out of 10
	iters: 100, epoch: 16 | loss: 0.4724984
	speed: 0.0659s/iter; left time: 87.6533s
	iters: 200, epoch: 16 | loss: 0.3085587
	speed: 0.0313s/iter; left time: 38.5259s
Epoch: 16 cost time: 9.023459672927856
Epoch: 16, Steps: 286 | Train Loss: 0.4014925 Vali Loss: 0.4013292
Updating learning rate to 3.0517578125e-07
EarlyStopping counter: 9 out of 10
	iters: 100, epoch: 17 | loss: 0.6976029
	speed: 0.0660s/iter; left time: 69.0182s
	iters: 200, epoch: 17 | loss: 0.2823235
	speed: 0.0312s/iter; left time: 29.5181s
Epoch: 17 cost time: 8.966391801834106
Epoch: 17, Steps: 286 | Train Loss: 0.4025025 Vali Loss: 0.4013303
Updating learning rate to 1.52587890625e-07
EarlyStopping counter: 10 out of 10
Early stopping
#####   loading best weights   #####
Process: python3 (PID: 554977) is using 1542 MiB of GPU memory.
Epoch: 17 | Elapsed Time: 1477.1691360473633 s | VRAM usage: 1.505859375 Gb | Train MSE: 0.4016 Train MAE: 0.2861 Vali MSE: 0.4012 Vali MAE: 0.2732 Test MSE: 0.1630 Test MAE: 0.2099



Args in experiment:
Namespace(model='TimeMixer', task_name='long_term_forecast', seed=2021, data='custom', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', train_prop=1.0, seq_len=96, label_len=0, pred_len=192, seasonal_patterns='Monthly', inverse=False, enc_in=21, dec_in=21, c_out=21, decomp_method='moving_avg', top_k=5, moving_avg=25, d_model=16, d_ff=32, e_layers=3, dropout=0.1, embed='timeF', channel_independence=1, use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', use_future_temporal_feature=0, output_attention=False, num_workers=4, train_epochs=20, batch_size=128, patience=10, delta=0.0, learning_rate=0.01, des='test', loss='MSE', lradj='type1', pct_start=0.2, use_amp=False, comment='none', use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', save_dir='./checkpoints/baseline/reproduction/weather_96_192', save_last=False, break_at=0)
Use GPU: cuda:0
train 36600
val 5079
test 10348
	iters: 100, epoch: 1 | loss: 0.6236008
	speed: 0.0377s/iter; left time: 211.0021s
	iters: 200, epoch: 1 | loss: 0.6159596
	speed: 0.0322s/iter; left time: 176.9746s
Epoch: 1 cost time: 9.478037357330322
Epoch: 1, Steps: 285 | Train Loss: 0.6392748 Vali Loss: 0.5435571
Updating learning rate to 0.01
Validation loss decreased (inf --> 0.5436).  Saving model state dict ...
	iters: 100, epoch: 2 | loss: 0.4971243
	speed: 0.0682s/iter; left time: 362.7534s
	iters: 200, epoch: 2 | loss: 0.4242816
	speed: 0.0331s/iter; left time: 172.3924s
Epoch: 2 cost time: 9.418285131454468
Epoch: 2, Steps: 285 | Train Loss: 0.5072106 Vali Loss: 0.4752141
Updating learning rate to 0.005
Validation loss decreased (0.5436 --> 0.4752).  Saving model state dict ...
	iters: 100, epoch: 3 | loss: 0.5490729
	speed: 0.0676s/iter; left time: 340.1486s
	iters: 200, epoch: 3 | loss: 0.4268781
	speed: 0.0326s/iter; left time: 160.9803s
Epoch: 3 cost time: 9.386699676513672
Epoch: 3, Steps: 285 | Train Loss: 0.4852636 Vali Loss: 0.4732322
Updating learning rate to 0.0025
Validation loss decreased (0.4752 --> 0.4732).  Saving model state dict ...
	iters: 100, epoch: 4 | loss: 0.4955055
	speed: 0.0684s/iter; left time: 324.5263s
	iters: 200, epoch: 4 | loss: 0.6843628
	speed: 0.0335s/iter; left time: 155.5419s
Epoch: 4 cost time: 9.466572761535645
Epoch: 4, Steps: 285 | Train Loss: 0.4779758 Vali Loss: 0.4716151
Updating learning rate to 0.00125
Validation loss decreased (0.4732 --> 0.4716).  Saving model state dict ...
	iters: 100, epoch: 5 | loss: 0.3624749
	speed: 0.0693s/iter; left time: 309.2238s
	iters: 200, epoch: 5 | loss: 0.4913764
	speed: 0.0322s/iter; left time: 140.2336s
Epoch: 5 cost time: 9.42389965057373
Epoch: 5, Steps: 285 | Train Loss: 0.4741553 Vali Loss: 0.4673113
Updating learning rate to 0.000625
Validation loss decreased (0.4716 --> 0.4673).  Saving model state dict ...
	iters: 100, epoch: 6 | loss: 0.6881442
	speed: 0.0682s/iter; left time: 284.8856s
	iters: 200, epoch: 6 | loss: 0.3813603
	speed: 0.0332s/iter; left time: 135.1220s
Epoch: 6 cost time: 9.49459719657898
Epoch: 6, Steps: 285 | Train Loss: 0.4708151 Vali Loss: 0.4666549
Updating learning rate to 0.0003125
Validation loss decreased (0.4673 --> 0.4667).  Saving model state dict ...
	iters: 100, epoch: 7 | loss: 0.5702137
	speed: 0.0696s/iter; left time: 270.9992s
	iters: 200, epoch: 7 | loss: 0.3722392
	speed: 0.0333s/iter; left time: 126.3584s
Epoch: 7 cost time: 9.487935066223145
Epoch: 7, Steps: 285 | Train Loss: 0.4691701 Vali Loss: 0.4657967
Updating learning rate to 0.00015625
Validation loss decreased (0.4667 --> 0.4658).  Saving model state dict ...
	iters: 100, epoch: 8 | loss: 0.3805182
	speed: 0.0681s/iter; left time: 245.5502s
	iters: 200, epoch: 8 | loss: 0.3829024
	speed: 0.0336s/iter; left time: 117.6912s
Epoch: 8 cost time: 9.604968786239624
Epoch: 8, Steps: 285 | Train Loss: 0.4682435 Vali Loss: 0.4670436
Updating learning rate to 7.8125e-05
EarlyStopping counter: 1 out of 10
	iters: 100, epoch: 9 | loss: 0.3904007
	speed: 0.0693s/iter; left time: 230.0483s
	iters: 200, epoch: 9 | loss: 0.4920322
	speed: 0.0325s/iter; left time: 104.6076s
Epoch: 9 cost time: 9.297029972076416
Epoch: 9, Steps: 285 | Train Loss: 0.4671022 Vali Loss: 0.4676829
Updating learning rate to 3.90625e-05
EarlyStopping counter: 2 out of 10
	iters: 100, epoch: 10 | loss: 0.3752999
	speed: 0.0673s/iter; left time: 204.3232s
	iters: 200, epoch: 10 | loss: 0.6117324
	speed: 0.0321s/iter; left time: 94.2263s
Epoch: 10 cost time: 9.292667150497437
Epoch: 10, Steps: 285 | Train Loss: 0.4670926 Vali Loss: 0.4671673
Updating learning rate to 1.953125e-05
EarlyStopping counter: 3 out of 10
	iters: 100, epoch: 11 | loss: 0.5854190
	speed: 0.0679s/iter; left time: 186.9182s
	iters: 200, epoch: 11 | loss: 0.6110980
	speed: 0.0324s/iter; left time: 86.0178s
Epoch: 11 cost time: 9.34103274345398
Epoch: 11, Steps: 285 | Train Loss: 0.4668629 Vali Loss: 0.4667713
Updating learning rate to 9.765625e-06
EarlyStopping counter: 4 out of 10
	iters: 100, epoch: 12 | loss: 0.3598004
	speed: 0.0683s/iter; left time: 168.5214s
	iters: 200, epoch: 12 | loss: 0.4768504
	speed: 0.0329s/iter; left time: 77.7793s
Epoch: 12 cost time: 9.456873655319214
Epoch: 12, Steps: 285 | Train Loss: 0.4665696 Vali Loss: 0.4670813
Updating learning rate to 4.8828125e-06
EarlyStopping counter: 5 out of 10
	iters: 100, epoch: 13 | loss: 0.3414535
	speed: 0.0688s/iter; left time: 150.0575s
	iters: 200, epoch: 13 | loss: 0.3378825
	speed: 0.0325s/iter; left time: 67.5725s
Epoch: 13 cost time: 9.401697874069214
Epoch: 13, Steps: 285 | Train Loss: 0.4661348 Vali Loss: 0.4670968
Updating learning rate to 2.44140625e-06
EarlyStopping counter: 6 out of 10
	iters: 100, epoch: 14 | loss: 0.3642458
	speed: 0.0674s/iter; left time: 127.7591s
	iters: 200, epoch: 14 | loss: 0.4667582
	speed: 0.0321s/iter; left time: 57.7355s
Epoch: 14 cost time: 9.247856616973877
Epoch: 14, Steps: 285 | Train Loss: 0.4669345 Vali Loss: 0.4672069
Updating learning rate to 1.220703125e-06
EarlyStopping counter: 7 out of 10
	iters: 100, epoch: 15 | loss: 0.4026246
	speed: 0.0674s/iter; left time: 108.5652s
	iters: 200, epoch: 15 | loss: 0.4386541
	speed: 0.0322s/iter; left time: 48.6812s
Epoch: 15 cost time: 9.26756238937378
Epoch: 15, Steps: 285 | Train Loss: 0.4667167 Vali Loss: 0.4672099
Updating learning rate to 6.103515625e-07
EarlyStopping counter: 8 out of 10
	iters: 100, epoch: 16 | loss: 0.3329275
	speed: 0.0675s/iter; left time: 89.4416s
	iters: 200, epoch: 16 | loss: 0.4974991
	speed: 0.0329s/iter; left time: 40.2937s
Epoch: 16 cost time: 9.407260417938232
Epoch: 16, Steps: 285 | Train Loss: 0.4670678 Vali Loss: 0.4672041
Updating learning rate to 3.0517578125e-07
EarlyStopping counter: 9 out of 10
	iters: 100, epoch: 17 | loss: 0.4880814
	speed: 0.0701s/iter; left time: 72.9899s
	iters: 200, epoch: 17 | loss: 0.3343327
	speed: 0.0324s/iter; left time: 30.4589s
Epoch: 17 cost time: 9.461144924163818
Epoch: 17, Steps: 285 | Train Loss: 0.4667746 Vali Loss: 0.4672049
Updating learning rate to 1.52587890625e-07
EarlyStopping counter: 10 out of 10
Early stopping
#####   loading best weights   #####
Process: python3 (PID: 556973) is using 1724 MiB of GPU memory.
Epoch: 17 | Elapsed Time: 1550.0275716781616 s | VRAM usage: 1.68359375 Gb | Train MSE: 0.4660 Train MAE: 0.3375 Vali MSE: 0.4658 Vali MAE: 0.3184 Test MSE: 0.2093 Test MAE: 0.2528



Args in experiment:
Namespace(model='TimeMixer', task_name='long_term_forecast', seed=2021, data='custom', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', train_prop=1.0, seq_len=96, label_len=0, pred_len=336, seasonal_patterns='Monthly', inverse=False, enc_in=21, dec_in=21, c_out=21, decomp_method='moving_avg', top_k=5, moving_avg=25, d_model=16, d_ff=32, e_layers=3, dropout=0.1, embed='timeF', channel_independence=1, use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', use_future_temporal_feature=0, output_attention=False, num_workers=4, train_epochs=20, batch_size=128, patience=10, delta=0.0, learning_rate=0.01, des='test', loss='MSE', lradj='type1', pct_start=0.2, use_amp=False, comment='none', use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', save_dir='./checkpoints/baseline/reproduction/weather_96_336', save_last=False, break_at=0)
Use GPU: cuda:0
train 36456
val 4935
test 10204
	iters: 100, epoch: 1 | loss: 0.6869724
	speed: 0.0415s/iter; left time: 231.4835s
	iters: 200, epoch: 1 | loss: 0.7600402
	speed: 0.0351s/iter; left time: 192.5036s
Epoch: 1 cost time: 10.351584434509277
Epoch: 1, Steps: 284 | Train Loss: 0.7279235 Vali Loss: 0.6406899
Updating learning rate to 0.01
Validation loss decreased (inf --> 0.6407).  Saving model state dict ...
	iters: 100, epoch: 2 | loss: 0.6291341
	speed: 0.0728s/iter; left time: 385.8477s
	iters: 200, epoch: 2 | loss: 0.6188838
	speed: 0.0351s/iter; left time: 182.5828s
Epoch: 2 cost time: 10.100485563278198
Epoch: 2, Steps: 284 | Train Loss: 0.5784809 Vali Loss: 0.5618678
Updating learning rate to 0.005
Validation loss decreased (0.6407 --> 0.5619).  Saving model state dict ...
	iters: 100, epoch: 3 | loss: 0.6290830
	speed: 0.0741s/iter; left time: 371.5695s
	iters: 200, epoch: 3 | loss: 0.5151370
	speed: 0.0361s/iter; left time: 177.4462s
Epoch: 3 cost time: 10.32091212272644
Epoch: 3, Steps: 284 | Train Loss: 0.5581141 Vali Loss: 0.5503345
Updating learning rate to 0.0025
Validation loss decreased (0.5619 --> 0.5503).  Saving model state dict ...
	iters: 100, epoch: 4 | loss: 0.5236735
	speed: 0.0756s/iter; left time: 357.2954s
	iters: 200, epoch: 4 | loss: 0.5005629
	speed: 0.0352s/iter; left time: 163.0879s
Epoch: 4 cost time: 10.17829704284668
Epoch: 4, Steps: 284 | Train Loss: 0.5500020 Vali Loss: 0.5491522
Updating learning rate to 0.00125
Validation loss decreased (0.5503 --> 0.5492).  Saving model state dict ...
	iters: 100, epoch: 5 | loss: 0.5583990
	speed: 0.0732s/iter; left time: 325.2983s
	iters: 200, epoch: 5 | loss: 0.5342603
	speed: 0.0356s/iter; left time: 154.6921s
Epoch: 5 cost time: 10.210779190063477
Epoch: 5, Steps: 284 | Train Loss: 0.5451084 Vali Loss: 0.5485188
Updating learning rate to 0.000625
Validation loss decreased (0.5492 --> 0.5485).  Saving model state dict ...
	iters: 100, epoch: 6 | loss: 0.6299649
	speed: 0.0750s/iter; left time: 312.2398s
	iters: 200, epoch: 6 | loss: 0.6310287
	speed: 0.0352s/iter; left time: 142.8853s
Epoch: 6 cost time: 10.23832893371582
Epoch: 6, Steps: 284 | Train Loss: 0.5416925 Vali Loss: 0.5495643
Updating learning rate to 0.0003125
EarlyStopping counter: 1 out of 10
	iters: 100, epoch: 7 | loss: 0.4782908
	speed: 0.0744s/iter; left time: 288.4631s
	iters: 200, epoch: 7 | loss: 0.5131626
	speed: 0.0353s/iter; left time: 133.5121s
Epoch: 7 cost time: 10.132812976837158
Epoch: 7, Steps: 284 | Train Loss: 0.5391878 Vali Loss: 0.5505149
Updating learning rate to 0.00015625
EarlyStopping counter: 2 out of 10
	iters: 100, epoch: 8 | loss: 0.4878000
	speed: 0.0744s/iter; left time: 267.2417s
	iters: 200, epoch: 8 | loss: 0.5389834
	speed: 0.0356s/iter; left time: 124.3203s
Epoch: 8 cost time: 10.253084659576416
Epoch: 8, Steps: 284 | Train Loss: 0.5381443 Vali Loss: 0.5516927
Updating learning rate to 7.8125e-05
EarlyStopping counter: 3 out of 10
	iters: 100, epoch: 9 | loss: 0.4807548
	speed: 0.0752s/iter; left time: 248.6844s
	iters: 200, epoch: 9 | loss: 0.6273692
	speed: 0.0363s/iter; left time: 116.4004s
Epoch: 9 cost time: 10.360679149627686
Epoch: 9, Steps: 284 | Train Loss: 0.5371170 Vali Loss: 0.5507772
Updating learning rate to 3.90625e-05
EarlyStopping counter: 4 out of 10
	iters: 100, epoch: 10 | loss: 0.6860734
	speed: 0.0740s/iter; left time: 223.8595s
	iters: 200, epoch: 10 | loss: 0.5101249
	speed: 0.0366s/iter; left time: 107.0643s
Epoch: 10 cost time: 10.254382133483887
Epoch: 10, Steps: 284 | Train Loss: 0.5365999 Vali Loss: 0.5509643
Updating learning rate to 1.953125e-05
EarlyStopping counter: 5 out of 10
	iters: 100, epoch: 11 | loss: 0.5957290
	speed: 0.0737s/iter; left time: 202.0199s
	iters: 200, epoch: 11 | loss: 0.6421835
	speed: 0.0361s/iter; left time: 95.3704s
Epoch: 11 cost time: 10.218614339828491
Epoch: 11, Steps: 284 | Train Loss: 0.5366686 Vali Loss: 0.5510255
Updating learning rate to 9.765625e-06
EarlyStopping counter: 6 out of 10
	iters: 100, epoch: 12 | loss: 0.5302755
	speed: 0.0739s/iter; left time: 181.4552s
	iters: 200, epoch: 12 | loss: 0.5779105
	speed: 0.0360s/iter; left time: 84.9526s
Epoch: 12 cost time: 10.263700008392334
Epoch: 12, Steps: 284 | Train Loss: 0.5367762 Vali Loss: 0.5511281
Updating learning rate to 4.8828125e-06
EarlyStopping counter: 7 out of 10
	iters: 100, epoch: 13 | loss: 0.4555887
	speed: 0.0753s/iter; left time: 163.6449s
	iters: 200, epoch: 13 | loss: 0.4314297
	speed: 0.0359s/iter; left time: 74.4903s
Epoch: 13 cost time: 10.301697492599487
Epoch: 13, Steps: 284 | Train Loss: 0.5368357 Vali Loss: 0.5514149
Updating learning rate to 2.44140625e-06
EarlyStopping counter: 8 out of 10
	iters: 100, epoch: 14 | loss: 0.6584585
	speed: 0.0738s/iter; left time: 139.3280s
	iters: 200, epoch: 14 | loss: 0.5319935
	speed: 0.0353s/iter; left time: 63.1550s
Epoch: 14 cost time: 10.128297090530396
Epoch: 14, Steps: 284 | Train Loss: 0.5367120 Vali Loss: 0.5513653
Updating learning rate to 1.220703125e-06
EarlyStopping counter: 9 out of 10
	iters: 100, epoch: 15 | loss: 0.6175944
	speed: 0.0740s/iter; left time: 118.7385s
	iters: 200, epoch: 15 | loss: 0.4824939
	speed: 0.0368s/iter; left time: 55.4263s
Epoch: 15 cost time: 10.375551700592041
Epoch: 15, Steps: 284 | Train Loss: 0.5364912 Vali Loss: 0.5513781
Updating learning rate to 6.103515625e-07
EarlyStopping counter: 10 out of 10
Early stopping
#####   loading best weights   #####
Process: python3 (PID: 559031) is using 1808 MiB of GPU memory.
Epoch: 15 | Elapsed Time: 1321.5733201503754 s | VRAM usage: 1.765625 Gb | Train MSE: 0.5404 Train MAE: 0.3895 Vali MSE: 0.5485 Vali MAE: 0.3757 Test MSE: 0.2646 Test MAE: 0.2925



Args in experiment:
Namespace(model='TimeMixer', task_name='long_term_forecast', seed=2021, data='custom', root_path='./dataset/weather/', data_path='weather.csv', features='M', target='OT', freq='h', train_prop=1.0, seq_len=96, label_len=0, pred_len=720, seasonal_patterns='Monthly', inverse=False, enc_in=21, dec_in=21, c_out=21, decomp_method='moving_avg', top_k=5, moving_avg=25, d_model=16, d_ff=32, e_layers=3, dropout=0.1, embed='timeF', channel_independence=1, use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', use_future_temporal_feature=0, output_attention=False, num_workers=4, train_epochs=20, batch_size=128, patience=10, delta=0.0, learning_rate=0.01, des='test', loss='MSE', lradj='type1', pct_start=0.2, use_amp=False, comment='none', use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', save_dir='./checkpoints/baseline/reproduction/weather_96_720', save_last=False, break_at=0)
Use GPU: cuda:0
train 36072
val 4551
test 9820
	iters: 100, epoch: 1 | loss: 0.8319755
	speed: 0.0464s/iter; left time: 256.2040s
	iters: 200, epoch: 1 | loss: 0.6952367
	speed: 0.0410s/iter; left time: 222.3702s
Epoch: 1 cost time: 11.872219800949097
Epoch: 1, Steps: 281 | Train Loss: 0.8188581 Vali Loss: 0.7462401
Updating learning rate to 0.01
Validation loss decreased (inf --> 0.7462).  Saving model state dict ...
	iters: 100, epoch: 2 | loss: 0.6683085
	speed: 0.0851s/iter; left time: 445.7535s
	iters: 200, epoch: 2 | loss: 0.5956969
	speed: 0.0419s/iter; left time: 215.1441s
Epoch: 2 cost time: 11.887380361557007
Epoch: 2, Steps: 281 | Train Loss: 0.6665653 Vali Loss: 0.6838478
Updating learning rate to 0.005
Validation loss decreased (0.7462 --> 0.6838).  Saving model state dict ...
	iters: 100, epoch: 3 | loss: 0.6219209
	speed: 0.0856s/iter; left time: 424.6196s
	iters: 200, epoch: 3 | loss: 0.5163321
	speed: 0.0419s/iter; left time: 203.7261s
Epoch: 3 cost time: 11.863537311553955
Epoch: 3, Steps: 281 | Train Loss: 0.6413490 Vali Loss: 0.6732011
Updating learning rate to 0.0025
Validation loss decreased (0.6838 --> 0.6732).  Saving model state dict ...
	iters: 100, epoch: 4 | loss: 0.6591613
	speed: 0.0838s/iter; left time: 391.8858s
	iters: 200, epoch: 4 | loss: 0.5768379
	speed: 0.0407s/iter; left time: 186.2030s
Epoch: 4 cost time: 11.576645374298096
Epoch: 4, Steps: 281 | Train Loss: 0.6322963 Vali Loss: 0.6756457
Updating learning rate to 0.00125
EarlyStopping counter: 1 out of 10
	iters: 100, epoch: 5 | loss: 0.5576703
	speed: 0.0833s/iter; left time: 366.2139s
	iters: 200, epoch: 5 | loss: 0.6078121
	speed: 0.0411s/iter; left time: 176.4120s
Epoch: 5 cost time: 11.561384677886963
Epoch: 5, Steps: 281 | Train Loss: 0.6260112 Vali Loss: 0.6716057
Updating learning rate to 0.000625
Validation loss decreased (0.6732 --> 0.6716).  Saving model state dict ...
	iters: 100, epoch: 6 | loss: 0.7664698
	speed: 0.0832s/iter; left time: 342.5624s
	iters: 200, epoch: 6 | loss: 0.6598163
	speed: 0.0413s/iter; left time: 165.8971s
Epoch: 6 cost time: 11.609611988067627
Epoch: 6, Steps: 281 | Train Loss: 0.6215388 Vali Loss: 0.6728573
Updating learning rate to 0.0003125
EarlyStopping counter: 1 out of 10
	iters: 100, epoch: 7 | loss: 0.6086184
	speed: 0.0828s/iter; left time: 317.3867s
	iters: 200, epoch: 7 | loss: 0.6753052
	speed: 0.0419s/iter; left time: 156.6148s
Epoch: 7 cost time: 11.709342956542969
Epoch: 7, Steps: 281 | Train Loss: 0.6186080 Vali Loss: 0.6730357
Updating learning rate to 0.00015625
EarlyStopping counter: 2 out of 10
	iters: 100, epoch: 8 | loss: 0.5245883
	speed: 0.0846s/iter; left time: 300.6925s
	iters: 200, epoch: 8 | loss: 0.5800338
	speed: 0.0412s/iter; left time: 142.2390s
Epoch: 8 cost time: 11.715825080871582
Epoch: 8, Steps: 281 | Train Loss: 0.6176893 Vali Loss: 0.6745807
Updating learning rate to 7.8125e-05
EarlyStopping counter: 3 out of 10
	iters: 100, epoch: 9 | loss: 0.5557234
	speed: 0.0853s/iter; left time: 279.2990s
	iters: 200, epoch: 9 | loss: 0.6056584
	speed: 0.0425s/iter; left time: 134.8425s
Epoch: 9 cost time: 11.849362134933472
Epoch: 9, Steps: 281 | Train Loss: 0.6163587 Vali Loss: 0.6737315
Updating learning rate to 3.90625e-05
EarlyStopping counter: 4 out of 10
	iters: 100, epoch: 10 | loss: 0.6151813
	speed: 0.0834s/iter; left time: 249.5249s
	iters: 200, epoch: 10 | loss: 0.6044269
	speed: 0.0409s/iter; left time: 118.3675s
Epoch: 10 cost time: 11.55564832687378
Epoch: 10, Steps: 281 | Train Loss: 0.6159408 Vali Loss: 0.6740487
Updating learning rate to 1.953125e-05
EarlyStopping counter: 5 out of 10
	iters: 100, epoch: 11 | loss: 0.5766563
	speed: 0.0832s/iter; left time: 225.5211s
	iters: 200, epoch: 11 | loss: 0.6520680
	speed: 0.0410s/iter; left time: 107.1709s
Epoch: 11 cost time: 11.644148349761963
Epoch: 11, Steps: 281 | Train Loss: 0.6155581 Vali Loss: 0.6740324
Updating learning rate to 9.765625e-06
EarlyStopping counter: 6 out of 10
	iters: 100, epoch: 12 | loss: 0.6556390
	speed: 0.0838s/iter; left time: 203.6226s
	iters: 200, epoch: 12 | loss: 0.6611357
	speed: 0.0423s/iter; left time: 98.6153s
Epoch: 12 cost time: 11.799102544784546
Epoch: 12, Steps: 281 | Train Loss: 0.6154084 Vali Loss: 0.6740998
Updating learning rate to 4.8828125e-06
EarlyStopping counter: 7 out of 10
	iters: 100, epoch: 13 | loss: 0.5817004
	speed: 0.0847s/iter; left time: 182.0973s
	iters: 200, epoch: 13 | loss: 0.5773046
	speed: 0.0411s/iter; left time: 84.2470s
Epoch: 13 cost time: 11.710957050323486
Epoch: 13, Steps: 281 | Train Loss: 0.6152076 Vali Loss: 0.6740436
Updating learning rate to 2.44140625e-06
EarlyStopping counter: 8 out of 10
	iters: 100, epoch: 14 | loss: 0.6947215
	speed: 0.0843s/iter; left time: 157.5200s
	iters: 200, epoch: 14 | loss: 0.6647661
	speed: 0.0413s/iter; left time: 73.0715s
Epoch: 14 cost time: 11.747894048690796
Epoch: 14, Steps: 281 | Train Loss: 0.6152448 Vali Loss: 0.6739904
Updating learning rate to 1.220703125e-06
EarlyStopping counter: 9 out of 10
	iters: 100, epoch: 15 | loss: 0.7671378
	speed: 0.0861s/iter; left time: 136.5826s
	iters: 200, epoch: 15 | loss: 0.6122159
	speed: 0.0416s/iter; left time: 61.7999s
Epoch: 15 cost time: 11.848395109176636
Epoch: 15, Steps: 281 | Train Loss: 0.6158555 Vali Loss: 0.6739848
Updating learning rate to 6.103515625e-07
EarlyStopping counter: 10 out of 10
Early stopping
#####   loading best weights   #####
Process: python3 (PID: 560976) is using 2196 MiB of GPU memory.
Epoch: 15 | Elapsed Time: 1510.1973209381104 s | VRAM usage: 2.14453125 Gb | Train MSE: 0.6247 Train MAE: 0.4407 Vali MSE: 0.6716 Vali MAE: 0.4543 Test MSE: 0.3401 Test MAE: 0.3427



