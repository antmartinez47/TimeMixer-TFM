horizon=720
maxconcurrent=1
gpu_fraction=$(echo "scale=2; 1/$maxconcurrent" | bc)  # Calculate GPU fraction with 2 decimal places
start_time=$(date +%s)  # Get the current time in seconds
python3 tune_timemixer.py \
    --model TimeMixer \
    --data ETTh1 \
    --root_path ./dataset/ETT-small/ \
    --data_path ETTh1.csv \
    --features M \
    --seq_len 96 \
    --label_len 0 \
    --pred_len $horizon \
    --enc_in 7 \
    --dec_in 7 \
    --c_out 7 \
    --d_model 16 \
    --d_ff 32 \
    --down_sampling_layers 3 \
    --down_sampling_window 2 \
    --down_sampling_method avg \
    --decomp_method moving_avg \
    --moving_avg 25 \
    --train_epochs 8 \
    --patience 3 \
    --num_workers 1 \
    --gpu 0 \
    --tune_search_algorithm hyperopt_tpe \
    --tune_trial_scheduler fifo \
    --tune_storage_path ./checkpoints/hptunning/hyperopt_tpe/ \
    --tune_experiment_name ETTh1_96_${horizon} \
    --tune_objective best_valid_loss \
    --tune_num_samples 1500 \
    --tune_max_trial_time_s 100 \
    --tune_time_budget_s 14400 \
    --tune_max_concurrent $maxconcurrent \
    --tune_gpu_resources $gpu_fraction \
    --tune_cpu_resources 1 \
    --tune_default_config "{
        \"batch_size\": 128, \
        \"learning_rate\": 0.01, \
        \"down_sampling_method\": \"avg\", \
        \"d_model\": 16, \
        \"alpha_d_ff\": 2, \
        \"decomp_method\": \"moving_avg\", \
        \"moving_avg\": 25, \
        \"e_layers\": 2, \
        \"dropout\": 0.1
    }" \
    --tune_param_space "{
        \"batch_size\": [\"choice\", [16, 32, 64, 128]], \
        \"learning_rate\": [\"loguniform\", [0.0005, 0.012]], \
        \"down_sampling_method\": [\"choice\", [\"avg\", \"conv\"]], \
        \"d_model\": [\"choice\", [8, 16, 32, 64, 128, 256, 512]], \
        \"alpha_d_ff\": [\"choice\", [2, 3, 4]], \
        \"decomp_method\": [\"choice\", [[\"moving_avg\", \"moving_avg\", [15, 25, 35, 55, 75]], [\"dft_decomp\"]]], \
        \"e_layers\": [\"choice\", [1, 2, 3, 4]], \
        \"dropout\": [\"normal\", [0.1, 0.025]]
    }" \
    --tune_hyperopt_n_initial_points 150 \
    --tune_hyperopt_gamma 0.25 \
    --seed 123;
end_time=$(date +%s)  # Get the current time in seconds
elapsed_time=$((end_time - start_time))  # Calculate the elapsed time
echo ""
echo ""
echo "Time taken ($maxconcurrent parallel trials): $elapsed_time seconds"
echo ""
echo ""2024-08-24 07:21:08,349	INFO worker.py:1781 -- Started a local Ray instance.
2024-08-24 07:21:08,759	INFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.
2024-08-24 07:21:13,336	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=741561)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4138d74d_1_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers=4,_2024-08-24_07-21-08/checkpoint_000000)
2024-08-24 07:21:15,475	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=741561)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4138d74d_1_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers=4,_2024-08-24_07-21-08/checkpoint_000001)
2024-08-24 07:21:17,618	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=741561)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4138d74d_1_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers=4,_2024-08-24_07-21-08/checkpoint_000002)
2024-08-24 07:21:19,749	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=741561)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4138d74d_1_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers=4,_2024-08-24_07-21-08/checkpoint_000003)
2024-08-24 07:21:21,877	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=741561)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4138d74d_1_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers=4,_2024-08-24_07-21-08/checkpoint_000004)
2024-08-24 07:21:24,019	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=741561)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4138d74d_1_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers=4,_2024-08-24_07-21-08/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     ETTh1_96_720    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 SearchGenerator â”‚
â”‚ Scheduler                        FIFOScheduler   â”‚
â”‚ Number of trials                 1500            â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-08-24_07-21-07_902418_739363/artifacts/2024-08-24_07-21-08/ETTh1_96_720/driver_artifacts`

Trial status: 1 PENDING
Current time: 2024-08-24 07:21:08. Total running time: 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   PENDING  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-4138d74d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4138d74d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09904 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00163 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=741561)[0m configuration
[36m(_train_fn pid=741561)[0m {'batch_size': 64, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.0990448800935579, 'e_layers': 4, 'learning_rate': 0.001631158227501476, 'd_ff': 32}
[36m(_train_fn pid=741561)[0m Use GPU: cuda:0
[36m(_train_fn pid=741561)[0m train 7825
[36m(_train_fn pid=741561)[0m val 2161
[36m(_train_fn pid=741561)[0m start_epoch 0
[36m(_train_fn pid=741561)[0m max_epoch 8
[36m(_train_fn pid=741561)[0m 	iters: 100, epoch: 1 | loss: 1.0937153
[36m(_train_fn pid=741561)[0m 	speed: 0.0219s/iter; left time: 19.1666s
[36m(_train_fn pid=741561)[0m Updating learning rate to 0.001631158227501476
[36m(_train_fn pid=741561)[0m saving checkpoint...
[36m(_train_fn pid=741561)[0m Validation loss decreased (inf --> 2.4255).  Saving model state dict ...
[36m(_train_fn pid=741561)[0m Epoch: 1 cost time: 2.2302567958831787
[36m(_train_fn pid=741561)[0m Epoch: 1, Steps: 122 | Train Loss: 1.1793961 Vali Loss: 2.4255067 Best vali loss: 2.4255067
[36m(_train_fn pid=741561)[0m 	iters: 100, epoch: 2 | loss: 0.6210622
[36m(_train_fn pid=741561)[0m 	speed: 0.0212s/iter; left time: 15.9886s
[36m(_train_fn pid=741561)[0m Updating learning rate to 0.000815579113750738
[36m(_train_fn pid=741561)[0m saving checkpoint...
[36m(_train_fn pid=741561)[0m Validation loss decreased (2.4255 --> 1.6133).  Saving model state dict ...
[36m(_train_fn pid=741561)[0m Epoch: 2 cost time: 1.8424577713012695
[36m(_train_fn pid=741561)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6936756 Vali Loss: 1.6132523 Best vali loss: 1.6132523
[36m(_train_fn pid=741561)[0m 	iters: 100, epoch: 3 | loss: 0.6045777
[36m(_train_fn pid=741561)[0m 	speed: 0.0215s/iter; left time: 13.6007s
[36m(_train_fn pid=741561)[0m Updating learning rate to 0.000407789556875369
[36m(_train_fn pid=741561)[0m saving checkpoint...
[36m(_train_fn pid=741561)[0m Validation loss decreased (1.6133 --> 1.5903).  Saving model state dict ...
[36m(_train_fn pid=741561)[0m Epoch: 3 cost time: 1.8540370464324951
[36m(_train_fn pid=741561)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6149486 Vali Loss: 1.5903464 Best vali loss: 1.5903464
[36m(_train_fn pid=741561)[0m 	iters: 100, epoch: 4 | loss: 0.5779676
[36m(_train_fn pid=741561)[0m 	speed: 0.0214s/iter; left time: 10.9318s
[36m(_train_fn pid=741561)[0m Updating learning rate to 0.0002038947784376845
[36m(_train_fn pid=741561)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=741561)[0m saving checkpoint...
[36m(_train_fn pid=741561)[0m Epoch: 4 cost time: 1.8499557971954346
[36m(_train_fn pid=741561)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6019722 Vali Loss: 1.5996884 Best vali loss: 1.5903464
[36m(_train_fn pid=741561)[0m 	iters: 100, epoch: 5 | loss: 0.5763015
[36m(_train_fn pid=741561)[0m 	speed: 0.0213s/iter; left time: 8.2729s
[36m(_train_fn pid=741561)[0m Updating learning rate to 0.00010194738921884225
[36m(_train_fn pid=741561)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=741561)[0m saving checkpoint...
[36m(_train_fn pid=741561)[0m Epoch: 5 cost time: 1.8464000225067139
[36m(_train_fn pid=741561)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5962454 Vali Loss: 1.6018344 Best vali loss: 1.5903464
[36m(_train_fn pid=741561)[0m 	iters: 100, epoch: 6 | loss: 0.6195892
[36m(_train_fn pid=741561)[0m 	speed: 0.0214s/iter; left time: 5.7141s

Trial trial-4138d74d completed after 6 iterations at 2024-08-24 07:21:24. Total running time: 15s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4138d74d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          2.14009 â”‚
â”‚ time_total_s                             13.60094 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.59035 â”‚
â”‚ train_loss                                0.59332 â”‚
â”‚ valid_loss                                1.59962 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=741561)[0m Updating learning rate to 5.097369460942112e-05
[36m(_train_fn pid=741561)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=741561)[0m saving checkpoint...
[36m(_train_fn pid=741561)[0m Epoch: 6 cost time: 1.860924482345581
[36m(_train_fn pid=741561)[0m Epoch: 6, Steps: 122 | Train Loss: 0.5933209 Vali Loss: 1.5996205 Best vali loss: 1.5903464
[36m(_train_fn pid=741561)[0m Early stopping

Trial trial-dcb4d3d5 started with configuration:
[36m(_train_fn pid=742183)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcb4d3d5_2_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0901,e_layers=_2024-08-24_07-21-24/checkpoint_000000)
2024-08-24 07:21:36,955	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=742183)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcb4d3d5_2_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0901,e_layers=_2024-08-24_07-21-24/checkpoint_000001)
2024-08-24 07:21:41,410	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=742183)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcb4d3d5_2_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0901,e_layers=_2024-08-24_07-21-24/checkpoint_000002)
2024-08-24 07:21:46,149	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=742183)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcb4d3d5_2_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0901,e_layers=_2024-08-24_07-21-24/checkpoint_000003)
2024-08-24 07:21:50,601	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-dcb4d3d5 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09013 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.01064 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=742183)[0m configuration
[36m(_train_fn pid=742183)[0m {'batch_size': 16, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.09012666779719704, 'e_layers': 2, 'learning_rate': 0.01064263000037022, 'd_ff': 48}
[36m(_train_fn pid=742183)[0m Use GPU: cuda:0
[36m(_train_fn pid=742183)[0m train 7825
[36m(_train_fn pid=742183)[0m val 2161
[36m(_train_fn pid=742183)[0m start_epoch 0
[36m(_train_fn pid=742183)[0m max_epoch 8
[36m(_train_fn pid=742183)[0m 	iters: 100, epoch: 1 | loss: 0.7670348
[36m(_train_fn pid=742183)[0m 	speed: 0.0161s/iter; left time: 61.5156s
[36m(_train_fn pid=742183)[0m 	iters: 200, epoch: 1 | loss: 0.7229387
[36m(_train_fn pid=742183)[0m 	speed: 0.0088s/iter; left time: 32.7614s
[36m(_train_fn pid=742183)[0m 	iters: 300, epoch: 1 | loss: 0.5460376
[36m(_train_fn pid=742183)[0m 	speed: 0.0088s/iter; left time: 31.9714s
[36m(_train_fn pid=742183)[0m 	iters: 400, epoch: 1 | loss: 0.7539803
[36m(_train_fn pid=742183)[0m 	speed: 0.0089s/iter; left time: 31.1244s
[36m(_train_fn pid=742183)[0m Updating learning rate to 0.01064263000037022
[36m(_train_fn pid=742183)[0m saving checkpoint...
[36m(_train_fn pid=742183)[0m Validation loss decreased (inf --> 1.5859).  Saving model state dict ...
[36m(_train_fn pid=742183)[0m Epoch: 1 cost time: 4.783728122711182
[36m(_train_fn pid=742183)[0m Epoch: 1, Steps: 489 | Train Loss: 0.6907429 Vali Loss: 1.5859447 Best vali loss: 1.5859447
[36m(_train_fn pid=742183)[0m 	iters: 100, epoch: 2 | loss: 0.5406883
[36m(_train_fn pid=742183)[0m 	speed: 0.0222s/iter; left time: 73.8745s
[36m(_train_fn pid=742183)[0m 	iters: 200, epoch: 2 | loss: 0.4932963
[36m(_train_fn pid=742183)[0m 	speed: 0.0088s/iter; left time: 28.5222s
[36m(_train_fn pid=742183)[0m 	iters: 300, epoch: 2 | loss: 0.5751286
[36m(_train_fn pid=742183)[0m 	speed: 0.0089s/iter; left time: 27.6789s
[36m(_train_fn pid=742183)[0m 	iters: 400, epoch: 2 | loss: 0.5749985
[36m(_train_fn pid=742183)[0m 	speed: 0.0090s/iter; left time: 27.0660s
[36m(_train_fn pid=742183)[0m Updating learning rate to 0.00532131500018511
[36m(_train_fn pid=742183)[0m saving checkpoint...
[36m(_train_fn pid=742183)[0m Validation loss decreased (1.5859 --> 1.5817).  Saving model state dict ...
[36m(_train_fn pid=742183)[0m Epoch: 2 cost time: 4.3819403648376465
[36m(_train_fn pid=742183)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6068047 Vali Loss: 1.5816860 Best vali loss: 1.5816860
[36m(_train_fn pid=742183)[0m 	iters: 100, epoch: 3 | loss: 0.5963274
[36m(_train_fn pid=742183)[0m 	speed: 0.0212s/iter; left time: 60.1525s
[36m(_train_fn pid=742183)[0m 	iters: 200, epoch: 3 | loss: 0.6042899
[36m(_train_fn pid=742183)[0m 	speed: 0.0080s/iter; left time: 21.9482s

Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:21:38. Total running time: 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: dcb4d3d5 with best_valid_loss=1.5816860035613731 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 16, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'conv', 'dropout': 0.09012666779719704, 'e_layers': 2, 'learning_rate': 0.01064263000037022}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-dcb4d3d5   RUNNING           2            10.5741       0.606805        1.58169             1.58169 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=742183)[0m 	iters: 300, epoch: 3 | loss: 0.5245984
[36m(_train_fn pid=742183)[0m 	speed: 0.0080s/iter; left time: 21.2107s
[36m(_train_fn pid=742183)[0m 	iters: 400, epoch: 3 | loss: 0.5206786
[36m(_train_fn pid=742183)[0m 	speed: 0.0080s/iter; left time: 20.2984s
[36m(_train_fn pid=742183)[0m Updating learning rate to 0.002660657500092555
[36m(_train_fn pid=742183)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=742183)[0m saving checkpoint...
[36m(_train_fn pid=742183)[0m Epoch: 3 cost time: 3.9677271842956543
[36m(_train_fn pid=742183)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5648127 Vali Loss: 1.6652436 Best vali loss: 1.5816860
[36m(_train_fn pid=742183)[0m 	iters: 100, epoch: 4 | loss: 0.5798008
[36m(_train_fn pid=742183)[0m 	speed: 0.0213s/iter; left time: 49.9924s
[36m(_train_fn pid=742183)[0m 	iters: 200, epoch: 4 | loss: 0.5172665
[36m(_train_fn pid=742183)[0m 	speed: 0.0089s/iter; left time: 19.9880s
[36m(_train_fn pid=742183)[0m 	iters: 300, epoch: 4 | loss: 0.6055023
[36m(_train_fn pid=742183)[0m 	speed: 0.0088s/iter; left time: 18.9850s
[36m(_train_fn pid=742183)[0m 	iters: 400, epoch: 4 | loss: 0.4981805
[36m(_train_fn pid=742183)[0m 	speed: 0.0085s/iter; left time: 17.3965s
[36m(_train_fn pid=742183)[0m Updating learning rate to 0.0013303287500462775
[36m(_train_fn pid=742183)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=742183)[0m saving checkpoint...
[36m(_train_fn pid=742183)[0m Epoch: 4 cost time: 4.2565834522247314
[36m(_train_fn pid=742183)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5351765 Vali Loss: 1.6553332 Best vali loss: 1.5816860
[36m(_train_fn pid=742183)[0m 	iters: 100, epoch: 5 | loss: 0.4492378
[36m(_train_fn pid=742183)[0m 	speed: 0.0203s/iter; left time: 37.6558s
[36m(_train_fn pid=742183)[0m 	iters: 200, epoch: 5 | loss: 0.4949534
[36m(_train_fn pid=742183)[0m 	speed: 0.0081s/iter; left time: 14.1825s
[36m(_train_fn pid=742183)[0m 	iters: 300, epoch: 5 | loss: 0.4523973
[36m(_train_fn pid=742183)[0m 	speed: 0.0080s/iter; left time: 13.3127s
[36m(_train_fn pid=742183)[0m 	iters: 400, epoch: 5 | loss: 0.6099716
[36m(_train_fn pid=742183)[0m 	speed: 0.0079s/iter; left time: 12.3261s

Trial trial-dcb4d3d5 completed after 5 iterations at 2024-08-24 07:21:50. Total running time: 41s
[36m(_train_fn pid=742183)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcb4d3d5_2_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0901,e_layers=_2024-08-24_07-21-24/checkpoint_000004)
[36m(_train_fn pid=742697)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d7816b5e_3_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0925,e_layers_2024-08-24_07-21-50/checkpoint_000000)
[36m(_train_fn pid=742697)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d7816b5e_3_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0925,e_layers_2024-08-24_07-21-50/checkpoint_000001)
[36m(_train_fn pid=742697)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d7816b5e_3_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0925,e_layers_2024-08-24_07-21-50/checkpoint_000002)
[36m(_train_fn pid=742697)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d7816b5e_3_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0925,e_layers_2024-08-24_07-21-50/checkpoint_000003)
[36m(_train_fn pid=742697)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d7816b5e_3_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0925,e_layers_2024-08-24_07-21-50/checkpoint_000004)
[36m(_train_fn pid=742697)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d7816b5e_3_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0925,e_layers_2024-08-24_07-21-50/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-dcb4d3d5 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          4.44869 â”‚
â”‚ time_total_s                             24.21266 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58169 â”‚
â”‚ train_loss                                0.51023 â”‚
â”‚ valid_loss                                1.62942 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=742183)[0m Updating learning rate to 0.0006651643750231387
[36m(_train_fn pid=742183)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=742183)[0m saving checkpoint...
[36m(_train_fn pid=742183)[0m Epoch: 5 cost time: 3.9652888774871826
[36m(_train_fn pid=742183)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5102343 Vali Loss: 1.6294178 Best vali loss: 1.5816860
[36m(_train_fn pid=742183)[0m Early stopping

Trial trial-d7816b5e started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d7816b5e config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09252 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00126 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=742697)[0m configuration
[36m(_train_fn pid=742697)[0m {'batch_size': 64, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.0925162833765015, 'e_layers': 2, 'learning_rate': 0.001259391180831956, 'd_ff': 384}
[36m(_train_fn pid=742697)[0m Use GPU: cuda:0
[36m(_train_fn pid=742697)[0m train 7825
[36m(_train_fn pid=742697)[0m val 2161
[36m(_train_fn pid=742697)[0m start_epoch 0
[36m(_train_fn pid=742697)[0m max_epoch 8
[36m(_train_fn pid=742697)[0m 	iters: 100, epoch: 1 | loss: 0.8068743
[36m(_train_fn pid=742697)[0m 	speed: 0.0507s/iter; left time: 44.4953s
[36m(_train_fn pid=742697)[0m Updating learning rate to 0.001259391180831956
[36m(_train_fn pid=742697)[0m saving checkpoint...
[36m(_train_fn pid=742697)[0m Validation loss decreased (inf --> 1.9736).  Saving model state dict ...
[36m(_train_fn pid=742697)[0m Epoch: 1 cost time: 5.776549339294434
[36m(_train_fn pid=742697)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8088944 Vali Loss: 1.9736138 Best vali loss: 1.9736138
[36m(_train_fn pid=742697)[0m 	iters: 100, epoch: 2 | loss: 0.6922387
[36m(_train_fn pid=742697)[0m 	speed: 0.0614s/iter; left time: 46.3705s
[36m(_train_fn pid=742697)[0m Updating learning rate to 0.000629695590415978
[36m(_train_fn pid=742697)[0m saving checkpoint...
[36m(_train_fn pid=742697)[0m Validation loss decreased (1.9736 --> 1.5988).  Saving model state dict ...
[36m(_train_fn pid=742697)[0m Epoch: 2 cost time: 5.376462936401367
[36m(_train_fn pid=742697)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6528367 Vali Loss: 1.5988191 Best vali loss: 1.5988191

Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:22:09. Total running time: 1min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: dcb4d3d5 with best_valid_loss=1.5816860035613731 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 16, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'conv', 'dropout': 0.09012666779719704, 'e_layers': 2, 'learning_rate': 0.01064263000037022}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d7816b5e   RUNNING           2            13.0936       0.652837        1.59882             1.59882 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=742697)[0m 	iters: 100, epoch: 3 | loss: 0.6324410
[36m(_train_fn pid=742697)[0m 	speed: 0.0616s/iter; left time: 38.9993s
[36m(_train_fn pid=742697)[0m Updating learning rate to 0.000314847795207989
[36m(_train_fn pid=742697)[0m saving checkpoint...
[36m(_train_fn pid=742697)[0m Validation loss decreased (1.5988 --> 1.5872).  Saving model state dict ...
[36m(_train_fn pid=742697)[0m Epoch: 3 cost time: 5.388181447982788
[36m(_train_fn pid=742697)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6027670 Vali Loss: 1.5872460 Best vali loss: 1.5872460
[36m(_train_fn pid=742697)[0m 	iters: 100, epoch: 4 | loss: 0.5887651
[36m(_train_fn pid=742697)[0m 	speed: 0.0617s/iter; left time: 31.5327s
[36m(_train_fn pid=742697)[0m Updating learning rate to 0.0001574238976039945
[36m(_train_fn pid=742697)[0m saving checkpoint...
[36m(_train_fn pid=742697)[0m Validation loss decreased (1.5872 --> 1.5720).  Saving model state dict ...
[36m(_train_fn pid=742697)[0m Epoch: 4 cost time: 5.396831750869751
[36m(_train_fn pid=742697)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5836542 Vali Loss: 1.5720086 Best vali loss: 1.5720086
[36m(_train_fn pid=742697)[0m 	iters: 100, epoch: 5 | loss: 0.5668857
[36m(_train_fn pid=742697)[0m 	speed: 0.0617s/iter; left time: 24.0024s
[36m(_train_fn pid=742697)[0m Updating learning rate to 7.871194880199725e-05
[36m(_train_fn pid=742697)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=742697)[0m saving checkpoint...
[36m(_train_fn pid=742697)[0m Epoch: 5 cost time: 5.395056486129761
[36m(_train_fn pid=742697)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5760052 Vali Loss: 1.5826508 Best vali loss: 1.5720086
[36m(_train_fn pid=742697)[0m 	iters: 100, epoch: 6 | loss: 0.5453596
[36m(_train_fn pid=742697)[0m 	speed: 0.0617s/iter; left time: 16.4844s
[36m(_train_fn pid=742697)[0m Updating learning rate to 3.935597440099863e-05
[36m(_train_fn pid=742697)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=742697)[0m saving checkpoint...
[36m(_train_fn pid=742697)[0m Epoch: 6 cost time: 5.409642457962036
[36m(_train_fn pid=742697)[0m Epoch: 6, Steps: 122 | Train Loss: 0.5729492 Vali Loss: 1.5800364 Best vali loss: 1.5720086
[36m(_train_fn pid=742697)[0m 	iters: 100, epoch: 7 | loss: 0.5122528[36m(_train_fn pid=742697)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d7816b5e_3_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0925,e_layers_2024-08-24_07-21-50/checkpoint_000006)
2024-08-24 07:22:59,348	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=743411)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0a718da3_4_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1001,e_layers=_2024-08-24_07-22-36/checkpoint_000000)

[36m(_train_fn pid=742697)[0m 	speed: 0.0619s/iter; left time: 8.9803s

Trial trial-d7816b5e completed after 7 iterations at 2024-08-24 07:22:36. Total running time: 1min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d7816b5e result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          6.19465 â”‚
â”‚ time_total_s                              43.9511 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.57201 â”‚
â”‚ train_loss                                0.57075 â”‚
â”‚ valid_loss                                1.58113 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=742697)[0m Updating learning rate to 1.9677987200499314e-05
[36m(_train_fn pid=742697)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=742697)[0m saving checkpoint...
[36m(_train_fn pid=742697)[0m Epoch: 7 cost time: 5.424333572387695
[36m(_train_fn pid=742697)[0m Epoch: 7, Steps: 122 | Train Loss: 0.5707520 Vali Loss: 1.5811286 Best vali loss: 1.5720086
[36m(_train_fn pid=742697)[0m Early stopping

Trial trial-0a718da3 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0a718da3 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10005 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00083 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=743411)[0m configuration
[36m(_train_fn pid=743411)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678, 'd_ff': 1536}
[36m(_train_fn pid=743411)[0m Use GPU: cuda:0
[36m(_train_fn pid=743411)[0m train 7825
[36m(_train_fn pid=743411)[0m val 2161
[36m(_train_fn pid=743411)[0m start_epoch 0
[36m(_train_fn pid=743411)[0m max_epoch 8

Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:22:39. Total running time: 1min 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: d7816b5e with best_valid_loss=1.5720085682290974 and params={'alpha_d_ff': 3, 'batch_size': 64, 'd_model': 128, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'conv', 'dropout': 0.0925162833765015, 'e_layers': 2, 'learning_rate': 0.001259391180831956}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0a718da3   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=743411)[0m 	iters: 100, epoch: 1 | loss: 0.7653094
[36m(_train_fn pid=743411)[0m 	speed: 0.0431s/iter; left time: 164.5154s
[36m(_train_fn pid=743411)[0m 	iters: 200, epoch: 1 | loss: 0.7836717
[36m(_train_fn pid=743411)[0m 	speed: 0.0365s/iter; left time: 135.5206s
[36m(_train_fn pid=743411)[0m 	iters: 300, epoch: 1 | loss: 0.7176012
[36m(_train_fn pid=743411)[0m 	speed: 0.0365s/iter; left time: 131.7585s
[36m(_train_fn pid=743411)[0m 	iters: 400, epoch: 1 | loss: 0.6195208
[36m(_train_fn pid=743411)[0m 	speed: 0.0365s/iter; left time: 128.2785s
[36m(_train_fn pid=743411)[0m Updating learning rate to 0.0008318929334924678
[36m(_train_fn pid=743411)[0m saving checkpoint...
[36m(_train_fn pid=743411)[0m Validation loss decreased (inf --> 1.8140).  Saving model state dict ...
[36m(_train_fn pid=743411)[0m Epoch: 1 cost time: 18.251808643341064
[36m(_train_fn pid=743411)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7663245 Vali Loss: 1.8139947 Best vali loss: 1.8139947
[36m(_train_fn pid=743411)[0m 	iters: 100, epoch: 2 | loss: 0.7420287
[36m(_train_fn pid=743411)[0m 	speed: 0.0919s/iter; left time: 305.3724s
[36m(_train_fn pid=743411)[0m 	iters: 200, epoch: 2 | loss: 0.6287075
[36m(_train_fn pid=743411)[0m 	speed: 0.0366s/iter; left time: 117.9491s
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:23:09. Total running time: 2min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: d7816b5e with best_valid_loss=1.5720085682290974 and params={'alpha_d_ff': 3, 'batch_size': 64, 'd_model': 128, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'conv', 'dropout': 0.0925162833765015, 'e_layers': 2, 'learning_rate': 0.001259391180831956}
2024-08-24 07:23:19,515	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=743411)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0a718da3_4_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1001,e_layers=_2024-08-24_07-22-36/checkpoint_000001)
2024-08-24 07:23:39,693	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=743411)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0a718da3_4_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1001,e_layers=_2024-08-24_07-22-36/checkpoint_000002)
2024-08-24 07:23:59,881	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=743411)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0a718da3_4_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1001,e_layers=_2024-08-24_07-22-36/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0a718da3   RUNNING           1            20.9204       0.766325        1.81399             1.81399 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=743411)[0m 	iters: 300, epoch: 2 | loss: 0.6702660
[36m(_train_fn pid=743411)[0m 	speed: 0.0366s/iter; left time: 114.2362s
[36m(_train_fn pid=743411)[0m 	iters: 400, epoch: 2 | loss: 0.6516390
[36m(_train_fn pid=743411)[0m 	speed: 0.0366s/iter; left time: 110.6324s
[36m(_train_fn pid=743411)[0m Updating learning rate to 0.0004159464667462339
[36m(_train_fn pid=743411)[0m saving checkpoint...
[36m(_train_fn pid=743411)[0m Validation loss decreased (1.8140 --> 1.5668).  Saving model state dict ...
[36m(_train_fn pid=743411)[0m Epoch: 2 cost time: 17.90560483932495
[36m(_train_fn pid=743411)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6557162 Vali Loss: 1.5667738 Best vali loss: 1.5667738
[36m(_train_fn pid=743411)[0m 	iters: 100, epoch: 3 | loss: 0.6505629
[36m(_train_fn pid=743411)[0m 	speed: 0.0920s/iter; left time: 260.8496s
[36m(_train_fn pid=743411)[0m 	iters: 200, epoch: 3 | loss: 0.6716614
[36m(_train_fn pid=743411)[0m 	speed: 0.0366s/iter; left time: 100.0527s
[36m(_train_fn pid=743411)[0m 	iters: 300, epoch: 3 | loss: 0.5851048
[36m(_train_fn pid=743411)[0m 	speed: 0.0366s/iter; left time: 96.4170s
[36m(_train_fn pid=743411)[0m 	iters: 400, epoch: 3 | loss: 0.6623663
[36m(_train_fn pid=743411)[0m 	speed: 0.0366s/iter; left time: 92.7921s
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:23:39. Total running time: 2min 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5667738212479485 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0a718da3   RUNNING           2            41.084        0.655716        1.56677             1.56677 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=743411)[0m Updating learning rate to 0.00020797323337311694
[36m(_train_fn pid=743411)[0m saving checkpoint...
[36m(_train_fn pid=743411)[0m Validation loss decreased (1.5668 --> 1.5640).  Saving model state dict ...
[36m(_train_fn pid=743411)[0m Epoch: 3 cost time: 17.917145490646362
[36m(_train_fn pid=743411)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6107522 Vali Loss: 1.5639688 Best vali loss: 1.5639688
[36m(_train_fn pid=743411)[0m 	iters: 100, epoch: 4 | loss: 0.5738512
[36m(_train_fn pid=743411)[0m 	speed: 0.0920s/iter; left time: 215.9200s
[36m(_train_fn pid=743411)[0m 	iters: 200, epoch: 4 | loss: 0.5783917
[36m(_train_fn pid=743411)[0m 	speed: 0.0366s/iter; left time: 82.2851s
[36m(_train_fn pid=743411)[0m 	iters: 300, epoch: 4 | loss: 0.6890633
[36m(_train_fn pid=743411)[0m 	speed: 0.0367s/iter; left time: 78.6547s
[36m(_train_fn pid=743411)[0m 	iters: 400, epoch: 4 | loss: 0.6363396
[36m(_train_fn pid=743411)[0m 	speed: 0.0367s/iter; left time: 74.9932s
[36m(_train_fn pid=743411)[0m Updating learning rate to 0.00010398661668655847
[36m(_train_fn pid=743411)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=743411)[0m saving checkpoint...
[36m(_train_fn pid=743411)[0m Epoch: 4 cost time: 17.943225860595703
[36m(_train_fn pid=743411)[0m Epoch: 4, Steps: 489 | Train Loss: 0.6050647 Vali Loss: 1.5683316 Best vali loss: 1.5639688
[36m(_train_fn pid=743411)[0m 	iters: 100, epoch: 5 | loss: 0.4995696
[36m(_train_fn pid=743411)[0m 	speed: 0.0919s/iter; left time: 170.7084s
[36m(_train_fn pid=743411)[0m 	iters: 200, epoch: 5 | loss: 0.5962168
[36m(_train_fn pid=743411)[0m 	speed: 0.0367s/iter; left time: 64.4892s
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:24:09. Total running time: 3min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:24:20,078	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=743411)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0a718da3_4_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1001,e_layers=_2024-08-24_07-22-36/checkpoint_000004)
2024-08-24 07:24:24,881	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:24:26,620	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=744158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0b9eea2a_5_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=0._2024-08-24_07-24-20/checkpoint_000001)[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
2024-08-24 07:24:28,456	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:24:30,192	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:24:32,046	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=744158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0b9eea2a_5_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=0._2024-08-24_07-24-20/checkpoint_000004)[32m [repeated 3x across cluster][0m
2024-08-24 07:24:33,776	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:24:35,504	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0a718da3   RUNNING           4            81.4413       0.605065        1.56833             1.56397 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=743411)[0m 	iters: 300, epoch: 5 | loss: 0.5545303
[36m(_train_fn pid=743411)[0m 	speed: 0.0367s/iter; left time: 60.7442s
[36m(_train_fn pid=743411)[0m 	iters: 400, epoch: 5 | loss: 0.4286912
[36m(_train_fn pid=743411)[0m 	speed: 0.0367s/iter; left time: 57.1319s

Trial trial-0a718da3 completed after 5 iterations at 2024-08-24 07:24:20. Total running time: 3min 11s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0a718da3 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         20.19376 â”‚
â”‚ time_total_s                            101.63502 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56397 â”‚
â”‚ train_loss                                0.60047 â”‚
â”‚ valid_loss                                1.56828 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=743411)[0m Updating learning rate to 5.1993308343279236e-05
[36m(_train_fn pid=743411)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=743411)[0m saving checkpoint...

Trial trial-0b9eea2a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0b9eea2a config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07432 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00673 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=744158)[0m configuration
[36m(_train_fn pid=744158)[0m {'batch_size': 64, 'd_model': 16, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'conv', 'dropout': 0.07431613933182805, 'e_layers': 3, 'learning_rate': 0.006730655699341551, 'd_ff': 32}
[36m(_train_fn pid=744158)[0m Use GPU: cuda:0
[36m(_train_fn pid=744158)[0m train 7825
[36m(_train_fn pid=744158)[0m val 2161
[36m(_train_fn pid=744158)[0m start_epoch 0
[36m(_train_fn pid=744158)[0m max_epoch 8
[36m(_train_fn pid=744158)[0m 	iters: 100, epoch: 1 | loss: 0.7553295
[36m(_train_fn pid=744158)[0m 	speed: 0.0181s/iter; left time: 15.8894s
[36m(_train_fn pid=744158)[0m Validation loss decreased (inf --> 1.7696).  Saving model state dict ...
[36m(_train_fn pid=744158)[0m Epoch: 1 cost time: 1.8377375602722168
[36m(_train_fn pid=744158)[0m Epoch: 1, Steps: 122 | Train Loss: 0.9306819 Vali Loss: 1.7696032 Best vali loss: 1.7696032
[36m(_train_fn pid=744158)[0m 	iters: 100, epoch: 2 | loss: 0.5833297
[36m(_train_fn pid=744158)[0m 	speed: 0.0176s/iter; left time: 13.3173s
[36m(_train_fn pid=744158)[0m Updating learning rate to 0.006730655699341551
[36m(_train_fn pid=744158)[0m saving checkpoint...
[36m(_train_fn pid=744158)[0m Updating learning rate to 0.0033653278496707756
[36m(_train_fn pid=744158)[0m saving checkpoint...
[36m(_train_fn pid=744158)[0m Validation loss decreased (1.7696 --> 1.6177).  Saving model state dict ...
[36m(_train_fn pid=744158)[0m Epoch: 2 cost time: 1.503631591796875
[36m(_train_fn pid=744158)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6269444 Vali Loss: 1.6176928 Best vali loss: 1.6176928
[36m(_train_fn pid=744158)[0m 	iters: 100, epoch: 3 | loss: 0.5177286
[36m(_train_fn pid=744158)[0m 	speed: 0.0183s/iter; left time: 11.5645s
[36m(_train_fn pid=744158)[0m Updating learning rate to 0.0016826639248353878
[36m(_train_fn pid=744158)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=744158)[0m saving checkpoint...
[36m(_train_fn pid=744158)[0m Epoch: 3 cost time: 1.6092166900634766
[36m(_train_fn pid=744158)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5714983 Vali Loss: 1.6289515 Best vali loss: 1.6176928
[36m(_train_fn pid=744158)[0m 	iters: 100, epoch: 4 | loss: 0.5590853
[36m(_train_fn pid=744158)[0m 	speed: 0.0175s/iter; left time: 8.9572s
[36m(_train_fn pid=744158)[0m Updating learning rate to 0.0008413319624176939
[36m(_train_fn pid=744158)[0m saving checkpoint...
[36m(_train_fn pid=744158)[0m Validation loss decreased (1.6177 --> 1.6169).  Saving model state dict ...
[36m(_train_fn pid=744158)[0m Epoch: 4 cost time: 1.5057315826416016
[36m(_train_fn pid=744158)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5470215 Vali Loss: 1.6168666 Best vali loss: 1.6168666
[36m(_train_fn pid=744158)[0m 	iters: 100, epoch: 5 | loss: 0.4749153
[36m(_train_fn pid=744158)[0m 	speed: 0.0182s/iter; left time: 7.0988s
[36m(_train_fn pid=744158)[0m Updating learning rate to 0.00042066598120884695
[36m(_train_fn pid=744158)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=744158)[0m saving checkpoint...
[36m(_train_fn pid=744158)[0m Epoch: 5 cost time: 1.625436544418335
[36m(_train_fn pid=744158)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5307177 Vali Loss: 1.6514319 Best vali loss: 1.6168666
[36m(_train_fn pid=744158)[0m 	iters: 100, epoch: 6 | loss: 0.5607295
[36m(_train_fn pid=744158)[0m 	speed: 0.0176s/iter; left time: 4.6972s
[36m(_train_fn pid=744158)[0m Updating learning rate to 0.00021033299060442347
[36m(_train_fn pid=744158)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=744158)[0m saving checkpoint...
[36m(_train_fn pid=744158)[0m Epoch: 6 cost time: 1.4983344078063965
[36m(_train_fn pid=744158)[0m Epoch: 6, Steps: 122 | Train Loss: 0.5188915 Vali Loss: 1.7012085 Best vali loss: 1.6168666
[36m(_train_fn pid=744158)[0m 	iters: 100, epoch: 7 | loss: 0.4749423
[36m(_train_fn pid=744158)[0m 	speed: 0.0173s/iter; left time: 2.5060s

Trial trial-0b9eea2a completed after 7 iterations at 2024-08-24 07:24:35. Total running time: 3min 26s
[36m(_train_fn pid=744781)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9492fa28_6_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0.0_2024-08-24_07-24-35/checkpoint_000000)[32m [repeated 3x across cluster][0m
2024-08-24 07:24:47,418	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:24:52,127	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=744781)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9492fa28_6_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0.0_2024-08-24_07-24-35/checkpoint_000002)[32m [repeated 2x across cluster][0m
2024-08-24 07:24:56,840	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0b9eea2a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                           1.7257 â”‚
â”‚ time_total_s                             13.08842 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.61687 â”‚
â”‚ train_loss                                0.51245 â”‚
â”‚ valid_loss                                  1.683 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=744158)[0m Updating learning rate to 0.00010516649530221174
[36m(_train_fn pid=744158)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=744158)[0m saving checkpoint...
[36m(_train_fn pid=744158)[0m Epoch: 7 cost time: 1.500880479812622
[36m(_train_fn pid=744158)[0m Epoch: 7, Steps: 122 | Train Loss: 0.5124514 Vali Loss: 1.6830034 Best vali loss: 1.6168666
[36m(_train_fn pid=744158)[0m Early stopping

Trial trial-9492fa28 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-9492fa28 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.07684 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00117 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=744781)[0m configuration
[36m(_train_fn pid=744781)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'avg', 'dropout': 0.07683623441236416, 'e_layers': 3, 'learning_rate': 0.0011650014804827074, 'd_ff': 192}
[36m(_train_fn pid=744781)[0m Use GPU: cuda:0
[36m(_train_fn pid=744781)[0m train 7825
[36m(_train_fn pid=744781)[0m val 2161
[36m(_train_fn pid=744781)[0m start_epoch 0
[36m(_train_fn pid=744781)[0m max_epoch 8

Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:24:39. Total running time: 3min 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-9492fa28   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=744781)[0m 	iters: 100, epoch: 1 | loss: 0.7745021
[36m(_train_fn pid=744781)[0m 	speed: 0.0219s/iter; left time: 40.6199s
[36m(_train_fn pid=744781)[0m 	iters: 200, epoch: 1 | loss: 0.8130726
[36m(_train_fn pid=744781)[0m 	speed: 0.0168s/iter; left time: 29.3864s
[36m(_train_fn pid=744781)[0m Updating learning rate to 0.0011650014804827074
[36m(_train_fn pid=744781)[0m saving checkpoint...
[36m(_train_fn pid=744781)[0m Validation loss decreased (inf --> 1.8907).  Saving model state dict ...
[36m(_train_fn pid=744781)[0m Epoch: 1 cost time: 4.3513875007629395
[36m(_train_fn pid=744781)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7887082 Vali Loss: 1.8906648 Best vali loss: 1.8906648
[36m(_train_fn pid=744781)[0m 	iters: 100, epoch: 2 | loss: 0.6543424
[36m(_train_fn pid=744781)[0m 	speed: 0.0303s/iter; left time: 48.7962s
[36m(_train_fn pid=744781)[0m 	iters: 200, epoch: 2 | loss: 0.5639811
[36m(_train_fn pid=744781)[0m 	speed: 0.0169s/iter; left time: 25.5492s
[36m(_train_fn pid=744781)[0m Updating learning rate to 0.0005825007402413537
[36m(_train_fn pid=744781)[0m saving checkpoint...
[36m(_train_fn pid=744781)[0m Validation loss decreased (1.8907 --> 1.5998).  Saving model state dict ...
[36m(_train_fn pid=744781)[0m Epoch: 2 cost time: 4.16146993637085
[36m(_train_fn pid=744781)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6242131 Vali Loss: 1.5998436 Best vali loss: 1.5998436
[36m(_train_fn pid=744781)[0m 	iters: 100, epoch: 3 | loss: 0.5603232
[36m(_train_fn pid=744781)[0m 	speed: 0.0302s/iter; left time: 41.2858s
[36m(_train_fn pid=744781)[0m 	iters: 200, epoch: 3 | loss: 0.6004304
[36m(_train_fn pid=744781)[0m 	speed: 0.0169s/iter; left time: 21.3687s
[36m(_train_fn pid=744781)[0m Updating learning rate to 0.00029125037012067684
[36m(_train_fn pid=744781)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=744781)[0m saving checkpoint...
[36m(_train_fn pid=744781)[0m Epoch: 3 cost time: 4.163570880889893
[36m(_train_fn pid=744781)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5865156 Vali Loss: 1.6035854 Best vali loss: 1.5998436
[36m(_train_fn pid=744781)[0m 	iters: 100, epoch: 4 | loss: 0.5038334
[36m(_train_fn pid=744781)[0m 	speed: 0.0300s/iter; left time: 33.6845s
[36m(_train_fn pid=744781)[0m 	iters: 200, epoch: 4 | loss: 0.5535214
[36m(_train_fn pid=744781)[0m 	speed: 0.0168s/iter; left time: 17.1791s
[36m(_train_fn pid=744781)[0m Updating learning rate to 0.00014562518506033842
[36m(_train_fn pid=744781)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=744781)[0m saving checkpoint...
[36m(_train_fn pid=744781)[0m Epoch: 4 cost time: 4.144836902618408
[36m(_train_fn pid=744781)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5684535 Vali Loss: 1.6092827 Best vali loss: 1.5998436
[36m(_train_fn pid=744781)[0m 	iters: 100, epoch: 5 | loss: 0.5305243
[36m(_train_fn pid=744781)[0m 	speed: 0.0304s/iter; left time: 26.6565s
[36m(_train_fn pid=744781)[0m 	iters: 200, epoch: 5 | loss: 0.6086575
[36m(_train_fn pid=744781)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9492fa28_6_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0.0_2024-08-24_07-24-35/checkpoint_000004)[32m [repeated 2x across cluster][0m
2024-08-24 07:25:01,543	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:05,541	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:06,834	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=745295)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2284a318_7_alpha_d_ff=4,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0754,e_layers_2024-08-24_07-25-01/checkpoint_000001)[32m [repeated 2x across cluster][0m
2024-08-24 07:25:08,122	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:09,413	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:10,698	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:11,992	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=745295)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2284a318_7_alpha_d_ff=4,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0754,e_layers_2024-08-24_07-25-01/checkpoint_000005)[32m [repeated 4x across cluster][0m
2024-08-24 07:25:13,280	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=744781)[0m 	speed: 0.0169s/iter; left time: 13.0930s
[36m(_train_fn pid=744781)[0m Updating learning rate to 7.281259253016921e-05
[36m(_train_fn pid=744781)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=744781)[0m saving checkpoint...

Trial trial-9492fa28 completed after 5 iterations at 2024-08-24 07:25:01. Total running time: 3min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-9492fa28 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          4.70153 â”‚
â”‚ time_total_s                             24.13603 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59984 â”‚
â”‚ train_loss                                0.55914 â”‚
â”‚ valid_loss                                  1.631 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=744781)[0m Epoch: 5 cost time: 4.151739597320557
[36m(_train_fn pid=744781)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5591384 Vali Loss: 1.6310034 Best vali loss: 1.5998436
[36m(_train_fn pid=744781)[0m Early stopping

Trial trial-2284a318 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2284a318 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07536 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00251 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=745295)[0m configuration
[36m(_train_fn pid=745295)[0m {'batch_size': 128, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.0753590163357007, 'e_layers': 2, 'learning_rate': 0.002511404254926715, 'd_ff': 64}
[36m(_train_fn pid=745295)[0m Use GPU: cuda:0
[36m(_train_fn pid=745295)[0m train 7825
[36m(_train_fn pid=745295)[0m val 2161
[36m(_train_fn pid=745295)[0m start_epoch 0
[36m(_train_fn pid=745295)[0m max_epoch 8
[36m(_train_fn pid=745295)[0m Validation loss decreased (inf --> 2.3546).  Saving model state dict ...
[36m(_train_fn pid=745295)[0m Validation loss decreased (2.3546 --> 1.6470).  Saving model state dict ...
[36m(_train_fn pid=745295)[0m Updating learning rate to 0.0012557021274633574[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=745295)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=745295)[0m Epoch: 2 cost time: 1.059654712677002[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=745295)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7711761 Vali Loss: 1.6469756 Best vali loss: 1.6469756[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=745295)[0m Validation loss decreased (1.6470 --> 1.6067).  Saving model state dict ...

Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:25:09. Total running time: 4min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2284a318   RUNNING           3            4.70794       0.626836        1.60671             1.60671 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=745295)[0m Validation loss decreased (1.6067 --> 1.6006).  Saving model state dict ...
[36m(_train_fn pid=745295)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=745295)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=745295)[0m Updating learning rate to 7.848138296645984e-05[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=745295)[0m saving checkpoint...[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=745295)[0m Epoch: 6 cost time: 1.0655431747436523[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=745295)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6080973 Vali Loss: 1.6038997 Best vali loss: 1.6005778[32m [repeated 4x across cluster][0m

Trial trial-2284a318 completed after 7 iterations at 2024-08-24 07:25:13. Total running time: 4min 4s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2284a318 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          1.28516 â”‚
â”‚ time_total_s                              9.85526 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.60058 â”‚
â”‚ train_loss                                 0.6075 â”‚
â”‚ valid_loss                                1.60426 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=745295)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=745295)[0m Early stopping

Trial trial-11c7eacb started with configuration:
[36m(_train_fn pid=745912)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-11c7eacb_8_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.08_2024-08-24_07-25-13/checkpoint_000000)[32m [repeated 2x across cluster][0m
2024-08-24 07:25:17,705	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:19,309	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:21,000	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:22,614	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:24,226	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=745912)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-11c7eacb_8_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.08_2024-08-24_07-25-13/checkpoint_000004)[32m [repeated 4x across cluster][0m
2024-08-24 07:25:25,822	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:25:27,429	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-11c7eacb config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.08181 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.01005 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=745912)[0m configuration
[36m(_train_fn pid=745912)[0m {'batch_size': 64, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.08180975226279208, 'e_layers': 3, 'learning_rate': 0.010052790919426012, 'd_ff': 32}
[36m(_train_fn pid=745912)[0m Use GPU: cuda:0
[36m(_train_fn pid=745912)[0m train 7825
[36m(_train_fn pid=745912)[0m val 2161
[36m(_train_fn pid=745912)[0m start_epoch 0
[36m(_train_fn pid=745912)[0m max_epoch 8
[36m(_train_fn pid=745912)[0m 	iters: 100, epoch: 1 | loss: 0.7190234
[36m(_train_fn pid=745912)[0m 	speed: 0.0170s/iter; left time: 14.9405s
[36m(_train_fn pid=745295)[0m Updating learning rate to 3.924069148322992e-05
[36m(_train_fn pid=745295)[0m saving checkpoint...
[36m(_train_fn pid=745295)[0m Epoch: 7 cost time: 1.0572550296783447
[36m(_train_fn pid=745295)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6074960 Vali Loss: 1.6042644 Best vali loss: 1.6005778
[36m(_train_fn pid=745912)[0m Updating learning rate to 0.010052790919426012
[36m(_train_fn pid=745912)[0m saving checkpoint...
[36m(_train_fn pid=745912)[0m Validation loss decreased (inf --> 1.8069).  Saving model state dict ...
[36m(_train_fn pid=745912)[0m Epoch: 1 cost time: 1.6993751525878906
[36m(_train_fn pid=745912)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8775735 Vali Loss: 1.8069457 Best vali loss: 1.8069457
[36m(_train_fn pid=745912)[0m 	iters: 100, epoch: 2 | loss: 0.5489573
[36m(_train_fn pid=745912)[0m 	speed: 0.0162s/iter; left time: 12.2028s
[36m(_train_fn pid=745912)[0m Updating learning rate to 0.005026395459713006
[36m(_train_fn pid=745912)[0m saving checkpoint...
[36m(_train_fn pid=745912)[0m Validation loss decreased (1.8069 --> 1.6216).  Saving model state dict ...
[36m(_train_fn pid=745912)[0m Epoch: 2 cost time: 1.3914542198181152
[36m(_train_fn pid=745912)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6304399 Vali Loss: 1.6216114 Best vali loss: 1.6216114
[36m(_train_fn pid=745912)[0m 	iters: 100, epoch: 3 | loss: 0.5968919
[36m(_train_fn pid=745912)[0m 	speed: 0.0169s/iter; left time: 10.6667s
[36m(_train_fn pid=745912)[0m Updating learning rate to 0.002513197729856503
[36m(_train_fn pid=745912)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=745912)[0m saving checkpoint...
[36m(_train_fn pid=745912)[0m Epoch: 3 cost time: 1.4898583889007568
[36m(_train_fn pid=745912)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5756444 Vali Loss: 1.6628245 Best vali loss: 1.6216114
[36m(_train_fn pid=745912)[0m 	iters: 100, epoch: 4 | loss: 0.5428523
[36m(_train_fn pid=745912)[0m 	speed: 0.0162s/iter; left time: 8.2763s
[36m(_train_fn pid=745912)[0m Updating learning rate to 0.0012565988649282515
[36m(_train_fn pid=745912)[0m saving checkpoint...
[36m(_train_fn pid=745912)[0m Validation loss decreased (1.6216 --> 1.6041).  Saving model state dict ...
[36m(_train_fn pid=745912)[0m Epoch: 4 cost time: 1.404524564743042
[36m(_train_fn pid=745912)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5546452 Vali Loss: 1.6041210 Best vali loss: 1.6041210
[36m(_train_fn pid=745912)[0m 	iters: 100, epoch: 5 | loss: 0.5969015
[36m(_train_fn pid=745912)[0m 	speed: 0.0161s/iter; left time: 6.2593s
[36m(_train_fn pid=745912)[0m Updating learning rate to 0.0006282994324641257
[36m(_train_fn pid=745912)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=745912)[0m saving checkpoint...
[36m(_train_fn pid=745912)[0m Epoch: 5 cost time: 1.3946428298950195
[36m(_train_fn pid=745912)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5375019 Vali Loss: 1.6184405 Best vali loss: 1.6041210
[36m(_train_fn pid=745912)[0m 	iters: 100, epoch: 6 | loss: 0.5070823
[36m(_train_fn pid=745912)[0m 	speed: 0.0160s/iter; left time: 4.2846s
[36m(_train_fn pid=745912)[0m Updating learning rate to 0.00031414971623206287
[36m(_train_fn pid=745912)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=745912)[0m saving checkpoint...
[36m(_train_fn pid=745912)[0m Epoch: 6 cost time: 1.3898670673370361
[36m(_train_fn pid=745912)[0m Epoch: 6, Steps: 122 | Train Loss: 0.5251698 Vali Loss: 1.6103546 Best vali loss: 1.6041210
[36m(_train_fn pid=745912)[0m 	iters: 100, epoch: 7 | loss: 0.4753174
[36m(_train_fn pid=745912)[0m 	speed: 0.0161s/iter; left time: 2.3362s

Trial trial-11c7eacb completed after 7 iterations at 2024-08-24 07:25:27. Total running time: 4min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-11c7eacb result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          1.60402 â”‚
â”‚ time_total_s                              12.0173 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.60412 â”‚
â”‚ train_loss                                0.51809 â”‚
â”‚ valid_loss                                1.61431 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=745912)[0m Updating learning rate to 0.00015707485811603143
[36m(_train_fn pid=745912)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=745912)[0m saving checkpoint...
[36m(_train_fn pid=745912)[0m Epoch: 7 cost time: 1.4048514366149902
[36m(_train_fn pid=745912)[0m Epoch: 7, Steps: 122 | Train Loss: 0.5180901 Vali Loss: 1.6143123 Best vali loss: 1.6041210
[36m(_train_fn pid=745912)[0m Early stopping

Trial trial-8ab49a95 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8ab49a95 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.05999 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00607 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=746533)[0m configuration
[36m(_train_fn pid=746533)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'conv', 'dropout': 0.05999454279983519, 'e_layers': 1, 'learning_rate': 0.006070584790668805, 'd_ff': 2048}
[36m(_train_fn pid=746533)[0m Use GPU: cuda:0
[36m(_train_fn pid=746533)[0m train 7825
[36m(_train_fn pid=746533)[0m val 2161
[36m(_train_fn pid=746533)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8ab49a95_9_alpha_d_ff=4,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=0_2024-08-24_07-25-27/checkpoint_000000)[32m [repeated 3x across cluster][0m
2024-08-24 07:26:15,535	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=746533)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8ab49a95_9_alpha_d_ff=4,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=0_2024-08-24_07-25-27/checkpoint_000001)
2024-08-24 07:26:38,317	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=746533)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8ab49a95_9_alpha_d_ff=4,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=0_2024-08-24_07-25-27/checkpoint_000002)
[36m(_train_fn pid=746533)[0m start_epoch 0
[36m(_train_fn pid=746533)[0m max_epoch 8
[36m(_train_fn pid=746533)[0m 	iters: 100, epoch: 1 | loss: 0.6574458
[36m(_train_fn pid=746533)[0m 	speed: 0.0463s/iter; left time: 176.4476s
[36m(_train_fn pid=746533)[0m 	iters: 200, epoch: 1 | loss: 0.8162857
[36m(_train_fn pid=746533)[0m 	speed: 0.0414s/iter; left time: 153.5659s

Trial status: 8 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:25:39. Total running time: 4min 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8ab49a95   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=746533)[0m 	iters: 300, epoch: 1 | loss: 0.8248365
[36m(_train_fn pid=746533)[0m 	speed: 0.0414s/iter; left time: 149.6153s
[36m(_train_fn pid=746533)[0m 	iters: 400, epoch: 1 | loss: 0.5791259
[36m(_train_fn pid=746533)[0m 	speed: 0.0415s/iter; left time: 145.7372s
[36m(_train_fn pid=746533)[0m Updating learning rate to 0.006070584790668805
[36m(_train_fn pid=746533)[0m saving checkpoint...
[36m(_train_fn pid=746533)[0m Validation loss decreased (inf --> 1.6205).  Saving model state dict ...
[36m(_train_fn pid=746533)[0m Epoch: 1 cost time: 20.496407985687256
[36m(_train_fn pid=746533)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7004874 Vali Loss: 1.6204935 Best vali loss: 1.6204935
[36m(_train_fn pid=746533)[0m 	iters: 100, epoch: 2 | loss: 9.3941574
[36m(_train_fn pid=746533)[0m 	speed: 0.1031s/iter; left time: 342.6819s
[36m(_train_fn pid=746533)[0m 	iters: 200, epoch: 2 | loss: 0.9094359
[36m(_train_fn pid=746533)[0m 	speed: 0.0416s/iter; left time: 134.0428s
[36m(_train_fn pid=746533)[0m 	iters: 300, epoch: 2 | loss: 0.8898506
[36m(_train_fn pid=746533)[0m 	speed: 0.0416s/iter; left time: 129.8778s
Trial status: 8 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:26:09. Total running time: 5min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8ab49a95   RUNNING           1           23.3556        0.700487        1.62049             1.62049 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=746533)[0m 	iters: 400, epoch: 2 | loss: 0.9243503
[36m(_train_fn pid=746533)[0m 	speed: 0.0415s/iter; left time: 125.5406s
[36m(_train_fn pid=746533)[0m Updating learning rate to 0.0030352923953344026
[36m(_train_fn pid=746533)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=746533)[0m saving checkpoint...
[36m(_train_fn pid=746533)[0m Epoch: 2 cost time: 20.347050189971924
[36m(_train_fn pid=746533)[0m Epoch: 2, Steps: 489 | Train Loss: 564.2539889 Vali Loss: 2.0293585 Best vali loss: 1.6204935
[36m(_train_fn pid=746533)[0m 	iters: 100, epoch: 3 | loss: 0.8156117
[36m(_train_fn pid=746533)[0m 	speed: 0.1028s/iter; left time: 291.5259s
[36m(_train_fn pid=746533)[0m 	iters: 200, epoch: 3 | loss: 0.8159094
[36m(_train_fn pid=746533)[0m 	speed: 0.0416s/iter; left time: 113.8925s
[36m(_train_fn pid=746533)[0m 	iters: 300, epoch: 3 | loss: 0.7266867
[36m(_train_fn pid=746533)[0m 	speed: 0.0416s/iter; left time: 109.6057s
[36m(_train_fn pid=746533)[0m 	iters: 400, epoch: 3 | loss: 0.7672297
[36m(_train_fn pid=746533)[0m 	speed: 0.0417s/iter; left time: 105.6302s
[36m(_train_fn pid=746533)[0m Updating learning rate to 0.0015176461976672013
[36m(_train_fn pid=746533)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=746533)[0m saving checkpoint...
[36m(_train_fn pid=746533)[0m Epoch: 3 cost time: 20.376668214797974
2024-08-24 07:27:01,108	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=746533)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8ab49a95_9_alpha_d_ff=4,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=0_2024-08-24_07-25-27/checkpoint_000003)
[36m(_train_fn pid=747179)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-49dc9ea1_10_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_07-27-01/checkpoint_000000)
[36m(_train_fn pid=746533)[0m Epoch: 3, Steps: 489 | Train Loss: 0.8002571 Vali Loss: 1.9873587 Best vali loss: 1.6204935
Trial status: 8 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:26:39. Total running time: 5min 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8ab49a95   RUNNING           3           68.8796        0.800257        1.98736             1.62049 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=746533)[0m 	iters: 100, epoch: 4 | loss: 0.8405523
[36m(_train_fn pid=746533)[0m 	speed: 0.1029s/iter; left time: 241.4997s
[36m(_train_fn pid=746533)[0m 	iters: 200, epoch: 4 | loss: 0.7043700
[36m(_train_fn pid=746533)[0m 	speed: 0.0417s/iter; left time: 93.5720s
[36m(_train_fn pid=746533)[0m 	iters: 300, epoch: 4 | loss: 0.7678339
[36m(_train_fn pid=746533)[0m 	speed: 0.0417s/iter; left time: 89.4304s
[36m(_train_fn pid=746533)[0m 	iters: 400, epoch: 4 | loss: 0.7653902
[36m(_train_fn pid=746533)[0m 	speed: 0.0417s/iter; left time: 85.2523s

Trial trial-8ab49a95 completed after 4 iterations at 2024-08-24 07:27:01. Total running time: 5min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8ab49a95 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         22.78902 â”‚
â”‚ time_total_s                             91.66864 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.62049 â”‚
â”‚ train_loss                                 0.7854 â”‚
â”‚ valid_loss                                1.97416 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=746533)[0m Updating learning rate to 0.0007588230988336006
[36m(_train_fn pid=746533)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=746533)[0m saving checkpoint...
[36m(_train_fn pid=746533)[0m Epoch: 4 cost time: 20.3881733417511
[36m(_train_fn pid=746533)[0m Epoch: 4, Steps: 489 | Train Loss: 0.7853986 Vali Loss: 1.9741560 Best vali loss: 1.6204935
[36m(_train_fn pid=746533)[0m Early stopping

Trial trial-49dc9ea1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-49dc9ea1 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.11885 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00322 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=747179)[0m configuration
[36m(_train_fn pid=747179)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'conv', 'dropout': 0.11884684425154694, 'e_layers': 4, 'learning_rate': 0.0032240924334661727, 'd_ff': 256}
[36m(_train_fn pid=747179)[0m Use GPU: cuda:0
[36m(_train_fn pid=747179)[0m train 7825
[36m(_train_fn pid=747179)[0m val 2161
[36m(_train_fn pid=747179)[0m start_epoch 0
[36m(_train_fn pid=747179)[0m max_epoch 8
[36m(_train_fn pid=747179)[0m Updating learning rate to 0.0032240924334661727
[36m(_train_fn pid=747179)[0m saving checkpoint...
[36m(_train_fn pid=747179)[0m Validation loss decreased (inf --> 1.9979).  Saving model state dict ...
[36m(_train_fn pid=747179)[0m Epoch: 1 cost time: 4.40998387336731
[36m(_train_fn pid=747179)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8164308 Vali Loss: 1.9979229 Best vali loss: 1.9979229

Trial status: 9 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:27:09. Total running time: 6min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:27:13,546	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=747179)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-49dc9ea1_10_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_07-27-01/checkpoint_000001)
2024-08-24 07:27:18,310	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=747179)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-49dc9ea1_10_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_07-27-01/checkpoint_000002)
2024-08-24 07:27:23,065	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=747179)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-49dc9ea1_10_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_07-27-01/checkpoint_000003)
2024-08-24 07:27:27,824	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=747179)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-49dc9ea1_10_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_07-27-01/checkpoint_000004)
2024-08-24 07:27:39,397	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=747693)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1954e8ad_11_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0862,e_layer_2024-08-24_07-27-27/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-49dc9ea1   RUNNING           1            5.3747        0.816431        1.99792             1.99792 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=747179)[0m Updating learning rate to 0.0016120462167330863
[36m(_train_fn pid=747179)[0m saving checkpoint...
[36m(_train_fn pid=747179)[0m Validation loss decreased (1.9979 --> 1.6140).  Saving model state dict ...
[36m(_train_fn pid=747179)[0m Epoch: 2 cost time: 4.200818061828613
[36m(_train_fn pid=747179)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6618462 Vali Loss: 1.6139826 Best vali loss: 1.6139826
[36m(_train_fn pid=747179)[0m Updating learning rate to 0.0008060231083665432
[36m(_train_fn pid=747179)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=747179)[0m saving checkpoint...
[36m(_train_fn pid=747179)[0m Epoch: 3 cost time: 4.19948148727417
[36m(_train_fn pid=747179)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6088089 Vali Loss: 1.6168833 Best vali loss: 1.6139826
[36m(_train_fn pid=747179)[0m Updating learning rate to 0.0004030115541832716
[36m(_train_fn pid=747179)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=747179)[0m saving checkpoint...
[36m(_train_fn pid=747179)[0m Epoch: 4 cost time: 4.200209379196167
[36m(_train_fn pid=747179)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5858278 Vali Loss: 1.6708928 Best vali loss: 1.6139826

Trial trial-49dc9ea1 completed after 5 iterations at 2024-08-24 07:27:27. Total running time: 6min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-49dc9ea1 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          4.75632 â”‚
â”‚ time_total_s                             24.40901 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.61398 â”‚
â”‚ train_loss                                0.56748 â”‚
â”‚ valid_loss                                1.70109 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=747179)[0m Updating learning rate to 0.0002015057770916358
[36m(_train_fn pid=747179)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=747179)[0m saving checkpoint...
[36m(_train_fn pid=747179)[0m Epoch: 5 cost time: 4.2000086307525635
[36m(_train_fn pid=747179)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5674817 Vali Loss: 1.7010943 Best vali loss: 1.6139826
[36m(_train_fn pid=747179)[0m Early stopping

Trial trial-1954e8ad started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1954e8ad config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.08619 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00322 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=747693)[0m configuration
[36m(_train_fn pid=747693)[0m {'batch_size': 32, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.08618920581912012, 'e_layers': 3, 'learning_rate': 0.0032161332521737297, 'd_ff': 512}
[36m(_train_fn pid=747693)[0m Use GPU: cuda:0
[36m(_train_fn pid=747693)[0m train 7825
[36m(_train_fn pid=747693)[0m val 2161
[36m(_train_fn pid=747693)[0m start_epoch 0
[36m(_train_fn pid=747693)[0m max_epoch 8
[36m(_train_fn pid=747693)[0m 	iters: 100, epoch: 1 | loss: 0.8568867
[36m(_train_fn pid=747693)[0m 	speed: 0.0399s/iter; left time: 73.9316s
[36m(_train_fn pid=747693)[0m 	iters: 200, epoch: 1 | loss: 0.7256024
[36m(_train_fn pid=747693)[0m 	speed: 0.0328s/iter; left time: 57.5218s
[36m(_train_fn pid=747693)[0m Updating learning rate to 0.0032161332521737297
[36m(_train_fn pid=747693)[0m saving checkpoint...
[36m(_train_fn pid=747693)[0m Validation loss decreased (inf --> 1.7180).  Saving model state dict ...
[36m(_train_fn pid=747693)[0m Epoch: 1 cost time: 8.455277442932129
[36m(_train_fn pid=747693)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7740099 Vali Loss: 1.7179554 Best vali loss: 1.7179554

Trial status: 10 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:27:39. Total running time: 6min 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=747693)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1954e8ad_11_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0862,e_layer_2024-08-24_07-27-27/checkpoint_000001)
[36m(_train_fn pid=747693)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1954e8ad_11_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0862,e_layer_2024-08-24_07-27-27/checkpoint_000002)
[36m(_train_fn pid=747693)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1954e8ad_11_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0862,e_layer_2024-08-24_07-27-27/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1954e8ad   RUNNING           1            9.98595       0.77401         1.71796             1.71796 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=747693)[0m 	iters: 100, epoch: 2 | loss: 0.6029040
[36m(_train_fn pid=747693)[0m 	speed: 0.0588s/iter; left time: 94.6603s
[36m(_train_fn pid=747693)[0m 	iters: 200, epoch: 2 | loss: 0.5510952
[36m(_train_fn pid=747693)[0m 	speed: 0.0328s/iter; left time: 49.5267s
[36m(_train_fn pid=747693)[0m Updating learning rate to 0.0016080666260868649
[36m(_train_fn pid=747693)[0m saving checkpoint...
[36m(_train_fn pid=747693)[0m Validation loss decreased (1.7180 --> 1.6207).  Saving model state dict ...
[36m(_train_fn pid=747693)[0m Epoch: 2 cost time: 8.04274606704712
[36m(_train_fn pid=747693)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6211448 Vali Loss: 1.6207105 Best vali loss: 1.6207105
[36m(_train_fn pid=747693)[0m 	iters: 100, epoch: 3 | loss: 0.7097486
[36m(_train_fn pid=747693)[0m 	speed: 0.0588s/iter; left time: 80.2355s
[36m(_train_fn pid=747693)[0m 	iters: 200, epoch: 3 | loss: 0.5372967
[36m(_train_fn pid=747693)[0m 	speed: 0.0328s/iter; left time: 41.5470s
[36m(_train_fn pid=747693)[0m Updating learning rate to 0.0008040333130434324
[36m(_train_fn pid=747693)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=747693)[0m saving checkpoint...
[36m(_train_fn pid=747693)[0m Epoch: 3 cost time: 8.040720462799072
[36m(_train_fn pid=747693)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5678595 Vali Loss: 1.6362103 Best vali loss: 1.6207105
[36m(_train_fn pid=747693)[0m 	iters: 100, epoch: 4 | loss: 0.5184531
[36m(_train_fn pid=747693)[0m 	speed: 0.0587s/iter; left time: 65.7907s
[36m(_train_fn pid=747693)[0m 	iters: 200, epoch: 4 | loss: 0.5643167
[36m(_train_fn pid=747693)[0m 	speed: 0.0328s/iter; left time: 33.5396s
[36m(_train_fn pid=747693)[0m Updating learning rate to 0.0004020166565217162
[36m(_train_fn pid=747693)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=747693)[0m saving checkpoint...
[36m(_train_fn pid=747693)[0m Epoch: 4 cost time: 8.042370319366455
[36m(_train_fn pid=747693)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5300301 Vali Loss: 1.6474037 Best vali loss: 1.6207105
Trial status: 10 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:28:09. Total running time: 7min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1954e8ad   RUNNING           4           37.4462        0.53003         1.6474              1.62071 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=747693)[0m 	iters: 100, epoch: 5 | loss: 0.5266601
[36m(_train_fn pid=747693)[0m 	speed: 0.0587s/iter; left time: 51.4361s
[36m(_train_fn pid=747693)[0m 	iters: 200, epoch: 5 | loss: 0.5108954
[36m(_train_fn pid=747693)[0m 	speed: 0.0328s/iter; left time: 25.4900s

Trial trial-1954e8ad completed after 5 iterations at 2024-08-24 07:28:16. Total running time: 7min 7s
[36m(_train_fn pid=747693)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1954e8ad_11_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0862,e_layer_2024-08-24_07-27-27/checkpoint_000004)
2024-08-24 07:28:26,364	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=748271)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-743b5daa_12_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-28-16/checkpoint_000000)
[36m(_train_fn pid=748271)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-743b5daa_12_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-28-16/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1954e8ad result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          9.14676 â”‚
â”‚ time_total_s                             46.59298 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.62071 â”‚
â”‚ train_loss                                0.50278 â”‚
â”‚ valid_loss                                1.63017 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=747693)[0m Updating learning rate to 0.0002010083282608581
[36m(_train_fn pid=747693)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=747693)[0m saving checkpoint...
[36m(_train_fn pid=747693)[0m Epoch: 5 cost time: 8.039398193359375
[36m(_train_fn pid=747693)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5027806 Vali Loss: 1.6301707 Best vali loss: 1.6207105
[36m(_train_fn pid=747693)[0m Early stopping

Trial trial-743b5daa started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-743b5daa config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.06854 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00202 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=748271)[0m configuration
[36m(_train_fn pid=748271)[0m {'batch_size': 16, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.0685366286539392, 'e_layers': 4, 'learning_rate': 0.002023064828980055, 'd_ff': 128}
[36m(_train_fn pid=748271)[0m Use GPU: cuda:0
[36m(_train_fn pid=748271)[0m train 7825
[36m(_train_fn pid=748271)[0m val 2161
[36m(_train_fn pid=748271)[0m start_epoch 0
[36m(_train_fn pid=748271)[0m max_epoch 8
[36m(_train_fn pid=748271)[0m 	iters: 100, epoch: 1 | loss: 0.8089256
[36m(_train_fn pid=748271)[0m 	speed: 0.0186s/iter; left time: 70.8541s
[36m(_train_fn pid=748271)[0m 	iters: 200, epoch: 1 | loss: 0.6579682
[36m(_train_fn pid=748271)[0m 	speed: 0.0136s/iter; left time: 50.4668s
[36m(_train_fn pid=748271)[0m 	iters: 300, epoch: 1 | loss: 0.6460844
[36m(_train_fn pid=748271)[0m 	speed: 0.0136s/iter; left time: 49.0448s
[36m(_train_fn pid=748271)[0m 	iters: 400, epoch: 1 | loss: 0.7087456
[36m(_train_fn pid=748271)[0m 	speed: 0.0136s/iter; left time: 47.7964s
[36m(_train_fn pid=748271)[0m Updating learning rate to 0.002023064828980055
[36m(_train_fn pid=748271)[0m saving checkpoint...
[36m(_train_fn pid=748271)[0m Validation loss decreased (inf --> 1.6641).  Saving model state dict ...
[36m(_train_fn pid=748271)[0m Epoch: 1 cost time: 6.890870094299316
[36m(_train_fn pid=748271)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7588825 Vali Loss: 1.6641127 Best vali loss: 1.6641127
[36m(_train_fn pid=748271)[0m 	iters: 100, epoch: 2 | loss: 0.7059402
[36m(_train_fn pid=748271)[0m 	speed: 0.0315s/iter; left time: 104.5901s
[36m(_train_fn pid=748271)[0m 	iters: 200, epoch: 2 | loss: 0.6710276
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 40.1666s
[36m(_train_fn pid=748271)[0m 	iters: 300, epoch: 2 | loss: 0.7160560
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 39.1397s
[36m(_train_fn pid=748271)[0m 	iters: 400, epoch: 2 | loss: 0.5035222
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 37.7834s
[36m(_train_fn pid=748271)[0m Updating learning rate to 0.0010115324144900275
[36m(_train_fn pid=748271)[0m saving checkpoint...
[36m(_train_fn pid=748271)[0m Validation loss decreased (1.6641 --> 1.6018).  Saving model state dict ...
[36m(_train_fn pid=748271)[0m Epoch: 2 cost time: 6.15148663520813
[36m(_train_fn pid=748271)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6074566 Vali Loss: 1.6017531 Best vali loss: 1.6017531
[36m(_train_fn pid=748271)[0m 	iters: 100, epoch: 3 | loss: 0.5575038
[36m(_train_fn pid=748271)[0m 	speed: 0.0306s/iter; left time: 86.8534s
[36m(_train_fn pid=748271)[0m 	iters: 200, epoch: 3 | loss: 0.5839530
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 34.2752s
[36m(_train_fn pid=748271)[0m 	iters: 300, epoch: 3 | loss: 0.6287709
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 32.9709s
[36m(_train_fn pid=748271)[0m 	iters: 400, epoch: 3 | loss: 0.5246887
[36m(_train_fn pid=748271)[0m 	speed: 0.0126s/iter; left time: 31.8738s

Trial status: 11 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:28:39. Total running time: 7min 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=748271)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-743b5daa_12_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-28-16/checkpoint_000002)
[36m(_train_fn pid=748271)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-743b5daa_12_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-28-16/checkpoint_000003)
[36m(_train_fn pid=748271)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-743b5daa_12_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-28-16/checkpoint_000004)
[36m(_train_fn pid=748271)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-743b5daa_12_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-28-16/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-743b5daa   RUNNING           2           14.7428        0.607457        1.60175             1.60175 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=748271)[0m Updating learning rate to 0.0005057662072450137
[36m(_train_fn pid=748271)[0m saving checkpoint...
[36m(_train_fn pid=748271)[0m Validation loss decreased (1.6018 --> 1.5984).  Saving model state dict ...
[36m(_train_fn pid=748271)[0m Epoch: 3 cost time: 6.166330814361572
[36m(_train_fn pid=748271)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5586708 Vali Loss: 1.5984217 Best vali loss: 1.5984217
[36m(_train_fn pid=748271)[0m 	iters: 100, epoch: 4 | loss: 0.4443847
[36m(_train_fn pid=748271)[0m 	speed: 0.0309s/iter; left time: 72.4387s
[36m(_train_fn pid=748271)[0m 	iters: 200, epoch: 4 | loss: 0.5570330
[36m(_train_fn pid=748271)[0m 	speed: 0.0126s/iter; left time: 28.3265s
[36m(_train_fn pid=748271)[0m 	iters: 300, epoch: 4 | loss: 0.6984437
[36m(_train_fn pid=748271)[0m 	speed: 0.0126s/iter; left time: 27.0868s
[36m(_train_fn pid=748271)[0m 	iters: 400, epoch: 4 | loss: 0.5030788
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 25.6020s
[36m(_train_fn pid=748271)[0m Updating learning rate to 0.00025288310362250687
[36m(_train_fn pid=748271)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=748271)[0m saving checkpoint...
[36m(_train_fn pid=748271)[0m Epoch: 4 cost time: 6.19605016708374
[36m(_train_fn pid=748271)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5332799 Vali Loss: 1.6280779 Best vali loss: 1.5984217
[36m(_train_fn pid=748271)[0m 	iters: 100, epoch: 5 | loss: 0.5688303
[36m(_train_fn pid=748271)[0m 	speed: 0.0305s/iter; left time: 56.5501s
[36m(_train_fn pid=748271)[0m 	iters: 200, epoch: 5 | loss: 0.5637992
[36m(_train_fn pid=748271)[0m 	speed: 0.0124s/iter; left time: 21.8095s
[36m(_train_fn pid=748271)[0m 	iters: 300, epoch: 5 | loss: 0.5231121
[36m(_train_fn pid=748271)[0m 	speed: 0.0123s/iter; left time: 20.4624s
[36m(_train_fn pid=748271)[0m 	iters: 400, epoch: 5 | loss: 0.4498919
[36m(_train_fn pid=748271)[0m 	speed: 0.0124s/iter; left time: 19.3018s
[36m(_train_fn pid=748271)[0m Updating learning rate to 0.00012644155181125343
[36m(_train_fn pid=748271)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=748271)[0m saving checkpoint...
[36m(_train_fn pid=748271)[0m Epoch: 5 cost time: 6.1018171310424805
[36m(_train_fn pid=748271)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5138504 Vali Loss: 1.6440406 Best vali loss: 1.5984217
[36m(_train_fn pid=748271)[0m 	iters: 100, epoch: 6 | loss: 0.4987380
[36m(_train_fn pid=748271)[0m 	speed: 0.0306s/iter; left time: 41.8184s
[36m(_train_fn pid=748271)[0m 	iters: 200, epoch: 6 | loss: 0.5094936
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 15.8865s
[36m(_train_fn pid=748271)[0m 	iters: 300, epoch: 6 | loss: 0.4956349
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 14.5859s
[36m(_train_fn pid=748271)[0m 	iters: 400, epoch: 6 | loss: 0.4562297
[36m(_train_fn pid=748271)[0m 	speed: 0.0125s/iter; left time: 13.3589s

Trial trial-743b5daa completed after 6 iterations at 2024-08-24 07:29:00. Total running time: 7min 51s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-743b5daa result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          6.81328 â”‚
â”‚ time_total_s                             41.98308 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.59842 â”‚
â”‚ train_loss                                0.50155 â”‚
â”‚ valid_loss                                1.63098 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=748271)[0m Updating learning rate to 6.322077590562672e-05
[36m(_train_fn pid=748271)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=748271)[0m saving checkpoint...
[36m(_train_fn pid=748271)[0m Epoch: 6 cost time: 6.165319204330444
[36m(_train_fn pid=748271)[0m Epoch: 6, Steps: 489 | Train Loss: 0.5015523 Vali Loss: 1.6309834 Best vali loss: 1.5984217
[36m(_train_fn pid=748271)[0m Early stopping

Trial trial-ddc42f98 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ddc42f98 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.12664 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00709 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=748911)[0m configuration
[36m(_train_fn pid=748911)[0m {'batch_size': 32, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.126638885779985, 'e_layers': 4, 'learning_rate': 0.007088916976912298, 'd_ff': 32}
[36m(_train_fn pid=748911)[0m Use GPU: cuda:0
[36m(_train_fn pid=748911)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ddc42f98_13_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1266,e_layers=_2024-08-24_07-29-00/checkpoint_000000)
2024-08-24 07:29:10,390	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=748911)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ddc42f98_13_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1266,e_layers=_2024-08-24_07-29-00/checkpoint_000001)
2024-08-24 07:29:13,791	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=748911)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ddc42f98_13_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1266,e_layers=_2024-08-24_07-29-00/checkpoint_000002)
2024-08-24 07:29:17,199	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=748911)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ddc42f98_13_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1266,e_layers=_2024-08-24_07-29-00/checkpoint_000003)
2024-08-24 07:29:20,608	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=748911)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ddc42f98_13_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1266,e_layers=_2024-08-24_07-29-00/checkpoint_000004)
2024-08-24 07:29:24,004	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=748911)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ddc42f98_13_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1266,e_layers=_2024-08-24_07-29-00/checkpoint_000005)
2024-08-24 07:29:27,726	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=748911)[0m train 7825
[36m(_train_fn pid=748911)[0m val 2161
[36m(_train_fn pid=748911)[0m start_epoch 0
[36m(_train_fn pid=748911)[0m max_epoch 8
[36m(_train_fn pid=748911)[0m 	iters: 100, epoch: 1 | loss: 0.7577793
[36m(_train_fn pid=748911)[0m 	speed: 0.0205s/iter; left time: 37.9005s
[36m(_train_fn pid=748911)[0m 	iters: 200, epoch: 1 | loss: 0.6824508
[36m(_train_fn pid=748911)[0m 	speed: 0.0134s/iter; left time: 23.4874s
[36m(_train_fn pid=748911)[0m Updating learning rate to 0.007088916976912298
[36m(_train_fn pid=748911)[0m saving checkpoint...
[36m(_train_fn pid=748911)[0m Validation loss decreased (inf --> 1.6363).  Saving model state dict ...
[36m(_train_fn pid=748911)[0m Epoch: 1 cost time: 3.7082481384277344
[36m(_train_fn pid=748911)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8025196 Vali Loss: 1.6363426 Best vali loss: 1.6363426
[36m(_train_fn pid=748911)[0m 	iters: 100, epoch: 2 | loss: 0.5924803
[36m(_train_fn pid=748911)[0m 	speed: 0.0226s/iter; left time: 36.4368s
[36m(_train_fn pid=748911)[0m 	iters: 200, epoch: 2 | loss: 0.6224239
[36m(_train_fn pid=748911)[0m 	speed: 0.0120s/iter; left time: 18.0872s

Trial status: 12 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:29:09. Total running time: 8min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ddc42f98   RUNNING           1            4.53575       0.80252         1.63634             1.63634 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=748911)[0m Updating learning rate to 0.003544458488456149
[36m(_train_fn pid=748911)[0m saving checkpoint...
[36m(_train_fn pid=748911)[0m Validation loss decreased (1.6363 --> 1.5942).  Saving model state dict ...
[36m(_train_fn pid=748911)[0m Epoch: 2 cost time: 2.977177381515503
[36m(_train_fn pid=748911)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6049339 Vali Loss: 1.5941744 Best vali loss: 1.5941744
[36m(_train_fn pid=748911)[0m 	iters: 100, epoch: 3 | loss: 0.5792725
[36m(_train_fn pid=748911)[0m 	speed: 0.0220s/iter; left time: 30.0485s
[36m(_train_fn pid=748911)[0m 	iters: 200, epoch: 3 | loss: 0.5549600
[36m(_train_fn pid=748911)[0m 	speed: 0.0120s/iter; left time: 15.2170s
[36m(_train_fn pid=748911)[0m Updating learning rate to 0.0017722292442280746
[36m(_train_fn pid=748911)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=748911)[0m saving checkpoint...
[36m(_train_fn pid=748911)[0m Epoch: 3 cost time: 2.980077028274536
[36m(_train_fn pid=748911)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5636728 Vali Loss: 1.6265273 Best vali loss: 1.5941744
[36m(_train_fn pid=748911)[0m 	iters: 100, epoch: 4 | loss: 0.5246577
[36m(_train_fn pid=748911)[0m 	speed: 0.0220s/iter; left time: 24.6639s
[36m(_train_fn pid=748911)[0m 	iters: 200, epoch: 4 | loss: 0.4942103
[36m(_train_fn pid=748911)[0m 	speed: 0.0120s/iter; left time: 12.3009s
[36m(_train_fn pid=748911)[0m Updating learning rate to 0.0008861146221140373
[36m(_train_fn pid=748911)[0m saving checkpoint...
[36m(_train_fn pid=748911)[0m Validation loss decreased (1.5942 --> 1.5897).  Saving model state dict ...
[36m(_train_fn pid=748911)[0m Epoch: 4 cost time: 2.985604763031006
[36m(_train_fn pid=748911)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5344528 Vali Loss: 1.5897235 Best vali loss: 1.5897235
[36m(_train_fn pid=748911)[0m 	iters: 100, epoch: 5 | loss: 0.5524709
[36m(_train_fn pid=748911)[0m 	speed: 0.0221s/iter; left time: 19.3685s
[36m(_train_fn pid=748911)[0m 	iters: 200, epoch: 5 | loss: 0.4831980
[36m(_train_fn pid=748911)[0m 	speed: 0.0121s/iter; left time: 9.3735s
[36m(_train_fn pid=748911)[0m Updating learning rate to 0.00044305731105701864
[36m(_train_fn pid=748911)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=748911)[0m saving checkpoint...
[36m(_train_fn pid=748911)[0m Epoch: 5 cost time: 2.9926528930664062
[36m(_train_fn pid=748911)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5110769 Vali Loss: 1.6233436 Best vali loss: 1.5897235
[36m(_train_fn pid=748911)[0m 	iters: 100, epoch: 6 | loss: 0.4825049
[36m(_train_fn pid=748911)[0m 	speed: 0.0219s/iter; left time: 13.8418s
[36m(_train_fn pid=748911)[0m 	iters: 200, epoch: 6 | loss: 0.5142988
[36m(_train_fn pid=748911)[0m 	speed: 0.0120s/iter; left time: 6.4115s
[36m(_train_fn pid=748911)[0m Updating learning rate to 0.00022152865552850932
[36m(_train_fn pid=748911)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=748911)[0m saving checkpoint...
[36m(_train_fn pid=748911)[0m Epoch: 6 cost time: 2.9719579219818115
[36m(_train_fn pid=748911)[0m Epoch: 6, Steps: 244 | Train Loss: 0.4942116 Vali Loss: 1.6393046 Best vali loss: 1.5897235
[36m(_train_fn pid=748911)[0m 	iters: 100, epoch: 7 | loss: 0.4588660
[36m(_train_fn pid=748911)[0m 	speed: 0.0233s/iter; left time: 9.0720s
[36m(_train_fn pid=748911)[0m 	iters: 200, epoch: 7 | loss: 0.4539115
[36m(_train_fn pid=748911)[0m 	speed: 0.0133s/iter; left time: 3.8446s

Trial trial-ddc42f98 completed after 7 iterations at 2024-08-24 07:29:27. Total running time: 8min 18s
[36m(_train_fn pid=748911)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ddc42f98_13_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1266,e_layers=_2024-08-24_07-29-00/checkpoint_000006)
[36m(_train_fn pid=749568)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ad2934c_14_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1097,e_laye_2024-08-24_07-29-27/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ddc42f98 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          3.72173 â”‚
â”‚ time_total_s                             25.25517 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58972 â”‚
â”‚ train_loss                                0.48483 â”‚
â”‚ valid_loss                                1.66408 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=748911)[0m Updating learning rate to 0.00011076432776425466
[36m(_train_fn pid=748911)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=748911)[0m saving checkpoint...
[36m(_train_fn pid=748911)[0m Epoch: 7 cost time: 3.3006715774536133
[36m(_train_fn pid=748911)[0m Epoch: 7, Steps: 244 | Train Loss: 0.4848287 Vali Loss: 1.6640795 Best vali loss: 1.5897235
[36m(_train_fn pid=748911)[0m Early stopping

Trial trial-5ad2934c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5ad2934c config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.10975 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00462 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=749568)[0m configuration
[36m(_train_fn pid=749568)[0m {'batch_size': 128, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.10974725729420516, 'e_layers': 2, 'learning_rate': 0.004616028475869769, 'd_ff': 1024}
[36m(_train_fn pid=749568)[0m Use GPU: cuda:0
[36m(_train_fn pid=749568)[0m train 7825
[36m(_train_fn pid=749568)[0m val 2161
[36m(_train_fn pid=749568)[0m start_epoch 0
[36m(_train_fn pid=749568)[0m max_epoch 8

Trial status: 13 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:29:39. Total running time: 8min 30s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5ad2934c   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=749568)[0m Validation loss decreased (inf --> 1.9650).  Saving model state dict ...
[36m(_train_fn pid=749568)[0m Updating learning rate to 0.004616028475869769
[36m(_train_fn pid=749568)[0m saving checkpoint...
[36m(_train_fn pid=749568)[0m Epoch: 1 cost time: 22.17442488670349
[36m(_train_fn pid=749568)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8548313 Vali Loss: 1.9649829 Best vali loss: 1.9649829
Trial status: 13 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:30:09. Total running time: 9min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:30:19,661	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=749568)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ad2934c_14_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1097,e_laye_2024-08-24_07-29-27/checkpoint_000001)
2024-08-24 07:30:44,395	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=749568)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ad2934c_14_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1097,e_laye_2024-08-24_07-29-27/checkpoint_000002)
2024-08-24 07:31:09,150	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=749568)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ad2934c_14_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1097,e_laye_2024-08-24_07-29-27/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5ad2934c   RUNNING           1           25.5091        0.854831        1.96498             1.96498 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=749568)[0m Updating learning rate to 0.0023080142379348846
[36m(_train_fn pid=749568)[0m saving checkpoint...
[36m(_train_fn pid=749568)[0m Validation loss decreased (1.9650 --> 1.6333).  Saving model state dict ...
[36m(_train_fn pid=749568)[0m Epoch: 2 cost time: 21.82283067703247
[36m(_train_fn pid=749568)[0m Epoch: 2, Steps: 61 | Train Loss: 0.8325350 Vali Loss: 1.6333299 Best vali loss: 1.6333299
Trial status: 13 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:30:39. Total running time: 9min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5ad2934c   RUNNING           2           50.2419        0.832535        1.63333             1.63333 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=749568)[0m Updating learning rate to 0.0011540071189674423
[36m(_train_fn pid=749568)[0m saving checkpoint...
[36m(_train_fn pid=749568)[0m Validation loss decreased (1.6333 --> 1.5897).  Saving model state dict ...
[36m(_train_fn pid=749568)[0m Epoch: 3 cost time: 21.818202018737793
[36m(_train_fn pid=749568)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6187595 Vali Loss: 1.5897388 Best vali loss: 1.5897388
[36m(_train_fn pid=749568)[0m Updating learning rate to 0.0005770035594837212
[36m(_train_fn pid=749568)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=749568)[0m saving checkpoint...
[36m(_train_fn pid=749568)[0m Epoch: 4 cost time: 21.85823345184326
[36m(_train_fn pid=749568)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6103702 Vali Loss: 1.5898137 Best vali loss: 1.5897388
Trial status: 13 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:31:09. Total running time: 10min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:31:33,951	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=749568)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ad2934c_14_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1097,e_laye_2024-08-24_07-29-27/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5ad2934c   RUNNING           4           99.7209        0.61037         1.58981             1.58974 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-5ad2934c completed after 5 iterations at 2024-08-24 07:31:33. Total running time: 10min 25s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5ad2934c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         24.79751 â”‚
â”‚ time_total_s                            124.51846 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58949 â”‚
â”‚ train_loss                                0.60563 â”‚
â”‚ valid_loss                                1.58949 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=749568)[0m Updating learning rate to 0.0002885017797418606
[36m(_train_fn pid=749568)[0m saving checkpoint...
[36m(_train_fn pid=749568)[0m Validation loss decreased (1.5897 --> 1.5895).  Saving model state dict ...

Trial trial-2aff9e60 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2aff9e60 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.03907 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00088 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=750388)[0m configuration
[36m(_train_fn pid=750388)[0m {'batch_size': 128, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.03907355046545624, 'e_layers': 3, 'learning_rate': 0.0008815990252248222, 'd_ff': 384}
[36m(_train_fn pid=750388)[0m Use GPU: cuda:0
[36m(_train_fn pid=750388)[0m train 7825
[36m(_train_fn pid=750388)[0m val 2161
[36m(_train_fn pid=750388)[0m start_epoch 0
[36m(_train_fn pid=750388)[0m max_epoch 8

Trial status: 14 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:31:39. Total running time: 10min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:31:44,920	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=750388)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2aff9e60_15_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0391,e_layer_2024-08-24_07-31-33/checkpoint_000000)
[36m(_train_fn pid=750388)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2aff9e60_15_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0391,e_layer_2024-08-24_07-31-33/checkpoint_000001)
[36m(_train_fn pid=750388)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2aff9e60_15_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0391,e_layer_2024-08-24_07-31-33/checkpoint_000002)
[36m(_train_fn pid=750388)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2aff9e60_15_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0391,e_layer_2024-08-24_07-31-33/checkpoint_000003)
[36m(_train_fn pid=750388)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2aff9e60_15_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0391,e_layer_2024-08-24_07-31-33/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2aff9e60   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=750388)[0m Updating learning rate to 0.0008815990252248222
[36m(_train_fn pid=750388)[0m saving checkpoint...
[36m(_train_fn pid=750388)[0m Validation loss decreased (inf --> 2.0558).  Saving model state dict ...
[36m(_train_fn pid=750388)[0m Epoch: 1 cost time: 7.133486032485962
[36m(_train_fn pid=750388)[0m Epoch: 1, Steps: 61 | Train Loss: 0.9181983 Vali Loss: 2.0557947 Best vali loss: 2.0557947
[36m(_train_fn pid=750388)[0m Updating learning rate to 0.0004407995126124111
[36m(_train_fn pid=750388)[0m saving checkpoint...
[36m(_train_fn pid=750388)[0m Validation loss decreased (2.0558 --> 1.7275).  Saving model state dict ...
[36m(_train_fn pid=750388)[0m Epoch: 2 cost time: 6.723689079284668
[36m(_train_fn pid=750388)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7415920 Vali Loss: 1.7275140 Best vali loss: 1.7275140
[36m(_train_fn pid=750388)[0m Updating learning rate to 0.00022039975630620554
[36m(_train_fn pid=750388)[0m saving checkpoint...
[36m(_train_fn pid=750388)[0m Validation loss decreased (1.7275 --> 1.6553).  Saving model state dict ...
[36m(_train_fn pid=750388)[0m Epoch: 3 cost time: 6.725036144256592
[36m(_train_fn pid=750388)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6533742 Vali Loss: 1.6553316 Best vali loss: 1.6553316
[36m(_train_fn pid=750388)[0m Updating learning rate to 0.00011019987815310277
[36m(_train_fn pid=750388)[0m saving checkpoint...
[36m(_train_fn pid=750388)[0m Validation loss decreased (1.6553 --> 1.6429).  Saving model state dict ...
[36m(_train_fn pid=750388)[0m Epoch: 4 cost time: 6.73204493522644
[36m(_train_fn pid=750388)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6405072 Vali Loss: 1.6428629 Best vali loss: 1.6428629
Trial status: 14 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:32:10. Total running time: 11min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2aff9e60   RUNNING           4           31.4835        0.640507        1.64286             1.64286 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=750388)[0m Updating learning rate to 5.5099939076551386e-05
[36m(_train_fn pid=750388)[0m saving checkpoint...
[36m(_train_fn pid=750388)[0m Validation loss decreased (1.6429 --> 1.6356).  Saving model state dict ...
[36m(_train_fn pid=750388)[0m Epoch: 5 cost time: 6.732350826263428
[36m(_train_fn pid=750388)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2aff9e60_15_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0391,e_layer_2024-08-24_07-31-33/checkpoint_000005)
[36m(_train_fn pid=750388)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2aff9e60_15_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0391,e_layer_2024-08-24_07-31-33/checkpoint_000006)
[36m(_train_fn pid=750388)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2aff9e60_15_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0391,e_layer_2024-08-24_07-31-33/checkpoint_000007)
2024-08-24 07:32:43,252	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=751225)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c515a439_16_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1131,e_layers=_2024-08-24_07-32-38/checkpoint_000000)
[36m(_train_fn pid=751225)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c515a439_16_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1131,e_layers=_2024-08-24_07-32-38/checkpoint_000001)
[36m(_train_fn pid=750388)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6360342 Vali Loss: 1.6356346 Best vali loss: 1.6356346
[36m(_train_fn pid=750388)[0m Updating learning rate to 2.7549969538275693e-05
[36m(_train_fn pid=750388)[0m saving checkpoint...
[36m(_train_fn pid=750388)[0m Validation loss decreased (1.6356 --> 1.6317).  Saving model state dict ...
[36m(_train_fn pid=750388)[0m Epoch: 6 cost time: 6.727696895599365
[36m(_train_fn pid=750388)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6333846 Vali Loss: 1.6317131 Best vali loss: 1.6317131
[36m(_train_fn pid=750388)[0m Updating learning rate to 1.3774984769137847e-05
[36m(_train_fn pid=750388)[0m saving checkpoint...
[36m(_train_fn pid=750388)[0m Validation loss decreased (1.6317 --> 1.6295).  Saving model state dict ...
[36m(_train_fn pid=750388)[0m Epoch: 7 cost time: 6.7194201946258545
[36m(_train_fn pid=750388)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6318291 Vali Loss: 1.6295438 Best vali loss: 1.6295438

Trial trial-2aff9e60 completed after 8 iterations at 2024-08-24 07:32:38. Total running time: 11min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2aff9e60 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          7.66553 â”‚
â”‚ time_total_s                             62.14213 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.62851 â”‚
â”‚ train_loss                                0.63114 â”‚
â”‚ valid_loss                                1.62851 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=750388)[0m Updating learning rate to 6.887492384568923e-06
[36m(_train_fn pid=750388)[0m saving checkpoint...
[36m(_train_fn pid=750388)[0m Validation loss decreased (1.6295 --> 1.6285).  Saving model state dict ...
[36m(_train_fn pid=750388)[0m Epoch: 8 cost time: 6.72764778137207
[36m(_train_fn pid=750388)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6311426 Vali Loss: 1.6285108 Best vali loss: 1.6285108

Trial status: 15 TERMINATED | 1 PENDING
Current time: 2024-08-24 07:32:40. Total running time: 11min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143        1.62851             1.62851 â”‚
â”‚ trial-c515a439   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-c515a439 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c515a439 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11313 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00058 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=751225)[0m configuration
[36m(_train_fn pid=751225)[0m {'batch_size': 64, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.11313326444448761, 'e_layers': 2, 'learning_rate': 0.0005834474389940705, 'd_ff': 128}
[36m(_train_fn pid=751225)[0m Use GPU: cuda:0
[36m(_train_fn pid=751225)[0m train 7825
[36m(_train_fn pid=751225)[0m val 2161
[36m(_train_fn pid=751225)[0m start_epoch 0
[36m(_train_fn pid=751225)[0m max_epoch 8
[36m(_train_fn pid=751225)[0m 	iters: 100, epoch: 1 | loss: 1.0350863
[36m(_train_fn pid=751225)[0m 	speed: 0.0209s/iter; left time: 18.2900s
[36m(_train_fn pid=751225)[0m Updating learning rate to 0.0005834474389940705
[36m(_train_fn pid=751225)[0m saving checkpoint...
[36m(_train_fn pid=751225)[0m Validation loss decreased (inf --> 2.3385).  Saving model state dict ...
[36m(_train_fn pid=751225)[0m Epoch: 1 cost time: 2.1243793964385986
[36m(_train_fn pid=751225)[0m Epoch: 1, Steps: 122 | Train Loss: 1.0620145 Vali Loss: 2.3385486 Best vali loss: 2.3385486
[36m(_train_fn pid=751225)[0m 	iters: 100, epoch: 2 | loss: 0.6238618
[36m(_train_fn pid=751225)[0m 	speed: 0.0201s/iter; left time: 15.1421s
[36m(_train_fn pid=751225)[0m Updating learning rate to 0.0002917237194970353
[36m(_train_fn pid=751225)[0m saving checkpoint...
2024-08-24 07:32:45,252	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:32:47,242	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=751225)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c515a439_16_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1131,e_layers=_2024-08-24_07-32-38/checkpoint_000002)
2024-08-24 07:32:49,238	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=751225)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c515a439_16_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1131,e_layers=_2024-08-24_07-32-38/checkpoint_000003)
2024-08-24 07:32:51,238	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=751225)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c515a439_16_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1131,e_layers=_2024-08-24_07-32-38/checkpoint_000004)
2024-08-24 07:32:53,227	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=751225)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c515a439_16_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1131,e_layers=_2024-08-24_07-32-38/checkpoint_000005)
2024-08-24 07:32:55,224	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=751225)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c515a439_16_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1131,e_layers=_2024-08-24_07-32-38/checkpoint_000006)
2024-08-24 07:32:57,218	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=751225)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c515a439_16_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1131,e_layers=_2024-08-24_07-32-38/checkpoint_000007)
[36m(_train_fn pid=751225)[0m Validation loss decreased (2.3385 --> 1.6329).  Saving model state dict ...
[36m(_train_fn pid=751225)[0m Epoch: 2 cost time: 1.6895997524261475
[36m(_train_fn pid=751225)[0m Epoch: 2, Steps: 122 | Train Loss: 0.7390416 Vali Loss: 1.6329159 Best vali loss: 1.6329159
[36m(_train_fn pid=751225)[0m 
[36m(_train_fn pid=751225)[0m 	iters: 100, epoch: 3 | loss: 0.6186970
[36m(_train_fn pid=751225)[0m 	speed: 0.0200s/iter; left time: 12.6477s
[36m(_train_fn pid=751225)[0m Updating learning rate to 0.00014586185974851764
[36m(_train_fn pid=751225)[0m saving checkpoint...
[36m(_train_fn pid=751225)[0m Validation loss decreased (1.6329 --> 1.5991).  Saving model state dict ...
[36m(_train_fn pid=751225)[0m Epoch: 3 cost time: 1.6874446868896484
[36m(_train_fn pid=751225)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6314422 Vali Loss: 1.5991175 Best vali loss: 1.5991175
[36m(_train_fn pid=751225)[0m 	iters: 100, epoch: 4 | loss: 0.5726362
[36m(_train_fn pid=751225)[0m 	speed: 0.0199s/iter; left time: 10.1883s
[36m(_train_fn pid=751225)[0m Updating learning rate to 7.293092987425882e-05
[36m(_train_fn pid=751225)[0m saving checkpoint...
[36m(_train_fn pid=751225)[0m Validation loss decreased (1.5991 --> 1.5937).  Saving model state dict ...
[36m(_train_fn pid=751225)[0m Epoch: 4 cost time: 1.6913204193115234
[36m(_train_fn pid=751225)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6201667 Vali Loss: 1.5936906 Best vali loss: 1.5936906
[36m(_train_fn pid=751225)[0m 	iters: 100, epoch: 5 | loss: 0.6096712
[36m(_train_fn pid=751225)[0m 	speed: 0.0200s/iter; left time: 7.7754s
[36m(_train_fn pid=751225)[0m Updating learning rate to 3.646546493712941e-05
[36m(_train_fn pid=751225)[0m saving checkpoint...
[36m(_train_fn pid=751225)[0m Validation loss decreased (1.5937 --> 1.5908).  Saving model state dict ...
[36m(_train_fn pid=751225)[0m Epoch: 5 cost time: 1.6948027610778809
[36m(_train_fn pid=751225)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6167204 Vali Loss: 1.5907982 Best vali loss: 1.5907982
[36m(_train_fn pid=751225)[0m 	iters: 100, epoch: 6 | loss: 0.5985957
[36m(_train_fn pid=751225)[0m 	speed: 0.0199s/iter; left time: 5.3202s
[36m(_train_fn pid=751225)[0m Updating learning rate to 1.8232732468564705e-05
[36m(_train_fn pid=751225)[0m saving checkpoint...
[36m(_train_fn pid=751225)[0m Validation loss decreased (1.5908 --> 1.5898).  Saving model state dict ...
[36m(_train_fn pid=751225)[0m Epoch: 6 cost time: 1.6854612827301025
[36m(_train_fn pid=751225)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6153092 Vali Loss: 1.5898433 Best vali loss: 1.5898433
[36m(_train_fn pid=751225)[0m 	iters: 100, epoch: 7 | loss: 0.6094612
[36m(_train_fn pid=751225)[0m 	speed: 0.0199s/iter; left time: 2.8858s
[36m(_train_fn pid=751225)[0m Updating learning rate to 9.116366234282352e-06
[36m(_train_fn pid=751225)[0m saving checkpoint...
[36m(_train_fn pid=751225)[0m Validation loss decreased (1.5898 --> 1.5894).  Saving model state dict ...
[36m(_train_fn pid=751225)[0m Epoch: 7 cost time: 1.6882851123809814
[36m(_train_fn pid=751225)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6147674 Vali Loss: 1.5893723 Best vali loss: 1.5893723
[36m(_train_fn pid=751225)[0m 	iters: 100, epoch: 8 | loss: 0.6308681
[36m(_train_fn pid=751225)[0m 	speed: 0.0200s/iter; left time: 0.4597s

Trial trial-c515a439 completed after 8 iterations at 2024-08-24 07:32:57. Total running time: 11min 48s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c515a439 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          1.99159 â”‚
â”‚ time_total_s                             16.78435 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.58937 â”‚
â”‚ train_loss                                 0.6141 â”‚
â”‚ valid_loss                                1.59012 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=751225)[0m Updating learning rate to 4.558183117141176e-06
[36m(_train_fn pid=751225)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=751225)[0m saving checkpoint...
[36m(_train_fn pid=751225)[0m Epoch: 8 cost time: 1.6908416748046875
[36m(_train_fn pid=751225)[0m Epoch: 8, Steps: 122 | Train Loss: 0.6140959 Vali Loss: 1.5901155 Best vali loss: 1.5893723

Trial trial-eff11b3a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-eff11b3a config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.08302 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00079 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=751932)[0m configuration
[36m(_train_fn pid=751932)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'conv', 'dropout': 0.08302184582269503, 'e_layers': 2, 'learning_rate': 0.0007874187463015802, 'd_ff': 1024}
[36m(_train_fn pid=751932)[0m Use GPU: cuda:0
[36m(_train_fn pid=751932)[0m train 7825
[36m(_train_fn pid=751932)[0m val 2161
[36m(_train_fn pid=751932)[0m start_epoch 0
[36m(_train_fn pid=751932)[0m max_epoch 8
[36m(_train_fn pid=751932)[0m 	iters: 100, epoch: 1 | loss: 0.7863896
[36m(_train_fn pid=751932)[0m 	speed: 0.1002s/iter; left time: 185.6701s

Trial status: 16 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:33:10. Total running time: 12min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=751932)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eff11b3a_17_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_07-32-57/checkpoint_000000)
[36m(_train_fn pid=751932)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eff11b3a_17_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_07-32-57/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-eff11b3a   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143        1.62851             1.62851 â”‚
â”‚ trial-c515a439   TERMINATED        8           16.7843        0.614096        1.59012             1.58937 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=751932)[0m 	iters: 200, epoch: 1 | loss: 0.7571285
[36m(_train_fn pid=751932)[0m 	speed: 0.0959s/iter; left time: 168.0590s
[36m(_train_fn pid=751932)[0m Updating learning rate to 0.0007874187463015802
[36m(_train_fn pid=751932)[0m saving checkpoint...
[36m(_train_fn pid=751932)[0m Validation loss decreased (inf --> 1.9264).  Saving model state dict ...
[36m(_train_fn pid=751932)[0m Epoch: 1 cost time: 23.569979667663574
[36m(_train_fn pid=751932)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7973226 Vali Loss: 1.9264196 Best vali loss: 1.9264196
[36m(_train_fn pid=751932)[0m 	iters: 100, epoch: 2 | loss: 0.6142238
[36m(_train_fn pid=751932)[0m 	speed: 0.1659s/iter; left time: 266.8906s
Trial status: 16 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:33:40. Total running time: 12min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-eff11b3a   RUNNING           1           26.7552        0.797323        1.92642             1.92642 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143        1.62851             1.62851 â”‚
â”‚ trial-c515a439   TERMINATED        8           16.7843        0.614096        1.59012             1.58937 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=751932)[0m 	iters: 200, epoch: 2 | loss: 0.6444771
[36m(_train_fn pid=751932)[0m 	speed: 0.0960s/iter; left time: 144.9026s
[36m(_train_fn pid=751932)[0m Updating learning rate to 0.0003937093731507901
[36m(_train_fn pid=751932)[0m saving checkpoint...
[36m(_train_fn pid=751932)[0m Validation loss decreased (1.9264 --> 1.5946).  Saving model state dict ...
[36m(_train_fn pid=751932)[0m Epoch: 2 cost time: 23.417858123779297
[36m(_train_fn pid=751932)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6795735 Vali Loss: 1.5946065 Best vali loss: 1.5946065
[36m(_train_fn pid=751932)[0m 	iters: 100, epoch: 3 | loss: 0.7396654
[36m(_train_fn pid=751932)[0m 	speed: 0.1660s/iter; left time: 226.5863s
Trial status: 16 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:34:10. Total running time: 13min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=751932)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eff11b3a_17_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_07-32-57/checkpoint_000002)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-eff11b3a   RUNNING           2           52.9427        0.679574        1.59461             1.59461 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143        1.62851             1.62851 â”‚
â”‚ trial-c515a439   TERMINATED        8           16.7843        0.614096        1.59012             1.58937 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=751932)[0m 	iters: 200, epoch: 3 | loss: 0.6278670
[36m(_train_fn pid=751932)[0m 	speed: 0.0961s/iter; left time: 121.6213s
[36m(_train_fn pid=751932)[0m Updating learning rate to 0.00019685468657539506
[36m(_train_fn pid=751932)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=751932)[0m saving checkpoint...
[36m(_train_fn pid=751932)[0m Epoch: 3 cost time: 23.44366979598999
[36m(_train_fn pid=751932)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6119895 Vali Loss: 1.6064053 Best vali loss: 1.5946065
[36m(_train_fn pid=751932)[0m 	iters: 100, epoch: 4 | loss: 0.7381953
[36m(_train_fn pid=751932)[0m 	speed: 0.1659s/iter; left time: 185.9321s
[36m(_train_fn pid=751932)[0m 	iters: 200, epoch: 4 | loss: 0.5390536
[36m(_train_fn pid=751932)[0m 	speed: 0.0962s/iter; left time: 98.2703s
Trial status: 16 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:34:40. Total running time: 13min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-eff11b3a   RUNNING           3           79.1321        0.611989        1.60641             1.59461 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143        1.62851             1.62851 â”‚
â”‚ trial-c515a439   TERMINATED        8           16.7843        0.614096        1.59012             1.58937 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-eff11b3a completed after 4 iterations at 2024-08-24 07:34:44. Total running time: 13min 35s
[36m(_train_fn pid=751932)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eff11b3a_17_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_07-32-57/checkpoint_000003)
2024-08-24 07:34:56,345	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=752615)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce680db1_18_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0914,e_layers_2024-08-24_07-34-44/checkpoint_000000)
[36m(_train_fn pid=752615)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce680db1_18_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0914,e_layers_2024-08-24_07-34-44/checkpoint_000001)
[36m(_train_fn pid=752615)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce680db1_18_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0914,e_layers_2024-08-24_07-34-44/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-eff11b3a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         26.21611 â”‚
â”‚ time_total_s                            105.34819 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.59461 â”‚
â”‚ train_loss                                0.58908 â”‚
â”‚ valid_loss                                1.60903 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=751932)[0m Updating learning rate to 9.842734328769753e-05
[36m(_train_fn pid=751932)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=751932)[0m saving checkpoint...

Trial trial-ce680db1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ce680db1 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09143 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00139 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=752615)[0m configuration
[36m(_train_fn pid=752615)[0m {'batch_size': 32, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.09142939194888641, 'e_layers': 3, 'learning_rate': 0.001386678468194237, 'd_ff': 512}
[36m(_train_fn pid=752615)[0m Use GPU: cuda:0
[36m(_train_fn pid=752615)[0m train 7825
[36m(_train_fn pid=752615)[0m val 2161
[36m(_train_fn pid=752615)[0m start_epoch 0
[36m(_train_fn pid=752615)[0m max_epoch 8
[36m(_train_fn pid=752615)[0m 	iters: 100, epoch: 1 | loss: 0.9168623
[36m(_train_fn pid=752615)[0m 	speed: 0.0396s/iter; left time: 73.3517s
[36m(_train_fn pid=752615)[0m 	iters: 200, epoch: 1 | loss: 0.8551521
[36m(_train_fn pid=752615)[0m 	speed: 0.0327s/iter; left time: 57.2428s
[36m(_train_fn pid=752615)[0m Updating learning rate to 0.001386678468194237
[36m(_train_fn pid=752615)[0m saving checkpoint...
[36m(_train_fn pid=752615)[0m Validation loss decreased (inf --> 1.9410).  Saving model state dict ...
[36m(_train_fn pid=752615)[0m Epoch: 1 cost time: 8.40009593963623
[36m(_train_fn pid=752615)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8160807 Vali Loss: 1.9410096 Best vali loss: 1.9410096
[36m(_train_fn pid=752615)[0m 	iters: 100, epoch: 2 | loss: 0.6595945
[36m(_train_fn pid=752615)[0m 	speed: 0.0584s/iter; left time: 93.9097s
[36m(_train_fn pid=752615)[0m 	iters: 200, epoch: 2 | loss: 0.5712970
[36m(_train_fn pid=752615)[0m 	speed: 0.0326s/iter; left time: 49.1232s
[36m(_train_fn pid=752615)[0m Updating learning rate to 0.0006933392340971185
[36m(_train_fn pid=752615)[0m saving checkpoint...
[36m(_train_fn pid=752615)[0m Validation loss decreased (1.9410 --> 1.5698).  Saving model state dict ...
[36m(_train_fn pid=752615)[0m Epoch: 2 cost time: 7.9794933795928955
[36m(_train_fn pid=752615)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6321878 Vali Loss: 1.5698002 Best vali loss: 1.5698002
[36m(_train_fn pid=752615)[0m 	iters: 100, epoch: 3 | loss: 0.6212330
[36m(_train_fn pid=752615)[0m 	speed: 0.0585s/iter; left time: 79.8691s

Trial status: 17 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:35:10. Total running time: 14min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ce680db1   RUNNING           2           19.0122        0.632188        1.5698              1.5698  â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143        1.62851             1.62851 â”‚
â”‚ trial-c515a439   TERMINATED        8           16.7843        0.614096        1.59012             1.58937 â”‚
â”‚ trial-eff11b3a   TERMINATED        4          105.348         0.58908         1.60903             1.59461 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=752615)[0m 	iters: 200, epoch: 3 | loss: 0.5523389
[36m(_train_fn pid=752615)[0m 	speed: 0.0326s/iter; left time: 41.2267s
[36m(_train_fn pid=752615)[0m Updating learning rate to 0.00034666961704855925
[36m(_train_fn pid=752615)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=752615)[0m saving checkpoint...
[36m(_train_fn pid=752615)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce680db1_18_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0914,e_layers_2024-08-24_07-34-44/checkpoint_000003)
[36m(_train_fn pid=752615)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce680db1_18_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0914,e_layers_2024-08-24_07-34-44/checkpoint_000004)
2024-08-24 07:35:37,016	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:35:38,799	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=753194)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e25555f_19_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0610,e_layers_2024-08-24_07-35-32/checkpoint_000001)[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=752615)[0m Epoch: 3 cost time: 7.983722686767578
[36m(_train_fn pid=752615)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5970065 Vali Loss: 1.6104131 Best vali loss: 1.5698002
[36m(_train_fn pid=752615)[0m 	iters: 100, epoch: 4 | loss: 0.6147260
[36m(_train_fn pid=752615)[0m 	speed: 0.0584s/iter; left time: 65.4940s
[36m(_train_fn pid=752615)[0m 	iters: 200, epoch: 4 | loss: 0.5302504
[36m(_train_fn pid=752615)[0m 	speed: 0.0326s/iter; left time: 33.3068s
[36m(_train_fn pid=752615)[0m Updating learning rate to 0.00017333480852427962
[36m(_train_fn pid=752615)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=752615)[0m saving checkpoint...
[36m(_train_fn pid=752615)[0m Epoch: 4 cost time: 7.993485689163208
[36m(_train_fn pid=752615)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5748613 Vali Loss: 1.6092271 Best vali loss: 1.5698002
[36m(_train_fn pid=752615)[0m 	iters: 100, epoch: 5 | loss: 0.5227292
[36m(_train_fn pid=752615)[0m 	speed: 0.0583s/iter; left time: 51.1512s
[36m(_train_fn pid=752615)[0m 	iters: 200, epoch: 5 | loss: 0.5608009
[36m(_train_fn pid=752615)[0m 	speed: 0.0326s/iter; left time: 25.3341s

Trial trial-ce680db1 completed after 5 iterations at 2024-08-24 07:35:32. Total running time: 14min 23s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ce680db1 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                           9.0819 â”‚
â”‚ time_total_s                             46.28955 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                            1.5698 â”‚
â”‚ train_loss                                0.56138 â”‚
â”‚ valid_loss                                1.58649 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=752615)[0m Updating learning rate to 8.666740426213981e-05
[36m(_train_fn pid=752615)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=752615)[0m saving checkpoint...
[36m(_train_fn pid=752615)[0m Epoch: 5 cost time: 7.979156017303467
[36m(_train_fn pid=752615)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5613787 Vali Loss: 1.5864908 Best vali loss: 1.5698002
[36m(_train_fn pid=752615)[0m Early stopping

Trial trial-3e25555f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3e25555f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.06102 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00054 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=753194)[0m configuration
[36m(_train_fn pid=753194)[0m {'batch_size': 128, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.06102074610384979, 'e_layers': 2, 'learning_rate': 0.0005418796974631459, 'd_ff': 64}
[36m(_train_fn pid=753194)[0m Use GPU: cuda:0
[36m(_train_fn pid=753194)[0m train 7825
[36m(_train_fn pid=753194)[0m val 2161
[36m(_train_fn pid=753194)[0m start_epoch 0
[36m(_train_fn pid=753194)[0m max_epoch 8
[36m(_train_fn pid=753194)[0m Validation loss decreased (inf --> 2.2465).  Saving model state dict ...
[36m(_train_fn pid=753194)[0m Validation loss decreased (2.2465 --> 1.9022).  Saving model state dict ...
[36m(_train_fn pid=753194)[0m Updating learning rate to 0.00027093984873157297[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=753194)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=753194)[0m Epoch: 2 cost time: 1.4892442226409912[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=753194)[0m Epoch: 2, Steps: 61 | Train Loss: 0.8176181 Vali Loss: 1.9021874 Best vali loss: 1.9021874[32m [repeated 2x across cluster][0m

Trial status: 18 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:35:40. Total running time: 14min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:35:40,595	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:35:42,389	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:35:44,190	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=753194)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e25555f_19_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0610,e_layers_2024-08-24_07-35-32/checkpoint_000004)[32m [repeated 3x across cluster][0m
2024-08-24 07:35:45,961	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:35:47,737	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:35:49,524	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=753194)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e25555f_19_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0610,e_layers_2024-08-24_07-35-32/checkpoint_000007)[32m [repeated 3x across cluster][0m
2024-08-24 07:35:59,567	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=753894)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-85234c81_20_alpha_d_ff=2,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1180,e_layers=_2024-08-24_07-35-49/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e25555f   RUNNING           2            4.37231       0.817618        1.90219             1.90219 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143        1.62851             1.62851 â”‚
â”‚ trial-c515a439   TERMINATED        8           16.7843        0.614096        1.59012             1.58937 â”‚
â”‚ trial-eff11b3a   TERMINATED        4          105.348         0.58908         1.60903             1.59461 â”‚
â”‚ trial-ce680db1   TERMINATED        5           46.2896        0.561379        1.58649             1.5698  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=753194)[0m Validation loss decreased (1.9022 --> 1.6982).  Saving model state dict ...
[36m(_train_fn pid=753194)[0m Validation loss decreased (1.6982 --> 1.6574).  Saving model state dict ...
[36m(_train_fn pid=753194)[0m Validation loss decreased (1.6574 --> 1.6475).  Saving model state dict ...
[36m(_train_fn pid=753194)[0m Updating learning rate to 3.386748109144662e-05[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=753194)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=753194)[0m Epoch: 5 cost time: 1.5066781044006348[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=753194)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6541429 Vali Loss: 1.6475219 Best vali loss: 1.6475219[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=753194)[0m Validation loss decreased (1.6475 --> 1.6428).  Saving model state dict ...
[36m(_train_fn pid=753194)[0m Validation loss decreased (1.6428 --> 1.6408).  Saving model state dict ...

Trial trial-3e25555f completed after 8 iterations at 2024-08-24 07:35:49. Total running time: 14min 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3e25555f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          1.78518 â”‚
â”‚ time_total_s                             15.08156 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.63981 â”‚
â”‚ train_loss                                0.64801 â”‚
â”‚ valid_loss                                1.63981 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=753194)[0m Validation loss decreased (1.6408 --> 1.6398).  Saving model state dict ...
[36m(_train_fn pid=753194)[0m Updating learning rate to 4.233435136430828e-06[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=753194)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=753194)[0m Epoch: 8 cost time: 1.498023509979248[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=753194)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6480125 Vali Loss: 1.6398104 Best vali loss: 1.6398104[32m [repeated 3x across cluster][0m

Trial trial-85234c81 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-85234c81 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.11799 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00217 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=753894)[0m configuration
[36m(_train_fn pid=753894)[0m {'batch_size': 16, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.11798535366656013, 'e_layers': 4, 'learning_rate': 0.0021653546679006206, 'd_ff': 16}
[36m(_train_fn pid=753894)[0m Use GPU: cuda:0
[36m(_train_fn pid=753894)[0m train 7825
[36m(_train_fn pid=753894)[0m val 2161
[36m(_train_fn pid=753894)[0m start_epoch 0
[36m(_train_fn pid=753894)[0m max_epoch 8
[36m(_train_fn pid=753894)[0m 	iters: 100, epoch: 1 | loss: 1.1083587
[36m(_train_fn pid=753894)[0m 	speed: 0.0205s/iter; left time: 78.3494s
[36m(_train_fn pid=753894)[0m 	iters: 200, epoch: 1 | loss: 0.8910300
[36m(_train_fn pid=753894)[0m 	speed: 0.0135s/iter; left time: 50.0327s
[36m(_train_fn pid=753894)[0m 	iters: 300, epoch: 1 | loss: 0.7439521
[36m(_train_fn pid=753894)[0m 	speed: 0.0134s/iter; left time: 48.5446s
[36m(_train_fn pid=753894)[0m 	iters: 400, epoch: 1 | loss: 0.8626451
[36m(_train_fn pid=753894)[0m 	speed: 0.0135s/iter; left time: 47.4505s
[36m(_train_fn pid=753894)[0m Updating learning rate to 0.0021653546679006206
[36m(_train_fn pid=753894)[0m saving checkpoint...
[36m(_train_fn pid=753894)[0m Validation loss decreased (inf --> 1.8600).  Saving model state dict ...
[36m(_train_fn pid=753894)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-85234c81_20_alpha_d_ff=2,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1180,e_layers=_2024-08-24_07-35-49/checkpoint_000001)
[36m(_train_fn pid=753894)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-85234c81_20_alpha_d_ff=2,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1180,e_layers=_2024-08-24_07-35-49/checkpoint_000002)
[36m(_train_fn pid=753894)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-85234c81_20_alpha_d_ff=2,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1180,e_layers=_2024-08-24_07-35-49/checkpoint_000003)
[36m(_train_fn pid=753894)[0m Epoch: 1 cost time: 7.036431789398193
[36m(_train_fn pid=753894)[0m Epoch: 1, Steps: 489 | Train Loss: 0.9597022 Vali Loss: 1.8600072 Best vali loss: 1.8600072
[36m(_train_fn pid=753894)[0m 	iters: 100, epoch: 2 | loss: 0.6839062
[36m(_train_fn pid=753894)[0m 	speed: 0.0314s/iter; left time: 104.4106s
[36m(_train_fn pid=753894)[0m 	iters: 200, epoch: 2 | loss: 0.5609648
[36m(_train_fn pid=753894)[0m 	speed: 0.0121s/iter; left time: 38.8612s
[36m(_train_fn pid=753894)[0m 	iters: 300, epoch: 2 | loss: 0.6142743
[36m(_train_fn pid=753894)[0m 	speed: 0.0120s/iter; left time: 37.5729s
[36m(_train_fn pid=753894)[0m 	iters: 400, epoch: 2 | loss: 0.6591694
[36m(_train_fn pid=753894)[0m 	speed: 0.0121s/iter; left time: 36.5046s
[36m(_train_fn pid=753894)[0m Updating learning rate to 0.0010826773339503103
[36m(_train_fn pid=753894)[0m saving checkpoint...
[36m(_train_fn pid=753894)[0m Validation loss decreased (1.8600 --> 1.5980).  Saving model state dict ...
[36m(_train_fn pid=753894)[0m Epoch: 2 cost time: 5.93638801574707
[36m(_train_fn pid=753894)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6245541 Vali Loss: 1.5979690 Best vali loss: 1.5979690
[36m(_train_fn pid=753894)[0m 	iters: 100, epoch: 3 | loss: 0.5782312
[36m(_train_fn pid=753894)[0m 	speed: 0.0299s/iter; left time: 84.8761s
[36m(_train_fn pid=753894)[0m 	iters: 200, epoch: 3 | loss: 0.6357735
[36m(_train_fn pid=753894)[0m 	speed: 0.0120s/iter; left time: 32.9440s
[36m(_train_fn pid=753894)[0m 	iters: 300, epoch: 3 | loss: 0.6216549
[36m(_train_fn pid=753894)[0m 	speed: 0.0119s/iter; left time: 31.4193s

Trial status: 19 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:36:10. Total running time: 15min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-85234c81   RUNNING           2           14.7384        0.624554        1.59797             1.59797 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138        1.631               1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496        1.60426             1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809         1.61431             1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399        1.97416             1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482        1.70109             1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781        1.63017             1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552        1.63098             1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829        1.66408             1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563         1.58949             1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143        1.62851             1.62851 â”‚
â”‚ trial-c515a439   TERMINATED        8           16.7843        0.614096        1.59012             1.58937 â”‚
â”‚ trial-eff11b3a   TERMINATED        4          105.348         0.58908         1.60903             1.59461 â”‚
â”‚ trial-ce680db1   TERMINATED        5           46.2896        0.561379        1.58649             1.5698  â”‚
â”‚ trial-3e25555f   TERMINATED        8           15.0816        0.648012        1.63981             1.63981 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=753894)[0m 	iters: 400, epoch: 3 | loss: 0.5318884
[36m(_train_fn pid=753894)[0m 	speed: 0.0120s/iter; left time: 30.4064s
[36m(_train_fn pid=753894)[0m Updating learning rate to 0.0005413386669751552
[36m(_train_fn pid=753894)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=753894)[0m saving checkpoint...
[36m(_train_fn pid=753894)[0m Epoch: 3 cost time: 5.903337717056274
[36m(_train_fn pid=753894)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5805166 Vali Loss: 1.6410952 Best vali loss: 1.5979690
[36m(_train_fn pid=753894)[0m 	iters: 100, epoch: 4 | loss: 0.5339079
[36m(_train_fn pid=753894)[0m 	speed: 0.0313s/iter; left time: 73.4793s
[36m(_train_fn pid=753894)[0m 	iters: 200, epoch: 4 | loss: 0.6689058
[36m(_train_fn pid=753894)[0m 	speed: 0.0135s/iter; left time: 30.4028s
[36m(_train_fn pid=753894)[0m 	iters: 300, epoch: 4 | loss: 0.6153271
[36m(_train_fn pid=753894)[0m 	speed: 0.0136s/iter; left time: 29.1248s
[36m(_train_fn pid=753894)[0m 	iters: 400, epoch: 4 | loss: 0.5643801
[36m(_train_fn pid=753894)[0m 	speed: 0.0135s/iter; left time: 27.6845s
[36m(_train_fn pid=753894)[0m Updating learning rate to 0.0002706693334875776
[36m(_train_fn pid=753894)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=753894)[0m saving checkpoint...
[36m(_train_fn pid=753894)[0m Epoch: 4 cost time: 6.662839889526367
[36m(_train_fn pid=753894)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5611029 Vali Loss: 1.6430351 Best vali loss: 1.5979690
[36m(_train_fn pid=753894)[0m 	iters: 100, epoch: 5 | loss: 0.6250725
[36m(_train_fn pid=753894)[0m 	speed: 0.0311s/iter; left time: 57.7342s
[36m(_train_fn pid=753894)[0m 	iters: 200, epoch: 5 | loss: 0.5676522
[36m(_train_fn pid=753894)[0m 	speed: 0.0119s/iter; left time: 20.9202s
[36m(_train_fn pid=753894)[0m 	iters: 300, epoch: 5 | loss: 0.5408511
[36m(_train_fn pid=753894)[0m 	speed: 0.0119s/iter; left time: 19.7147s
[36m(_train_fn pid=753894)[0m 	iters: 400, epoch: 5 | loss: 0.5347807
[36m(_train_fn pid=753894)[0m 	speed: 0.0119s/iter; left time: 18.6024s

Trial trial-85234c81 completed after 5 iterations at 2024-08-24 07:36:26. Total running time: 15min 17s
[36m(_train_fn pid=753894)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-85234c81_20_alpha_d_ff=2,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1180,e_layers=_2024-08-24_07-35-49/checkpoint_000004)
[36m(_train_fn pid=754442)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f4eb6174_21_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-36-26/checkpoint_000000)
[36m(_train_fn pid=754442)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f4eb6174_21_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-36-26/checkpoint_000001)
[36m(_train_fn pid=754442)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f4eb6174_21_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-36-26/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-85234c81 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          6.55133 â”‚
â”‚ time_total_s                             35.19303 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59797 â”‚
â”‚ train_loss                                0.55007 â”‚
â”‚ valid_loss                                1.68666 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=753894)[0m Updating learning rate to 0.0001353346667437888
[36m(_train_fn pid=753894)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=753894)[0m saving checkpoint...
[36m(_train_fn pid=753894)[0m Epoch: 5 cost time: 5.86998438835144
[36m(_train_fn pid=753894)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5500719 Vali Loss: 1.6866557 Best vali loss: 1.5979690
[36m(_train_fn pid=753894)[0m Early stopping

Trial trial-f4eb6174 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f4eb6174 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.08575 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00269 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=754442)[0m configuration
[36m(_train_fn pid=754442)[0m {'batch_size': 16, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.08574615620252438, 'e_layers': 4, 'learning_rate': 0.0026917288040676983, 'd_ff': 24}
[36m(_train_fn pid=754442)[0m Use GPU: cuda:0
[36m(_train_fn pid=754442)[0m train 7825
[36m(_train_fn pid=754442)[0m val 2161
[36m(_train_fn pid=754442)[0m start_epoch 0
[36m(_train_fn pid=754442)[0m max_epoch 8
[36m(_train_fn pid=754442)[0m 	iters: 100, epoch: 1 | loss: 1.2280856
[36m(_train_fn pid=754442)[0m 	speed: 0.0183s/iter; left time: 69.6797s
[36m(_train_fn pid=754442)[0m 	iters: 200, epoch: 1 | loss: 0.9199959
[36m(_train_fn pid=754442)[0m 	speed: 0.0132s/iter; left time: 48.8798s
[36m(_train_fn pid=754442)[0m 	iters: 300, epoch: 1 | loss: 0.7345706
[36m(_train_fn pid=754442)[0m 	speed: 0.0131s/iter; left time: 47.3558s
[36m(_train_fn pid=754442)[0m 	iters: 400, epoch: 1 | loss: 0.7681191
[36m(_train_fn pid=754442)[0m 	speed: 0.0118s/iter; left time: 41.5916s
[36m(_train_fn pid=754442)[0m Updating learning rate to 0.0026917288040676983
[36m(_train_fn pid=754442)[0m saving checkpoint...
[36m(_train_fn pid=754442)[0m Validation loss decreased (inf --> 1.6766).  Saving model state dict ...
[36m(_train_fn pid=754442)[0m Epoch: 1 cost time: 6.4250168800354
[36m(_train_fn pid=754442)[0m Epoch: 1, Steps: 489 | Train Loss: 0.9380787 Vali Loss: 1.6766210 Best vali loss: 1.6766210
[36m(_train_fn pid=754442)[0m 	iters: 100, epoch: 2 | loss: 0.6074550
[36m(_train_fn pid=754442)[0m 	speed: 0.0286s/iter; left time: 95.1375s
[36m(_train_fn pid=754442)[0m 	iters: 200, epoch: 2 | loss: 0.5655324
[36m(_train_fn pid=754442)[0m 	speed: 0.0117s/iter; left time: 37.7468s
[36m(_train_fn pid=754442)[0m 	iters: 300, epoch: 2 | loss: 0.5698752
[36m(_train_fn pid=754442)[0m 	speed: 0.0117s/iter; left time: 36.4957s

Trial status: 20 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:36:40. Total running time: 15min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f4eb6174   RUNNING           1            7.42091       0.938079        1.67662             1.67662 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
15 more TERMINATED
[36m(_train_fn pid=754442)[0m 	iters: 400, epoch: 2 | loss: 0.6114665
[36m(_train_fn pid=754442)[0m 	speed: 0.0116s/iter; left time: 35.1888s
[36m(_train_fn pid=754442)[0m Updating learning rate to 0.0013458644020338491
[36m(_train_fn pid=754442)[0m saving checkpoint...
[36m(_train_fn pid=754442)[0m Validation loss decreased (1.6766 --> 1.5831).  Saving model state dict ...
[36m(_train_fn pid=754442)[0m Epoch: 2 cost time: 5.760655164718628
[36m(_train_fn pid=754442)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6075838 Vali Loss: 1.5830985 Best vali loss: 1.5830985
[36m(_train_fn pid=754442)[0m 	iters: 100, epoch: 3 | loss: 0.5133644
[36m(_train_fn pid=754442)[0m 	speed: 0.0286s/iter; left time: 80.9401s
[36m(_train_fn pid=754442)[0m 	iters: 200, epoch: 3 | loss: 0.4603781
[36m(_train_fn pid=754442)[0m 	speed: 0.0115s/iter; left time: 31.3336s
[36m(_train_fn pid=754442)[0m 	iters: 300, epoch: 3 | loss: 0.5498721
[36m(_train_fn pid=754442)[0m 	speed: 0.0114s/iter; left time: 30.0416s
[36m(_train_fn pid=754442)[0m 	iters: 400, epoch: 3 | loss: 0.7018434
[36m(_train_fn pid=754442)[0m 	speed: 0.0114s/iter; left time: 28.9684s
[36m(_train_fn pid=754442)[0m Updating learning rate to 0.0006729322010169246
[36m(_train_fn pid=754442)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=754442)[0m saving checkpoint...
[36m(_train_fn pid=754442)[0m Epoch: 3 cost time: 5.6501781940460205
[36m(_train_fn pid=754442)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5709466 Vali Loss: 1.6131573 Best vali loss: 1.5830985
[36m(_train_fn pid=754442)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f4eb6174_21_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-36-26/checkpoint_000003)
[36m(_train_fn pid=754442)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f4eb6174_21_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-36-26/checkpoint_000004)
[36m(_train_fn pid=754983)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ae4bfd_22_alpha_d_ff=2,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1088,e_layers=_2024-08-24_07-37-01/checkpoint_000000)
[36m(_train_fn pid=754442)[0m 	iters: 100, epoch: 4 | loss: 0.5580909
[36m(_train_fn pid=754442)[0m 	speed: 0.0283s/iter; left time: 66.3191s
[36m(_train_fn pid=754442)[0m 	iters: 200, epoch: 4 | loss: 0.5870084
[36m(_train_fn pid=754442)[0m 	speed: 0.0116s/iter; left time: 26.1145s
[36m(_train_fn pid=754442)[0m 	iters: 300, epoch: 4 | loss: 0.5579221
[36m(_train_fn pid=754442)[0m 	speed: 0.0116s/iter; left time: 24.8211s
[36m(_train_fn pid=754442)[0m 	iters: 400, epoch: 4 | loss: 0.5475181
[36m(_train_fn pid=754442)[0m 	speed: 0.0117s/iter; left time: 23.9015s
[36m(_train_fn pid=754442)[0m Updating learning rate to 0.0003364661005084623
[36m(_train_fn pid=754442)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=754442)[0m saving checkpoint...
[36m(_train_fn pid=754442)[0m Epoch: 4 cost time: 5.744008541107178
[36m(_train_fn pid=754442)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5517704 Vali Loss: 1.6265227 Best vali loss: 1.5830985
[36m(_train_fn pid=754442)[0m 	iters: 100, epoch: 5 | loss: 0.5599650
[36m(_train_fn pid=754442)[0m 	speed: 0.0300s/iter; left time: 55.6448s
[36m(_train_fn pid=754442)[0m 	iters: 200, epoch: 5 | loss: 0.4992104
[36m(_train_fn pid=754442)[0m 	speed: 0.0132s/iter; left time: 23.2321s
[36m(_train_fn pid=754442)[0m 	iters: 300, epoch: 5 | loss: 0.5258496
[36m(_train_fn pid=754442)[0m 	speed: 0.0132s/iter; left time: 21.9028s
[36m(_train_fn pid=754442)[0m 	iters: 400, epoch: 5 | loss: 0.5161765
[36m(_train_fn pid=754442)[0m 	speed: 0.0132s/iter; left time: 20.5504s

Trial trial-f4eb6174 completed after 5 iterations at 2024-08-24 07:37:01. Total running time: 15min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f4eb6174 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          7.11422 â”‚
â”‚ time_total_s                             33.48892 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                            1.5831 â”‚
â”‚ train_loss                                0.53847 â”‚
â”‚ valid_loss                                1.61271 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=754442)[0m Updating learning rate to 0.00016823305025423114
[36m(_train_fn pid=754442)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=754442)[0m saving checkpoint...
[36m(_train_fn pid=754442)[0m Epoch: 5 cost time: 6.506057977676392
[36m(_train_fn pid=754442)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5384666 Vali Loss: 1.6127136 Best vali loss: 1.5830985
[36m(_train_fn pid=754442)[0m Early stopping

Trial trial-c0ae4bfd started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c0ae4bfd config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10881 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00068 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=754983)[0m configuration
[36m(_train_fn pid=754983)[0m {'batch_size': 16, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1088131757058847, 'e_layers': 3, 'learning_rate': 0.0006767066134725878, 'd_ff': 128}
[36m(_train_fn pid=754983)[0m Use GPU: cuda:0
[36m(_train_fn pid=754983)[0m train 7825
[36m(_train_fn pid=754983)[0m val 2161
[36m(_train_fn pid=754983)[0m start_epoch 0
[36m(_train_fn pid=754983)[0m max_epoch 8
[36m(_train_fn pid=754983)[0m 	iters: 100, epoch: 1 | loss: 0.7351595
[36m(_train_fn pid=754983)[0m 	speed: 0.0187s/iter; left time: 71.3451s
[36m(_train_fn pid=754983)[0m 	iters: 200, epoch: 1 | loss: 0.6763084
[36m(_train_fn pid=754983)[0m 	speed: 0.0115s/iter; left time: 42.7765s
[36m(_train_fn pid=754983)[0m 	iters: 300, epoch: 1 | loss: 0.6924267
[36m(_train_fn pid=754983)[0m 	speed: 0.0115s/iter; left time: 41.4902s
[36m(_train_fn pid=754983)[0m 	iters: 400, epoch: 1 | loss: 0.8682152
[36m(_train_fn pid=754983)[0m 	speed: 0.0115s/iter; left time: 40.5352s

Trial status: 21 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:37:10. Total running time: 16min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c0ae4bfd   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
16 more TERMINATED
[36m(_train_fn pid=754983)[0m Updating learning rate to 0.0006767066134725878
[36m(_train_fn pid=754983)[0m saving checkpoint...
[36m(_train_fn pid=754983)[0m Validation loss decreased (inf --> 1.9011).  Saving model state dict ...
[36m(_train_fn pid=754983)[0m Epoch: 1 cost time: 6.097365617752075
[36m(_train_fn pid=754983)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7880828 Vali Loss: 1.9010832 Best vali loss: 1.9010832
[36m(_train_fn pid=754983)[0m 	iters: 100, epoch: 2 | loss: 0.6312344
[36m(_train_fn pid=754983)[0m 	speed: 0.0302s/iter; left time: 100.5385s
[36m(_train_fn pid=754983)[0m 	iters: 200, epoch: 2 | loss: 0.5806886
[36m(_train_fn pid=754983)[0m 	speed: 0.0116s/iter; left time: 37.4346s
[36m(_train_fn pid=754983)[0m 	iters: 300, epoch: 2 | loss: 0.5523619
[36m(_train_fn pid=754983)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ae4bfd_22_alpha_d_ff=2,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1088,e_layers=_2024-08-24_07-37-01/checkpoint_000001)
[36m(_train_fn pid=754983)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ae4bfd_22_alpha_d_ff=2,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1088,e_layers=_2024-08-24_07-37-01/checkpoint_000002)
[36m(_train_fn pid=754983)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ae4bfd_22_alpha_d_ff=2,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1088,e_layers=_2024-08-24_07-37-01/checkpoint_000003)
[36m(_train_fn pid=754983)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ae4bfd_22_alpha_d_ff=2,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1088,e_layers=_2024-08-24_07-37-01/checkpoint_000004)
[36m(_train_fn pid=754983)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ae4bfd_22_alpha_d_ff=2,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1088,e_layers=_2024-08-24_07-37-01/checkpoint_000005)
[36m(_train_fn pid=754983)[0m 	speed: 0.0116s/iter; left time: 36.2062s
[36m(_train_fn pid=754983)[0m 	iters: 400, epoch: 2 | loss: 0.5454220
[36m(_train_fn pid=754983)[0m 	speed: 0.0116s/iter; left time: 35.1030s
[36m(_train_fn pid=754983)[0m Updating learning rate to 0.0003383533067362939
[36m(_train_fn pid=754983)[0m saving checkpoint...
[36m(_train_fn pid=754983)[0m Validation loss decreased (1.9011 --> 1.6157).  Saving model state dict ...
[36m(_train_fn pid=754983)[0m Epoch: 2 cost time: 5.716164827346802
[36m(_train_fn pid=754983)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6255984 Vali Loss: 1.6157270 Best vali loss: 1.6157270
[36m(_train_fn pid=754983)[0m 	iters: 100, epoch: 3 | loss: 0.7278379
[36m(_train_fn pid=754983)[0m 	speed: 0.0297s/iter; left time: 84.2344s
[36m(_train_fn pid=754983)[0m 	iters: 200, epoch: 3 | loss: 0.6804481
[36m(_train_fn pid=754983)[0m 	speed: 0.0109s/iter; left time: 29.8406s
[36m(_train_fn pid=754983)[0m 	iters: 300, epoch: 3 | loss: 0.5358733
[36m(_train_fn pid=754983)[0m 	speed: 0.0109s/iter; left time: 28.6912s
[36m(_train_fn pid=754983)[0m 	iters: 400, epoch: 3 | loss: 0.5945845
[36m(_train_fn pid=754983)[0m 	speed: 0.0109s/iter; left time: 27.6858s
[36m(_train_fn pid=754983)[0m Updating learning rate to 0.00016917665336814696
[36m(_train_fn pid=754983)[0m saving checkpoint...
[36m(_train_fn pid=754983)[0m Validation loss decreased (1.6157 --> 1.5866).  Saving model state dict ...
[36m(_train_fn pid=754983)[0m Epoch: 3 cost time: 5.388995409011841
[36m(_train_fn pid=754983)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5887227 Vali Loss: 1.5865665 Best vali loss: 1.5865665
[36m(_train_fn pid=754983)[0m 	iters: 100, epoch: 4 | loss: 0.5584425
[36m(_train_fn pid=754983)[0m 	speed: 0.0289s/iter; left time: 67.8074s
[36m(_train_fn pid=754983)[0m 	iters: 200, epoch: 4 | loss: 0.4987266
[36m(_train_fn pid=754983)[0m 	speed: 0.0107s/iter; left time: 24.0129s
[36m(_train_fn pid=754983)[0m 	iters: 300, epoch: 4 | loss: 0.4515795
[36m(_train_fn pid=754983)[0m 	speed: 0.0107s/iter; left time: 22.9869s
[36m(_train_fn pid=754983)[0m 	iters: 400, epoch: 4 | loss: 0.5121195
[36m(_train_fn pid=754983)[0m 	speed: 0.0109s/iter; left time: 22.2130s
[36m(_train_fn pid=754983)[0m Updating learning rate to 8.458832668407348e-05
[36m(_train_fn pid=754983)[0m saving checkpoint...
[36m(_train_fn pid=754983)[0m Validation loss decreased (1.5866 --> 1.5786).  Saving model state dict ...
[36m(_train_fn pid=754983)[0m Epoch: 4 cost time: 5.328819513320923
[36m(_train_fn pid=754983)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5722143 Vali Loss: 1.5785839 Best vali loss: 1.5785839
[36m(_train_fn pid=754983)[0m 	iters: 100, epoch: 5 | loss: 0.4476072
[36m(_train_fn pid=754983)[0m 	speed: 0.0289s/iter; left time: 53.7002s
[36m(_train_fn pid=754983)[0m 	iters: 200, epoch: 5 | loss: 0.4864178
[36m(_train_fn pid=754983)[0m 	speed: 0.0108s/iter; left time: 19.0594s
[36m(_train_fn pid=754983)[0m 	iters: 300, epoch: 5 | loss: 0.5680195
[36m(_train_fn pid=754983)[0m 	speed: 0.0108s/iter; left time: 17.9291s
[36m(_train_fn pid=754983)[0m 	iters: 400, epoch: 5 | loss: 0.6298363
[36m(_train_fn pid=754983)[0m 	speed: 0.0110s/iter; left time: 17.0528s
[36m(_train_fn pid=754983)[0m Updating learning rate to 4.229416334203674e-05
[36m(_train_fn pid=754983)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=754983)[0m saving checkpoint...
[36m(_train_fn pid=754983)[0m Epoch: 5 cost time: 5.35491943359375
[36m(_train_fn pid=754983)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5641791 Vali Loss: 1.5919196 Best vali loss: 1.5785839
[36m(_train_fn pid=754983)[0m 	iters: 100, epoch: 6 | loss: 0.5776648
[36m(_train_fn pid=754983)[0m 	speed: 0.0286s/iter; left time: 39.1665s
[36m(_train_fn pid=754983)[0m 	iters: 200, epoch: 6 | loss: 0.5027714
[36m(_train_fn pid=754983)[0m 	speed: 0.0110s/iter; left time: 13.9773s
[36m(_train_fn pid=754983)[0m 	iters: 300, epoch: 6 | loss: 0.5504117
[36m(_train_fn pid=754983)[0m 	speed: 0.0109s/iter; left time: 12.7419s
Trial status: 21 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:37:40. Total running time: 16min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c0ae4bfd   RUNNING           5            32.2238       0.564179        1.59192             1.57858 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
16 more TERMINATED
[36m(_train_fn pid=754983)[0m 	iters: 400, epoch: 6 | loss: 0.5117672
[36m(_train_fn pid=754983)[0m 	speed: 0.0108s/iter; left time: 11.5454s
[36m(_train_fn pid=754983)[0m Updating learning rate to 2.114708167101837e-05
[36m(_train_fn pid=754983)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=754983)[0m saving checkpoint...
[36m(_train_fn pid=754983)[0m Epoch: 6 cost time: 5.417742729187012
[36m(_train_fn pid=754983)[0m Epoch: 6, Steps: 489 | Train Loss: 0.5602774 Vali Loss: 1.5858696 Best vali loss: 1.5785839
[36m(_train_fn pid=754983)[0m 	iters: 100, epoch: 7 | loss: 0.4906004
[36m(_train_fn pid=754983)[0m 	speed: 0.0302s/iter; left time: 26.5172s
[36m(_train_fn pid=754983)[0m 	iters: 200, epoch: 7 | loss: 0.5551782
[36m(_train_fn pid=754983)[0m 	speed: 0.0117s/iter; left time: 9.0923s
[36m(_train_fn pid=754983)[0m 	iters: 300, epoch: 7 | loss: 0.5358501
[36m(_train_fn pid=754983)[0m 	speed: 0.0118s/iter; left time: 7.9801s
[36m(_train_fn pid=754983)[0m 	iters: 400, epoch: 7 | loss: 0.6141639
[36m(_train_fn pid=754983)[0m 	speed: 0.0117s/iter; left time: 6.7705s
[36m(_train_fn pid=754983)[0m Updating learning rate to 1.0573540835509185e-05
[36m(_train_fn pid=754983)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=754983)[0m saving checkpoint...
[36m(_train_fn pid=754983)[0m Epoch: 7 cost time: 5.769437074661255
[36m(_train_fn pid=754983)[0m Epoch: 7, Steps: 489 | Train Loss: 0.5587548 Vali Loss: 1.5865663 Best vali loss: 1.5785839
[36m(_train_fn pid=754983)[0m Early stopping

Trial trial-c0ae4bfd completed after 7 iterations at 2024-08-24 07:37:49. Total running time: 16min 40s
[36m(_train_fn pid=754983)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ae4bfd_22_alpha_d_ff=2,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1088,e_layers=_2024-08-24_07-37-01/checkpoint_000006)
[36m(_train_fn pid=755701)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fccc4bc0_23_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0884,e_layers=_2024-08-24_07-37-49/checkpoint_000000)
2024-08-24 07:37:59,122	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=755701)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fccc4bc0_23_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0884,e_layers=_2024-08-24_07-37-49/checkpoint_000001)
2024-08-24 07:38:02,482	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=755701)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fccc4bc0_23_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0884,e_layers=_2024-08-24_07-37-49/checkpoint_000002)
2024-08-24 07:38:05,732	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=755701)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fccc4bc0_23_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0884,e_layers=_2024-08-24_07-37-49/checkpoint_000003)
2024-08-24 07:38:08,977	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=755701)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fccc4bc0_23_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0884,e_layers=_2024-08-24_07-37-49/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c0ae4bfd result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          6.54818 â”‚
â”‚ time_total_s                             44.97021 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.57858 â”‚
â”‚ train_loss                                0.55875 â”‚
â”‚ valid_loss                                1.58657 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-fccc4bc0 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fccc4bc0 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.08842 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00351 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=755701)[0m configuration
[36m(_train_fn pid=755701)[0m {'batch_size': 16, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.08841679656276359, 'e_layers': 1, 'learning_rate': 0.00350736338472329, 'd_ff': 64}
[36m(_train_fn pid=755701)[0m Use GPU: cuda:0
[36m(_train_fn pid=755701)[0m train 7825
[36m(_train_fn pid=755701)[0m val 2161
[36m(_train_fn pid=755701)[0m start_epoch 0
[36m(_train_fn pid=755701)[0m max_epoch 8
[36m(_train_fn pid=755701)[0m 	iters: 100, epoch: 1 | loss: 0.8426039
[36m(_train_fn pid=755701)[0m 	speed: 0.0135s/iter; left time: 51.4188s
[36m(_train_fn pid=755701)[0m 	iters: 200, epoch: 1 | loss: 0.6522778
[36m(_train_fn pid=755701)[0m 	speed: 0.0063s/iter; left time: 23.5032s
[36m(_train_fn pid=755701)[0m 	iters: 300, epoch: 1 | loss: 0.7024888
[36m(_train_fn pid=755701)[0m 	speed: 0.0063s/iter; left time: 22.7343s
[36m(_train_fn pid=755701)[0m 	iters: 400, epoch: 1 | loss: 0.7949676
[36m(_train_fn pid=755701)[0m 	speed: 0.0061s/iter; left time: 21.3130s
[36m(_train_fn pid=755701)[0m Updating learning rate to 0.00350736338472329
[36m(_train_fn pid=755701)[0m saving checkpoint...
[36m(_train_fn pid=755701)[0m Validation loss decreased (inf --> 1.6159).  Saving model state dict ...
[36m(_train_fn pid=755701)[0m Epoch: 1 cost time: 3.4867281913757324
[36m(_train_fn pid=755701)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7506089 Vali Loss: 1.6159466 Best vali loss: 1.6159466
[36m(_train_fn pid=755701)[0m 	iters: 100, epoch: 2 | loss: 0.5746064
[36m(_train_fn pid=755701)[0m 	speed: 0.0160s/iter; left time: 53.2884s
[36m(_train_fn pid=755701)[0m 	iters: 200, epoch: 2 | loss: 0.7047482
[36m(_train_fn pid=755701)[0m 	speed: 0.0059s/iter; left time: 19.1088s
[36m(_train_fn pid=755701)[0m 	iters: 300, epoch: 2 | loss: 0.5264689
[36m(_train_fn pid=755701)[0m 	speed: 0.0059s/iter; left time: 18.3957s
[36m(_train_fn pid=755701)[0m 	iters: 400, epoch: 2 | loss: 0.6573486
[36m(_train_fn pid=755701)[0m 	speed: 0.0060s/iter; left time: 18.1179s
[36m(_train_fn pid=755701)[0m Updating learning rate to 0.001753681692361645
[36m(_train_fn pid=755701)[0m saving checkpoint...
[36m(_train_fn pid=755701)[0m Validation loss decreased (1.6159 --> 1.5857).  Saving model state dict ...
[36m(_train_fn pid=755701)[0m Epoch: 2 cost time: 2.939699172973633
[36m(_train_fn pid=755701)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6056605 Vali Loss: 1.5856867 Best vali loss: 1.5856867
[36m(_train_fn pid=755701)[0m 	iters: 100, epoch: 3 | loss: 0.4949225
[36m(_train_fn pid=755701)[0m 	speed: 0.0165s/iter; left time: 46.6945s
[36m(_train_fn pid=755701)[0m 	iters: 200, epoch: 3 | loss: 0.6140832
[36m(_train_fn pid=755701)[0m 	speed: 0.0060s/iter; left time: 16.4391s
[36m(_train_fn pid=755701)[0m 	iters: 300, epoch: 3 | loss: 0.6961544
[36m(_train_fn pid=755701)[0m 	speed: 0.0058s/iter; left time: 15.1780s
[36m(_train_fn pid=755701)[0m 	iters: 400, epoch: 3 | loss: 0.5390783
[36m(_train_fn pid=755701)[0m 	speed: 0.0057s/iter; left time: 14.4119s
[36m(_train_fn pid=755701)[0m Updating learning rate to 0.0008768408461808225
[36m(_train_fn pid=755701)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=755701)[0m saving checkpoint...
[36m(_train_fn pid=755701)[0m Epoch: 3 cost time: 2.942448139190674
[36m(_train_fn pid=755701)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5758588 Vali Loss: 1.6224413 Best vali loss: 1.5856867
[36m(_train_fn pid=755701)[0m 	iters: 100, epoch: 4 | loss: 0.6932265
[36m(_train_fn pid=755701)[0m 	speed: 0.0153s/iter; left time: 35.9760s
[36m(_train_fn pid=755701)[0m 	iters: 200, epoch: 4 | loss: 0.4947478
[36m(_train_fn pid=755701)[0m 	speed: 0.0057s/iter; left time: 12.7129s
[36m(_train_fn pid=755701)[0m 	iters: 300, epoch: 4 | loss: 0.6032220
[36m(_train_fn pid=755701)[0m 	speed: 0.0055s/iter; left time: 11.9057s
[36m(_train_fn pid=755701)[0m 	iters: 400, epoch: 4 | loss: 0.5536388
[36m(_train_fn pid=755701)[0m 	speed: 0.0056s/iter; left time: 11.4453s
[36m(_train_fn pid=755701)[0m Updating learning rate to 0.00043842042309041125
[36m(_train_fn pid=755701)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=755701)[0m saving checkpoint...
[36m(_train_fn pid=755701)[0m Epoch: 4 cost time: 2.825542449951172
[36m(_train_fn pid=755701)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5572541 Vali Loss: 1.6176849 Best vali loss: 1.5856867
[36m(_train_fn pid=755701)[0m 	iters: 100, epoch: 5 | loss: 0.6386977
[36m(_train_fn pid=755701)[0m 	speed: 0.0157s/iter; left time: 29.0999s
[36m(_train_fn pid=755701)[0m 	iters: 200, epoch: 5 | loss: 0.4801794
[36m(_train_fn pid=755701)[0m 	speed: 0.0057s/iter; left time: 9.9592s
[36m(_train_fn pid=755701)[0m 	iters: 300, epoch: 5 | loss: 0.4753021
[36m(_train_fn pid=755701)[0m 	speed: 0.0057s/iter; left time: 9.4608s
[36m(_train_fn pid=755701)[0m 	iters: 400, epoch: 5 | loss: 0.5570882
[36m(_train_fn pid=755701)[0m 	speed: 0.0057s/iter; left time: 8.8699s

Trial trial-fccc4bc0 completed after 5 iterations at 2024-08-24 07:38:08. Total running time: 17min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fccc4bc0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.24264 â”‚
â”‚ time_total_s                             17.54682 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58569 â”‚
â”‚ train_loss                                0.54456 â”‚
â”‚ valid_loss                                1.63227 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=755701)[0m Updating learning rate to 0.00021921021154520563
[36m(_train_fn pid=755701)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=755701)[0m saving checkpoint...
[36m(_train_fn pid=756232)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1dd9d13_24_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_07-38-08/checkpoint_000000)
2024-08-24 07:38:57,730	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=756232)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1dd9d13_24_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_07-38-08/checkpoint_000001)
[36m(_train_fn pid=755701)[0m Epoch: 5 cost time: 2.8217124938964844
[36m(_train_fn pid=755701)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5445578 Vali Loss: 1.6322655 Best vali loss: 1.5856867
[36m(_train_fn pid=755701)[0m Early stopping

Trial status: 23 TERMINATED | 1 PENDING
Current time: 2024-08-24 07:38:10. Total running time: 17min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-e1dd9d13   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED

Trial trial-e1dd9d13 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e1dd9d13 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09209 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00111 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=756232)[0m configuration
[36m(_train_fn pid=756232)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'conv', 'dropout': 0.09209471286683422, 'e_layers': 1, 'learning_rate': 0.001110959647597393, 'd_ff': 2048}
[36m(_train_fn pid=756232)[0m Use GPU: cuda:0
[36m(_train_fn pid=756232)[0m train 7825
[36m(_train_fn pid=756232)[0m val 2161
[36m(_train_fn pid=756232)[0m start_epoch 0
[36m(_train_fn pid=756232)[0m max_epoch 8
[36m(_train_fn pid=756232)[0m 	iters: 100, epoch: 1 | loss: 0.7739544
[36m(_train_fn pid=756232)[0m 	speed: 0.0881s/iter; left time: 163.2092s
[36m(_train_fn pid=756232)[0m 	iters: 200, epoch: 1 | loss: 0.7156401
[36m(_train_fn pid=756232)[0m 	speed: 0.0834s/iter; left time: 146.2810s
[36m(_train_fn pid=756232)[0m Updating learning rate to 0.001110959647597393
[36m(_train_fn pid=756232)[0m saving checkpoint...
[36m(_train_fn pid=756232)[0m Validation loss decreased (inf --> 1.8870).  Saving model state dict ...
[36m(_train_fn pid=756232)[0m Epoch: 1 cost time: 20.558469772338867
[36m(_train_fn pid=756232)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7661206 Vali Loss: 1.8869623 Best vali loss: 1.8869623

Trial status: 23 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:38:40. Total running time: 17min 31s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e1dd9d13   RUNNING           1            23.4256       0.766121        1.88696             1.88696 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED
[36m(_train_fn pid=756232)[0m 	iters: 100, epoch: 2 | loss: 0.6481429
[36m(_train_fn pid=756232)[0m 	speed: 0.1447s/iter; left time: 232.8626s
[36m(_train_fn pid=756232)[0m 	iters: 200, epoch: 2 | loss: 0.6501441
[36m(_train_fn pid=756232)[0m 	speed: 0.0840s/iter; left time: 126.7544s
[36m(_train_fn pid=756232)[0m Updating learning rate to 0.0005554798237986965
[36m(_train_fn pid=756232)[0m saving checkpoint...
[36m(_train_fn pid=756232)[0m Validation loss decreased (1.8870 --> 1.6297).  Saving model state dict ...
[36m(_train_fn pid=756232)[0m Epoch: 2 cost time: 20.478392601013184
[36m(_train_fn pid=756232)[0m Epoch: 2, Steps: 244 | Train Loss: 0.9481510 Vali Loss: 1.6296999 Best vali loss: 1.6296999
[36m(_train_fn pid=756232)[0m 	iters: 100, epoch: 3 | loss: 0.6951867
[36m(_train_fn pid=756232)[0m 	speed: 0.1452s/iter; left time: 198.2373s
Trial status: 23 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:39:10. Total running time: 18min 1s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 07:39:20,674	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=756232)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1dd9d13_24_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_07-38-08/checkpoint_000002)
2024-08-24 07:39:43,649	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=756232)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1dd9d13_24_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_07-38-08/checkpoint_000003)
2024-08-24 07:40:06,640	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=756232)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1dd9d13_24_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_07-38-08/checkpoint_000004)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e1dd9d13   RUNNING           2            46.3255       0.948151        1.6297              1.6297  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED
[36m(_train_fn pid=756232)[0m 	iters: 200, epoch: 3 | loss: 0.6305501
[36m(_train_fn pid=756232)[0m 	speed: 0.0842s/iter; left time: 106.5000s
[36m(_train_fn pid=756232)[0m Updating learning rate to 0.00027773991189934823
[36m(_train_fn pid=756232)[0m saving checkpoint...
[36m(_train_fn pid=756232)[0m Validation loss decreased (1.6297 --> 1.5962).  Saving model state dict ...
[36m(_train_fn pid=756232)[0m Epoch: 3 cost time: 20.52838706970215
[36m(_train_fn pid=756232)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6325271 Vali Loss: 1.5961571 Best vali loss: 1.5961571
[36m(_train_fn pid=756232)[0m 	iters: 100, epoch: 4 | loss: 0.5918615
[36m(_train_fn pid=756232)[0m 	speed: 0.1454s/iter; left time: 163.0232s
[36m(_train_fn pid=756232)[0m 	iters: 200, epoch: 4 | loss: 0.6013362
[36m(_train_fn pid=756232)[0m 	speed: 0.0842s/iter; left time: 85.9416s
Trial status: 23 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:39:40. Total running time: 18min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e1dd9d13   RUNNING           3            69.2645       0.632527        1.59616             1.59616 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
18 more TERMINATED
[36m(_train_fn pid=756232)[0m Updating learning rate to 0.00013886995594967412
[36m(_train_fn pid=756232)[0m saving checkpoint...
[36m(_train_fn pid=756232)[0m Validation loss decreased (1.5962 --> 1.5857).  Saving model state dict ...
[36m(_train_fn pid=756232)[0m Epoch: 4 cost time: 20.541418313980103
[36m(_train_fn pid=756232)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6227398 Vali Loss: 1.5857007 Best vali loss: 1.5857007
[36m(_train_fn pid=756232)[0m 	iters: 100, epoch: 5 | loss: 0.6451011
[36m(_train_fn pid=756232)[0m 	speed: 0.1456s/iter; left time: 127.7206s
[36m(_train_fn pid=756232)[0m 	iters: 200, epoch: 5 | loss: 0.5212827
[36m(_train_fn pid=756232)[0m 	speed: 0.0843s/iter; left time: 65.4915s

Trial trial-e1dd9d13 completed after 5 iterations at 2024-08-24 07:40:06. Total running time: 18min 57s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e1dd9d13 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         22.98535 â”‚
â”‚ time_total_s                            115.22053 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58017 â”‚
â”‚ train_loss                                 0.6193 â”‚
â”‚ valid_loss                                1.58017 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=756232)[0m Updating learning rate to 6.943497797483706e-05
[36m(_train_fn pid=756232)[0m saving checkpoint...
[36m(_train_fn pid=756232)[0m Validation loss decreased (1.5857 --> 1.5802).  Saving model state dict ...

Trial trial-d4e87f4a started with configuration:
2024-08-24 07:40:10,960	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=757019)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e87f4a_25_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1414,e_layers_2024-08-24_07-40-06/checkpoint_000000)
2024-08-24 07:40:12,683	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=757019)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e87f4a_25_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1414,e_layers_2024-08-24_07-40-06/checkpoint_000001)
2024-08-24 07:40:14,408	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=757019)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e87f4a_25_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1414,e_layers_2024-08-24_07-40-06/checkpoint_000002)
2024-08-24 07:40:16,136	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=757019)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e87f4a_25_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1414,e_layers_2024-08-24_07-40-06/checkpoint_000003)
2024-08-24 07:40:17,792	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=757019)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e87f4a_25_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1414,e_layers_2024-08-24_07-40-06/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d4e87f4a config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.14141 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00259 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=757019)[0m configuration
[36m(_train_fn pid=757019)[0m {'batch_size': 64, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.1414077329233074, 'e_layers': 2, 'learning_rate': 0.0025856772071394508, 'd_ff': 64}
[36m(_train_fn pid=757019)[0m Use GPU: cuda:0
[36m(_train_fn pid=757019)[0m train 7825
[36m(_train_fn pid=757019)[0m val 2161
[36m(_train_fn pid=757019)[0m start_epoch 0
[36m(_train_fn pid=757019)[0m max_epoch 8
[36m(_train_fn pid=757019)[0m 	iters: 100, epoch: 1 | loss: 0.8600832
[36m(_train_fn pid=757019)[0m 	speed: 0.0188s/iter; left time: 16.5176s

Trial status: 24 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:40:10. Total running time: 19min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d4e87f4a   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
19 more TERMINATED
[36m(_train_fn pid=757019)[0m Validation loss decreased (inf --> 2.0883).  Saving model state dict ...
[36m(_train_fn pid=757019)[0m Epoch: 1 cost time: 1.8733737468719482
[36m(_train_fn pid=757019)[0m Epoch: 1, Steps: 122 | Train Loss: 1.0405726 Vali Loss: 2.0882537 Best vali loss: 2.0882537
[36m(_train_fn pid=757019)[0m 	iters: 100, epoch: 2 | loss: 0.5277364
[36m(_train_fn pid=757019)[0m 	speed: 0.0172s/iter; left time: 13.0002s
[36m(_train_fn pid=757019)[0m Updating learning rate to 0.0025856772071394508
[36m(_train_fn pid=757019)[0m saving checkpoint...
[36m(_train_fn pid=757019)[0m Updating learning rate to 0.0012928386035697254
[36m(_train_fn pid=757019)[0m saving checkpoint...
[36m(_train_fn pid=757019)[0m Validation loss decreased (2.0883 --> 1.5983).  Saving model state dict ...
[36m(_train_fn pid=757019)[0m Epoch: 2 cost time: 1.4569880962371826
[36m(_train_fn pid=757019)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6658583 Vali Loss: 1.5982728 Best vali loss: 1.5982728
[36m(_train_fn pid=757019)[0m 	iters: 100, epoch: 3 | loss: 0.6051356
[36m(_train_fn pid=757019)[0m 	speed: 0.0173s/iter; left time: 10.9484s
[36m(_train_fn pid=757019)[0m Updating learning rate to 0.0006464193017848627
[36m(_train_fn pid=757019)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=757019)[0m saving checkpoint...
[36m(_train_fn pid=757019)[0m Epoch: 3 cost time: 1.4653303623199463
[36m(_train_fn pid=757019)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6048934 Vali Loss: 1.6189795 Best vali loss: 1.5982728
[36m(_train_fn pid=757019)[0m 	iters: 100, epoch: 4 | loss: 0.5388291
[36m(_train_fn pid=757019)[0m 	speed: 0.0173s/iter; left time: 8.8207s
[36m(_train_fn pid=757019)[0m Updating learning rate to 0.00032320965089243134
[36m(_train_fn pid=757019)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=757019)[0m saving checkpoint...
[36m(_train_fn pid=757019)[0m Epoch: 4 cost time: 1.4643137454986572
[36m(_train_fn pid=757019)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5959709 Vali Loss: 1.6228555 Best vali loss: 1.5982728
[36m(_train_fn pid=757019)[0m 	iters: 100, epoch: 5 | loss: 0.6297322
[36m(_train_fn pid=757019)[0m 	speed: 0.0166s/iter; left time: 6.4458s

Trial trial-d4e87f4a completed after 5 iterations at 2024-08-24 07:40:17. Total running time: 19min 9s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d4e87f4a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.65387 â”‚
â”‚ time_total_s                              9.35826 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59827 â”‚
â”‚ train_loss                                0.58935 â”‚
â”‚ valid_loss                                1.63067 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=757019)[0m Updating learning rate to 0.00016160482544621567
[36m(_train_fn pid=757019)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=757019)[0m saving checkpoint...
[36m(_train_fn pid=757019)[0m Epoch: 5 cost time: 1.3937036991119385
[36m(_train_fn pid=757019)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5893524 Vali Loss: 1.6306716 Best vali loss: 1.5982728
[36m(_train_fn pid=757019)[0m Early stopping

Trial trial-0adcf665 started with configuration:
2024-08-24 07:40:28,032	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=757488)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0adcf665_26_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0631,e_layer_2024-08-24_07-40-17/checkpoint_000000)
[36m(_train_fn pid=757488)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0adcf665_26_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0631,e_layer_2024-08-24_07-40-17/checkpoint_000001)
[36m(_train_fn pid=757488)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0adcf665_26_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0631,e_layer_2024-08-24_07-40-17/checkpoint_000002)
[36m(_train_fn pid=757488)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0adcf665_26_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0631,e_layer_2024-08-24_07-40-17/checkpoint_000003)
[36m(_train_fn pid=757488)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0adcf665_26_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0631,e_layer_2024-08-24_07-40-17/checkpoint_000004)
[36m(_train_fn pid=757488)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0adcf665_26_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0631,e_layer_2024-08-24_07-40-17/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0adcf665 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.06309 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00155 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=757488)[0m configuration
[36m(_train_fn pid=757488)[0m {'batch_size': 128, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.06309285380426805, 'e_layers': 1, 'learning_rate': 0.001554587008537956, 'd_ff': 512}
[36m(_train_fn pid=757488)[0m Use GPU: cuda:0
[36m(_train_fn pid=757488)[0m train 7825
[36m(_train_fn pid=757488)[0m val 2161
[36m(_train_fn pid=757488)[0m start_epoch 0
[36m(_train_fn pid=757488)[0m max_epoch 8
[36m(_train_fn pid=757488)[0m Updating learning rate to 0.001554587008537956
[36m(_train_fn pid=757488)[0m saving checkpoint...
[36m(_train_fn pid=757488)[0m Validation loss decreased (inf --> 1.9843).  Saving model state dict ...
[36m(_train_fn pid=757488)[0m Epoch: 1 cost time: 7.26544976234436
[36m(_train_fn pid=757488)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8052530 Vali Loss: 1.9842759 Best vali loss: 1.9842759
[36m(_train_fn pid=757488)[0m Updating learning rate to 0.000777293504268978
[36m(_train_fn pid=757488)[0m saving checkpoint...
[36m(_train_fn pid=757488)[0m Validation loss decreased (1.9843 --> 1.6289).  Saving model state dict ...
[36m(_train_fn pid=757488)[0m Epoch: 2 cost time: 6.8856401443481445
[36m(_train_fn pid=757488)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6820158 Vali Loss: 1.6288751 Best vali loss: 1.6288751

Trial status: 25 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:40:40. Total running time: 19min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0adcf665   RUNNING           2            16.4254       0.682016        1.62888             1.62888 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
20 more TERMINATED
[36m(_train_fn pid=757488)[0m Updating learning rate to 0.000388646752134489
[36m(_train_fn pid=757488)[0m saving checkpoint...
[36m(_train_fn pid=757488)[0m Validation loss decreased (1.6289 --> 1.5983).  Saving model state dict ...
[36m(_train_fn pid=757488)[0m Epoch: 3 cost time: 6.884035587310791
[36m(_train_fn pid=757488)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6219725 Vali Loss: 1.5982773 Best vali loss: 1.5982773
[36m(_train_fn pid=757488)[0m Updating learning rate to 0.0001943233760672445
[36m(_train_fn pid=757488)[0m saving checkpoint...
[36m(_train_fn pid=757488)[0m Validation loss decreased (1.5983 --> 1.5888).  Saving model state dict ...
[36m(_train_fn pid=757488)[0m Epoch: 4 cost time: 6.887619256973267
[36m(_train_fn pid=757488)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6148924 Vali Loss: 1.5887886 Best vali loss: 1.5887886
[36m(_train_fn pid=757488)[0m Updating learning rate to 9.716168803362225e-05
[36m(_train_fn pid=757488)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=757488)[0m saving checkpoint...
[36m(_train_fn pid=757488)[0m Epoch: 5 cost time: 6.878878831863403
[36m(_train_fn pid=757488)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6123869 Vali Loss: 1.5902028 Best vali loss: 1.5887886
[36m(_train_fn pid=757488)[0m Updating learning rate to 4.8580844016811125e-05
[36m(_train_fn pid=757488)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=757488)[0m saving checkpoint...
[36m(_train_fn pid=757488)[0m Epoch: 6 cost time: 6.8798909187316895
[36m(_train_fn pid=757488)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6109848 Vali Loss: 1.5891256 Best vali loss: 1.5887886
Trial status: 25 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:41:11. Total running time: 20min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=757488)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0adcf665_26_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0631,e_layer_2024-08-24_07-40-17/checkpoint_000006)
[36m(_train_fn pid=758239)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcc1b404_27_alpha_d_ff=2,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1145,e_layers=4_2024-08-24_07-41-14/checkpoint_000000)
[36m(_train_fn pid=758239)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcc1b404_27_alpha_d_ff=2,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1145,e_layers=4_2024-08-24_07-41-14/checkpoint_000001)
2024-08-24 07:41:25,588	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:41:29,290	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=758239)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcc1b404_27_alpha_d_ff=2,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1145,e_layers=4_2024-08-24_07-41-14/checkpoint_000002)
2024-08-24 07:41:33,000	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=758239)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcc1b404_27_alpha_d_ff=2,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1145,e_layers=4_2024-08-24_07-41-14/checkpoint_000003)
2024-08-24 07:41:36,317	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0adcf665   RUNNING           6            47.6807       0.610985        1.58913             1.58879 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
20 more TERMINATED
[36m(_train_fn pid=757488)[0m Updating learning rate to 2.4290422008405563e-05
[36m(_train_fn pid=757488)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=757488)[0m saving checkpoint...
[36m(_train_fn pid=757488)[0m Epoch: 7 cost time: 6.881207227706909
[36m(_train_fn pid=757488)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6111378 Vali Loss: 1.5894434 Best vali loss: 1.5887886
[36m(_train_fn pid=757488)[0m Early stopping

Trial trial-0adcf665 completed after 7 iterations at 2024-08-24 07:41:14. Total running time: 20min 6s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0adcf665 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          7.80986 â”‚
â”‚ time_total_s                             55.49056 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58879 â”‚
â”‚ train_loss                                0.61114 â”‚
â”‚ valid_loss                                1.58944 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-bcc1b404 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-bcc1b404 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11454 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00616 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=758239)[0m configuration
[36m(_train_fn pid=758239)[0m {'batch_size': 32, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.11454227720447253, 'e_layers': 4, 'learning_rate': 0.006155108895561174, 'd_ff': 16}
[36m(_train_fn pid=758239)[0m Use GPU: cuda:0
[36m(_train_fn pid=758239)[0m train 7825
[36m(_train_fn pid=758239)[0m val 2161
[36m(_train_fn pid=758239)[0m start_epoch 0
[36m(_train_fn pid=758239)[0m max_epoch 8
[36m(_train_fn pid=758239)[0m 	iters: 100, epoch: 1 | loss: 0.7185013
[36m(_train_fn pid=758239)[0m 	speed: 0.0205s/iter; left time: 37.9524s
[36m(_train_fn pid=758239)[0m 	iters: 200, epoch: 1 | loss: 0.7855136
[36m(_train_fn pid=758239)[0m 	speed: 0.0133s/iter; left time: 23.3683s
[36m(_train_fn pid=758239)[0m Updating learning rate to 0.006155108895561174
[36m(_train_fn pid=758239)[0m saving checkpoint...
[36m(_train_fn pid=758239)[0m Validation loss decreased (inf --> 1.7041).  Saving model state dict ...
[36m(_train_fn pid=758239)[0m Epoch: 1 cost time: 3.655651807785034
[36m(_train_fn pid=758239)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8729796 Vali Loss: 1.7041168 Best vali loss: 1.7041168
[36m(_train_fn pid=758239)[0m 	iters: 100, epoch: 2 | loss: 0.5410368
[36m(_train_fn pid=758239)[0m 	speed: 0.0231s/iter; left time: 37.1848s
[36m(_train_fn pid=758239)[0m 	iters: 200, epoch: 2 | loss: 0.5797977
[36m(_train_fn pid=758239)[0m 	speed: 0.0134s/iter; left time: 20.2454s
[36m(_train_fn pid=758239)[0m Updating learning rate to 0.003077554447780587
[36m(_train_fn pid=758239)[0m saving checkpoint...
[36m(_train_fn pid=758239)[0m Validation loss decreased (1.7041 --> 1.6022).  Saving model state dict ...
[36m(_train_fn pid=758239)[0m Epoch: 2 cost time: 3.327204942703247
[36m(_train_fn pid=758239)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6152170 Vali Loss: 1.6021551 Best vali loss: 1.6021551
[36m(_train_fn pid=758239)[0m 	iters: 100, epoch: 3 | loss: 0.6341153
[36m(_train_fn pid=758239)[0m 	speed: 0.0237s/iter; left time: 32.3837s
[36m(_train_fn pid=758239)[0m 	iters: 200, epoch: 3 | loss: 0.5105574
[36m(_train_fn pid=758239)[0m 	speed: 0.0134s/iter; left time: 16.9572s
[36m(_train_fn pid=758239)[0m Updating learning rate to 0.0015387772238902935
[36m(_train_fn pid=758239)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=758239)[0m saving checkpoint...
[36m(_train_fn pid=758239)[0m Epoch: 3 cost time: 3.319619655609131
[36m(_train_fn pid=758239)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5704751 Vali Loss: 1.6062114 Best vali loss: 1.6021551
[36m(_train_fn pid=758239)[0m 	iters: 100, epoch: 4 | loss: 0.6005628
[36m(_train_fn pid=758239)[0m 	speed: 0.0236s/iter; left time: 26.4970s
[36m(_train_fn pid=758239)[0m 	iters: 200, epoch: 4 | loss: 0.5679615
[36m(_train_fn pid=758239)[0m 	speed: 0.0134s/iter; left time: 13.6541s
[36m(_train_fn pid=758239)[0m Updating learning rate to 0.0007693886119451468
[36m(_train_fn pid=758239)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=758239)[0m saving checkpoint...
[36m(_train_fn pid=758239)[0m Epoch: 4 cost time: 3.3241395950317383
[36m(_train_fn pid=758239)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5518072 Vali Loss: 1.6256962 Best vali loss: 1.6021551
[36m(_train_fn pid=758239)[0m 	iters: 100, epoch: 5 | loss: 0.4862526
[36m(_train_fn pid=758239)[0m 	speed: 0.0222s/iter; left time: 19.4591s
[36m(_train_fn pid=758239)[0m 	iters: 200, epoch: 5 | loss: 0.4962541
[36m(_train_fn pid=758239)[0m 	speed: 0.0118s/iter; left time: 9.1786s

Trial trial-bcc1b404 completed after 5 iterations at 2024-08-24 07:41:36. Total running time: 20min 27s
[36m(_train_fn pid=758239)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcc1b404_27_alpha_d_ff=2,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1145,e_layers=4_2024-08-24_07-41-14/checkpoint_000004)
2024-08-24 07:42:09,130	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=758738)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28369f7f_28_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1075,e_layers_2024-08-24_07-41-36/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-bcc1b404 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.31495 â”‚
â”‚ time_total_s                             18.87388 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.60216 â”‚
â”‚ train_loss                                0.53797 â”‚
â”‚ valid_loss                                1.62631 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=758239)[0m Updating learning rate to 0.0003846943059725734
[36m(_train_fn pid=758239)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=758239)[0m saving checkpoint...
[36m(_train_fn pid=758239)[0m Epoch: 5 cost time: 2.9457106590270996
[36m(_train_fn pid=758239)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5379694 Vali Loss: 1.6263080 Best vali loss: 1.6021551
[36m(_train_fn pid=758239)[0m Early stopping

Trial trial-28369f7f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-28369f7f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10749 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00199 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=758738)[0m configuration
[36m(_train_fn pid=758738)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.10749459299869123, 'e_layers': 2, 'learning_rate': 0.001987040383673968, 'd_ff': 1536}
[36m(_train_fn pid=758738)[0m Use GPU: cuda:0
[36m(_train_fn pid=758738)[0m train 7825
[36m(_train_fn pid=758738)[0m val 2161
[36m(_train_fn pid=758738)[0m start_epoch 0
[36m(_train_fn pid=758738)[0m max_epoch 8

Trial status: 27 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:41:41. Total running time: 20min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-28369f7f   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
[36m(_train_fn pid=758738)[0m 	iters: 100, epoch: 1 | loss: 0.7366210
[36m(_train_fn pid=758738)[0m 	speed: 0.1148s/iter; left time: 212.7819s
[36m(_train_fn pid=758738)[0m 	iters: 200, epoch: 1 | loss: 0.6908072
[36m(_train_fn pid=758738)[0m 	speed: 0.1089s/iter; left time: 190.8561s
[36m(_train_fn pid=758738)[0m Updating learning rate to 0.001987040383673968
[36m(_train_fn pid=758738)[0m saving checkpoint...
[36m(_train_fn pid=758738)[0m Validation loss decreased (inf --> 1.7903).  Saving model state dict ...
[36m(_train_fn pid=758738)[0m Epoch: 1 cost time: 26.911640882492065
[36m(_train_fn pid=758738)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7660039 Vali Loss: 1.7903017 Best vali loss: 1.7903017
Trial status: 27 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:42:11. Total running time: 21min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-28369f7f   RUNNING           1            30.6755       0.766004        1.7903              1.7903  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
[36m(_train_fn pid=758738)[0m 	iters: 100, epoch: 2 | loss: 0.8017771
[36m(_train_fn pid=758738)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28369f7f_28_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1075,e_layers_2024-08-24_07-41-36/checkpoint_000001)
[36m(_train_fn pid=758738)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28369f7f_28_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1075,e_layers_2024-08-24_07-41-36/checkpoint_000002)
[36m(_train_fn pid=758738)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28369f7f_28_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1075,e_layers_2024-08-24_07-41-36/checkpoint_000003)
[36m(_train_fn pid=758738)[0m 	speed: 0.1899s/iter; left time: 305.4876s
[36m(_train_fn pid=758738)[0m 	iters: 200, epoch: 2 | loss: 0.7291015
[36m(_train_fn pid=758738)[0m 	speed: 0.1083s/iter; left time: 163.3853s
[36m(_train_fn pid=758738)[0m Updating learning rate to 0.000993520191836984
[36m(_train_fn pid=758738)[0m saving checkpoint...
[36m(_train_fn pid=758738)[0m Validation loss decreased (1.7903 --> 1.6242).  Saving model state dict ...
[36m(_train_fn pid=758738)[0m Epoch: 2 cost time: 26.422696113586426
[36m(_train_fn pid=758738)[0m Epoch: 2, Steps: 244 | Train Loss: 1.3235153 Vali Loss: 1.6241745 Best vali loss: 1.6241745
Trial status: 27 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:42:41. Total running time: 21min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-28369f7f   RUNNING           2            60.4476       1.32352         1.62417             1.62417 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
[36m(_train_fn pid=758738)[0m 	iters: 100, epoch: 3 | loss: 0.7002449
[36m(_train_fn pid=758738)[0m 	speed: 0.1894s/iter; left time: 258.5252s
[36m(_train_fn pid=758738)[0m 	iters: 200, epoch: 3 | loss: 0.6494690
[36m(_train_fn pid=758738)[0m 	speed: 0.1084s/iter; left time: 137.0884s
[36m(_train_fn pid=758738)[0m Updating learning rate to 0.000496760095918492
[36m(_train_fn pid=758738)[0m saving checkpoint...
[36m(_train_fn pid=758738)[0m Validation loss decreased (1.6242 --> 1.5914).  Saving model state dict ...
[36m(_train_fn pid=758738)[0m Epoch: 3 cost time: 26.433597564697266
[36m(_train_fn pid=758738)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6348659 Vali Loss: 1.5914286 Best vali loss: 1.5914286
Trial status: 27 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:43:11. Total running time: 22min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-28369f7f   RUNNING           3            90.2315       0.634866        1.59143             1.59143 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
22 more TERMINATED
[36m(_train_fn pid=758738)[0m 	iters: 100, epoch: 4 | loss: 0.5484810
[36m(_train_fn pid=758738)[0m 	speed: 0.1896s/iter; left time: 212.5225s
[36m(_train_fn pid=758738)[0m 	iters: 200, epoch: 4 | loss: 0.6486111
[36m(_train_fn pid=758738)[0m 	speed: 0.1084s/iter; left time: 110.7176s

Trial trial-28369f7f completed after 4 iterations at 2024-08-24 07:43:38. Total running time: 22min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-28369f7f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         29.78868 â”‚
â”‚ time_total_s                            120.02022 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.58275 â”‚
â”‚ train_loss                                0.62303 â”‚
â”‚ valid_loss                                1.58275 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=758738)[0m Updating learning rate to 0.000248380047959246
[36m(_train_fn pid=758738)[0m saving checkpoint...
[36m(_train_fn pid=758738)[0m Validation loss decreased (1.5914 --> 1.5827).  Saving model state dict ...

Trial trial-a4b0dce8 started with configuration:
2024-08-24 07:43:52,505	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=759467)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a4b0dce8_29_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_07-43-38/checkpoint_000000)
2024-08-24 07:44:03,936	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=759467)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a4b0dce8_29_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_07-43-38/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a4b0dce8 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11276 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                       0.0014 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=759467)[0m configuration
[36m(_train_fn pid=759467)[0m {'batch_size': 16, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'avg', 'dropout': 0.11275548032028908, 'e_layers': 4, 'learning_rate': 0.0014017610546721896, 'd_ff': 384}
[36m(_train_fn pid=759467)[0m Use GPU: cuda:0
[36m(_train_fn pid=759467)[0m train 7825
[36m(_train_fn pid=759467)[0m val 2161
[36m(_train_fn pid=759467)[0m start_epoch 0
[36m(_train_fn pid=759467)[0m max_epoch 8

Trial status: 28 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:43:41. Total running time: 22min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a4b0dce8   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
[36m(_train_fn pid=759467)[0m 	iters: 100, epoch: 1 | loss: 0.7834736
[36m(_train_fn pid=759467)[0m 	speed: 0.0257s/iter; left time: 98.1761s
[36m(_train_fn pid=759467)[0m 	iters: 200, epoch: 1 | loss: 0.7123156
[36m(_train_fn pid=759467)[0m 	speed: 0.0207s/iter; left time: 77.0028s
[36m(_train_fn pid=759467)[0m 	iters: 300, epoch: 1 | loss: 0.7143344
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 75.1647s
[36m(_train_fn pid=759467)[0m 	iters: 400, epoch: 1 | loss: 0.6199630
[36m(_train_fn pid=759467)[0m 	speed: 0.0209s/iter; left time: 73.2924s
[36m(_train_fn pid=759467)[0m Updating learning rate to 0.0014017610546721896
[36m(_train_fn pid=759467)[0m saving checkpoint...
[36m(_train_fn pid=759467)[0m Validation loss decreased (inf --> 1.6294).  Saving model state dict ...
[36m(_train_fn pid=759467)[0m Epoch: 1 cost time: 10.412962436676025
[36m(_train_fn pid=759467)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7250338 Vali Loss: 1.6293698 Best vali loss: 1.6293698
[36m(_train_fn pid=759467)[0m 	iters: 100, epoch: 2 | loss: 0.6955079
[36m(_train_fn pid=759467)[0m 	speed: 0.0521s/iter; left time: 173.1180s
[36m(_train_fn pid=759467)[0m 	iters: 200, epoch: 2 | loss: 0.6424528
[36m(_train_fn pid=759467)[0m 	speed: 0.0207s/iter; left time: 66.8867s
[36m(_train_fn pid=759467)[0m 	iters: 300, epoch: 2 | loss: 0.5983204
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 64.8262s
[36m(_train_fn pid=759467)[0m 	iters: 400, epoch: 2 | loss: 0.5611562
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 62.7624s
[36m(_train_fn pid=759467)[0m Updating learning rate to 0.0007008805273360948
[36m(_train_fn pid=759467)[0m saving checkpoint...
[36m(_train_fn pid=759467)[0m Validation loss decreased (1.6294 --> 1.5716).  Saving model state dict ...
[36m(_train_fn pid=759467)[0m Epoch: 2 cost time: 10.18043327331543
[36m(_train_fn pid=759467)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6089963 Vali Loss: 1.5716154 Best vali loss: 1.5716154
[36m(_train_fn pid=759467)[0m 	iters: 100, epoch: 3 | loss: 0.5769767
[36m(_train_fn pid=759467)[0m 	speed: 0.0521s/iter; left time: 147.8277s
[36m(_train_fn pid=759467)[0m 	iters: 200, epoch: 3 | loss: 0.4602056
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 56.8976s
[36m(_train_fn pid=759467)[0m 	iters: 300, epoch: 3 | loss: 0.5216074
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 54.7914s
Trial status: 28 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:44:11. Total running time: 23min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=759467)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a4b0dce8_29_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_07-43-38/checkpoint_000002)
2024-08-24 07:44:15,380	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:44:26,897	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=759467)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a4b0dce8_29_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_07-43-38/checkpoint_000003)
2024-08-24 07:44:38,358	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=759467)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a4b0dce8_29_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_07-43-38/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a4b0dce8   RUNNING           2            23.4904       0.608996        1.57162             1.57162 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
23 more TERMINATED
[36m(_train_fn pid=759467)[0m 	iters: 400, epoch: 3 | loss: 0.5712662
[36m(_train_fn pid=759467)[0m 	speed: 0.0207s/iter; left time: 52.5477s
[36m(_train_fn pid=759467)[0m Updating learning rate to 0.0003504402636680474
[36m(_train_fn pid=759467)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=759467)[0m saving checkpoint...
[36m(_train_fn pid=759467)[0m Epoch: 3 cost time: 10.20252799987793
[36m(_train_fn pid=759467)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5560171 Vali Loss: 1.5986502 Best vali loss: 1.5716154
[36m(_train_fn pid=759467)[0m 	iters: 100, epoch: 4 | loss: 0.4867369
[36m(_train_fn pid=759467)[0m 	speed: 0.0522s/iter; left time: 122.3584s
[36m(_train_fn pid=759467)[0m 	iters: 200, epoch: 4 | loss: 0.5767521
[36m(_train_fn pid=759467)[0m 	speed: 0.0209s/iter; left time: 46.8560s
[36m(_train_fn pid=759467)[0m 	iters: 300, epoch: 4 | loss: 0.5743177
[36m(_train_fn pid=759467)[0m 	speed: 0.0209s/iter; left time: 44.7507s
[36m(_train_fn pid=759467)[0m 	iters: 400, epoch: 4 | loss: 0.4781399
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 42.5974s
[36m(_train_fn pid=759467)[0m Updating learning rate to 0.0001752201318340237
[36m(_train_fn pid=759467)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=759467)[0m saving checkpoint...
[36m(_train_fn pid=759467)[0m Epoch: 4 cost time: 10.23266887664795
[36m(_train_fn pid=759467)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5007905 Vali Loss: 1.6194427 Best vali loss: 1.5716154
[36m(_train_fn pid=759467)[0m 	iters: 100, epoch: 5 | loss: 0.4892338
[36m(_train_fn pid=759467)[0m 	speed: 0.0526s/iter; left time: 97.7547s
[36m(_train_fn pid=759467)[0m 	iters: 200, epoch: 5 | loss: 0.4628171
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 36.5714s
[36m(_train_fn pid=759467)[0m 	iters: 300, epoch: 5 | loss: 0.4174957
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 34.5383s
[36m(_train_fn pid=759467)[0m 	iters: 400, epoch: 5 | loss: 0.3836820
[36m(_train_fn pid=759467)[0m 	speed: 0.0208s/iter; left time: 32.4426s

Trial trial-a4b0dce8 completed after 5 iterations at 2024-08-24 07:44:38. Total running time: 23min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a4b0dce8 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         11.45822 â”‚
â”‚ time_total_s                             57.90416 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.57162 â”‚
â”‚ train_loss                                0.43348 â”‚
â”‚ valid_loss                                1.63452 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=759467)[0m Updating learning rate to 8.761006591701185e-05
[36m(_train_fn pid=759467)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=759467)[0m saving checkpoint...
[36m(_train_fn pid=759467)[0m Epoch: 5 cost time: 10.22067666053772
[36m(_train_fn pid=759467)[0m Epoch: 5, Steps: 489 | Train Loss: 0.4334756 Vali Loss: 1.6345155 Best vali loss: 1.5716154
[36m(_train_fn pid=759467)[0m Early stopping

Trial trial-71c3c524 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-71c3c524 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09581 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00122 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=760085)[0m configuration
[36m(_train_fn pid=760085)[0m {'batch_size': 128, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'avg', 'dropout': 0.09581194700722287, 'e_layers': 3, 'learning_rate': 0.0012177619174732505, 'd_ff': 512}
[36m(_train_fn pid=760085)[0m Use GPU: cuda:0
[36m(_train_fn pid=760085)[0m train 7825
[36m(_train_fn pid=760085)[0m val 2161
[36m(_train_fn pid=760085)[0m start_epoch 0
[36m(_train_fn pid=760085)[0m max_epoch 8

Trial status: 29 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:44:41. Total running time: 23min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=760085)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-71c3c524_30_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_07-44-38/checkpoint_000000)
2024-08-24 07:45:10,001	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760085)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-71c3c524_30_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_07-44-38/checkpoint_000001)
2024-08-24 07:45:24,487	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760085)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-71c3c524_30_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_07-44-38/checkpoint_000002)
2024-08-24 07:45:38,977	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760085)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-71c3c524_30_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_07-44-38/checkpoint_000003)
2024-08-24 07:45:53,437	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760085)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-71c3c524_30_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_07-44-38/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-71c3c524   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
24 more TERMINATED
[36m(_train_fn pid=760085)[0m Validation loss decreased (inf --> 1.9964).  Saving model state dict ...
[36m(_train_fn pid=760085)[0m Updating learning rate to 0.0012177619174732505
[36m(_train_fn pid=760085)[0m saving checkpoint...
[36m(_train_fn pid=760085)[0m Epoch: 1 cost time: 13.08236575126648
[36m(_train_fn pid=760085)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8713788 Vali Loss: 1.9964077 Best vali loss: 1.9964077
[36m(_train_fn pid=760085)[0m Updating learning rate to 0.0006088809587366253
[36m(_train_fn pid=760085)[0m saving checkpoint...
[36m(_train_fn pid=760085)[0m Validation loss decreased (1.9964 --> 1.6440).  Saving model state dict ...
[36m(_train_fn pid=760085)[0m Epoch: 2 cost time: 12.893239974975586
[36m(_train_fn pid=760085)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7076139 Vali Loss: 1.6439567 Best vali loss: 1.6439567
Trial status: 29 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:45:11. Total running time: 24min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-71c3c524   RUNNING           2            29.56         0.707614        1.64396             1.64396 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
24 more TERMINATED
[36m(_train_fn pid=760085)[0m Updating learning rate to 0.00030444047936831263
[36m(_train_fn pid=760085)[0m saving checkpoint...
[36m(_train_fn pid=760085)[0m Validation loss decreased (1.6440 --> 1.6028).  Saving model state dict ...
[36m(_train_fn pid=760085)[0m Epoch: 3 cost time: 12.897115707397461
[36m(_train_fn pid=760085)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6273386 Vali Loss: 1.6028375 Best vali loss: 1.6028375
[36m(_train_fn pid=760085)[0m Updating learning rate to 0.00015222023968415631
[36m(_train_fn pid=760085)[0m saving checkpoint...
[36m(_train_fn pid=760085)[0m Validation loss decreased (1.6028 --> 1.6023).  Saving model state dict ...
[36m(_train_fn pid=760085)[0m Epoch: 4 cost time: 12.899173021316528
[36m(_train_fn pid=760085)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6136606 Vali Loss: 1.6023324 Best vali loss: 1.6023324
Trial status: 29 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:45:41. Total running time: 24min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-71c3c524   RUNNING           4            58.5292       0.613661        1.60233             1.60233 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
24 more TERMINATED
[36m(_train_fn pid=760085)[0m Updating learning rate to 7.611011984207816e-05
2024-08-24 07:46:07,896	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760085)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-71c3c524_30_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_07-44-38/checkpoint_000005)
2024-08-24 07:46:22,343	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760085)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-71c3c524_30_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_07-44-38/checkpoint_000006)
[36m(_train_fn pid=760971)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4424e324_31_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-46-22/checkpoint_000000)
2024-08-24 07:46:34,062	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760971)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4424e324_31_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-46-22/checkpoint_000001)
2024-08-24 07:46:38,560	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760971)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4424e324_31_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-46-22/checkpoint_000002)
[36m(_train_fn pid=760085)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=760085)[0m saving checkpoint...
[36m(_train_fn pid=760085)[0m Epoch: 5 cost time: 12.886323690414429
[36m(_train_fn pid=760085)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6102979 Vali Loss: 1.6035719 Best vali loss: 1.6023324
[36m(_train_fn pid=760085)[0m Updating learning rate to 3.805505992103908e-05
[36m(_train_fn pid=760085)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=760085)[0m saving checkpoint...
[36m(_train_fn pid=760085)[0m Epoch: 6 cost time: 12.8846275806427
[36m(_train_fn pid=760085)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6084405 Vali Loss: 1.6041680 Best vali loss: 1.6023324
Trial status: 29 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:46:11. Total running time: 25min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-71c3c524   RUNNING           6            87.4418       0.60844         1.60417             1.60233 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
24 more TERMINATED

Trial trial-71c3c524 completed after 7 iterations at 2024-08-24 07:46:22. Total running time: 25min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-71c3c524 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                         14.44325 â”‚
â”‚ time_total_s                             101.8851 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.60233 â”‚
â”‚ train_loss                                 0.6078 â”‚
â”‚ valid_loss                                1.60335 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=760085)[0m Updating learning rate to 1.902752996051954e-05
[36m(_train_fn pid=760085)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=760085)[0m saving checkpoint...

Trial trial-4424e324 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4424e324 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10756 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00169 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=760971)[0m configuration
[36m(_train_fn pid=760971)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'avg', 'dropout': 0.10755673832071197, 'e_layers': 3, 'learning_rate': 0.0016855740820126755, 'd_ff': 128}
[36m(_train_fn pid=760971)[0m Use GPU: cuda:0
[36m(_train_fn pid=760971)[0m train 7825
[36m(_train_fn pid=760971)[0m val 2161
[36m(_train_fn pid=760971)[0m start_epoch 0
[36m(_train_fn pid=760971)[0m max_epoch 8
[36m(_train_fn pid=760971)[0m 	iters: 100, epoch: 1 | loss: 0.7632021
[36m(_train_fn pid=760971)[0m 	speed: 0.0212s/iter; left time: 39.2229s
[36m(_train_fn pid=760971)[0m 	iters: 200, epoch: 1 | loss: 0.8050890
[36m(_train_fn pid=760971)[0m 	speed: 0.0160s/iter; left time: 28.0931s
[36m(_train_fn pid=760971)[0m Updating learning rate to 0.0016855740820126755
[36m(_train_fn pid=760971)[0m saving checkpoint...
[36m(_train_fn pid=760971)[0m Validation loss decreased (inf --> 1.8424).  Saving model state dict ...
[36m(_train_fn pid=760971)[0m Epoch: 1 cost time: 4.168126583099365
[36m(_train_fn pid=760971)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7808477 Vali Loss: 1.8423517 Best vali loss: 1.8423517
[36m(_train_fn pid=760971)[0m 	iters: 100, epoch: 2 | loss: 0.5667748
[36m(_train_fn pid=760971)[0m 	speed: 0.0290s/iter; left time: 46.5856s
[36m(_train_fn pid=760971)[0m 	iters: 200, epoch: 2 | loss: 0.4848577
[36m(_train_fn pid=760971)[0m 	speed: 0.0160s/iter; left time: 24.1091s
[36m(_train_fn pid=760971)[0m Updating learning rate to 0.0008427870410063378
[36m(_train_fn pid=760971)[0m saving checkpoint...
[36m(_train_fn pid=760971)[0m Validation loss decreased (1.8424 --> 1.5989).  Saving model state dict ...
[36m(_train_fn pid=760971)[0m Epoch: 2 cost time: 3.9490973949432373
[36m(_train_fn pid=760971)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6193053 Vali Loss: 1.5988705 Best vali loss: 1.5988705
[36m(_train_fn pid=760971)[0m 	iters: 100, epoch: 3 | loss: 0.6419533
[36m(_train_fn pid=760971)[0m 	speed: 0.0289s/iter; left time: 39.4480s
[36m(_train_fn pid=760971)[0m 	iters: 200, epoch: 3 | loss: 0.5957562
[36m(_train_fn pid=760971)[0m 	speed: 0.0161s/iter; left time: 20.3714s
[36m(_train_fn pid=760971)[0m Updating learning rate to 0.0004213935205031689
[36m(_train_fn pid=760971)[0m saving checkpoint...
[36m(_train_fn pid=760971)[0m Validation loss decreased (1.5989 --> 1.5740).  Saving model state dict ...
[36m(_train_fn pid=760971)[0m Epoch: 3 cost time: 3.961359739303589
[36m(_train_fn pid=760971)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5774959 Vali Loss: 1.5739515 Best vali loss: 1.5739515
[36m(_train_fn pid=760971)[0m 	iters: 100, epoch: 4 | loss: 0.5165914
[36m(_train_fn pid=760971)[0m 	speed: 0.0289s/iter; left time: 32.4439s

Trial status: 30 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:46:41. Total running time: 25min 32s
[36m(_train_fn pid=760971)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4424e324_31_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-46-22/checkpoint_000003)
2024-08-24 07:46:43,070	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:46:47,565	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760971)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4424e324_31_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-46-22/checkpoint_000004)
2024-08-24 07:46:52,073	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=760971)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4424e324_31_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-46-22/checkpoint_000005)
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4424e324   RUNNING           3            14.1111       0.577496        1.57395             1.57395 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
25 more TERMINATED
[36m(_train_fn pid=760971)[0m 	iters: 200, epoch: 4 | loss: 0.5417382
[36m(_train_fn pid=760971)[0m 	speed: 0.0161s/iter; left time: 16.4749s
[36m(_train_fn pid=760971)[0m Updating learning rate to 0.00021069676025158444
[36m(_train_fn pid=760971)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=760971)[0m saving checkpoint...
[36m(_train_fn pid=760971)[0m Epoch: 4 cost time: 3.973047971725464
[36m(_train_fn pid=760971)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5572228 Vali Loss: 1.5999091 Best vali loss: 1.5739515
[36m(_train_fn pid=760971)[0m 	iters: 100, epoch: 5 | loss: 0.5643618
[36m(_train_fn pid=760971)[0m 	speed: 0.0290s/iter; left time: 25.3896s
[36m(_train_fn pid=760971)[0m 	iters: 200, epoch: 5 | loss: 0.5409362
[36m(_train_fn pid=760971)[0m 	speed: 0.0161s/iter; left time: 12.4944s
[36m(_train_fn pid=760971)[0m Updating learning rate to 0.00010534838012579222
[36m(_train_fn pid=760971)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=760971)[0m saving checkpoint...
[36m(_train_fn pid=760971)[0m Epoch: 5 cost time: 3.9655165672302246
[36m(_train_fn pid=760971)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5460959 Vali Loss: 1.6071153 Best vali loss: 1.5739515
[36m(_train_fn pid=760971)[0m 	iters: 100, epoch: 6 | loss: 0.4982060
[36m(_train_fn pid=760971)[0m 	speed: 0.0289s/iter; left time: 18.2701s
[36m(_train_fn pid=760971)[0m 	iters: 200, epoch: 6 | loss: 0.5632666
[36m(_train_fn pid=760971)[0m 	speed: 0.0161s/iter; left time: 8.5947s

Trial trial-4424e324 completed after 6 iterations at 2024-08-24 07:46:52. Total running time: 25min 43s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4424e324 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          4.50506 â”‚
â”‚ time_total_s                             27.61603 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.57395 â”‚
â”‚ train_loss                                 0.5406 â”‚
â”‚ valid_loss                                1.60361 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=760971)[0m Updating learning rate to 5.267419006289611e-05
[36m(_train_fn pid=760971)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=760971)[0m saving checkpoint...
[36m(_train_fn pid=760971)[0m Epoch: 6 cost time: 3.969897747039795
[36m(_train_fn pid=760971)[0m Epoch: 6, Steps: 244 | Train Loss: 0.5405992 Vali Loss: 1.6036068 Best vali loss: 1.5739515
[36m(_train_fn pid=760971)[0m Early stopping

Trial trial-fce1ff29 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fce1ff29 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.13778 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                       0.0013 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=761569)[0m configuration
[36m(_train_fn pid=761569)[0m {'batch_size': 32, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'conv', 'dropout': 0.13778358764163456, 'e_layers': 3, 'learning_rate': 0.001298704963885529, 'd_ff': 768}
[36m(_train_fn pid=761569)[0m Use GPU: cuda:0
[36m(_train_fn pid=761569)[0m train 7825
[36m(_train_fn pid=761569)[0m val 2161
[36m(_train_fn pid=761569)[0m start_epoch 0
[36m(_train_fn pid=761569)[0m max_epoch 8
[36m(_train_fn pid=761569)[0m 	iters: 100, epoch: 1 | loss: 0.7840043
[36m(_train_fn pid=761569)[0m 	speed: 0.0707s/iter; left time: 130.9527s
[36m(_train_fn pid=761569)[0m 	iters: 200, epoch: 1 | loss: 0.7446433
[36m(_train_fn pid=761569)[0m 	speed: 0.0660s/iter; left time: 115.6822s

Trial status: 31 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:47:11. Total running time: 26min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:47:13,057	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=761569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fce1ff29_32_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_07-46-52/checkpoint_000000)
[36m(_train_fn pid=761569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fce1ff29_32_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_07-46-52/checkpoint_000001)
[36m(_train_fn pid=761569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fce1ff29_32_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_07-46-52/checkpoint_000002)
[36m(_train_fn pid=761569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fce1ff29_32_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_07-46-52/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fce1ff29   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
[36m(_train_fn pid=761569)[0m Updating learning rate to 0.001298704963885529
[36m(_train_fn pid=761569)[0m saving checkpoint...
[36m(_train_fn pid=761569)[0m Validation loss decreased (inf --> 1.8500).  Saving model state dict ...
[36m(_train_fn pid=761569)[0m Epoch: 1 cost time: 16.31725263595581
[36m(_train_fn pid=761569)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7692672 Vali Loss: 1.8499630 Best vali loss: 1.8499630
[36m(_train_fn pid=761569)[0m 	iters: 100, epoch: 2 | loss: 0.5557604
[36m(_train_fn pid=761569)[0m 	speed: 0.1140s/iter; left time: 183.4750s
[36m(_train_fn pid=761569)[0m 	iters: 200, epoch: 2 | loss: 0.6822432
[36m(_train_fn pid=761569)[0m 	speed: 0.0662s/iter; left time: 99.8284s
[36m(_train_fn pid=761569)[0m Updating learning rate to 0.0006493524819427645
[36m(_train_fn pid=761569)[0m saving checkpoint...
[36m(_train_fn pid=761569)[0m Validation loss decreased (1.8500 --> 1.5926).  Saving model state dict ...
[36m(_train_fn pid=761569)[0m Epoch: 2 cost time: 16.1428644657135
[36m(_train_fn pid=761569)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6388812 Vali Loss: 1.5926323 Best vali loss: 1.5926323
[36m(_train_fn pid=761569)[0m 	iters: 100, epoch: 3 | loss: 0.6037788
[36m(_train_fn pid=761569)[0m 	speed: 0.1142s/iter; left time: 155.8762s
Trial status: 31 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:47:41. Total running time: 26min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fce1ff29   RUNNING           2            36.6314       0.638881        1.59263             1.59263 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
[36m(_train_fn pid=761569)[0m 	iters: 200, epoch: 3 | loss: 0.6176445
[36m(_train_fn pid=761569)[0m 	speed: 0.0662s/iter; left time: 83.7424s
[36m(_train_fn pid=761569)[0m Updating learning rate to 0.00032467624097138226
[36m(_train_fn pid=761569)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=761569)[0m saving checkpoint...
[36m(_train_fn pid=761569)[0m Epoch: 3 cost time: 16.159542322158813
[36m(_train_fn pid=761569)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5925508 Vali Loss: 1.7280348 Best vali loss: 1.5926323
[36m(_train_fn pid=761569)[0m 	iters: 100, epoch: 4 | loss: 0.4925542
[36m(_train_fn pid=761569)[0m 	speed: 0.1141s/iter; left time: 127.9165s
[36m(_train_fn pid=761569)[0m 	iters: 200, epoch: 4 | loss: 0.5904250
[36m(_train_fn pid=761569)[0m 	speed: 0.0662s/iter; left time: 67.5713s
[36m(_train_fn pid=761569)[0m Updating learning rate to 0.00016233812048569113
[36m(_train_fn pid=761569)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=761569)[0m saving checkpoint...
[36m(_train_fn pid=761569)[0m Epoch: 4 cost time: 16.14833354949951
[36m(_train_fn pid=761569)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5686045 Vali Loss: 1.6838149 Best vali loss: 1.5926323
Trial status: 31 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:48:11. Total running time: 27min 2s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=761569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fce1ff29_32_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_07-46-52/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fce1ff29   RUNNING           4            72.6741       0.568604        1.68381             1.59263 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
26 more TERMINATED
[36m(_train_fn pid=761569)[0m 	iters: 100, epoch: 5 | loss: 0.4972939
[36m(_train_fn pid=761569)[0m 	speed: 0.1140s/iter; left time: 99.9930s
[36m(_train_fn pid=761569)[0m 	iters: 200, epoch: 5 | loss: 0.5417120
[36m(_train_fn pid=761569)[0m 	speed: 0.0661s/iter; left time: 51.3935s

Trial trial-fce1ff29 completed after 5 iterations at 2024-08-24 07:48:25. Total running time: 27min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fce1ff29 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         18.02439 â”‚
â”‚ time_total_s                             90.69851 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59263 â”‚
â”‚ train_loss                                0.55006 â”‚
â”‚ valid_loss                                1.69071 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=761569)[0m Updating learning rate to 8.116906024284556e-05
[36m(_train_fn pid=761569)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=761569)[0m saving checkpoint...
[36m(_train_fn pid=761569)[0m Epoch: 5 cost time: 16.15269184112549
[36m(_train_fn pid=761569)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5500596 Vali Loss: 1.6907109 Best vali loss: 1.5926323
[36m(_train_fn pid=761569)[0m Early stopping

Trial trial-422fc89d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-422fc89d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.12297 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00483 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=762282)[0m configuration
[36m(_train_fn pid=762282)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.12297411951496522, 'e_layers': 3, 'learning_rate': 0.004831003909328543, 'd_ff': 2048}
[36m(_train_fn pid=762282)[0m Use GPU: cuda:0
[36m(_train_fn pid=762282)[0m train 7825
[36m(_train_fn pid=762282)[0m val 2161
[36m(_train_fn pid=762282)[0m start_epoch 0
[36m(_train_fn pid=762282)[0m max_epoch 8

Trial status: 32 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:48:41. Total running time: 27min 32s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-422fc89d   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
[36m(_train_fn pid=762282)[0m 	iters: 100, epoch: 1 | loss: 0.7948951
[36m(_train_fn pid=762282)[0m 	speed: 0.1727s/iter; left time: 319.9870s
[36m(_train_fn pid=762282)[0m 	iters: 200, epoch: 1 | loss: 0.8232680
[36m(_train_fn pid=762282)[0m 	speed: 0.1668s/iter; left time: 292.3532s
Trial status: 32 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:49:11. Total running time: 28min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=762282)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-422fc89d_33_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1230,e_layer_2024-08-24_07-48-25/checkpoint_000000)
[36m(_train_fn pid=762282)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-422fc89d_33_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1230,e_layer_2024-08-24_07-48-25/checkpoint_000001)
2024-08-24 07:49:58,862	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-422fc89d   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
[36m(_train_fn pid=762282)[0m Updating learning rate to 0.004831003909328543
[36m(_train_fn pid=762282)[0m saving checkpoint...
[36m(_train_fn pid=762282)[0m Validation loss decreased (inf --> 1.8579).  Saving model state dict ...
[36m(_train_fn pid=762282)[0m Epoch: 1 cost time: 41.037028551101685
[36m(_train_fn pid=762282)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8352575 Vali Loss: 1.8578506 Best vali loss: 1.8578506
[36m(_train_fn pid=762282)[0m 	iters: 100, epoch: 2 | loss: 117466416.0000000
[36m(_train_fn pid=762282)[0m 	speed: 0.2878s/iter; left time: 463.0268s
Trial status: 32 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:49:41. Total running time: 28min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-422fc89d   RUNNING           1            46.4481       0.835257        1.85785             1.85785 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
[36m(_train_fn pid=762282)[0m 	iters: 200, epoch: 2 | loss: 145756.4531250
[36m(_train_fn pid=762282)[0m 	speed: 0.1641s/iter; left time: 247.6785s
[36m(_train_fn pid=762282)[0m Updating learning rate to 0.0024155019546642717
[36m(_train_fn pid=762282)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=762282)[0m saving checkpoint...
[36m(_train_fn pid=762282)[0m Epoch: 2 cost time: 40.07990598678589
[36m(_train_fn pid=762282)[0m Epoch: 2, Steps: 244 | Train Loss: 254891482.1206065 Vali Loss: 261184.9930037 Best vali loss: 1.8578506
Trial status: 32 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:50:11. Total running time: 29min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-422fc89d   RUNNING           2            91.4141    2.54891e+08   261185                   1.85785 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009    0.593321           1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127    0.510234           1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511    0.570752           1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635     0.600472           1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884    0.512451           1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED
[36m(_train_fn pid=762282)[0m 	iters: 100, epoch: 3 | loss: 30842.0664062
[36m(_train_fn pid=762282)[0m 	speed: 0.2848s/iter; left time: 388.7584s
[36m(_train_fn pid=762282)[0m 	iters: 200, epoch: 3 | loss: 27376.3652344
[36m(_train_fn pid=762282)[0m 	speed: 0.1641s/iter; left time: 207.5701s
Trial status: 32 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:50:41. Total running time: 29min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 07:50:43,749	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=762282)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-422fc89d_33_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1230,e_layer_2024-08-24_07-48-25/checkpoint_000002)
[36m(_train_fn pid=762985)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c6eb872b_34_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0638,e_layers=_2024-08-24_07-50-43/checkpoint_000000)
2024-08-24 07:50:51,893	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=762985)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c6eb872b_34_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0638,e_layers=_2024-08-24_07-50-43/checkpoint_000001)
2024-08-24 07:50:54,738	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=762985)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c6eb872b_34_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0638,e_layers=_2024-08-24_07-50-43/checkpoint_000002)
2024-08-24 07:50:57,613	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=762985)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c6eb872b_34_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0638,e_layers=_2024-08-24_07-50-43/checkpoint_000003)
2024-08-24 07:51:00,469	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-422fc89d   RUNNING           2            91.4141    2.54891e+08   261185                   1.85785 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009    0.593321           1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127    0.510234           1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511    0.570752           1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635     0.600472           1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884    0.512451           1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
27 more TERMINATED

Trial trial-422fc89d completed after 3 iterations at 2024-08-24 07:50:43. Total running time: 29min 34s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-422fc89d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000002 â”‚
â”‚ time_this_iter_s                         44.88441 â”‚
â”‚ time_total_s                             136.2985 â”‚
â”‚ training_iteration                              3 â”‚
â”‚ best_valid_loss                           1.85785 â”‚
â”‚ train_loss                             44497.2987 â”‚
â”‚ valid_loss                            48560.13565 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=762282)[0m Updating learning rate to 0.0012077509773321358
[36m(_train_fn pid=762282)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=762282)[0m saving checkpoint...

Trial trial-c6eb872b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c6eb872b config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.06378 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00396 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=762985)[0m configuration
[36m(_train_fn pid=762985)[0m {'batch_size': 32, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.06377790242828937, 'e_layers': 2, 'learning_rate': 0.003963854600167525, 'd_ff': 96}
[36m(_train_fn pid=762985)[0m Use GPU: cuda:0
[36m(_train_fn pid=762985)[0m train 7825
[36m(_train_fn pid=762985)[0m val 2161
[36m(_train_fn pid=762985)[0m start_epoch 0
[36m(_train_fn pid=762985)[0m max_epoch 8
[36m(_train_fn pid=762985)[0m 	iters: 100, epoch: 1 | loss: 0.8004009
[36m(_train_fn pid=762985)[0m 	speed: 0.0171s/iter; left time: 31.6342s
[36m(_train_fn pid=762985)[0m 	iters: 200, epoch: 1 | loss: 0.7758799
[36m(_train_fn pid=762985)[0m 	speed: 0.0097s/iter; left time: 17.0682s
[36m(_train_fn pid=762985)[0m Validation loss decreased (inf --> 1.6921).  Saving model state dict ...
[36m(_train_fn pid=762985)[0m Epoch: 1 cost time: 2.8220086097717285
[36m(_train_fn pid=762985)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7695920 Vali Loss: 1.6920850 Best vali loss: 1.6920850
[36m(_train_fn pid=762985)[0m Updating learning rate to 0.003963854600167525
[36m(_train_fn pid=762985)[0m saving checkpoint...
[36m(_train_fn pid=762985)[0m 	iters: 100, epoch: 2 | loss: 0.6437613
[36m(_train_fn pid=762985)[0m 	speed: 0.0182s/iter; left time: 29.3572s
[36m(_train_fn pid=762985)[0m 	iters: 200, epoch: 2 | loss: 0.6248586
[36m(_train_fn pid=762985)[0m 	speed: 0.0099s/iter; left time: 14.9762s
[36m(_train_fn pid=762985)[0m Updating learning rate to 0.0019819273000837626
[36m(_train_fn pid=762985)[0m saving checkpoint...
[36m(_train_fn pid=762985)[0m Validation loss decreased (1.6921 --> 1.6007).  Saving model state dict ...
[36m(_train_fn pid=762985)[0m Epoch: 2 cost time: 2.4591429233551025
[36m(_train_fn pid=762985)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6150141 Vali Loss: 1.6007350 Best vali loss: 1.6007350
[36m(_train_fn pid=762985)[0m 	iters: 100, epoch: 3 | loss: 0.5090405
[36m(_train_fn pid=762985)[0m 	speed: 0.0186s/iter; left time: 25.3495s
[36m(_train_fn pid=762985)[0m 	iters: 200, epoch: 3 | loss: 0.4670141
[36m(_train_fn pid=762985)[0m 	speed: 0.0099s/iter; left time: 12.5158s
[36m(_train_fn pid=762985)[0m Updating learning rate to 0.0009909636500418813
[36m(_train_fn pid=762985)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=762985)[0m saving checkpoint...
[36m(_train_fn pid=762985)[0m Epoch: 3 cost time: 2.4636178016662598
[36m(_train_fn pid=762985)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5762633 Vali Loss: 1.6220974 Best vali loss: 1.6007350
[36m(_train_fn pid=762985)[0m 	iters: 100, epoch: 4 | loss: 0.6023138
[36m(_train_fn pid=762985)[0m 	speed: 0.0187s/iter; left time: 21.0111s
[36m(_train_fn pid=762985)[0m 	iters: 200, epoch: 4 | loss: 0.5834957
[36m(_train_fn pid=762985)[0m 	speed: 0.0100s/iter; left time: 10.1827s
[36m(_train_fn pid=762985)[0m Updating learning rate to 0.0004954818250209407
[36m(_train_fn pid=762985)[0m saving checkpoint...
[36m(_train_fn pid=762985)[0m Validation loss decreased (1.6007 --> 1.5989).  Saving model state dict ...
[36m(_train_fn pid=762985)[0m Epoch: 4 cost time: 2.4890975952148438
[36m(_train_fn pid=762985)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5532036 Vali Loss: 1.5988639 Best vali loss: 1.5988639
[36m(_train_fn pid=762985)[0m 	iters: 100, epoch: 5 | loss: 0.5121747
[36m(_train_fn pid=762985)[0m 	speed: 0.0186s/iter; left time: 16.3019s
[36m(_train_fn pid=762985)[0m 	iters: 200, epoch: 5 | loss: 0.4938931
[36m(_train_fn pid=762985)[0m 	speed: 0.0100s/iter; left time: 7.7462s
[36m(_train_fn pid=762985)[0m Updating learning rate to 0.0002477409125104703
[36m(_train_fn pid=762985)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=762985)[0m saving checkpoint...
[36m(_train_fn pid=762985)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c6eb872b_34_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0638,e_layers=_2024-08-24_07-50-43/checkpoint_000004)
2024-08-24 07:51:03,320	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=762985)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c6eb872b_34_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0638,e_layers=_2024-08-24_07-50-43/checkpoint_000005)
2024-08-24 07:51:05,976	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=762985)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c6eb872b_34_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0638,e_layers=_2024-08-24_07-50-43/checkpoint_000006)
[36m(_train_fn pid=763632)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5d4622b7_35_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-51-05/checkpoint_000000)
2024-08-24 07:51:18,932	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=763632)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5d4622b7_35_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-51-05/checkpoint_000001)
2024-08-24 07:51:23,852	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=762985)[0m Epoch: 5 cost time: 2.473405599594116
[36m(_train_fn pid=762985)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5384541 Vali Loss: 1.6086896 Best vali loss: 1.5988639
[36m(_train_fn pid=762985)[0m 	iters: 100, epoch: 6 | loss: 0.5642253
[36m(_train_fn pid=762985)[0m 	speed: 0.0186s/iter; left time: 11.7727s
[36m(_train_fn pid=762985)[0m 	iters: 200, epoch: 6 | loss: 0.6196599
[36m(_train_fn pid=762985)[0m 	speed: 0.0099s/iter; left time: 5.2933s
[36m(_train_fn pid=762985)[0m Updating learning rate to 0.00012387045625523516
[36m(_train_fn pid=762985)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=762985)[0m saving checkpoint...
[36m(_train_fn pid=762985)[0m Epoch: 6 cost time: 2.4676003456115723
[36m(_train_fn pid=762985)[0m Epoch: 6, Steps: 244 | Train Loss: 0.5300624 Vali Loss: 1.6172760 Best vali loss: 1.5988639
[36m(_train_fn pid=762985)[0m 	iters: 100, epoch: 7 | loss: 0.4924993
[36m(_train_fn pid=762985)[0m 	speed: 0.0178s/iter; left time: 6.9355s
[36m(_train_fn pid=762985)[0m 	iters: 200, epoch: 7 | loss: 0.5277150
[36m(_train_fn pid=762985)[0m 	speed: 0.0091s/iter; left time: 2.6437s

Trial trial-c6eb872b completed after 7 iterations at 2024-08-24 07:51:05. Total running time: 29min 57s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c6eb872b result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          2.65351 â”‚
â”‚ time_total_s                             20.52027 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.59886 â”‚
â”‚ train_loss                                0.52536 â”‚
â”‚ valid_loss                                1.61599 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=762985)[0m Updating learning rate to 6.193522812761758e-05
[36m(_train_fn pid=762985)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=762985)[0m saving checkpoint...
[36m(_train_fn pid=762985)[0m Epoch: 7 cost time: 2.277830123901367
[36m(_train_fn pid=762985)[0m Epoch: 7, Steps: 244 | Train Loss: 0.5253562 Vali Loss: 1.6159874 Best vali loss: 1.5988639
[36m(_train_fn pid=762985)[0m Early stopping

Trial trial-5d4622b7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5d4622b7 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.06692 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                       0.0006 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=763632)[0m configuration
[36m(_train_fn pid=763632)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.06692368878325008, 'e_layers': 3, 'learning_rate': 0.0005987453094460454, 'd_ff': 128}
[36m(_train_fn pid=763632)[0m Use GPU: cuda:0
[36m(_train_fn pid=763632)[0m train 7825
[36m(_train_fn pid=763632)[0m val 2161
[36m(_train_fn pid=763632)[0m start_epoch 0
[36m(_train_fn pid=763632)[0m max_epoch 8
[36m(_train_fn pid=763632)[0m 	iters: 100, epoch: 1 | loss: 0.7643011
[36m(_train_fn pid=763632)[0m 	speed: 0.0229s/iter; left time: 42.3506s

Trial status: 34 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:51:12. Total running time: 30min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5d4622b7   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
29 more TERMINATED
[36m(_train_fn pid=763632)[0m 	iters: 200, epoch: 1 | loss: 0.8307989
[36m(_train_fn pid=763632)[0m 	speed: 0.0177s/iter; left time: 31.0593s
[36m(_train_fn pid=763632)[0m Updating learning rate to 0.0005987453094460454
[36m(_train_fn pid=763632)[0m saving checkpoint...
[36m(_train_fn pid=763632)[0m Validation loss decreased (inf --> 1.9307).  Saving model state dict ...
[36m(_train_fn pid=763632)[0m Epoch: 1 cost time: 4.574968099594116
[36m(_train_fn pid=763632)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7900287 Vali Loss: 1.9306966 Best vali loss: 1.9306966
[36m(_train_fn pid=763632)[0m 	iters: 100, epoch: 2 | loss: 0.5791263
[36m(_train_fn pid=763632)[0m 	speed: 0.0315s/iter; left time: 50.6710s
[36m(_train_fn pid=763632)[0m 	iters: 200, epoch: 2 | loss: 0.4984381
[36m(_train_fn pid=763632)[0m 	speed: 0.0177s/iter; left time: 26.7506s
[36m(_train_fn pid=763632)[0m Updating learning rate to 0.0002993726547230227
[36m(_train_fn pid=763632)[0m saving checkpoint...
[36m(_train_fn pid=763632)[0m Validation loss decreased (1.9307 --> 1.5728).  Saving model state dict ...
[36m(_train_fn pid=763632)[0m Epoch: 2 cost time: 4.368467330932617
[36m(_train_fn pid=763632)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6422872 Vali Loss: 1.5728036 Best vali loss: 1.5728036
[36m(_train_fn pid=763632)[0m 	iters: 100, epoch: 3 | loss: 0.6768371
[36m(_train_fn pid=763632)[0m 	speed: 0.0316s/iter; left time: 43.1314s
[36m(_train_fn pid=763632)[0m 	iters: 200, epoch: 3 | loss: 0.6334243
[36m(_train_fn pid=763632)[0m 	speed: 0.0177s/iter; left time: 22.3682s
[36m(_train_fn pid=763632)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5d4622b7_35_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-51-05/checkpoint_000002)
2024-08-24 07:51:28,756	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=763632)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5d4622b7_35_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-51-05/checkpoint_000003)
2024-08-24 07:51:33,670	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=763632)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5d4622b7_35_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-51-05/checkpoint_000004)
2024-08-24 07:51:46,106	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=764149)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcb9971a_36_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0840,e_layer_2024-08-24_07-51-33/checkpoint_000000)
[36m(_train_fn pid=764149)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcb9971a_36_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0840,e_layer_2024-08-24_07-51-33/checkpoint_000001)
[36m(_train_fn pid=763632)[0m Updating learning rate to 0.00014968632736151136
[36m(_train_fn pid=763632)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=763632)[0m saving checkpoint...
[36m(_train_fn pid=763632)[0m Epoch: 3 cost time: 4.371007680892944
[36m(_train_fn pid=763632)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6066940 Vali Loss: 1.5735881 Best vali loss: 1.5728036
[36m(_train_fn pid=763632)[0m 	iters: 100, epoch: 4 | loss: 0.5394517
[36m(_train_fn pid=763632)[0m 	speed: 0.0314s/iter; left time: 35.2375s
[36m(_train_fn pid=763632)[0m 	iters: 200, epoch: 4 | loss: 0.5827655
[36m(_train_fn pid=763632)[0m 	speed: 0.0176s/iter; left time: 18.0116s
[36m(_train_fn pid=763632)[0m Updating learning rate to 7.484316368075568e-05
[36m(_train_fn pid=763632)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=763632)[0m saving checkpoint...
[36m(_train_fn pid=763632)[0m Epoch: 4 cost time: 4.344604253768921
[36m(_train_fn pid=763632)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5956769 Vali Loss: 1.5822317 Best vali loss: 1.5728036
[36m(_train_fn pid=763632)[0m 	iters: 100, epoch: 5 | loss: 0.5979078
[36m(_train_fn pid=763632)[0m 	speed: 0.0315s/iter; left time: 27.6058s
[36m(_train_fn pid=763632)[0m 	iters: 200, epoch: 5 | loss: 0.5582171
[36m(_train_fn pid=763632)[0m 	speed: 0.0177s/iter; left time: 13.7794s

Trial trial-5d4622b7 completed after 5 iterations at 2024-08-24 07:51:33. Total running time: 30min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5d4622b7 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          4.91156 â”‚
â”‚ time_total_s                                 25.2 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                            1.5728 â”‚
â”‚ train_loss                                0.58753 â”‚
â”‚ valid_loss                                1.59506 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=763632)[0m Updating learning rate to 3.742158184037784e-05
[36m(_train_fn pid=763632)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=763632)[0m saving checkpoint...
[36m(_train_fn pid=763632)[0m Epoch: 5 cost time: 4.364476919174194
[36m(_train_fn pid=763632)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5875331 Vali Loss: 1.5950589 Best vali loss: 1.5728036
[36m(_train_fn pid=763632)[0m Early stopping

Trial trial-bcb9971a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-bcb9971a config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.08403 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00317 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=764149)[0m configuration
[36m(_train_fn pid=764149)[0m {'batch_size': 16, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.08402778843997957, 'e_layers': 3, 'learning_rate': 0.0031681743497504506, 'd_ff': 384}
[36m(_train_fn pid=764149)[0m Use GPU: cuda:0
[36m(_train_fn pid=764149)[0m train 7825
[36m(_train_fn pid=764149)[0m val 2161
[36m(_train_fn pid=764149)[0m start_epoch 0
[36m(_train_fn pid=764149)[0m max_epoch 8
[36m(_train_fn pid=764149)[0m 	iters: 100, epoch: 1 | loss: 0.7498296
[36m(_train_fn pid=764149)[0m 	speed: 0.0248s/iter; left time: 94.7184s
[36m(_train_fn pid=764149)[0m 	iters: 200, epoch: 1 | loss: 0.8185453
[36m(_train_fn pid=764149)[0m 	speed: 0.0176s/iter; left time: 65.1711s
[36m(_train_fn pid=764149)[0m 	iters: 300, epoch: 1 | loss: 0.5408155
[36m(_train_fn pid=764149)[0m 	speed: 0.0175s/iter; left time: 63.2767s

Trial status: 35 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:51:42. Total running time: 30min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-bcb9971a   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED
[36m(_train_fn pid=764149)[0m 	iters: 400, epoch: 1 | loss: 0.6724550
[36m(_train_fn pid=764149)[0m 	speed: 0.0175s/iter; left time: 61.6367s
[36m(_train_fn pid=764149)[0m Updating learning rate to 0.0031681743497504506
[36m(_train_fn pid=764149)[0m saving checkpoint...
[36m(_train_fn pid=764149)[0m Validation loss decreased (inf --> 1.6362).  Saving model state dict ...
[36m(_train_fn pid=764149)[0m Epoch: 1 cost time: 9.047444820404053
[36m(_train_fn pid=764149)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7228894 Vali Loss: 1.6361956 Best vali loss: 1.6361956
[36m(_train_fn pid=764149)[0m 	iters: 100, epoch: 2 | loss: 0.7018597
[36m(_train_fn pid=764149)[0m 	speed: 0.0456s/iter; left time: 151.5677s
[36m(_train_fn pid=764149)[0m 	iters: 200, epoch: 2 | loss: 0.5923792
[36m(_train_fn pid=764149)[0m 	speed: 0.0176s/iter; left time: 56.6721s
[36m(_train_fn pid=764149)[0m 	iters: 300, epoch: 2 | loss: 0.6123382
[36m(_train_fn pid=764149)[0m 	speed: 0.0175s/iter; left time: 54.7872s
[36m(_train_fn pid=764149)[0m 	iters: 400, epoch: 2 | loss: 0.5031971
[36m(_train_fn pid=764149)[0m 	speed: 0.0175s/iter; left time: 53.0647s
[36m(_train_fn pid=764149)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcb9971a_36_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0840,e_layer_2024-08-24_07-51-33/checkpoint_000002)
[36m(_train_fn pid=764149)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcb9971a_36_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0840,e_layer_2024-08-24_07-51-33/checkpoint_000003)
[36m(_train_fn pid=764149)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-bcb9971a_36_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0840,e_layer_2024-08-24_07-51-33/checkpoint_000004)
[36m(_train_fn pid=764149)[0m Updating learning rate to 0.0015840871748752253
[36m(_train_fn pid=764149)[0m saving checkpoint...
[36m(_train_fn pid=764149)[0m Validation loss decreased (1.6362 --> 1.5773).  Saving model state dict ...
[36m(_train_fn pid=764149)[0m Epoch: 2 cost time: 8.626760721206665
[36m(_train_fn pid=764149)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6112557 Vali Loss: 1.5773147 Best vali loss: 1.5773147
[36m(_train_fn pid=764149)[0m 	iters: 100, epoch: 3 | loss: 0.5834482
[36m(_train_fn pid=764149)[0m 	speed: 0.0460s/iter; left time: 130.3227s
[36m(_train_fn pid=764149)[0m 	iters: 200, epoch: 3 | loss: 0.5504382
[36m(_train_fn pid=764149)[0m 	speed: 0.0176s/iter; left time: 48.2554s
[36m(_train_fn pid=764149)[0m 	iters: 300, epoch: 3 | loss: 0.7384732
[36m(_train_fn pid=764149)[0m 	speed: 0.0176s/iter; left time: 46.4462s
[36m(_train_fn pid=764149)[0m 	iters: 400, epoch: 3 | loss: 0.4456615
[36m(_train_fn pid=764149)[0m 	speed: 0.0176s/iter; left time: 44.7256s
[36m(_train_fn pid=764149)[0m Updating learning rate to 0.0007920435874376126
[36m(_train_fn pid=764149)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=764149)[0m saving checkpoint...
[36m(_train_fn pid=764149)[0m Epoch: 3 cost time: 8.667995691299438
[36m(_train_fn pid=764149)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5499962 Vali Loss: 1.6018687 Best vali loss: 1.5773147
[36m(_train_fn pid=764149)[0m 	iters: 100, epoch: 4 | loss: 0.5516737
[36m(_train_fn pid=764149)[0m 	speed: 0.0460s/iter; left time: 107.8324s
[36m(_train_fn pid=764149)[0m 	iters: 200, epoch: 4 | loss: 0.5429659
[36m(_train_fn pid=764149)[0m 	speed: 0.0177s/iter; left time: 39.7263s
[36m(_train_fn pid=764149)[0m 	iters: 300, epoch: 4 | loss: 0.4489590
[36m(_train_fn pid=764149)[0m 	speed: 0.0177s/iter; left time: 37.9095s
Trial status: 35 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:52:12. Total running time: 31min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-bcb9971a   RUNNING           3            30.3942       0.549996        1.60187             1.57731 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
30 more TERMINATED
[36m(_train_fn pid=764149)[0m 	iters: 400, epoch: 4 | loss: 0.4516251
[36m(_train_fn pid=764149)[0m 	speed: 0.0177s/iter; left time: 36.1620s
[36m(_train_fn pid=764149)[0m Updating learning rate to 0.0003960217937188063
[36m(_train_fn pid=764149)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=764149)[0m saving checkpoint...
[36m(_train_fn pid=764149)[0m Epoch: 4 cost time: 8.682425498962402
[36m(_train_fn pid=764149)[0m Epoch: 4, Steps: 489 | Train Loss: 0.4761310 Vali Loss: 1.5910986 Best vali loss: 1.5773147
[36m(_train_fn pid=764149)[0m 	iters: 100, epoch: 5 | loss: 0.4229279
[36m(_train_fn pid=764149)[0m 	speed: 0.0458s/iter; left time: 85.1295s
[36m(_train_fn pid=764149)[0m 	iters: 200, epoch: 5 | loss: 0.4321492
[36m(_train_fn pid=764149)[0m 	speed: 0.0177s/iter; left time: 31.0743s
[36m(_train_fn pid=764149)[0m 	iters: 300, epoch: 5 | loss: 0.4113308
[36m(_train_fn pid=764149)[0m 	speed: 0.0177s/iter; left time: 29.3604s
[36m(_train_fn pid=764149)[0m 	iters: 400, epoch: 5 | loss: 0.4184535
[36m(_train_fn pid=764149)[0m 	speed: 0.0177s/iter; left time: 27.5553s

Trial trial-bcb9971a completed after 5 iterations at 2024-08-24 07:52:25. Total running time: 31min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-bcb9971a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          9.90948 â”‚
â”‚ time_total_s                             50.18376 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.57731 â”‚
â”‚ train_loss                                0.39829 â”‚
â”‚ valid_loss                                1.58401 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=764149)[0m Updating learning rate to 0.00019801089685940316
[36m(_train_fn pid=764149)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=764149)[0m saving checkpoint...
[36m(_train_fn pid=764149)[0m Epoch: 5 cost time: 8.70202350616455
[36m(_train_fn pid=764149)[0m Epoch: 5, Steps: 489 | Train Loss: 0.3982858 Vali Loss: 1.5840113 Best vali loss: 1.5773147
[36m(_train_fn pid=764149)[0m Early stopping

Trial trial-302d000c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-302d000c config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13725 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00962 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=764739)[0m configuration
[36m(_train_fn pid=764739)[0m {'batch_size': 128, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.1372485290869624, 'e_layers': 4, 'learning_rate': 0.009615210437847388, 'd_ff': 256}
[36m(_train_fn pid=764739)[0m Use GPU: cuda:0
[36m(_train_fn pid=764739)[0m train 7825
[36m(_train_fn pid=764739)[0m val 2161
[36m(_train_fn pid=764739)[0m start_epoch 02024-08-24 07:52:37,252	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=764739)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-302d000c_37_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=_2024-08-24_07-52-25/checkpoint_000000)
[36m(_train_fn pid=764739)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-302d000c_37_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=_2024-08-24_07-52-25/checkpoint_000001)
[36m(_train_fn pid=764739)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-302d000c_37_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=_2024-08-24_07-52-25/checkpoint_000002)
[36m(_train_fn pid=764739)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-302d000c_37_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=_2024-08-24_07-52-25/checkpoint_000003)
[36m(_train_fn pid=764739)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-302d000c_37_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=_2024-08-24_07-52-25/checkpoint_000004)
[36m(_train_fn pid=764739)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-302d000c_37_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=_2024-08-24_07-52-25/checkpoint_000005)

[36m(_train_fn pid=764739)[0m max_epoch 8
[36m(_train_fn pid=764739)[0m Validation loss decreased (inf --> 1.9370).  Saving model state dict ...
[36m(_train_fn pid=764739)[0m Updating learning rate to 0.009615210437847388
[36m(_train_fn pid=764739)[0m saving checkpoint...
[36m(_train_fn pid=764739)[0m Epoch: 1 cost time: 8.419830560684204
[36m(_train_fn pid=764739)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8740030 Vali Loss: 1.9369654 Best vali loss: 1.9369654

Trial status: 36 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:52:42. Total running time: 31min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-302d000c   RUNNING           1            9.79553       0.874003        1.93697             1.93697 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
[36m(_train_fn pid=764739)[0m Updating learning rate to 0.004807605218923694
[36m(_train_fn pid=764739)[0m saving checkpoint...
[36m(_train_fn pid=764739)[0m Validation loss decreased (1.9370 --> 1.6233).  Saving model state dict ...
[36m(_train_fn pid=764739)[0m Epoch: 2 cost time: 8.209161758422852
[36m(_train_fn pid=764739)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6470609 Vali Loss: 1.6233003 Best vali loss: 1.6233003
[36m(_train_fn pid=764739)[0m Updating learning rate to 0.002403802609461847
[36m(_train_fn pid=764739)[0m saving checkpoint...
[36m(_train_fn pid=764739)[0m Validation loss decreased (1.6233 --> 1.6207).  Saving model state dict ...
[36m(_train_fn pid=764739)[0m Epoch: 3 cost time: 8.213178873062134
[36m(_train_fn pid=764739)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6018395 Vali Loss: 1.6207378 Best vali loss: 1.6207378
[36m(_train_fn pid=764739)[0m Updating learning rate to 0.0012019013047309234
[36m(_train_fn pid=764739)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=764739)[0m saving checkpoint...
[36m(_train_fn pid=764739)[0m Epoch: 4 cost time: 8.202839136123657
[36m(_train_fn pid=764739)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5761618 Vali Loss: 1.6239374 Best vali loss: 1.6207378
Trial status: 36 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:53:12. Total running time: 32min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-302d000c   RUNNING           4            37.2942       0.576162        1.62394             1.62074 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
31 more TERMINATED
[36m(_train_fn pid=764739)[0m Updating learning rate to 0.0006009506523654617
[36m(_train_fn pid=764739)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=764739)[0m saving checkpoint...
[36m(_train_fn pid=764739)[0m Epoch: 5 cost time: 8.21418023109436
[36m(_train_fn pid=764739)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5611465 Vali Loss: 1.6388491 Best vali loss: 1.6207378

Trial trial-302d000c completed after 6 iterations at 2024-08-24 07:53:23. Total running time: 32min 14s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-302d000c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          9.16041 â”‚
â”‚ time_total_s                             55.61922 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.62074 â”‚
â”‚ train_loss                                0.55007 â”‚
â”‚ valid_loss                                1.63072 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=764739)[0m Updating learning rate to 0.00030047532618273086
[36m(_train_fn pid=764739)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=764739)[0m saving checkpoint...
[36m(_train_fn pid=764739)[0m Epoch: 6 cost time: 8.210041284561157
[36m(_train_fn pid=764739)[0m Epoch: 6, Steps: 61 | Train Loss: 0.5500745 Vali Loss: 1.6307238 Best vali loss: 1.6207378
[36m(_train_fn pid=764739)[0m Early stopping

[36m(_train_fn pid=765416)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e4c3658_38_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-53-23/checkpoint_000000)
[36m(_train_fn pid=765416)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e4c3658_38_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-53-23/checkpoint_000001)
2024-08-24 07:53:32,300	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:53:35,171	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=765416)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e4c3658_38_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-53-23/checkpoint_000002)
2024-08-24 07:53:38,043	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=765416)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e4c3658_38_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-53-23/checkpoint_000003)
2024-08-24 07:53:40,896	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=765416)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e4c3658_38_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-53-23/checkpoint_000004)
2024-08-24 07:53:43,755	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=765416)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e4c3658_38_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-53-23/checkpoint_000005)
Trial trial-5e4c3658 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5e4c3658 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.07162 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                       0.0023 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=765416)[0m configuration
[36m(_train_fn pid=765416)[0m {'batch_size': 32, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.07162120286235375, 'e_layers': 3, 'learning_rate': 0.0022996457554414775, 'd_ff': 32}
[36m(_train_fn pid=765416)[0m Use GPU: cuda:0
[36m(_train_fn pid=765416)[0m train 7825
[36m(_train_fn pid=765416)[0m val 2161
[36m(_train_fn pid=765416)[0m start_epoch 0
[36m(_train_fn pid=765416)[0m max_epoch 8
[36m(_train_fn pid=765416)[0m 	iters: 100, epoch: 1 | loss: 1.0060456
[36m(_train_fn pid=765416)[0m 	speed: 0.0163s/iter; left time: 30.2136s
[36m(_train_fn pid=765416)[0m 	iters: 200, epoch: 1 | loss: 0.7730117
[36m(_train_fn pid=765416)[0m 	speed: 0.0111s/iter; left time: 19.5256s
[36m(_train_fn pid=765416)[0m Updating learning rate to 0.0022996457554414775
[36m(_train_fn pid=765416)[0m saving checkpoint...
[36m(_train_fn pid=765416)[0m Validation loss decreased (inf --> 1.9150).  Saving model state dict ...
[36m(_train_fn pid=765416)[0m Epoch: 1 cost time: 2.9690775871276855
[36m(_train_fn pid=765416)[0m Epoch: 1, Steps: 244 | Train Loss: 1.0077502 Vali Loss: 1.9149718 Best vali loss: 1.9149718
[36m(_train_fn pid=765416)[0m 	iters: 100, epoch: 2 | loss: 0.5897273
[36m(_train_fn pid=765416)[0m 	speed: 0.0198s/iter; left time: 31.8545s
[36m(_train_fn pid=765416)[0m 	iters: 200, epoch: 2 | loss: 0.5932168
[36m(_train_fn pid=765416)[0m 	speed: 0.0113s/iter; left time: 17.0007s
[36m(_train_fn pid=765416)[0m Updating learning rate to 0.0011498228777207388
[36m(_train_fn pid=765416)[0m saving checkpoint...
[36m(_train_fn pid=765416)[0m Validation loss decreased (1.9150 --> 1.5930).  Saving model state dict ...
[36m(_train_fn pid=765416)[0m Epoch: 2 cost time: 2.791097640991211
[36m(_train_fn pid=765416)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6323477 Vali Loss: 1.5930194 Best vali loss: 1.5930194
[36m(_train_fn pid=765416)[0m 	iters: 100, epoch: 3 | loss: 0.6673945
[36m(_train_fn pid=765416)[0m 	speed: 0.0189s/iter; left time: 25.7879s
[36m(_train_fn pid=765416)[0m 	iters: 200, epoch: 3 | loss: 0.6415299
[36m(_train_fn pid=765416)[0m 	speed: 0.0102s/iter; left time: 12.9505s
[36m(_train_fn pid=765416)[0m Updating learning rate to 0.0005749114388603694
[36m(_train_fn pid=765416)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=765416)[0m saving checkpoint...
[36m(_train_fn pid=765416)[0m Epoch: 3 cost time: 2.5569841861724854
[36m(_train_fn pid=765416)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5870799 Vali Loss: 1.6132747 Best vali loss: 1.5930194
[36m(_train_fn pid=765416)[0m 	iters: 100, epoch: 4 | loss: 0.6201370
[36m(_train_fn pid=765416)[0m 	speed: 0.0185s/iter; left time: 20.7079s
[36m(_train_fn pid=765416)[0m 	iters: 200, epoch: 4 | loss: 0.5431423
[36m(_train_fn pid=765416)[0m 	speed: 0.0103s/iter; left time: 10.4796s
[36m(_train_fn pid=765416)[0m Updating learning rate to 0.0002874557194301847
[36m(_train_fn pid=765416)[0m saving checkpoint...
[36m(_train_fn pid=765416)[0m Validation loss decreased (1.5930 --> 1.5775).  Saving model state dict ...
[36m(_train_fn pid=765416)[0m Epoch: 4 cost time: 2.5550835132598877
[36m(_train_fn pid=765416)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5761875 Vali Loss: 1.5775499 Best vali loss: 1.5775499
[36m(_train_fn pid=765416)[0m 	iters: 100, epoch: 5 | loss: 0.6535476
[36m(_train_fn pid=765416)[0m 	speed: 0.0185s/iter; left time: 16.1900s
[36m(_train_fn pid=765416)[0m 	iters: 200, epoch: 5 | loss: 0.7081879
[36m(_train_fn pid=765416)[0m 	speed: 0.0102s/iter; left time: 7.9045s
[36m(_train_fn pid=765416)[0m Updating learning rate to 0.00014372785971509234
[36m(_train_fn pid=765416)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=765416)[0m saving checkpoint...
[36m(_train_fn pid=765416)[0m Epoch: 5 cost time: 2.542426347732544
[36m(_train_fn pid=765416)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5689206 Vali Loss: 1.5992501 Best vali loss: 1.5775499
[36m(_train_fn pid=765416)[0m 	iters: 100, epoch: 6 | loss: 0.4959665
[36m(_train_fn pid=765416)[0m 	speed: 0.0183s/iter; left time: 11.5738s

Trial status: 37 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:53:42. Total running time: 32min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5e4c3658   RUNNING           5            15.4116       0.568921        1.59925             1.57755 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
32 more TERMINATED
[36m(_train_fn pid=765416)[0m 	iters: 200, epoch: 6 | loss: 0.5294279
[36m(_train_fn pid=765416)[0m 	speed: 0.0103s/iter; left time: 5.4694s
[36m(_train_fn pid=765416)[0m Updating learning rate to 7.186392985754617e-05
[36m(_train_fn pid=765416)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=765416)[0m saving checkpoint...
[36m(_train_fn pid=765416)[0m Epoch: 6 cost time: 2.5465123653411865
[36m(_train_fn pid=765416)[0m Epoch: 6, Steps: 244 | Train Loss: 0.5649831 Vali Loss: 1.5985670 Best vali loss: 1.5775499
[36m(_train_fn pid=765416)[0m 	iters: 100, epoch: 7 | loss: 0.5136545
[36m(_train_fn pid=765416)[0m 	speed: 0.0192s/iter; left time: 7.4713s
2024-08-24 07:53:46,848	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=765416)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e4c3658_38_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0.0_2024-08-24_07-53-23/checkpoint_000006)
2024-08-24 07:54:11,187	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=766064)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-587538db_39_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_07-53-46/checkpoint_000000)
2024-08-24 07:54:33,455	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=766064)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-587538db_39_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_07-53-46/checkpoint_000001)
[36m(_train_fn pid=765416)[0m 	iters: 200, epoch: 7 | loss: 0.5303747
[36m(_train_fn pid=765416)[0m 	speed: 0.0112s/iter; left time: 3.2456s

Trial trial-5e4c3658 completed after 7 iterations at 2024-08-24 07:53:46. Total running time: 32min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5e4c3658 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          3.09047 â”‚
â”‚ time_total_s                             21.35956 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.57755 â”‚
â”‚ train_loss                                0.56307 â”‚
â”‚ valid_loss                                1.59562 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=765416)[0m Updating learning rate to 3.5931964928773086e-05
[36m(_train_fn pid=765416)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=765416)[0m saving checkpoint...
[36m(_train_fn pid=765416)[0m Epoch: 7 cost time: 2.7758164405822754
[36m(_train_fn pid=765416)[0m Epoch: 7, Steps: 244 | Train Loss: 0.5630735 Vali Loss: 1.5956233 Best vali loss: 1.5775499
[36m(_train_fn pid=765416)[0m Early stopping

Trial trial-587538db started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-587538db config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.06486 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00373 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=766064)[0m configuration
[36m(_train_fn pid=766064)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.06485950535148399, 'e_layers': 1, 'learning_rate': 0.003729593055226916, 'd_ff': 2048}
[36m(_train_fn pid=766064)[0m Use GPU: cuda:0
[36m(_train_fn pid=766064)[0m train 7825
[36m(_train_fn pid=766064)[0m val 2161
[36m(_train_fn pid=766064)[0m start_epoch 0
[36m(_train_fn pid=766064)[0m max_epoch 8
[36m(_train_fn pid=766064)[0m 	iters: 100, epoch: 1 | loss: 0.7755696
[36m(_train_fn pid=766064)[0m 	speed: 0.0854s/iter; left time: 158.3139s
[36m(_train_fn pid=766064)[0m 	iters: 200, epoch: 1 | loss: 0.7046027
[36m(_train_fn pid=766064)[0m 	speed: 0.0811s/iter; left time: 142.2398s
[36m(_train_fn pid=766064)[0m Updating learning rate to 0.003729593055226916
[36m(_train_fn pid=766064)[0m saving checkpoint...
[36m(_train_fn pid=766064)[0m Validation loss decreased (inf --> 1.6708).  Saving model state dict ...
[36m(_train_fn pid=766064)[0m Epoch: 1 cost time: 19.972997426986694
[36m(_train_fn pid=766064)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7450400 Vali Loss: 1.6708409 Best vali loss: 1.6708409

Trial status: 38 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:54:12. Total running time: 33min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-587538db   RUNNING           1            22.7451       0.74504         1.67084             1.67084 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
33 more TERMINATED
[36m(_train_fn pid=766064)[0m 	iters: 100, epoch: 2 | loss: 0.8356271
[36m(_train_fn pid=766064)[0m 	speed: 0.1409s/iter; left time: 226.7106s
[36m(_train_fn pid=766064)[0m 	iters: 200, epoch: 2 | loss: 0.7685727
[36m(_train_fn pid=766064)[0m 	speed: 0.0816s/iter; left time: 123.1577s
[36m(_train_fn pid=766064)[0m Updating learning rate to 0.001864796527613458
[36m(_train_fn pid=766064)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=766064)[0m saving checkpoint...
[36m(_train_fn pid=766064)[0m Epoch: 2 cost time: 19.90821623802185
[36m(_train_fn pid=766064)[0m Epoch: 2, Steps: 244 | Train Loss: 7.7382011 Vali Loss: 1.9172505 Best vali loss: 1.6708409
[36m(_train_fn pid=766064)[0m 	iters: 100, epoch: 3 | loss: 0.8050977
[36m(_train_fn pid=766064)[0m 	speed: 0.1412s/iter; left time: 192.7750s
Trial status: 38 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:54:42. Total running time: 33min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:54:55,757	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=766064)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-587538db_39_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_07-53-46/checkpoint_000002)
2024-08-24 07:55:18,077	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=766064)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-587538db_39_alpha_d_ff=4,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_07-53-46/checkpoint_000003)
2024-08-24 07:55:22,838	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:55:24,402	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=766706)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ba979bd7_40_alpha_d_ff=3,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0739,e_layer_2024-08-24_07-55-18/checkpoint_000001)[32m [repeated 2x across cluster][0m
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-587538db   RUNNING           2            45.0125       7.7382          1.91725             1.67084 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
33 more TERMINATED
[36m(_train_fn pid=766064)[0m 	iters: 200, epoch: 3 | loss: 0.6768681
[36m(_train_fn pid=766064)[0m 	speed: 0.0818s/iter; left time: 103.4880s
[36m(_train_fn pid=766064)[0m Updating learning rate to 0.000932398263806729
[36m(_train_fn pid=766064)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=766064)[0m saving checkpoint...
[36m(_train_fn pid=766064)[0m Epoch: 3 cost time: 19.94481611251831
[36m(_train_fn pid=766064)[0m Epoch: 3, Steps: 244 | Train Loss: 0.7379518 Vali Loss: 1.8628001 Best vali loss: 1.6708409
[36m(_train_fn pid=766064)[0m 	iters: 100, epoch: 4 | loss: 0.7526165
[36m(_train_fn pid=766064)[0m 	speed: 0.1413s/iter; left time: 158.3896s
[36m(_train_fn pid=766064)[0m 	iters: 200, epoch: 4 | loss: 0.6500905
[36m(_train_fn pid=766064)[0m 	speed: 0.0819s/iter; left time: 83.5806s
Trial status: 38 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:55:12. Total running time: 34min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-587538db   RUNNING           3            67.3077       0.737952        1.8628              1.67084 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
33 more TERMINATED

Trial trial-587538db completed after 4 iterations at 2024-08-24 07:55:18. Total running time: 34min 9s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-587538db result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         22.31728 â”‚
â”‚ time_total_s                             89.62499 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.67084 â”‚
â”‚ train_loss                                 0.7209 â”‚
â”‚ valid_loss                                1.81349 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=766064)[0m Updating learning rate to 0.0004661991319033645
[36m(_train_fn pid=766064)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=766064)[0m saving checkpoint...
[36m(_train_fn pid=766064)[0m Epoch: 4 cost time: 19.96524143218994
[36m(_train_fn pid=766064)[0m Epoch: 4, Steps: 244 | Train Loss: 0.7209010 Vali Loss: 1.8134916 Best vali loss: 1.6708409
[36m(_train_fn pid=766064)[0m Early stopping

Trial trial-ba979bd7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ba979bd7 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07387 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00065 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=766706)[0m configuration
[36m(_train_fn pid=766706)[0m {'batch_size': 128, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.07387322026704046, 'e_layers': 3, 'learning_rate': 0.0006476743214879139, 'd_ff': 48}
[36m(_train_fn pid=766706)[0m Use GPU: cuda:0
[36m(_train_fn pid=766706)[0m train 7825
[36m(_train_fn pid=766706)[0m val 2161
[36m(_train_fn pid=766706)[0m start_epoch 0
[36m(_train_fn pid=766706)[0m max_epoch 8
[36m(_train_fn pid=766706)[0m Validation loss decreased (inf --> 3.0008).  Saving model state dict ...
[36m(_train_fn pid=766706)[0m Validation loss decreased (3.0008 --> 1.8494).  Saving model state dict ...
[36m(_train_fn pid=766706)[0m Updating learning rate to 0.00032383716074395693[32m [repeated 2x across cluster][0m
2024-08-24 07:55:25,963	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:55:27,535	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:55:29,092	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:55:30,654	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=766706)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ba979bd7_40_alpha_d_ff=3,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0739,e_layer_2024-08-24_07-55-18/checkpoint_000005)[32m [repeated 4x across cluster][0m
2024-08-24 07:55:32,223	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:55:33,800	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=767400)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-87b712b1_41_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-55-33/checkpoint_000000)[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=766706)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=766706)[0m Epoch: 2 cost time: 1.292372226715088[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=766706)[0m Epoch: 2, Steps: 61 | Train Loss: 0.9060945 Vali Loss: 1.8493991 Best vali loss: 1.8493991[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=766706)[0m Validation loss decreased (1.8494 --> 1.7359).  Saving model state dict ...
[36m(_train_fn pid=766706)[0m Validation loss decreased (1.7359 --> 1.6931).  Saving model state dict ...
[36m(_train_fn pid=766706)[0m Validation loss decreased (1.6931 --> 1.6770).  Saving model state dict ...
[36m(_train_fn pid=766706)[0m Validation loss decreased (1.6770 --> 1.6701).  Saving model state dict ...
[36m(_train_fn pid=766706)[0m Updating learning rate to 2.0239822546497308e-05[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=766706)[0m saving checkpoint...[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=766706)[0m Epoch: 6 cost time: 1.2938847541809082[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=766706)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6577003 Vali Loss: 1.6700796 Best vali loss: 1.6700796[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=766706)[0m Validation loss decreased (1.6701 --> 1.6669).  Saving model state dict ...

Trial trial-ba979bd7 completed after 8 iterations at 2024-08-24 07:55:33. Total running time: 34min 25s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ba979bd7 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          1.57374 â”‚
â”‚ time_total_s                             13.32572 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.66541 â”‚
â”‚ train_loss                                0.65454 â”‚
â”‚ valid_loss                                1.66541 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=766706)[0m Validation loss decreased (1.6669 --> 1.6654).  Saving model state dict ...

Trial trial-87b712b1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-87b712b1 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10655 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.01066 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=767400)[0m configuration
[36m(_train_fn pid=767400)[0m {'batch_size': 16, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.10654897127238003, 'e_layers': 4, 'learning_rate': 0.010664834889612618, 'd_ff': 128}
[36m(_train_fn pid=767400)[0m Use GPU: cuda:0
[36m(_train_fn pid=767400)[0m train 7825
[36m(_train_fn pid=767400)[0m val 2161
[36m(_train_fn pid=767400)[0m start_epoch 0
[36m(_train_fn pid=767400)[0m max_epoch 8
[36m(_train_fn pid=766706)[0m Updating learning rate to 5.059955636624327e-06[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=766706)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=766706)[0m Epoch: 8 cost time: 1.2936811447143555[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=766706)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6545413 Vali Loss: 1.6654125 Best vali loss: 1.6654125[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=767400)[0m 	iters: 100, epoch: 1 | loss: 0.6912466
[36m(_train_fn pid=767400)[0m 	speed: 0.0185s/iter; left time: 70.4030s
[36m(_train_fn pid=767400)[0m 	iters: 200, epoch: 1 | loss: 0.5240960
[36m(_train_fn pid=767400)[0m 	speed: 0.0135s/iter; left time: 50.1832s
[36m(_train_fn pid=767400)[0m 	iters: 300, epoch: 1 | loss: 0.5467145
[36m(_train_fn pid=767400)[0m 	speed: 0.0135s/iter; left time: 48.8731s
[36m(_train_fn pid=767400)[0m 	iters: 400, epoch: 1 | loss: 0.6517942
[36m(_train_fn pid=767400)[0m 	speed: 0.0135s/iter; left time: 47.5233s

Trial status: 40 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:55:42. Total running time: 34min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-87b712b1   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
35 more TERMINATED
[36m(_train_fn pid=767400)[0m Updating learning rate to 0.010664834889612618
[36m(_train_fn pid=767400)[0m saving checkpoint...
[36m(_train_fn pid=767400)[0m Validation loss decreased (inf --> 1.5659).  Saving model state dict ...
[36m(_train_fn pid=767400)[0m Epoch: 1 cost time: 6.844863414764404
[36m(_train_fn pid=767400)[0m Epoch: 1, Steps: 489 | Train Loss: 0.6573212 Vali Loss: 1.5659109 Best vali loss: 1.5659109
[36m(_train_fn pid=767400)[0m 	iters: 100, epoch: 2 | loss: 0.7126487
[36m(_train_fn pid=767400)[0m 	speed: 0.0312s/iter; left time: 103.8432s
[36m(_train_fn pid=767400)[0m 	iters: 200, epoch: 2 | loss: 0.6544035
[36m(_train_fn pid=767400)[0m 	speed: 0.0123s/iter; left time: 39.5003s
[36m(_train_fn pid=767400)[0m 	iters: 300, epoch: 2 | loss: 0.6860719
[36m(_train_fn pid=767400)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-87b712b1_41_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-55-33/checkpoint_000001)
[36m(_train_fn pid=767400)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-87b712b1_41_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-55-33/checkpoint_000002)
[36m(_train_fn pid=767400)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-87b712b1_41_alpha_d_ff=4,batch_size=16,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-55-33/checkpoint_000003)
2024-08-24 07:56:08,317	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=767858)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2291caba_42_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-56-04/checkpoint_000000)
2024-08-24 07:56:09,528	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=767858)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2291caba_42_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-56-04/checkpoint_000001)
2024-08-24 07:56:10,740	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=767858)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2291caba_42_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-56-04/checkpoint_000002)
[36m(_train_fn pid=767858)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2291caba_42_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-56-04/checkpoint_000003)
2024-08-24 07:56:11,949	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=767400)[0m 	speed: 0.0122s/iter; left time: 38.1971s
[36m(_train_fn pid=767400)[0m 	iters: 400, epoch: 2 | loss: 0.5411470
[36m(_train_fn pid=767400)[0m 	speed: 0.0122s/iter; left time: 37.0430s
[36m(_train_fn pid=767400)[0m Updating learning rate to 0.005332417444806309
[36m(_train_fn pid=767400)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=767400)[0m saving checkpoint...
[36m(_train_fn pid=767400)[0m Epoch: 2 cost time: 6.039533615112305
[36m(_train_fn pid=767400)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6064354 Vali Loss: 1.5989734 Best vali loss: 1.5659109
[36m(_train_fn pid=767400)[0m 	iters: 100, epoch: 3 | loss: 0.5232065
[36m(_train_fn pid=767400)[0m 	speed: 0.0309s/iter; left time: 87.4713s
[36m(_train_fn pid=767400)[0m 	iters: 200, epoch: 3 | loss: 0.5675387
[36m(_train_fn pid=767400)[0m 	speed: 0.0123s/iter; left time: 33.6768s
[36m(_train_fn pid=767400)[0m 	iters: 300, epoch: 3 | loss: 0.6563274
[36m(_train_fn pid=767400)[0m 	speed: 0.0123s/iter; left time: 32.5367s
[36m(_train_fn pid=767400)[0m 	iters: 400, epoch: 3 | loss: 0.4907288
[36m(_train_fn pid=767400)[0m 	speed: 0.0123s/iter; left time: 31.2300s
[36m(_train_fn pid=767400)[0m Updating learning rate to 0.0026662087224031544
[36m(_train_fn pid=767400)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=767400)[0m saving checkpoint...
[36m(_train_fn pid=767400)[0m Epoch: 3 cost time: 6.074052095413208
[36m(_train_fn pid=767400)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5476153 Vali Loss: 1.6253803 Best vali loss: 1.5659109
[36m(_train_fn pid=767400)[0m 	iters: 100, epoch: 4 | loss: 0.4312255
[36m(_train_fn pid=767400)[0m 	speed: 0.0314s/iter; left time: 73.7587s
[36m(_train_fn pid=767400)[0m 	iters: 200, epoch: 4 | loss: 0.5094042
[36m(_train_fn pid=767400)[0m 	speed: 0.0134s/iter; left time: 30.0580s
[36m(_train_fn pid=767400)[0m 	iters: 300, epoch: 4 | loss: 0.5133178
[36m(_train_fn pid=767400)[0m 	speed: 0.0134s/iter; left time: 28.8625s
[36m(_train_fn pid=767400)[0m 	iters: 400, epoch: 4 | loss: 0.4159914
[36m(_train_fn pid=767400)[0m 	speed: 0.0134s/iter; left time: 27.4733s

Trial trial-87b712b1 completed after 4 iterations at 2024-08-24 07:56:04. Total running time: 34min 55s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-87b712b1 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                          7.26869 â”‚
â”‚ time_total_s                             28.63049 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.56591 â”‚
â”‚ train_loss                                0.47504 â”‚
â”‚ valid_loss                                1.71375 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=767400)[0m Updating learning rate to 0.0013331043612015772
[36m(_train_fn pid=767400)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=767400)[0m saving checkpoint...
[36m(_train_fn pid=767400)[0m Epoch: 4 cost time: 6.617555618286133
[36m(_train_fn pid=767400)[0m Epoch: 4, Steps: 489 | Train Loss: 0.4750374 Vali Loss: 1.7137463 Best vali loss: 1.5659109
[36m(_train_fn pid=767400)[0m Early stopping

Trial trial-2291caba started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2291caba config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.08351 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00757 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=767858)[0m configuration
[36m(_train_fn pid=767858)[0m {'batch_size': 128, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'avg', 'dropout': 0.08350870836512937, 'e_layers': 4, 'learning_rate': 0.007572815449552786, 'd_ff': 16}
[36m(_train_fn pid=767858)[0m Use GPU: cuda:0
[36m(_train_fn pid=767858)[0m train 7825
[36m(_train_fn pid=767858)[0m val 2161
[36m(_train_fn pid=767858)[0m start_epoch 0
[36m(_train_fn pid=767858)[0m max_epoch 8
[36m(_train_fn pid=767858)[0m Validation loss decreased (inf --> 2.0023).  Saving model state dict ...
[36m(_train_fn pid=767858)[0m Validation loss decreased (2.0023 --> 1.6333).  Saving model state dict ...
[36m(_train_fn pid=767858)[0m Updating learning rate to 0.003786407724776393[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=767858)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=767858)[0m Epoch: 2 cost time: 1.0367681980133057[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=767858)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6947802 Vali Loss: 1.6333359 Best vali loss: 1.6333359[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=767858)[0m Validation loss decreased (1.6333 --> 1.6097).  Saving model state dict ...
[36m(_train_fn pid=767858)[0m EarlyStopping counter: 1 out of 3

Trial status: 41 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:56:12. Total running time: 35min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 07:56:13,153	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=767858)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2291caba_42_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-56-04/checkpoint_000004)
2024-08-24 07:56:14,358	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=767858)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2291caba_42_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0._2024-08-24_07-56-04/checkpoint_000005)
[36m(_train_fn pid=768398)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8415ef6e_43_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1381,e_layer_2024-08-24_07-56-14/checkpoint_000000)
2024-08-24 07:56:23,819	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=768398)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8415ef6e_43_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1381,e_layer_2024-08-24_07-56-14/checkpoint_000001)
2024-08-24 07:56:27,069	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=768398)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8415ef6e_43_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1381,e_layer_2024-08-24_07-56-14/checkpoint_000002)
2024-08-24 07:56:30,332	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=768398)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8415ef6e_43_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1381,e_layer_2024-08-24_07-56-14/checkpoint_000003)
2024-08-24 07:56:33,586	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=768398)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8415ef6e_43_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1381,e_layer_2024-08-24_07-56-14/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2291caba   RUNNING           4            5.46845       0.595314        1.61379             1.60968 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
36 more TERMINATED
[36m(_train_fn pid=767858)[0m EarlyStopping counter: 2 out of 3

Trial trial-2291caba completed after 6 iterations at 2024-08-24 07:56:14. Total running time: 35min 5s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2291caba result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          1.19641 â”‚
â”‚ time_total_s                               7.8728 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.60968 â”‚
â”‚ train_loss                                0.58223 â”‚
â”‚ valid_loss                                1.64002 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=767858)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=767858)[0m Early stopping

Trial trial-8415ef6e started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8415ef6e config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.13815 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00235 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=768398)[0m configuration
[36m(_train_fn pid=768398)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.13814729364011258, 'e_layers': 2, 'learning_rate': 0.0023458558945768436, 'd_ff': 256}
[36m(_train_fn pid=768398)[0m Use GPU: cuda:0
[36m(_train_fn pid=767858)[0m Updating learning rate to 0.00023665048279852455[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=767858)[0m saving checkpoint...[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=767858)[0m Epoch: 6 cost time: 1.0305461883544922[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=767858)[0m Epoch: 6, Steps: 61 | Train Loss: 0.5822273 Vali Loss: 1.6400245 Best vali loss: 1.6096759[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=768398)[0m train 7825
[36m(_train_fn pid=768398)[0m val 2161
[36m(_train_fn pid=768398)[0m start_epoch 0
[36m(_train_fn pid=768398)[0m max_epoch 8
[36m(_train_fn pid=768398)[0m Validation loss decreased (inf --> 1.9687).  Saving model state dict ...
[36m(_train_fn pid=768398)[0m Validation loss decreased (1.9687 --> 1.5968).  Saving model state dict ...
[36m(_train_fn pid=768398)[0m Updating learning rate to 0.0011729279472884218[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=768398)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=768398)[0m Epoch: 2 cost time: 2.812980890274048[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=768398)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6657065 Vali Loss: 1.5968336 Best vali loss: 1.5968336[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=768398)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=768398)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=768398)[0m Updating learning rate to 0.00029323198682210545[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=768398)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=768398)[0m Epoch: 4 cost time: 2.8281843662261963[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=768398)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6038548 Vali Loss: 1.6067919 Best vali loss: 1.5968336[32m [repeated 2x across cluster][0m

Trial trial-8415ef6e completed after 5 iterations at 2024-08-24 07:56:33. Total running time: 35min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8415ef6e result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.24545 â”‚
â”‚ time_total_s                              17.0908 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59683 â”‚
â”‚ train_loss                                0.59698 â”‚
â”‚ valid_loss                                1.61509 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=768398)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=768398)[0m Early stopping

Trial trial-8e78993d started with configuration:
[36m(_train_fn pid=768893)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e78993d_44_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_07-56-33/checkpoint_000000)
[36m(_train_fn pid=768893)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e78993d_44_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_07-56-33/checkpoint_000001)
[36m(_train_fn pid=768893)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e78993d_44_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_07-56-33/checkpoint_000002)
[36m(_train_fn pid=768893)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e78993d_44_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_07-56-33/checkpoint_000003)
[36m(_train_fn pid=768893)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e78993d_44_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_07-56-33/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8e78993d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.10261 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00103 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=768893)[0m configuration
[36m(_train_fn pid=768893)[0m {'batch_size': 128, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'conv', 'dropout': 0.10260761506606624, 'e_layers': 3, 'learning_rate': 0.0010271946508031776, 'd_ff': 256}
[36m(_train_fn pid=768893)[0m Use GPU: cuda:0
[36m(_train_fn pid=768398)[0m Updating learning rate to 0.00014661599341105272
[36m(_train_fn pid=768398)[0m saving checkpoint...
[36m(_train_fn pid=768398)[0m Epoch: 5 cost time: 2.813190221786499
[36m(_train_fn pid=768398)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5969848 Vali Loss: 1.6150915 Best vali loss: 1.5968336
[36m(_train_fn pid=768893)[0m train 7825
[36m(_train_fn pid=768893)[0m val 2161
[36m(_train_fn pid=768893)[0m start_epoch 0
[36m(_train_fn pid=768893)[0m max_epoch 8

Trial status: 43 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:56:42. Total running time: 35min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8e78993d   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
[36m(_train_fn pid=768893)[0m Updating learning rate to 0.0010271946508031776
[36m(_train_fn pid=768893)[0m saving checkpoint...
[36m(_train_fn pid=768893)[0m Validation loss decreased (inf --> 2.1264).  Saving model state dict ...
[36m(_train_fn pid=768893)[0m Epoch: 1 cost time: 6.239119052886963
[36m(_train_fn pid=768893)[0m Epoch: 1, Steps: 61 | Train Loss: 0.9077472 Vali Loss: 2.1263600 Best vali loss: 2.1263600
[36m(_train_fn pid=768893)[0m Updating learning rate to 0.0005135973254015888
[36m(_train_fn pid=768893)[0m saving checkpoint...
[36m(_train_fn pid=768893)[0m Validation loss decreased (2.1264 --> 1.6640).  Saving model state dict ...
[36m(_train_fn pid=768893)[0m Epoch: 2 cost time: 6.043617010116577
[36m(_train_fn pid=768893)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7204602 Vali Loss: 1.6640011 Best vali loss: 1.6640011
[36m(_train_fn pid=768893)[0m Updating learning rate to 0.0002567986627007944
[36m(_train_fn pid=768893)[0m saving checkpoint...
[36m(_train_fn pid=768893)[0m Validation loss decreased (1.6640 --> 1.6212).  Saving model state dict ...
[36m(_train_fn pid=768893)[0m Epoch: 3 cost time: 6.045334815979004
[36m(_train_fn pid=768893)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6293581 Vali Loss: 1.6212141 Best vali loss: 1.6212141
[36m(_train_fn pid=768893)[0m Updating learning rate to 0.0001283993313503972
[36m(_train_fn pid=768893)[0m saving checkpoint...
[36m(_train_fn pid=768893)[0m Validation loss decreased (1.6212 --> 1.6135).  Saving model state dict ...
[36m(_train_fn pid=768893)[0m Epoch: 4 cost time: 6.054283380508423
[36m(_train_fn pid=768893)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6151541 Vali Loss: 1.6134516 Best vali loss: 1.6134516
[36m(_train_fn pid=768893)[0m Updating learning rate to 6.41996656751986e-05
[36m(_train_fn pid=768893)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=768893)[0m saving checkpoint...
[36m(_train_fn pid=768893)[0m Epoch: 5 cost time: 6.058089256286621
[36m(_train_fn pid=768893)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6099764 Vali Loss: 1.6207087 Best vali loss: 1.6134516
Trial status: 43 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:57:12. Total running time: 36min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=768893)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e78993d_44_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_07-56-33/checkpoint_000005)
[36m(_train_fn pid=768893)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e78993d_44_alpha_d_ff=2,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_07-56-33/checkpoint_000006)
2024-08-24 07:57:34,630	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=769618)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3ee4276a_45_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_07-57-23/checkpoint_000000)
[36m(_train_fn pid=769618)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3ee4276a_45_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_07-57-23/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8e78993d   RUNNING           5            34.6235       0.609976        1.62071             1.61345 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
38 more TERMINATED
[36m(_train_fn pid=768893)[0m Updating learning rate to 3.20998328375993e-05
[36m(_train_fn pid=768893)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=768893)[0m saving checkpoint...
[36m(_train_fn pid=768893)[0m Epoch: 6 cost time: 6.071989059448242
[36m(_train_fn pid=768893)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6071516 Vali Loss: 1.6228249 Best vali loss: 1.6134516

Trial trial-8e78993d completed after 7 iterations at 2024-08-24 07:57:23. Total running time: 36min 14s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8e78993d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          6.80813 â”‚
â”‚ time_total_s                             48.25617 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.61345 â”‚
â”‚ train_loss                                0.60533 â”‚
â”‚ valid_loss                                1.62206 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=768893)[0m Updating learning rate to 1.604991641879965e-05
[36m(_train_fn pid=768893)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=768893)[0m saving checkpoint...
[36m(_train_fn pid=768893)[0m Epoch: 7 cost time: 6.061452865600586
[36m(_train_fn pid=768893)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6053347 Vali Loss: 1.6220595 Best vali loss: 1.6134516
[36m(_train_fn pid=768893)[0m Early stopping

Trial trial-3ee4276a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3ee4276a config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.13864 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00546 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=769618)[0m configuration
[36m(_train_fn pid=769618)[0m {'batch_size': 128, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'conv', 'dropout': 0.13863899258397563, 'e_layers': 3, 'learning_rate': 0.005457415328835374, 'd_ff': 512}
[36m(_train_fn pid=769618)[0m Use GPU: cuda:0
[36m(_train_fn pid=769618)[0m train 7825
[36m(_train_fn pid=769618)[0m val 2161
[36m(_train_fn pid=769618)[0m start_epoch 0
[36m(_train_fn pid=769618)[0m max_epoch 8
[36m(_train_fn pid=769618)[0m Validation loss decreased (inf --> 1.9980).  Saving model state dict ...
[36m(_train_fn pid=769618)[0m Updating learning rate to 0.005457415328835374
[36m(_train_fn pid=769618)[0m saving checkpoint...
[36m(_train_fn pid=769618)[0m Epoch: 1 cost time: 7.856638669967651
[36m(_train_fn pid=769618)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8546665 Vali Loss: 1.9980048 Best vali loss: 1.9980048

Trial status: 44 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:57:42. Total running time: 36min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3ee4276a   RUNNING           1            9.17043       0.854667        1.998               1.998   â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
39 more TERMINATED
[36m(_train_fn pid=769618)[0m Updating learning rate to 0.002728707664417687
[36m(_train_fn pid=769618)[0m saving checkpoint...
[36m(_train_fn pid=769618)[0m Validation loss decreased (1.9980 --> 1.5951).  Saving model state dict ...
[36m(_train_fn pid=769618)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3ee4276a_45_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_07-57-23/checkpoint_000002)
[36m(_train_fn pid=769618)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3ee4276a_45_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_07-57-23/checkpoint_000003)
[36m(_train_fn pid=769618)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3ee4276a_45_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_07-57-23/checkpoint_000004)
2024-08-24 07:58:12,111	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:58:13,136	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:58:14,198	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770187)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-64278b87_46_alpha_d_ff=4,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-58-08/checkpoint_000002)[32m [repeated 3x across cluster][0m
2024-08-24 07:58:15,260	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:58:16,283	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:58:17,343	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 07:58:18,387	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=769618)[0m Epoch: 2 cost time: 7.645877122879028
[36m(_train_fn pid=769618)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6550894 Vali Loss: 1.5951363 Best vali loss: 1.5951363
[36m(_train_fn pid=769618)[0m Updating learning rate to 0.0013643538322088435
[36m(_train_fn pid=769618)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=769618)[0m saving checkpoint...
[36m(_train_fn pid=769618)[0m Epoch: 3 cost time: 7.643961191177368
[36m(_train_fn pid=769618)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6050279 Vali Loss: 1.6780757 Best vali loss: 1.5951363
[36m(_train_fn pid=769618)[0m Updating learning rate to 0.0006821769161044218
[36m(_train_fn pid=769618)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=769618)[0m saving checkpoint...
[36m(_train_fn pid=769618)[0m Epoch: 4 cost time: 7.650163888931274
[36m(_train_fn pid=769618)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5794771 Vali Loss: 1.6523341 Best vali loss: 1.5951363

Trial trial-3ee4276a completed after 5 iterations at 2024-08-24 07:58:08. Total running time: 37min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3ee4276a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          8.54247 â”‚
â”‚ time_total_s                             43.35342 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59514 â”‚
â”‚ train_loss                                0.56499 â”‚
â”‚ valid_loss                                1.70166 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=769618)[0m Updating learning rate to 0.0003410884580522109
[36m(_train_fn pid=769618)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=769618)[0m saving checkpoint...
[36m(_train_fn pid=769618)[0m Epoch: 5 cost time: 7.649841785430908
[36m(_train_fn pid=769618)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5649916 Vali Loss: 1.7016577 Best vali loss: 1.5951363
[36m(_train_fn pid=769618)[0m Early stopping

Trial trial-64278b87 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-64278b87 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11763 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00064 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=770187)[0m configuration
[36m(_train_fn pid=770187)[0m {'batch_size': 128, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.11763114608045945, 'e_layers': 3, 'learning_rate': 0.0006437986881331838, 'd_ff': 32}
[36m(_train_fn pid=770187)[0m Use GPU: cuda:0
[36m(_train_fn pid=770187)[0m train 7825
[36m(_train_fn pid=770187)[0m val 2161
[36m(_train_fn pid=770187)[0m start_epoch 0
[36m(_train_fn pid=770187)[0m max_epoch 8
[36m(_train_fn pid=770187)[0m Updating learning rate to 0.0006437986881331838
[36m(_train_fn pid=770187)[0m saving checkpoint...
[36m(_train_fn pid=770187)[0m Validation loss decreased (inf --> 3.2748).  Saving model state dict ...

Trial status: 45 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:58:12. Total running time: 37min 3s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-64278b87   RUNNING           1            1.65521       1.5235          3.27482             3.27482 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
40 more TERMINATED
[36m(_train_fn pid=770187)[0m Updating learning rate to 0.0003218993440665919
[36m(_train_fn pid=770187)[0m saving checkpoint...
[36m(_train_fn pid=770187)[0m Validation loss decreased (3.2748 --> 1.9107).  Saving model state dict ...
[36m(_train_fn pid=770187)[0m Updating learning rate to 0.00016094967203329595
[36m(_train_fn pid=770187)[0m saving checkpoint...
[36m(_train_fn pid=770187)[0m Validation loss decreased (1.9107 --> 1.7938).  Saving model state dict ...
[36m(_train_fn pid=770187)[0m Epoch: 3 cost time: 0.8921020030975342[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=770187)[0m Epoch: 3, Steps: 61 | Train Loss: 0.7284050 Vali Loss: 1.7938270 Best vali loss: 1.7938270[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=770187)[0m Updating learning rate to 8.047483601664797e-05
[36m(_train_fn pid=770187)[0m saving checkpoint...
[36m(_train_fn pid=770187)[0m Validation loss decreased (1.7938 --> 1.7351).  Saving model state dict ...
[36m(_train_fn pid=770187)[0m Updating learning rate to 4.023741800832399e-05
[36m(_train_fn pid=770187)[0m saving checkpoint...
[36m(_train_fn pid=770187)[0m Validation loss decreased (1.7351 --> 1.7088).  Saving model state dict ...
[36m(_train_fn pid=770187)[0m Updating learning rate to 2.0118709004161994e-05
[36m(_train_fn pid=770187)[0m saving checkpoint...
[36m(_train_fn pid=770187)[0m Validation loss decreased (1.7088 --> 1.6993).  Saving model state dict ...
[36m(_train_fn pid=770187)[0m Updating learning rate to 1.0059354502080997e-05
[36m(_train_fn pid=770187)[0m saving checkpoint...
2024-08-24 07:58:19,449	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770187)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-64278b87_46_alpha_d_ff=4,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_07-58-08/checkpoint_000007)[32m [repeated 5x across cluster][0m
[36m(_train_fn pid=770869)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-529c47d2_47_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0779,e_layers_2024-08-24_07-58-19/checkpoint_000000)
2024-08-24 07:58:27,654	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770869)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-529c47d2_47_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0779,e_layers_2024-08-24_07-58-19/checkpoint_000001)
2024-08-24 07:58:30,348	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770869)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-529c47d2_47_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0779,e_layers_2024-08-24_07-58-19/checkpoint_000002)
2024-08-24 07:58:33,046	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770869)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-529c47d2_47_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0779,e_layers_2024-08-24_07-58-19/checkpoint_000003)
2024-08-24 07:58:35,745	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770869)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-529c47d2_47_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0779,e_layers_2024-08-24_07-58-19/checkpoint_000004)
2024-08-24 07:58:38,418	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770869)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-529c47d2_47_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0779,e_layers_2024-08-24_07-58-19/checkpoint_000005)
2024-08-24 07:58:41,115	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770869)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-529c47d2_47_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0779,e_layers_2024-08-24_07-58-19/checkpoint_000006)
[36m(_train_fn pid=770187)[0m Validation loss decreased (1.6993 --> 1.6947).  Saving model state dict ...

Trial trial-64278b87 completed after 8 iterations at 2024-08-24 07:58:19. Total running time: 37min 10s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-64278b87 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          1.05911 â”‚
â”‚ time_total_s                              8.98098 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.69203 â”‚
â”‚ train_loss                                0.66207 â”‚
â”‚ valid_loss                                1.69203 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=770187)[0m Updating learning rate to 5.029677251040498e-06
[36m(_train_fn pid=770187)[0m saving checkpoint...
[36m(_train_fn pid=770187)[0m Validation loss decreased (1.6947 --> 1.6920).  Saving model state dict ...
[36m(_train_fn pid=770187)[0m Epoch: 8 cost time: 0.8982095718383789[32m [repeated 5x across cluster][0m
[36m(_train_fn pid=770187)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6620746 Vali Loss: 1.6920306 Best vali loss: 1.6920306[32m [repeated 5x across cluster][0m

Trial trial-529c47d2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-529c47d2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07786 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00055 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=770869)[0m configuration
[36m(_train_fn pid=770869)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.07786261880184259, 'e_layers': 1, 'learning_rate': 0.0005530639989227764, 'd_ff': 128}
[36m(_train_fn pid=770869)[0m Use GPU: cuda:0
[36m(_train_fn pid=770869)[0m train 7825
[36m(_train_fn pid=770869)[0m val 2161
[36m(_train_fn pid=770869)[0m start_epoch 0
[36m(_train_fn pid=770869)[0m max_epoch 8
[36m(_train_fn pid=770869)[0m 	iters: 100, epoch: 1 | loss: 0.9033840
[36m(_train_fn pid=770869)[0m 	speed: 0.0165s/iter; left time: 30.6075s
[36m(_train_fn pid=770869)[0m 	iters: 200, epoch: 1 | loss: 0.9075613
[36m(_train_fn pid=770869)[0m 	speed: 0.0092s/iter; left time: 16.1806s
[36m(_train_fn pid=770869)[0m Updating learning rate to 0.0005530639989227764
[36m(_train_fn pid=770869)[0m saving checkpoint...
[36m(_train_fn pid=770869)[0m Validation loss decreased (inf --> 2.0905).  Saving model state dict ...
[36m(_train_fn pid=770869)[0m Epoch: 1 cost time: 2.727837085723877
[36m(_train_fn pid=770869)[0m Epoch: 1, Steps: 244 | Train Loss: 0.9727059 Vali Loss: 2.0904592 Best vali loss: 2.0904592
[36m(_train_fn pid=770869)[0m 	iters: 100, epoch: 2 | loss: 0.5722918
[36m(_train_fn pid=770869)[0m 	speed: 0.0177s/iter; left time: 28.4143s
[36m(_train_fn pid=770869)[0m 	iters: 200, epoch: 2 | loss: 0.6836877
[36m(_train_fn pid=770869)[0m 	speed: 0.0091s/iter; left time: 13.7835s
[36m(_train_fn pid=770869)[0m Updating learning rate to 0.0002765319994613882
[36m(_train_fn pid=770869)[0m saving checkpoint...
[36m(_train_fn pid=770869)[0m Validation loss decreased (2.0905 --> 1.5921).  Saving model state dict ...
[36m(_train_fn pid=770869)[0m Epoch: 2 cost time: 2.278292417526245
[36m(_train_fn pid=770869)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6859606 Vali Loss: 1.5920779 Best vali loss: 1.5920779
[36m(_train_fn pid=770869)[0m 	iters: 100, epoch: 3 | loss: 0.6755500
[36m(_train_fn pid=770869)[0m 	speed: 0.0177s/iter; left time: 24.1915s
[36m(_train_fn pid=770869)[0m 	iters: 200, epoch: 3 | loss: 0.5688549
[36m(_train_fn pid=770869)[0m 	speed: 0.0093s/iter; left time: 11.7017s
[36m(_train_fn pid=770869)[0m Updating learning rate to 0.0001382659997306941
[36m(_train_fn pid=770869)[0m saving checkpoint...
[36m(_train_fn pid=770869)[0m Validation loss decreased (1.5921 --> 1.5774).  Saving model state dict ...
[36m(_train_fn pid=770869)[0m Epoch: 3 cost time: 2.306644916534424
[36m(_train_fn pid=770869)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6219637 Vali Loss: 1.5774004 Best vali loss: 1.5774004
[36m(_train_fn pid=770869)[0m 	iters: 100, epoch: 4 | loss: 0.6446224
[36m(_train_fn pid=770869)[0m 	speed: 0.0176s/iter; left time: 19.7824s
[36m(_train_fn pid=770869)[0m 	iters: 200, epoch: 4 | loss: 0.6218884
[36m(_train_fn pid=770869)[0m 	speed: 0.0093s/iter; left time: 9.4572s
[36m(_train_fn pid=770869)[0m Updating learning rate to 6.913299986534705e-05
[36m(_train_fn pid=770869)[0m saving checkpoint...
[36m(_train_fn pid=770869)[0m Validation loss decreased (1.5774 --> 1.5763).  Saving model state dict ...
[36m(_train_fn pid=770869)[0m Epoch: 4 cost time: 2.302342176437378
[36m(_train_fn pid=770869)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6162684 Vali Loss: 1.5763117 Best vali loss: 1.5763117
[36m(_train_fn pid=770869)[0m 	iters: 100, epoch: 5 | loss: 0.5992328
[36m(_train_fn pid=770869)[0m 	speed: 0.0177s/iter; left time: 15.5199s
[36m(_train_fn pid=770869)[0m 	iters: 200, epoch: 5 | loss: 0.6272150
[36m(_train_fn pid=770869)[0m 	speed: 0.0093s/iter; left time: 7.1941s
[36m(_train_fn pid=770869)[0m Updating learning rate to 3.456649993267353e-05
[36m(_train_fn pid=770869)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=770869)[0m saving checkpoint...
[36m(_train_fn pid=770869)[0m Epoch: 5 cost time: 2.3088936805725098
[36m(_train_fn pid=770869)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6141700 Vali Loss: 1.5763189 Best vali loss: 1.5763117
[36m(_train_fn pid=770869)[0m 	iters: 100, epoch: 6 | loss: 0.6122989
[36m(_train_fn pid=770869)[0m 	speed: 0.0176s/iter; left time: 11.1602s
[36m(_train_fn pid=770869)[0m 	iters: 200, epoch: 6 | loss: 0.7087523
[36m(_train_fn pid=770869)[0m 	speed: 0.0092s/iter; left time: 4.9125s
[36m(_train_fn pid=770869)[0m Updating learning rate to 1.7283249966336764e-05
[36m(_train_fn pid=770869)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=770869)[0m saving checkpoint...
[36m(_train_fn pid=770869)[0m Epoch: 6 cost time: 2.2912538051605225
[36m(_train_fn pid=770869)[0m Epoch: 6, Steps: 244 | Train Loss: 0.6132800 Vali Loss: 1.5765210 Best vali loss: 1.5763117
[36m(_train_fn pid=770869)[0m 	iters: 100, epoch: 7 | loss: 0.5255163
[36m(_train_fn pid=770869)[0m 	speed: 0.0177s/iter; left time: 6.8754s
[36m(_train_fn pid=770869)[0m 	iters: 200, epoch: 7 | loss: 0.5693411
[36m(_train_fn pid=770869)[0m 	speed: 0.0093s/iter; left time: 2.6783s
[36m(_train_fn pid=770869)[0m Updating learning rate to 8.641624983168382e-06
[36m(_train_fn pid=770869)[0m saving checkpoint...
[36m(_train_fn pid=770869)[0m Validation loss decreased (1.5763 --> 1.5754).  Saving model state dict ...
[36m(_train_fn pid=770869)[0m Epoch: 7 cost time: 2.3099591732025146
[36m(_train_fn pid=770869)[0m Epoch: 7, Steps: 244 | Train Loss: 0.6121462 Vali Loss: 1.5754246 Best vali loss: 1.5754246
[36m(_train_fn pid=770869)[0m 	iters: 100, epoch: 8 | loss: 0.5792742
2024-08-24 07:58:43,815	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=770869)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-529c47d2_47_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0779,e_layers_2024-08-24_07-58-19/checkpoint_000007)
[36m(_train_fn pid=771590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56cff665_48_alpha_d_ff=2,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_07-58-43/checkpoint_000000)
[36m(_train_fn pid=771590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56cff665_48_alpha_d_ff=2,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_07-58-43/checkpoint_000001)
[36m(_train_fn pid=771590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56cff665_48_alpha_d_ff=2,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_07-58-43/checkpoint_000002)
[36m(_train_fn pid=770869)[0m 	speed: 0.0177s/iter; left time: 2.5601s

Trial status: 46 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:58:42. Total running time: 37min 33s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-529c47d2   RUNNING           7            19.6468       0.612146        1.57542             1.57542 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
41 more TERMINATED
[36m(_train_fn pid=770869)[0m 	iters: 200, epoch: 8 | loss: 0.6663330
[36m(_train_fn pid=770869)[0m 	speed: 0.0093s/iter; left time: 0.4170s

Trial trial-529c47d2 completed after 8 iterations at 2024-08-24 07:58:43. Total running time: 37min 35s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-529c47d2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          2.69077 â”‚
â”‚ time_total_s                             22.33753 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.57542 â”‚
â”‚ train_loss                                0.61198 â”‚
â”‚ valid_loss                                1.57635 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=770869)[0m Updating learning rate to 4.320812491584191e-06
[36m(_train_fn pid=770869)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=770869)[0m saving checkpoint...
[36m(_train_fn pid=770869)[0m Epoch: 8 cost time: 2.302917957305908
[36m(_train_fn pid=770869)[0m Epoch: 8, Steps: 244 | Train Loss: 0.6119792 Vali Loss: 1.5763518 Best vali loss: 1.5754246

Trial trial-56cff665 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-56cff665 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.07185 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00816 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=771590)[0m configuration
[36m(_train_fn pid=771590)[0m {'batch_size': 16, 'd_model': 16, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.07184703186059412, 'e_layers': 4, 'learning_rate': 0.008161454485010898, 'd_ff': 32}
[36m(_train_fn pid=771590)[0m Use GPU: cuda:0
[36m(_train_fn pid=771590)[0m train 7825
[36m(_train_fn pid=771590)[0m val 2161
[36m(_train_fn pid=771590)[0m start_epoch 0
[36m(_train_fn pid=771590)[0m max_epoch 8
[36m(_train_fn pid=771590)[0m 	iters: 200, epoch: 1 | loss: 0.6230896[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=771590)[0m 	speed: 0.0134s/iter; left time: 49.7566s[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=771590)[0m Updating learning rate to 0.008161454485010898
[36m(_train_fn pid=771590)[0m saving checkpoint...
[36m(_train_fn pid=771590)[0m Validation loss decreased (inf --> 1.5871).  Saving model state dict ...
[36m(_train_fn pid=771590)[0m Epoch: 1 cost time: 6.783884525299072
[36m(_train_fn pid=771590)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7073465 Vali Loss: 1.5870896 Best vali loss: 1.5870896
[36m(_train_fn pid=771590)[0m 	iters: 100, epoch: 2 | loss: 0.5836875[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=771590)[0m 	speed: 0.0320s/iter; left time: 106.3409s[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=771590)[0m Updating learning rate to 0.004080727242505449
[36m(_train_fn pid=771590)[0m saving checkpoint...
[36m(_train_fn pid=771590)[0m Validation loss decreased (1.5871 --> 1.5677).  Saving model state dict ...
[36m(_train_fn pid=771590)[0m Epoch: 2 cost time: 6.564240217208862
[36m(_train_fn pid=771590)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6046833 Vali Loss: 1.5676552 Best vali loss: 1.5676552
[36m(_train_fn pid=771590)[0m 	iters: 400, epoch: 2 | loss: 0.6983252[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=771590)[0m 	speed: 0.0133s/iter; left time: 40.2676s[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=771590)[0m Updating learning rate to 0.0020403636212527245
[36m(_train_fn pid=771590)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=771590)[0m saving checkpoint...
[36m(_train_fn pid=771590)[0m Epoch: 3 cost time: 5.967647314071655
[36m(_train_fn pid=771590)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5562575 Vali Loss: 1.5807162 Best vali loss: 1.5676552
[36m(_train_fn pid=771590)[0m 	iters: 400, epoch: 3 | loss: 0.5761980[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=771590)[0m 	speed: 0.0121s/iter; left time: 30.7808s[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=771590)[0m 	iters: 400, epoch: 4 | loss: 0.4661705[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=771590)[0m 	speed: 0.0132s/iter; left time: 27.0767s[32m [repeated 4x across cluster][0m

Trial status: 47 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:59:12. Total running time: 38min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=771590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56cff665_48_alpha_d_ff=2,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_07-58-43/checkpoint_000003)
[36m(_train_fn pid=771590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56cff665_48_alpha_d_ff=2,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_07-58-43/checkpoint_000004)
2024-08-24 07:59:25,807	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=772138)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-723e5131_49_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0436,e_layers_2024-08-24_07-59-21/checkpoint_000000)
2024-08-24 07:59:27,261	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=772138)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-723e5131_49_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0436,e_layers_2024-08-24_07-59-21/checkpoint_000001)
2024-08-24 07:59:28,694	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=772138)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-723e5131_49_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0436,e_layers_2024-08-24_07-59-21/checkpoint_000002)
2024-08-24 07:59:30,179	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=772138)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-723e5131_49_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0436,e_layers_2024-08-24_07-59-21/checkpoint_000003)
2024-08-24 07:59:31,668	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=772138)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-723e5131_49_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0436,e_layers_2024-08-24_07-59-21/checkpoint_000004)
2024-08-24 07:59:33,103	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=772138)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-723e5131_49_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0436,e_layers_2024-08-24_07-59-21/checkpoint_000005)
[36m(_train_fn pid=772138)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-723e5131_49_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0436,e_layers_2024-08-24_07-59-21/checkpoint_000006)
2024-08-24 07:59:34,543	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=772138)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-723e5131_49_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0436,e_layers_2024-08-24_07-59-21/checkpoint_000007)
2024-08-24 07:59:35,979	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-56cff665   RUNNING           3            21.5971       0.556257        1.58072             1.56766 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
42 more TERMINATED
[36m(_train_fn pid=771590)[0m Updating learning rate to 0.0010201818106263623
[36m(_train_fn pid=771590)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=771590)[0m saving checkpoint...
[36m(_train_fn pid=771590)[0m Epoch: 4 cost time: 6.548208236694336
[36m(_train_fn pid=771590)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5121824 Vali Loss: 1.6420154 Best vali loss: 1.5676552
[36m(_train_fn pid=771590)[0m 	iters: 300, epoch: 5 | loss: 0.4721860[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=771590)[0m 	speed: 0.0135s/iter; left time: 22.2912s[32m [repeated 3x across cluster][0m

Trial trial-56cff665 completed after 5 iterations at 2024-08-24 07:59:21. Total running time: 38min 12s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-56cff665 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          7.20993 â”‚
â”‚ time_total_s                             35.97588 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56766 â”‚
â”‚ train_loss                                0.48001 â”‚
â”‚ valid_loss                                1.64127 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=771590)[0m Updating learning rate to 0.0005100909053131811
[36m(_train_fn pid=771590)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=771590)[0m saving checkpoint...
[36m(_train_fn pid=771590)[0m Epoch: 5 cost time: 6.588152170181274
[36m(_train_fn pid=771590)[0m Epoch: 5, Steps: 489 | Train Loss: 0.4800100 Vali Loss: 1.6412706 Best vali loss: 1.5676552
[36m(_train_fn pid=771590)[0m Early stopping

Trial trial-723e5131 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-723e5131 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.04362 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00069 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=772138)[0m configuration
[36m(_train_fn pid=772138)[0m {'batch_size': 128, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.04362499154729027, 'e_layers': 4, 'learning_rate': 0.0006878604038986386, 'd_ff': 24}
[36m(_train_fn pid=772138)[0m Use GPU: cuda:0
[36m(_train_fn pid=771590)[0m 	iters: 400, epoch: 5 | loss: 0.4538213
[36m(_train_fn pid=771590)[0m 	speed: 0.0134s/iter; left time: 20.8312s
[36m(_train_fn pid=772138)[0m train 7825
[36m(_train_fn pid=772138)[0m val 2161
[36m(_train_fn pid=772138)[0m start_epoch 0
[36m(_train_fn pid=772138)[0m max_epoch 8
[36m(_train_fn pid=772138)[0m Validation loss decreased (inf --> 3.6906).  Saving model state dict ...
[36m(_train_fn pid=772138)[0m Validation loss decreased (3.6906 --> 1.8506).  Saving model state dict ...
[36m(_train_fn pid=772138)[0m Updating learning rate to 0.0003439302019493193[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=772138)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=772138)[0m Epoch: 2 cost time: 1.2096304893493652[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=772138)[0m Epoch: 2, Steps: 61 | Train Loss: 1.0001149 Vali Loss: 1.8505692 Best vali loss: 1.8505692[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=772138)[0m Validation loss decreased (1.8506 --> 1.7028).  Saving model state dict ...
[36m(_train_fn pid=772138)[0m Validation loss decreased (1.7028 --> 1.6711).  Saving model state dict ...
[36m(_train_fn pid=772138)[0m Validation loss decreased (1.6711 --> 1.6613).  Saving model state dict ...
[36m(_train_fn pid=772138)[0m Validation loss decreased (1.6613 --> 1.6573).  Saving model state dict ...
[36m(_train_fn pid=772138)[0m Updating learning rate to 2.1495637621832456e-05[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=772138)[0m saving checkpoint...[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=772138)[0m Epoch: 6 cost time: 1.189340591430664[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=772138)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6424693 Vali Loss: 1.6573238 Best vali loss: 1.6573238[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=772138)[0m Validation loss decreased (1.6573 --> 1.6553).  Saving model state dict ...
[36m(_train_fn pid=772138)[0m Validation loss decreased (1.6553 --> 1.6543).  Saving model state dict ...

Trial trial-723e5131 completed after 8 iterations at 2024-08-24 07:59:35. Total running time: 38min 27s
2024-08-24 07:59:48,089	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=772836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8f94cc69_50_alpha_d_ff=3,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_07-59-35/checkpoint_000000)
[36m(_train_fn pid=772836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8f94cc69_50_alpha_d_ff=3,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_07-59-35/checkpoint_000001)
[36m(_train_fn pid=772836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8f94cc69_50_alpha_d_ff=3,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_07-59-35/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-723e5131 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          1.43325 â”‚
â”‚ time_total_s                             12.45927 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.65431 â”‚
â”‚ train_loss                                 0.6401 â”‚
â”‚ valid_loss                                1.65431 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-8f94cc69 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8f94cc69 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.16327 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00288 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=772836)[0m configuration
[36m(_train_fn pid=772836)[0m {'batch_size': 128, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.1632685529344955, 'e_layers': 1, 'learning_rate': 0.0028812227027726627, 'd_ff': 768}
[36m(_train_fn pid=772836)[0m Use GPU: cuda:0
[36m(_train_fn pid=772138)[0m Updating learning rate to 5.373909405458114e-06[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=772138)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=772138)[0m Epoch: 8 cost time: 1.1880362033843994[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=772138)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6401037 Vali Loss: 1.6543147 Best vali loss: 1.6543147[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=772836)[0m train 7825
[36m(_train_fn pid=772836)[0m val 2161
[36m(_train_fn pid=772836)[0m start_epoch 0
[36m(_train_fn pid=772836)[0m max_epoch 8

Trial status: 49 TERMINATED | 1 RUNNING
Current time: 2024-08-24 07:59:42. Total running time: 38min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8f94cc69   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
44 more TERMINATED
[36m(_train_fn pid=772836)[0m Validation loss decreased (inf --> 1.9943).  Saving model state dict ...
[36m(_train_fn pid=772836)[0m Updating learning rate to 0.0028812227027726627
[36m(_train_fn pid=772836)[0m saving checkpoint...
[36m(_train_fn pid=772836)[0m Epoch: 1 cost time: 8.227945327758789
[36m(_train_fn pid=772836)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8451378 Vali Loss: 1.9942558 Best vali loss: 1.9942558
[36m(_train_fn pid=772836)[0m Updating learning rate to 0.0014406113513863313
[36m(_train_fn pid=772836)[0m saving checkpoint...
[36m(_train_fn pid=772836)[0m Validation loss decreased (1.9943 --> 1.6145).  Saving model state dict ...
[36m(_train_fn pid=772836)[0m Epoch: 2 cost time: 8.05241060256958
[36m(_train_fn pid=772836)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6867914 Vali Loss: 1.6144747 Best vali loss: 1.6144747
[36m(_train_fn pid=772836)[0m Updating learning rate to 0.0007203056756931657
[36m(_train_fn pid=772836)[0m saving checkpoint...
[36m(_train_fn pid=772836)[0m Validation loss decreased (1.6145 --> 1.5924).  Saving model state dict ...
[36m(_train_fn pid=772836)[0m Epoch: 3 cost time: 8.069079875946045
[36m(_train_fn pid=772836)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6180620 Vali Loss: 1.5924032 Best vali loss: 1.5924032
Trial status: 49 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:00:12. Total running time: 39min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=772836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8f94cc69_50_alpha_d_ff=3,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_07-59-35/checkpoint_000003)
[36m(_train_fn pid=772836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8f94cc69_50_alpha_d_ff=3,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_07-59-35/checkpoint_000004)
[36m(_train_fn pid=772836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8f94cc69_50_alpha_d_ff=3,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_07-59-35/checkpoint_000005)
[36m(_train_fn pid=773509)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c910a0da_51_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-00-33/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8f94cc69   RUNNING           3            27.7461       0.618062        1.5924              1.5924  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
44 more TERMINATED
[36m(_train_fn pid=772836)[0m Updating learning rate to 0.00036015283784658283
[36m(_train_fn pid=772836)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=772836)[0m saving checkpoint...
[36m(_train_fn pid=772836)[0m Epoch: 4 cost time: 8.087402105331421
[36m(_train_fn pid=772836)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6125693 Vali Loss: 1.5940779 Best vali loss: 1.5924032
[36m(_train_fn pid=772836)[0m Updating learning rate to 0.00018007641892329142
[36m(_train_fn pid=772836)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=772836)[0m saving checkpoint...
[36m(_train_fn pid=772836)[0m Epoch: 5 cost time: 8.100956439971924
[36m(_train_fn pid=772836)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6096239 Vali Loss: 1.5942726 Best vali loss: 1.5924032

Trial trial-8f94cc69 completed after 6 iterations at 2024-08-24 08:00:33. Total running time: 39min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8f94cc69 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          9.08808 â”‚
â”‚ time_total_s                             55.00637 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                            1.5924 â”‚
â”‚ train_loss                                0.60829 â”‚
â”‚ valid_loss                                1.59562 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=772836)[0m Updating learning rate to 9.003820946164571e-05
[36m(_train_fn pid=772836)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=772836)[0m saving checkpoint...
[36m(_train_fn pid=772836)[0m Epoch: 6 cost time: 8.10006046295166
[36m(_train_fn pid=772836)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6082933 Vali Loss: 1.5956181 Best vali loss: 1.5924032
[36m(_train_fn pid=772836)[0m Early stopping

Trial trial-c910a0da started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c910a0da config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.16088 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00107 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=773509)[0m configuration
[36m(_train_fn pid=773509)[0m {'batch_size': 64, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.16087775958631867, 'e_layers': 2, 'learning_rate': 0.0010744845863370736, 'd_ff': 384}
[36m(_train_fn pid=773509)[0m Use GPU: cuda:0
[36m(_train_fn pid=773509)[0m train 7825
[36m(_train_fn pid=773509)[0m val 2161
[36m(_train_fn pid=773509)[0m start_epoch 0
[36m(_train_fn pid=773509)[0m max_epoch 8
[36m(_train_fn pid=773509)[0m 	iters: 100, epoch: 1 | loss: 0.7620745
[36m(_train_fn pid=773509)[0m 	speed: 0.0533s/iter; left time: 46.7700s
[36m(_train_fn pid=773509)[0m Updating learning rate to 0.0010744845863370736
[36m(_train_fn pid=773509)[0m saving checkpoint...
[36m(_train_fn pid=773509)[0m Validation loss decreased (inf --> 1.9753).  Saving model state dict ...
[36m(_train_fn pid=773509)[0m Epoch: 1 cost time: 6.142896413803101
[36m(_train_fn pid=773509)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8290810 Vali Loss: 1.9752529 Best vali loss: 1.9752529

Trial status: 50 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:00:42. Total running time: 39min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=773509)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c910a0da_51_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-00-33/checkpoint_000001)
[36m(_train_fn pid=773509)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c910a0da_51_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-00-33/checkpoint_000002)
[36m(_train_fn pid=773509)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c910a0da_51_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-00-33/checkpoint_000003)
[36m(_train_fn pid=773509)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c910a0da_51_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-00-33/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c910a0da   RUNNING           1            7.33907       0.829081        1.97525             1.97525 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
45 more TERMINATED
[36m(_train_fn pid=773509)[0m 	iters: 100, epoch: 2 | loss: 0.6634302
[36m(_train_fn pid=773509)[0m 	speed: 0.0667s/iter; left time: 50.3385s
[36m(_train_fn pid=773509)[0m Updating learning rate to 0.0005372422931685368
[36m(_train_fn pid=773509)[0m saving checkpoint...
[36m(_train_fn pid=773509)[0m Validation loss decreased (1.9753 --> 1.5741).  Saving model state dict ...
[36m(_train_fn pid=773509)[0m Epoch: 2 cost time: 5.9569597244262695
[36m(_train_fn pid=773509)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6519248 Vali Loss: 1.5740671 Best vali loss: 1.5740671
[36m(_train_fn pid=773509)[0m 	iters: 100, epoch: 3 | loss: 0.5354837
[36m(_train_fn pid=773509)[0m 	speed: 0.0667s/iter; left time: 42.2434s
[36m(_train_fn pid=773509)[0m Updating learning rate to 0.0002686211465842684
[36m(_train_fn pid=773509)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=773509)[0m saving checkpoint...
[36m(_train_fn pid=773509)[0m Epoch: 3 cost time: 5.956659555435181
[36m(_train_fn pid=773509)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6086265 Vali Loss: 1.5831855 Best vali loss: 1.5740671
[36m(_train_fn pid=773509)[0m 	iters: 100, epoch: 4 | loss: 0.5953677
[36m(_train_fn pid=773509)[0m 	speed: 0.0667s/iter; left time: 34.0836s
[36m(_train_fn pid=773509)[0m Updating learning rate to 0.0001343105732921342
[36m(_train_fn pid=773509)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=773509)[0m saving checkpoint...
[36m(_train_fn pid=773509)[0m Epoch: 4 cost time: 5.95892333984375
[36m(_train_fn pid=773509)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5987341 Vali Loss: 1.6080805 Best vali loss: 1.5740671
[36m(_train_fn pid=773509)[0m 	iters: 100, epoch: 5 | loss: 0.6166474
[36m(_train_fn pid=773509)[0m 	speed: 0.0667s/iter; left time: 25.9543s

Trial trial-c910a0da completed after 5 iterations at 2024-08-24 08:01:09. Total running time: 40min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c910a0da result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          6.67791 â”‚
â”‚ time_total_s                              34.0157 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.57407 â”‚
â”‚ train_loss                                0.58984 â”‚
â”‚ valid_loss                                1.58705 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=773509)[0m Updating learning rate to 6.71552866460671e-05
[36m(_train_fn pid=773509)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=773509)[0m saving checkpoint...
[36m(_train_fn pid=773509)[0m Epoch: 5 cost time: 5.970632553100586
[36m(_train_fn pid=773509)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5898386 Vali Loss: 1.5870472 Best vali loss: 1.5740671
[36m(_train_fn pid=773509)[0m Early stopping

Trial trial-0ed8cfa0 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0ed8cfa0 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09671 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00056 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=774053)[0m configuration
[36m(_train_fn pid=774053)[0m {'batch_size': 64, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.09670579644015762, 'e_layers': 3, 'learning_rate': 0.000560973724229431, 'd_ff': 256}
[36m(_train_fn pid=774053)[0m Use GPU: cuda:0
[36m(_train_fn pid=774053)[0m train 7825
[36m(_train_fn pid=774053)[0m val 2161
[36m(_train_fn pid=774053)[0m start_epoch 0
[36m(_train_fn pid=774053)[0m max_epoch 8

Trial status: 51 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:01:13. Total running time: 40min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=774053)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0ed8cfa0_52_alpha_d_ff=4,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-01-09/checkpoint_000000)
2024-08-24 08:01:21,604	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=774053)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0ed8cfa0_52_alpha_d_ff=4,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-01-09/checkpoint_000001)
2024-08-24 08:01:26,368	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=774053)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0ed8cfa0_52_alpha_d_ff=4,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-01-09/checkpoint_000002)
2024-08-24 08:01:31,144	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=774053)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0ed8cfa0_52_alpha_d_ff=4,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-01-09/checkpoint_000003)
[36m(_train_fn pid=774053)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0ed8cfa0_52_alpha_d_ff=4,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-01-09/checkpoint_000004)
2024-08-24 08:01:35,903	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:01:40,697	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=774053)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0ed8cfa0_52_alpha_d_ff=4,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-01-09/checkpoint_000005)
[36m(_train_fn pid=774053)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0ed8cfa0_52_alpha_d_ff=4,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-01-09/checkpoint_000006)
2024-08-24 08:01:45,474	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0ed8cfa0   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
46 more TERMINATED
[36m(_train_fn pid=774053)[0m 	iters: 100, epoch: 1 | loss: 0.9186212
[36m(_train_fn pid=774053)[0m 	speed: 0.0393s/iter; left time: 34.4382s
[36m(_train_fn pid=774053)[0m Updating learning rate to 0.000560973724229431
[36m(_train_fn pid=774053)[0m saving checkpoint...
[36m(_train_fn pid=774053)[0m Validation loss decreased (inf --> 2.1437).  Saving model state dict ...
[36m(_train_fn pid=774053)[0m Epoch: 1 cost time: 4.423938035964966
[36m(_train_fn pid=774053)[0m Epoch: 1, Steps: 122 | Train Loss: 0.9541545 Vali Loss: 2.1437082 Best vali loss: 2.1437082
[36m(_train_fn pid=774053)[0m 	iters: 100, epoch: 2 | loss: 0.5965622
[36m(_train_fn pid=774053)[0m 	speed: 0.0478s/iter; left time: 36.0691s
[36m(_train_fn pid=774053)[0m Updating learning rate to 0.0002804868621147155
[36m(_train_fn pid=774053)[0m saving checkpoint...
[36m(_train_fn pid=774053)[0m Validation loss decreased (2.1437 --> 1.6123).  Saving model state dict ...
[36m(_train_fn pid=774053)[0m Epoch: 2 cost time: 4.235403299331665
[36m(_train_fn pid=774053)[0m Epoch: 2, Steps: 122 | Train Loss: 0.7093661 Vali Loss: 1.6122635 Best vali loss: 1.6122635
[36m(_train_fn pid=774053)[0m 	iters: 100, epoch: 3 | loss: 0.5804275
[36m(_train_fn pid=774053)[0m 	speed: 0.0476s/iter; left time: 30.1293s
[36m(_train_fn pid=774053)[0m Updating learning rate to 0.00014024343105735774
[36m(_train_fn pid=774053)[0m saving checkpoint...
[36m(_train_fn pid=774053)[0m Validation loss decreased (1.6123 --> 1.5888).  Saving model state dict ...
[36m(_train_fn pid=774053)[0m Epoch: 3 cost time: 4.223461389541626
[36m(_train_fn pid=774053)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6239184 Vali Loss: 1.5887916 Best vali loss: 1.5887916
[36m(_train_fn pid=774053)[0m 	iters: 100, epoch: 4 | loss: 0.6395201
[36m(_train_fn pid=774053)[0m 	speed: 0.0476s/iter; left time: 24.3451s
[36m(_train_fn pid=774053)[0m Updating learning rate to 7.012171552867887e-05
[36m(_train_fn pid=774053)[0m saving checkpoint...
[36m(_train_fn pid=774053)[0m Validation loss decreased (1.5888 --> 1.5828).  Saving model state dict ...
[36m(_train_fn pid=774053)[0m Epoch: 4 cost time: 4.230203628540039
[36m(_train_fn pid=774053)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6143637 Vali Loss: 1.5828240 Best vali loss: 1.5828240
[36m(_train_fn pid=774053)[0m 	iters: 100, epoch: 5 | loss: 0.5712356
[36m(_train_fn pid=774053)[0m 	speed: 0.0478s/iter; left time: 18.5863s
[36m(_train_fn pid=774053)[0m Updating learning rate to 3.5060857764339435e-05
[36m(_train_fn pid=774053)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=774053)[0m saving checkpoint...
[36m(_train_fn pid=774053)[0m Epoch: 5 cost time: 4.2251341342926025
[36m(_train_fn pid=774053)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6114100 Vali Loss: 1.5831230 Best vali loss: 1.5828240
[36m(_train_fn pid=774053)[0m 	iters: 100, epoch: 6 | loss: 0.6322253
[36m(_train_fn pid=774053)[0m 	speed: 0.0478s/iter; left time: 12.7642s
[36m(_train_fn pid=774053)[0m Updating learning rate to 1.7530428882169718e-05
[36m(_train_fn pid=774053)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=774053)[0m saving checkpoint...
[36m(_train_fn pid=774053)[0m Epoch: 6 cost time: 4.25581955909729
[36m(_train_fn pid=774053)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6099789 Vali Loss: 1.5833509 Best vali loss: 1.5828240
Trial status: 51 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:01:43. Total running time: 40min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0ed8cfa0   RUNNING           6            29.2211       0.609979        1.58335             1.58282 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
46 more TERMINATED
[36m(_train_fn pid=774053)[0m 	iters: 100, epoch: 7 | loss: 0.6266927
[36m(_train_fn pid=774053)[0m 	speed: 0.0479s/iter; left time: 6.9469s
[36m(_train_fn pid=774053)[0m Updating learning rate to 8.765214441084859e-06
[36m(_train_fn pid=774053)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=774053)[0m saving checkpoint...
[36m(_train_fn pid=774053)[0m Epoch: 7 cost time: 4.24953556060791
[36m(_train_fn pid=774053)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6092276 Vali Loss: 1.5834000 Best vali loss: 1.5828240
[36m(_train_fn pid=774053)[0m Early stopping

Trial trial-0ed8cfa0 completed after 7 iterations at 2024-08-24 08:01:45. Total running time: 40min 36s
2024-08-24 08:02:07,000	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=774736)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-17cf266d_53_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-01-45/checkpoint_000000)
[36m(_train_fn pid=774736)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-17cf266d_53_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-01-45/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0ed8cfa0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                           4.7839 â”‚
â”‚ time_total_s                             34.00501 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58282 â”‚
â”‚ train_loss                                0.60923 â”‚
â”‚ valid_loss                                 1.5834 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-17cf266d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-17cf266d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.12097 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00131 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=774736)[0m configuration
[36m(_train_fn pid=774736)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.12096598604565238, 'e_layers': 1, 'learning_rate': 0.0013110717207731467, 'd_ff': 1024}
[36m(_train_fn pid=774736)[0m Use GPU: cuda:0
[36m(_train_fn pid=774736)[0m train 7825
[36m(_train_fn pid=774736)[0m val 2161
[36m(_train_fn pid=774736)[0m start_epoch 0
[36m(_train_fn pid=774736)[0m max_epoch 8
[36m(_train_fn pid=774736)[0m 	iters: 100, epoch: 1 | loss: 0.7766623
[36m(_train_fn pid=774736)[0m 	speed: 0.0741s/iter; left time: 137.2513s
[36m(_train_fn pid=774736)[0m 	iters: 200, epoch: 1 | loss: 0.6960242
[36m(_train_fn pid=774736)[0m 	speed: 0.0695s/iter; left time: 121.8553s
[36m(_train_fn pid=774736)[0m Updating learning rate to 0.0013110717207731467
[36m(_train_fn pid=774736)[0m saving checkpoint...
[36m(_train_fn pid=774736)[0m Validation loss decreased (inf --> 1.8718).  Saving model state dict ...
[36m(_train_fn pid=774736)[0m Epoch: 1 cost time: 17.161959886550903
[36m(_train_fn pid=774736)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7843417 Vali Loss: 1.8718321 Best vali loss: 1.8718321

Trial status: 52 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:02:13. Total running time: 41min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-17cf266d   RUNNING           1            19.5428       0.784342        1.87183             1.87183 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
47 more TERMINATED
[36m(_train_fn pid=774736)[0m 	iters: 100, epoch: 2 | loss: 0.7013797
[36m(_train_fn pid=774736)[0m 	speed: 0.1201s/iter; left time: 193.2972s
[36m(_train_fn pid=774736)[0m 	iters: 200, epoch: 2 | loss: 0.6116881
[36m(_train_fn pid=774736)[0m 	speed: 0.0695s/iter; left time: 104.8832s
[36m(_train_fn pid=774736)[0m Updating learning rate to 0.0006555358603865734
[36m(_train_fn pid=774736)[0m saving checkpoint...
[36m(_train_fn pid=774736)[0m Validation loss decreased (1.8718 --> 1.5790).  Saving model state dict ...
[36m(_train_fn pid=774736)[0m Epoch: 2 cost time: 16.970850467681885
[36m(_train_fn pid=774736)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7810765 Vali Loss: 1.5789715 Best vali loss: 1.5789715
[36m(_train_fn pid=774736)[0m 	iters: 100, epoch: 3 | loss: 0.5751623
[36m(_train_fn pid=774736)[0m 	speed: 0.1201s/iter; left time: 163.9733s
[36m(_train_fn pid=774736)[0m 	iters: 200, epoch: 3 | loss: 0.6036166
[36m(_train_fn pid=774736)[0m 	speed: 0.0697s/iter; left time: 88.1564s
Trial status: 52 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:02:43. Total running time: 41min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=774736)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-17cf266d_53_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-01-45/checkpoint_000002)
[36m(_train_fn pid=774736)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-17cf266d_53_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-01-45/checkpoint_000003)
[36m(_train_fn pid=774736)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-17cf266d_53_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-01-45/checkpoint_000004)
[36m(_train_fn pid=774736)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-17cf266d_53_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-01-45/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-17cf266d   RUNNING           2            38.4985       0.781076        1.57897             1.57897 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
47 more TERMINATED
[36m(_train_fn pid=774736)[0m Updating learning rate to 0.0003277679301932867
[36m(_train_fn pid=774736)[0m saving checkpoint...
[36m(_train_fn pid=774736)[0m Validation loss decreased (1.5790 --> 1.5675).  Saving model state dict ...
[36m(_train_fn pid=774736)[0m Epoch: 3 cost time: 17.002605199813843
[36m(_train_fn pid=774736)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6163309 Vali Loss: 1.5674819 Best vali loss: 1.5674819
[36m(_train_fn pid=774736)[0m 	iters: 100, epoch: 4 | loss: 0.5672690
[36m(_train_fn pid=774736)[0m 	speed: 0.1205s/iter; left time: 135.1092s
[36m(_train_fn pid=774736)[0m 	iters: 200, epoch: 4 | loss: 0.5209265
[36m(_train_fn pid=774736)[0m 	speed: 0.0697s/iter; left time: 71.1472s
[36m(_train_fn pid=774736)[0m Updating learning rate to 0.00016388396509664334
[36m(_train_fn pid=774736)[0m saving checkpoint...
[36m(_train_fn pid=774736)[0m Validation loss decreased (1.5675 --> 1.5660).  Saving model state dict ...
[36m(_train_fn pid=774736)[0m Epoch: 4 cost time: 17.02150797843933
[36m(_train_fn pid=774736)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6126292 Vali Loss: 1.5659731 Best vali loss: 1.5659731
[36m(_train_fn pid=774736)[0m 	iters: 100, epoch: 5 | loss: 0.6185828
[36m(_train_fn pid=774736)[0m 	speed: 0.1203s/iter; left time: 105.5101s
Trial status: 52 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:03:13. Total running time: 42min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-17cf266d   RUNNING           4            76.5031       0.612629        1.56597             1.56597 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
47 more TERMINATED
[36m(_train_fn pid=774736)[0m 	iters: 200, epoch: 5 | loss: 0.5382563
[36m(_train_fn pid=774736)[0m 	speed: 0.0698s/iter; left time: 54.2143s
[36m(_train_fn pid=774736)[0m Updating learning rate to 8.194198254832167e-05
[36m(_train_fn pid=774736)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=774736)[0m saving checkpoint...
[36m(_train_fn pid=774736)[0m Epoch: 5 cost time: 17.01608109474182
[36m(_train_fn pid=774736)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6110175 Vali Loss: 1.5676108 Best vali loss: 1.5659731
[36m(_train_fn pid=774736)[0m 	iters: 100, epoch: 6 | loss: 0.6301550
[36m(_train_fn pid=774736)[0m 	speed: 0.1201s/iter; left time: 76.0255s
[36m(_train_fn pid=774736)[0m 	iters: 200, epoch: 6 | loss: 0.7083673
[36m(_train_fn pid=774736)[0m 	speed: 0.0697s/iter; left time: 37.1682s
[36m(_train_fn pid=774736)[0m Updating learning rate to 4.0970991274160835e-05
[36m(_train_fn pid=774736)[0m saving checkpoint...
[36m(_train_fn pid=774736)[0m Validation loss decreased (1.5660 --> 1.5643).  Saving model state dict ...

Trial trial-17cf266d completed after 6 iterations at 2024-08-24 08:03:41. Total running time: 42min 33s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-17cf266d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.00958 â”‚
â”‚ time_total_s                            114.49502 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56429 â”‚
â”‚ train_loss                                0.60983 â”‚
â”‚ valid_loss                                1.56429 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 53 TERMINATED | 1 PENDING
Current time: 2024-08-24 08:03:43. Total running time: 42min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:03:52,369	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=775594)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d6f53a96_54_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1382,e_layers=_2024-08-24_08-03-41/checkpoint_000000)
[36m(_train_fn pid=775594)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d6f53a96_54_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1382,e_layers=_2024-08-24_08-03-41/checkpoint_000001)
[36m(_train_fn pid=775594)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d6f53a96_54_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1382,e_layers=_2024-08-24_08-03-41/checkpoint_000002)
[36m(_train_fn pid=775594)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d6f53a96_54_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1382,e_layers=_2024-08-24_08-03-41/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-d6f53a96   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
48 more TERMINATED

Trial trial-d6f53a96 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d6f53a96 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13821 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00794 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=775594)[0m configuration
[36m(_train_fn pid=775594)[0m {'batch_size': 16, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.13821395795094985, 'e_layers': 4, 'learning_rate': 0.007936007211568171, 'd_ff': 48}
[36m(_train_fn pid=775594)[0m Use GPU: cuda:0
[36m(_train_fn pid=775594)[0m train 7825
[36m(_train_fn pid=775594)[0m val 2161
[36m(_train_fn pid=775594)[0m start_epoch 0
[36m(_train_fn pid=775594)[0m max_epoch 8
[36m(_train_fn pid=775594)[0m 	iters: 100, epoch: 1 | loss: 0.6997092
[36m(_train_fn pid=775594)[0m 	speed: 0.0200s/iter; left time: 76.1923s
[36m(_train_fn pid=775594)[0m 	iters: 200, epoch: 1 | loss: 0.6037026
[36m(_train_fn pid=775594)[0m 	speed: 0.0130s/iter; left time: 48.4170s
[36m(_train_fn pid=775594)[0m 	iters: 300, epoch: 1 | loss: 0.7282173
[36m(_train_fn pid=775594)[0m 	speed: 0.0130s/iter; left time: 47.0660s
[36m(_train_fn pid=775594)[0m 	iters: 400, epoch: 1 | loss: 0.5743545
[36m(_train_fn pid=775594)[0m 	speed: 0.0130s/iter; left time: 45.6779s
[36m(_train_fn pid=775594)[0m Updating learning rate to 0.007936007211568171
[36m(_train_fn pid=775594)[0m saving checkpoint...
[36m(_train_fn pid=775594)[0m Validation loss decreased (inf --> 1.5936).  Saving model state dict ...
[36m(_train_fn pid=775594)[0m Epoch: 1 cost time: 6.8042378425598145
[36m(_train_fn pid=775594)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7385666 Vali Loss: 1.5935836 Best vali loss: 1.5935836
[36m(_train_fn pid=775594)[0m 	iters: 100, epoch: 2 | loss: 0.6154574
[36m(_train_fn pid=775594)[0m 	speed: 0.0306s/iter; left time: 101.7596s
[36m(_train_fn pid=775594)[0m 	iters: 200, epoch: 2 | loss: 0.5670198
[36m(_train_fn pid=775594)[0m 	speed: 0.0125s/iter; left time: 40.3779s
[36m(_train_fn pid=775594)[0m 	iters: 300, epoch: 2 | loss: 0.4604990
[36m(_train_fn pid=775594)[0m 	speed: 0.0130s/iter; left time: 40.6367s
[36m(_train_fn pid=775594)[0m 	iters: 400, epoch: 2 | loss: 0.6990056
[36m(_train_fn pid=775594)[0m 	speed: 0.0130s/iter; left time: 39.3272s
[36m(_train_fn pid=775594)[0m Updating learning rate to 0.0039680036057840855
[36m(_train_fn pid=775594)[0m saving checkpoint...
[36m(_train_fn pid=775594)[0m Validation loss decreased (1.5936 --> 1.5842).  Saving model state dict ...
[36m(_train_fn pid=775594)[0m Epoch: 2 cost time: 6.221598386764526
[36m(_train_fn pid=775594)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6035577 Vali Loss: 1.5841759 Best vali loss: 1.5841759
[36m(_train_fn pid=775594)[0m 	iters: 100, epoch: 3 | loss: 0.6669617
[36m(_train_fn pid=775594)[0m 	speed: 0.0305s/iter; left time: 86.4635s
[36m(_train_fn pid=775594)[0m 	iters: 200, epoch: 3 | loss: 0.5175203
[36m(_train_fn pid=775594)[0m 	speed: 0.0115s/iter; left time: 31.5579s
[36m(_train_fn pid=775594)[0m 	iters: 300, epoch: 3 | loss: 0.5384296
[36m(_train_fn pid=775594)[0m 	speed: 0.0115s/iter; left time: 30.3641s
[36m(_train_fn pid=775594)[0m 	iters: 400, epoch: 3 | loss: 0.6054604
[36m(_train_fn pid=775594)[0m 	speed: 0.0115s/iter; left time: 29.2253s
[36m(_train_fn pid=775594)[0m Updating learning rate to 0.0019840018028920428
[36m(_train_fn pid=775594)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=775594)[0m saving checkpoint...
[36m(_train_fn pid=775594)[0m Epoch: 3 cost time: 5.700390815734863
[36m(_train_fn pid=775594)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5618304 Vali Loss: 1.6006238 Best vali loss: 1.5841759
[36m(_train_fn pid=775594)[0m 	iters: 100, epoch: 4 | loss: 0.4016458
[36m(_train_fn pid=775594)[0m 	speed: 0.0303s/iter; left time: 71.1258s
[36m(_train_fn pid=775594)[0m 	iters: 200, epoch: 4 | loss: 0.6314133
[36m(_train_fn pid=775594)[0m 	speed: 0.0130s/iter; left time: 29.2370s
[36m(_train_fn pid=775594)[0m 	iters: 300, epoch: 4 | loss: 0.4630223
[36m(_train_fn pid=775594)[0m 	speed: 0.0130s/iter; left time: 27.9103s
[36m(_train_fn pid=775594)[0m 	iters: 400, epoch: 4 | loss: 0.6158555
[36m(_train_fn pid=775594)[0m 	speed: 0.0130s/iter; left time: 26.6446s
[36m(_train_fn pid=775594)[0m Updating learning rate to 0.0009920009014460214
[36m(_train_fn pid=775594)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=775594)[0m saving checkpoint...
[36m(_train_fn pid=775594)[0m Epoch: 4 cost time: 6.4085493087768555
[36m(_train_fn pid=775594)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5270610 Vali Loss: 1.5962700 Best vali loss: 1.5841759

Trial status: 53 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:04:13. Total running time: 43min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=775594)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d6f53a96_54_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1382,e_layers=_2024-08-24_08-03-41/checkpoint_000004)
[36m(_train_fn pid=776140)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7080bbc2_55_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_08-04-19/checkpoint_000000)
2024-08-24 08:05:11,221	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d6f53a96   RUNNING           4            28.2401       0.527061        1.59627             1.58418 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
48 more TERMINATED
[36m(_train_fn pid=775594)[0m 	iters: 100, epoch: 5 | loss: 0.4182915
[36m(_train_fn pid=775594)[0m 	speed: 0.0305s/iter; left time: 56.6117s
[36m(_train_fn pid=775594)[0m 	iters: 200, epoch: 5 | loss: 0.4547344
[36m(_train_fn pid=775594)[0m 	speed: 0.0115s/iter; left time: 20.2591s
[36m(_train_fn pid=775594)[0m 	iters: 300, epoch: 5 | loss: 0.4689656
[36m(_train_fn pid=775594)[0m 	speed: 0.0114s/iter; left time: 18.9257s
[36m(_train_fn pid=775594)[0m 	iters: 400, epoch: 5 | loss: 0.4586250
[36m(_train_fn pid=775594)[0m 	speed: 0.0113s/iter; left time: 17.5956s

Trial trial-d6f53a96 completed after 5 iterations at 2024-08-24 08:04:19. Total running time: 43min 10s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d6f53a96 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          6.29957 â”‚
â”‚ time_total_s                             34.53969 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58418 â”‚
â”‚ train_loss                                0.49189 â”‚
â”‚ valid_loss                                 1.5887 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=775594)[0m Updating learning rate to 0.0004960004507230107
[36m(_train_fn pid=775594)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=775594)[0m saving checkpoint...
[36m(_train_fn pid=775594)[0m Epoch: 5 cost time: 5.638799428939819
[36m(_train_fn pid=775594)[0m Epoch: 5, Steps: 489 | Train Loss: 0.4918892 Vali Loss: 1.5887025 Best vali loss: 1.5841759
[36m(_train_fn pid=775594)[0m Early stopping

Trial trial-7080bbc2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7080bbc2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.10218 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00077 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=776140)[0m configuration
[36m(_train_fn pid=776140)[0m {'batch_size': 128, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'conv', 'dropout': 0.10218454962509814, 'e_layers': 2, 'learning_rate': 0.0007680724475496717, 'd_ff': 1024}
[36m(_train_fn pid=776140)[0m Use GPU: cuda:0
[36m(_train_fn pid=776140)[0m train 7825
[36m(_train_fn pid=776140)[0m val 2161
[36m(_train_fn pid=776140)[0m start_epoch 0
[36m(_train_fn pid=776140)[0m max_epoch 8

Trial status: 54 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:04:43. Total running time: 43min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7080bbc2   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
49 more TERMINATED
[36m(_train_fn pid=776140)[0m Updating learning rate to 0.0007680724475496717
[36m(_train_fn pid=776140)[0m saving checkpoint...
[36m(_train_fn pid=776140)[0m Validation loss decreased (inf --> 2.0015).  Saving model state dict ...
[36m(_train_fn pid=776140)[0m Epoch: 1 cost time: 21.938085556030273
[36m(_train_fn pid=776140)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8648023 Vali Loss: 2.0015433 Best vali loss: 2.0015433
[36m(_train_fn pid=776140)[0m Updating learning rate to 0.0003840362237748358
[36m(_train_fn pid=776140)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7080bbc2_55_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_08-04-19/checkpoint_000001)
[36m(_train_fn pid=776140)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7080bbc2_55_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_08-04-19/checkpoint_000002)
2024-08-24 08:05:35,895	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:06:00,579	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=776140)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7080bbc2_55_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_08-04-19/checkpoint_000003)
[36m(_train_fn pid=776140)[0m saving checkpoint...
[36m(_train_fn pid=776140)[0m Validation loss decreased (2.0015 --> 1.6747).  Saving model state dict ...
[36m(_train_fn pid=776140)[0m Epoch: 2 cost time: 21.819466590881348
[36m(_train_fn pid=776140)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7367689 Vali Loss: 1.6746622 Best vali loss: 1.6746622
Trial status: 54 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:05:13. Total running time: 44min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7080bbc2   RUNNING           2            49.7232       0.736769        1.67466             1.67466 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
49 more TERMINATED
[36m(_train_fn pid=776140)[0m Updating learning rate to 0.0001920181118874179
[36m(_train_fn pid=776140)[0m saving checkpoint...
[36m(_train_fn pid=776140)[0m Validation loss decreased (1.6747 --> 1.6308).  Saving model state dict ...
[36m(_train_fn pid=776140)[0m Epoch: 3 cost time: 21.887877702713013
[36m(_train_fn pid=776140)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6366988 Vali Loss: 1.6308390 Best vali loss: 1.6308390
Trial status: 54 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:05:43. Total running time: 44min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7080bbc2   RUNNING           3            74.3931       0.636699        1.63084             1.63084 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
49 more TERMINATED
[36m(_train_fn pid=776140)[0m Updating learning rate to 9.600905594370896e-05
[36m(_train_fn pid=776140)[0m saving checkpoint...
[36m(_train_fn pid=776140)[0m Validation loss decreased (1.6308 --> 1.6220).  Saving model state dict ...
[36m(_train_fn pid=776140)[0m Epoch: 4 cost time: 21.907965898513794
[36m(_train_fn pid=776140)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6242227 Vali Loss: 1.6219842 Best vali loss: 1.6219842
Trial status: 54 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:06:13. Total running time: 45min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7080bbc2   RUNNING           4            99.0811       0.624223        1.62198             1.62198 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
49 more TERMINATED
[36m(_train_fn pid=776140)[0m Updating learning rate to 4.800452797185448e-05
2024-08-24 08:06:25,323	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=776140)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7080bbc2_55_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_08-04-19/checkpoint_000004)
[36m(_train_fn pid=776951)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c53a2728_56_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1271,e_layers=_2024-08-24_08-06-25/checkpoint_000000)
2024-08-24 08:06:38,188	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=776951)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c53a2728_56_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1271,e_layers=_2024-08-24_08-06-25/checkpoint_000001)
2024-08-24 08:06:43,126	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=776951)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c53a2728_56_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1271,e_layers=_2024-08-24_08-06-25/checkpoint_000002)
2024-08-24 08:06:48,063	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=776951)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c53a2728_56_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1271,e_layers=_2024-08-24_08-06-25/checkpoint_000003)
2024-08-24 08:06:52,986	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=776140)[0m saving checkpoint...
[36m(_train_fn pid=776140)[0m Validation loss decreased (1.6220 --> 1.6189).  Saving model state dict ...

Trial trial-7080bbc2 completed after 5 iterations at 2024-08-24 08:06:25. Total running time: 45min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7080bbc2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          24.7297 â”‚
â”‚ time_total_s                            123.81082 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.61895 â”‚
â”‚ train_loss                                0.62128 â”‚
â”‚ valid_loss                                1.61895 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-c53a2728 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c53a2728 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.12714 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00148 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=776951)[0m configuration
[36m(_train_fn pid=776951)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.12714144849325615, 'e_layers': 3, 'learning_rate': 0.0014796183942151452, 'd_ff': 192}
[36m(_train_fn pid=776951)[0m Use GPU: cuda:0
[36m(_train_fn pid=776951)[0m train 7825
[36m(_train_fn pid=776951)[0m val 2161
[36m(_train_fn pid=776951)[0m start_epoch 0
[36m(_train_fn pid=776951)[0m max_epoch 8
[36m(_train_fn pid=776951)[0m 	iters: 100, epoch: 1 | loss: 0.7815453
[36m(_train_fn pid=776951)[0m 	speed: 0.0245s/iter; left time: 45.4826s
[36m(_train_fn pid=776951)[0m 	iters: 200, epoch: 1 | loss: 0.8090735
[36m(_train_fn pid=776951)[0m 	speed: 0.0173s/iter; left time: 30.2560s
[36m(_train_fn pid=776951)[0m Updating learning rate to 0.0014796183942151452
[36m(_train_fn pid=776951)[0m saving checkpoint...
[36m(_train_fn pid=776951)[0m Validation loss decreased (inf --> 1.8775).  Saving model state dict ...
[36m(_train_fn pid=776951)[0m Epoch: 1 cost time: 4.683706045150757
[36m(_train_fn pid=776951)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7933630 Vali Loss: 1.8774980 Best vali loss: 1.8774980
[36m(_train_fn pid=776951)[0m 	iters: 100, epoch: 2 | loss: 0.6343546
[36m(_train_fn pid=776951)[0m 	speed: 0.0320s/iter; left time: 51.5167s
[36m(_train_fn pid=776951)[0m 	iters: 200, epoch: 2 | loss: 0.5660767
[36m(_train_fn pid=776951)[0m 	speed: 0.0172s/iter; left time: 25.9828s
[36m(_train_fn pid=776951)[0m Updating learning rate to 0.0007398091971075726
[36m(_train_fn pid=776951)[0m saving checkpoint...
[36m(_train_fn pid=776951)[0m Validation loss decreased (1.8775 --> 1.5819).  Saving model state dict ...
[36m(_train_fn pid=776951)[0m Epoch: 2 cost time: 4.2465221881866455
[36m(_train_fn pid=776951)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6243262 Vali Loss: 1.5818988 Best vali loss: 1.5818988
[36m(_train_fn pid=776951)[0m 	iters: 100, epoch: 3 | loss: 0.5663509
[36m(_train_fn pid=776951)[0m 	speed: 0.0322s/iter; left time: 43.9522s
[36m(_train_fn pid=776951)[0m 	iters: 200, epoch: 3 | loss: 0.6121292
[36m(_train_fn pid=776951)[0m 	speed: 0.0173s/iter; left time: 21.8857s
[36m(_train_fn pid=776951)[0m Updating learning rate to 0.0003699045985537863
[36m(_train_fn pid=776951)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=776951)[0m saving checkpoint...
[36m(_train_fn pid=776951)[0m Epoch: 3 cost time: 4.256951808929443
[36m(_train_fn pid=776951)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5898612 Vali Loss: 1.5833860 Best vali loss: 1.5818988

Trial status: 55 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:06:43. Total running time: 45min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c53a2728   RUNNING           3            15.6313       0.589861        1.58339             1.5819  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
50 more TERMINATED
[36m(_train_fn pid=776951)[0m 	iters: 100, epoch: 4 | loss: 0.5003611
[36m(_train_fn pid=776951)[0m 	speed: 0.0321s/iter; left time: 35.9735s
[36m(_train_fn pid=776951)[0m 	iters: 200, epoch: 4 | loss: 0.5660751
[36m(_train_fn pid=776951)[0m 	speed: 0.0173s/iter; left time: 17.6873s
[36m(_train_fn pid=776951)[0m Updating learning rate to 0.00018495229927689314
[36m(_train_fn pid=776951)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=776951)[0m saving checkpoint...
[36m(_train_fn pid=776951)[0m Epoch: 4 cost time: 4.2689104080200195
[36m(_train_fn pid=776951)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5668136 Vali Loss: 1.5921232 Best vali loss: 1.5818988
[36m(_train_fn pid=776951)[0m 	iters: 100, epoch: 5 | loss: 0.5227955
[36m(_train_fn pid=776951)[0m 	speed: 0.0321s/iter; left time: 28.1186s
[36m(_train_fn pid=776951)[0m 	iters: 200, epoch: 5 | loss: 0.5949370
[36m(_train_fn pid=776951)[0m 	speed: 0.0172s/iter; left time: 13.3767s

Trial trial-c53a2728 completed after 5 iterations at 2024-08-24 08:06:52. Total running time: 45min 44s
[36m(_train_fn pid=776951)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c53a2728_56_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1271,e_layers=_2024-08-24_08-06-25/checkpoint_000004)
[36m(_train_fn pid=777472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f401ec3_57_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1303,e_layer_2024-08-24_08-06-52/checkpoint_000000)
2024-08-24 08:07:22,581	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=777472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f401ec3_57_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1303,e_layer_2024-08-24_08-06-52/checkpoint_000001)
2024-08-24 08:07:35,745	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=777472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f401ec3_57_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1303,e_layer_2024-08-24_08-06-52/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c53a2728 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          4.91177 â”‚
â”‚ time_total_s                             25.48669 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                            1.5819 â”‚
â”‚ train_loss                                0.55639 â”‚
â”‚ valid_loss                                1.58752 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=776951)[0m Updating learning rate to 9.247614963844657e-05
[36m(_train_fn pid=776951)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=776951)[0m saving checkpoint...
[36m(_train_fn pid=776951)[0m Epoch: 5 cost time: 4.245198965072632
[36m(_train_fn pid=776951)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5563893 Vali Loss: 1.5875177 Best vali loss: 1.5818988
[36m(_train_fn pid=776951)[0m Early stopping

Trial trial-5f401ec3 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5f401ec3 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13029 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00326 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=777472)[0m configuration
[36m(_train_fn pid=777472)[0m {'batch_size': 128, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1302920020331198, 'e_layers': 2, 'learning_rate': 0.003255861410677605, 'd_ff': 1024}
[36m(_train_fn pid=777472)[0m Use GPU: cuda:0
[36m(_train_fn pid=777472)[0m train 7825
[36m(_train_fn pid=777472)[0m val 2161
[36m(_train_fn pid=777472)[0m start_epoch 0
[36m(_train_fn pid=777472)[0m max_epoch 8
[36m(_train_fn pid=777472)[0m Validation loss decreased (inf --> 1.9731).  Saving model state dict ...
[36m(_train_fn pid=777472)[0m Updating learning rate to 0.003255861410677605
[36m(_train_fn pid=777472)[0m saving checkpoint...
[36m(_train_fn pid=777472)[0m Epoch: 1 cost time: 11.982632875442505
[36m(_train_fn pid=777472)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8203905 Vali Loss: 1.9731080 Best vali loss: 1.9731080

Trial status: 56 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:07:13. Total running time: 46min 4s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5f401ec3   RUNNING           1            13.927        0.820391        1.97311             1.97311 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
51 more TERMINATED
[36m(_train_fn pid=777472)[0m Updating learning rate to 0.0016279307053388024
[36m(_train_fn pid=777472)[0m saving checkpoint...
[36m(_train_fn pid=777472)[0m Validation loss decreased (1.9731 --> 1.6174).  Saving model state dict ...
[36m(_train_fn pid=777472)[0m Epoch: 2 cost time: 11.605159044265747
[36m(_train_fn pid=777472)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7194860 Vali Loss: 1.6173988 Best vali loss: 1.6173988
[36m(_train_fn pid=777472)[0m Updating learning rate to 0.0008139653526694012
[36m(_train_fn pid=777472)[0m saving checkpoint...
[36m(_train_fn pid=777472)[0m Validation loss decreased (1.6174 --> 1.5887).  Saving model state dict ...
[36m(_train_fn pid=777472)[0m Epoch: 3 cost time: 11.624762296676636
[36m(_train_fn pid=777472)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6135193 Vali Loss: 1.5886845 Best vali loss: 1.5886845
Trial status: 56 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:07:43. Total running time: 46min 34s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=777472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f401ec3_57_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1303,e_layer_2024-08-24_08-06-52/checkpoint_000003)
2024-08-24 08:07:48,883	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:08:02,045	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=777472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f401ec3_57_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1303,e_layer_2024-08-24_08-06-52/checkpoint_000004)
2024-08-24 08:08:15,202	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=777472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f401ec3_57_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1303,e_layer_2024-08-24_08-06-52/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5f401ec3   RUNNING           3            40.2277       0.613519        1.58868             1.58868 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
51 more TERMINATED
[36m(_train_fn pid=777472)[0m Updating learning rate to 0.0004069826763347006
[36m(_train_fn pid=777472)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=777472)[0m saving checkpoint...
[36m(_train_fn pid=777472)[0m Epoch: 4 cost time: 11.618224620819092
[36m(_train_fn pid=777472)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6001218 Vali Loss: 1.5952082 Best vali loss: 1.5886845
[36m(_train_fn pid=777472)[0m Updating learning rate to 0.0002034913381673503
[36m(_train_fn pid=777472)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=777472)[0m saving checkpoint...
[36m(_train_fn pid=777472)[0m Epoch: 5 cost time: 11.63146424293518
[36m(_train_fn pid=777472)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5921479 Vali Loss: 1.5930329 Best vali loss: 1.5886845
Trial status: 56 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:08:13. Total running time: 47min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5f401ec3   RUNNING           5            66.5214       0.592148        1.59303             1.58868 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
51 more TERMINATED

Trial trial-5f401ec3 completed after 6 iterations at 2024-08-24 08:08:15. Total running time: 47min 6s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5f401ec3 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          13.1547 â”‚
â”‚ time_total_s                             79.67613 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.58868 â”‚
â”‚ train_loss                                 0.5864 â”‚
â”‚ valid_loss                                1.60236 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=777472)[0m Updating learning rate to 0.00010174566908367515
[36m(_train_fn pid=777472)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=777472)[0m saving checkpoint...
[36m(_train_fn pid=777472)[0m Epoch: 6 cost time: 11.633619785308838
[36m(_train_fn pid=777472)[0m Epoch: 6, Steps: 61 | Train Loss: 0.5863996 Vali Loss: 1.6023643 Best vali loss: 1.5886845
[36m(_train_fn pid=777472)[0m Early stopping

Trial trial-44221150 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-44221150 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07229 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00245 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=778226)[0m configuration
[36m(_train_fn pid=778226)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'conv', 'dropout': 0.07228976271877133, 'e_layers': 3, 'learning_rate': 0.0024522362480619477, 'd_ff': 1024}
[36m(_train_fn pid=778226)[0m Use GPU: cuda:0
[36m(_train_fn pid=778226)[0m train 7825
[36m(_train_fn pid=778226)[0m val 2161
[36m(_train_fn pid=778226)[0m start_epoch 0
[36m(_train_fn pid=778226)[0m max_epoch 8
[36m(_train_fn pid=778226)[0m 	iters: 100, epoch: 1 | loss: 0.7306578
[36m(_train_fn pid=778226)[0m 	speed: 0.0803s/iter; left time: 306.0836s
[36m(_train_fn pid=778226)[0m 	iters: 200, epoch: 1 | loss: 0.6636057
[36m(_train_fn pid=778226)[0m 	speed: 0.0757s/iter; left time: 280.9225s
2024-08-24 08:08:59,212	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778226)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-44221150_58_alpha_d_ff=2,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_08-08-15/checkpoint_000000)
2024-08-24 08:09:40,257	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778226)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-44221150_58_alpha_d_ff=2,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_08-08-15/checkpoint_000001)
[36m(_train_fn pid=778226)[0m 	iters: 300, epoch: 1 | loss: 0.6332363
[36m(_train_fn pid=778226)[0m 	speed: 0.0756s/iter; left time: 273.3163s

Trial status: 57 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:08:43. Total running time: 47min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-44221150   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
52 more TERMINATED
[36m(_train_fn pid=778226)[0m 	iters: 400, epoch: 1 | loss: 0.6204264
[36m(_train_fn pid=778226)[0m 	speed: 0.0757s/iter; left time: 265.7954s
[36m(_train_fn pid=778226)[0m Updating learning rate to 0.0024522362480619477
[36m(_train_fn pid=778226)[0m saving checkpoint...
[36m(_train_fn pid=778226)[0m Validation loss decreased (inf --> 1.6272).  Saving model state dict ...
[36m(_train_fn pid=778226)[0m Epoch: 1 cost time: 37.20394492149353
[36m(_train_fn pid=778226)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7091428 Vali Loss: 1.6271953 Best vali loss: 1.6271953
[36m(_train_fn pid=778226)[0m 	iters: 100, epoch: 2 | loss: 58.6122093
[36m(_train_fn pid=778226)[0m 	speed: 0.1838s/iter; left time: 610.8516s
Trial status: 57 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:09:13. Total running time: 48min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-44221150   RUNNING           1            41.731        0.709143        1.6272              1.6272  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
52 more TERMINATED
[36m(_train_fn pid=778226)[0m 	iters: 200, epoch: 2 | loss: 41012.0117188
[36m(_train_fn pid=778226)[0m 	speed: 0.0751s/iter; left time: 241.9916s
[36m(_train_fn pid=778226)[0m 	iters: 300, epoch: 2 | loss: 960599.2500000
[36m(_train_fn pid=778226)[0m 	speed: 0.0752s/iter; left time: 234.9505s
[36m(_train_fn pid=778226)[0m 	iters: 400, epoch: 2 | loss: 7025.3618164
[36m(_train_fn pid=778226)[0m 	speed: 0.0761s/iter; left time: 230.2296s
[36m(_train_fn pid=778226)[0m Updating learning rate to 0.0012261181240309739
[36m(_train_fn pid=778226)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=778226)[0m saving checkpoint...
[36m(_train_fn pid=778226)[0m Epoch: 2 cost time: 36.9899365901947
[36m(_train_fn pid=778226)[0m Epoch: 2, Steps: 489 | Train Loss: 545578.0299851 Vali Loss: 4484.7233254 Best vali loss: 1.6271953
Trial status: 57 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:09:43. Total running time: 48min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:10:21,899	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778226)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-44221150_58_alpha_d_ff=2,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_08-08-15/checkpoint_000002)
2024-08-24 08:10:26,590	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778896)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f8779e9_59_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.1_2024-08-24_08-10-21/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)      train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-44221150   RUNNING           2            82.7714   545578            4484.72                1.6272  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
52 more TERMINATED
[36m(_train_fn pid=778226)[0m 	iters: 100, epoch: 3 | loss: 2367.1313477
[36m(_train_fn pid=778226)[0m 	speed: 0.1854s/iter; left time: 525.6601s
[36m(_train_fn pid=778226)[0m 	iters: 200, epoch: 3 | loss: 1629.6667480
[36m(_train_fn pid=778226)[0m 	speed: 0.0768s/iter; left time: 210.0844s
[36m(_train_fn pid=778226)[0m 	iters: 300, epoch: 3 | loss: 1004.2579346
[36m(_train_fn pid=778226)[0m 	speed: 0.0768s/iter; left time: 202.4606s
[36m(_train_fn pid=778226)[0m 	iters: 400, epoch: 3 | loss: 1109.1173096
[36m(_train_fn pid=778226)[0m 	speed: 0.0769s/iter; left time: 195.0165s
Trial status: 57 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:10:13. Total running time: 49min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)      train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-44221150   RUNNING           2            82.7714   545578            4484.72                1.6272  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
52 more TERMINATED

Trial trial-44221150 completed after 3 iterations at 2024-08-24 08:10:21. Total running time: 49min 13s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-44221150 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000002 â”‚
â”‚ time_this_iter_s                         41.62948 â”‚
â”‚ time_total_s                            124.40086 â”‚
â”‚ training_iteration                              3 â”‚
â”‚ best_valid_loss                            1.6272 â”‚
â”‚ train_loss                             1474.94652 â”‚
â”‚ valid_loss                             1683.74527 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=778226)[0m Updating learning rate to 0.0006130590620154869
[36m(_train_fn pid=778226)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=778226)[0m saving checkpoint...

Trial trial-5f8779e9 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5f8779e9 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11201 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00356 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=778896)[0m configuration
[36m(_train_fn pid=778896)[0m {'batch_size': 32, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.11201260664706003, 'e_layers': 2, 'learning_rate': 0.003563478201218512, 'd_ff': 24}
[36m(_train_fn pid=778896)[0m Use GPU: cuda:0
[36m(_train_fn pid=778896)[0m train 7825
[36m(_train_fn pid=778896)[0m val 2161
[36m(_train_fn pid=778896)[0m start_epoch 0
[36m(_train_fn pid=778896)[0m max_epoch 8
[36m(_train_fn pid=778896)[0m 	iters: 100, epoch: 1 | loss: 0.8816951
[36m(_train_fn pid=778896)[0m 	speed: 0.0140s/iter; left time: 25.9008s
[36m(_train_fn pid=778896)[0m 	iters: 200, epoch: 1 | loss: 0.7417056
[36m(_train_fn pid=778896)[0m 	speed: 0.0090s/iter; left time: 15.7642s
[36m(_train_fn pid=778896)[0m Validation loss decreased (inf --> 1.7243).  Saving model state dict ...
[36m(_train_fn pid=778896)[0m Epoch: 1 cost time: 2.4333908557891846
[36m(_train_fn pid=778896)[0m Epoch: 1, Steps: 244 | Train Loss: 0.9546253 Vali Loss: 1.7242949 Best vali loss: 1.7242949
[36m(_train_fn pid=778896)[0m 	iters: 100, epoch: 2 | loss: 0.5872396
[36m(_train_fn pid=778896)[0m 	speed: 0.0161s/iter; left time: 25.8914s
2024-08-24 08:10:29,100	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778896)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f8779e9_59_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.1_2024-08-24_08-10-21/checkpoint_000001)
2024-08-24 08:10:31,622	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778896)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f8779e9_59_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.1_2024-08-24_08-10-21/checkpoint_000002)
2024-08-24 08:10:34,135	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778896)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f8779e9_59_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.1_2024-08-24_08-10-21/checkpoint_000003)
[36m(_train_fn pid=778896)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f8779e9_59_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.1_2024-08-24_08-10-21/checkpoint_000004)
2024-08-24 08:10:36,452	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:10:38,946	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778896)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f8779e9_59_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.1_2024-08-24_08-10-21/checkpoint_000005)
2024-08-24 08:10:41,440	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=778896)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5f8779e9_59_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.1_2024-08-24_08-10-21/checkpoint_000006)
[36m(_train_fn pid=778896)[0m Updating learning rate to 0.003563478201218512
[36m(_train_fn pid=778896)[0m saving checkpoint...
[36m(_train_fn pid=778896)[0m 	iters: 200, epoch: 2 | loss: 0.6338302
[36m(_train_fn pid=778896)[0m 	speed: 0.0090s/iter; left time: 13.5898s
[36m(_train_fn pid=778896)[0m Updating learning rate to 0.001781739100609256
[36m(_train_fn pid=778896)[0m saving checkpoint...
[36m(_train_fn pid=778896)[0m Validation loss decreased (1.7243 --> 1.5960).  Saving model state dict ...
[36m(_train_fn pid=778896)[0m Epoch: 2 cost time: 2.240708351135254
[36m(_train_fn pid=778896)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6195250 Vali Loss: 1.5960444 Best vali loss: 1.5960444
[36m(_train_fn pid=778896)[0m 	iters: 100, epoch: 3 | loss: 0.6347460
[36m(_train_fn pid=778896)[0m 	speed: 0.0161s/iter; left time: 22.0443s
[36m(_train_fn pid=778896)[0m 	iters: 200, epoch: 3 | loss: 0.5769625
[36m(_train_fn pid=778896)[0m 	speed: 0.0090s/iter; left time: 11.3824s
[36m(_train_fn pid=778896)[0m Updating learning rate to 0.000890869550304628
[36m(_train_fn pid=778896)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=778896)[0m saving checkpoint...
[36m(_train_fn pid=778896)[0m Epoch: 3 cost time: 2.236726760864258
[36m(_train_fn pid=778896)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5863961 Vali Loss: 1.5986287 Best vali loss: 1.5960444
[36m(_train_fn pid=778896)[0m 	iters: 100, epoch: 4 | loss: 0.6014999
[36m(_train_fn pid=778896)[0m 	speed: 0.0161s/iter; left time: 18.0833s
[36m(_train_fn pid=778896)[0m 	iters: 200, epoch: 4 | loss: 0.5324305
[36m(_train_fn pid=778896)[0m 	speed: 0.0090s/iter; left time: 9.2296s
[36m(_train_fn pid=778896)[0m Updating learning rate to 0.000445434775152314
[36m(_train_fn pid=778896)[0m saving checkpoint...
[36m(_train_fn pid=778896)[0m Validation loss decreased (1.5960 --> 1.5889).  Saving model state dict ...
[36m(_train_fn pid=778896)[0m Epoch: 4 cost time: 2.249579429626465
[36m(_train_fn pid=778896)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5707524 Vali Loss: 1.5888728 Best vali loss: 1.5888728
[36m(_train_fn pid=778896)[0m 	iters: 100, epoch: 5 | loss: 0.5313221
[36m(_train_fn pid=778896)[0m 	speed: 0.0155s/iter; left time: 13.5677s
[36m(_train_fn pid=778896)[0m 	iters: 200, epoch: 5 | loss: 0.5587890
[36m(_train_fn pid=778896)[0m 	speed: 0.0082s/iter; left time: 6.3922s
[36m(_train_fn pid=778896)[0m Updating learning rate to 0.000222717387576157
[36m(_train_fn pid=778896)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=778896)[0m saving checkpoint...
[36m(_train_fn pid=778896)[0m Epoch: 5 cost time: 2.054769515991211
[36m(_train_fn pid=778896)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5612112 Vali Loss: 1.5929645 Best vali loss: 1.5888728
[36m(_train_fn pid=778896)[0m 	iters: 100, epoch: 6 | loss: 0.5722915
[36m(_train_fn pid=778896)[0m 	speed: 0.0156s/iter; left time: 9.8834s
[36m(_train_fn pid=778896)[0m 	iters: 200, epoch: 6 | loss: 0.4893281
[36m(_train_fn pid=778896)[0m 	speed: 0.0090s/iter; left time: 4.7710s
[36m(_train_fn pid=778896)[0m Updating learning rate to 0.0001113586937880785
[36m(_train_fn pid=778896)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=778896)[0m saving checkpoint...
[36m(_train_fn pid=778896)[0m Epoch: 6 cost time: 2.226522445678711
[36m(_train_fn pid=778896)[0m Epoch: 6, Steps: 244 | Train Loss: 0.5553363 Vali Loss: 1.6160372 Best vali loss: 1.5888728
[36m(_train_fn pid=778896)[0m 	iters: 100, epoch: 7 | loss: 0.5586297
[36m(_train_fn pid=778896)[0m 	speed: 0.0160s/iter; left time: 6.2395s
[36m(_train_fn pid=778896)[0m 	iters: 200, epoch: 7 | loss: 0.6378090
[36m(_train_fn pid=778896)[0m 	speed: 0.0089s/iter; left time: 2.5827s

Trial trial-5f8779e9 completed after 7 iterations at 2024-08-24 08:10:41. Total running time: 49min 32s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5f8779e9 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          2.49179 â”‚
â”‚ time_total_s                             17.93466 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58887 â”‚
â”‚ train_loss                                0.55199 â”‚
â”‚ valid_loss                                1.60024 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=778896)[0m Updating learning rate to 5.567934689403925e-05
[36m(_train_fn pid=778896)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=778896)[0m saving checkpoint...
[36m(_train_fn pid=778896)[0m Epoch: 7 cost time: 2.229569911956787
[36m(_train_fn pid=778896)[0m Epoch: 7, Steps: 244 | Train Loss: 0.5519861 Vali Loss: 1.6002399 Best vali loss: 1.5888728
[36m(_train_fn pid=778896)[0m Early stopping

Trial trial-2d72a19b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2d72a19b config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.03549 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00769 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=779534)[0m configuration
[36m(_train_fn pid=779534)[0m {'batch_size': 32, 'd_model': 16, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'conv', 'dropout': 0.035490327585910086, 'e_layers': 3, 'learning_rate': 0.007693459699054254, 'd_ff': 48}
[36m(_train_fn pid=779534)[0m Use GPU: cuda:0
[36m(_train_fn pid=779534)[0m train 7825
[36m(_train_fn pid=779534)[0m val 2161
[36m(_train_fn pid=779534)[0m start_epoch 0
[36m(_train_fn pid=779534)[0m max_epoch 8

Trial status: 59 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:10:43. Total running time: 49min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=779534)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d72a19b_60_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=0_2024-08-24_08-10-41/checkpoint_000000)
2024-08-24 08:10:50,551	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=779534)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d72a19b_60_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=0_2024-08-24_08-10-41/checkpoint_000001)
2024-08-24 08:10:53,808	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=779534)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d72a19b_60_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=0_2024-08-24_08-10-41/checkpoint_000002)
2024-08-24 08:10:57,005	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=779534)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d72a19b_60_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=0_2024-08-24_08-10-41/checkpoint_000003)
[36m(_train_fn pid=779534)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d72a19b_60_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=0_2024-08-24_08-10-41/checkpoint_000004)
2024-08-24 08:11:00,004	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2d72a19b   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
54 more TERMINATED
[36m(_train_fn pid=779534)[0m 	iters: 100, epoch: 1 | loss: 0.7126926
[36m(_train_fn pid=779534)[0m 	speed: 0.0170s/iter; left time: 31.4324s
[36m(_train_fn pid=779534)[0m 	iters: 200, epoch: 1 | loss: 0.6803378
[36m(_train_fn pid=779534)[0m 	speed: 0.0117s/iter; left time: 20.5561s
[36m(_train_fn pid=779534)[0m Updating learning rate to 0.007693459699054254
[36m(_train_fn pid=779534)[0m saving checkpoint...
[36m(_train_fn pid=779534)[0m Validation loss decreased (inf --> 1.6463).  Saving model state dict ...
[36m(_train_fn pid=779534)[0m Epoch: 1 cost time: 3.123107433319092
[36m(_train_fn pid=779534)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7890168 Vali Loss: 1.6462915 Best vali loss: 1.6462915
[36m(_train_fn pid=779534)[0m 	iters: 100, epoch: 2 | loss: 0.6373334
[36m(_train_fn pid=779534)[0m 	speed: 0.0204s/iter; left time: 32.8795s
[36m(_train_fn pid=779534)[0m 	iters: 200, epoch: 2 | loss: 0.5691858
[36m(_train_fn pid=779534)[0m 	speed: 0.0117s/iter; left time: 17.6215s
[36m(_train_fn pid=779534)[0m Updating learning rate to 0.003846729849527127
[36m(_train_fn pid=779534)[0m saving checkpoint...
[36m(_train_fn pid=779534)[0m Validation loss decreased (1.6463 --> 1.6138).  Saving model state dict ...
[36m(_train_fn pid=779534)[0m Epoch: 2 cost time: 2.896597146987915
[36m(_train_fn pid=779534)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6011965 Vali Loss: 1.6138442 Best vali loss: 1.6138442
[36m(_train_fn pid=779534)[0m 	iters: 100, epoch: 3 | loss: 0.4997104
[36m(_train_fn pid=779534)[0m 	speed: 0.0207s/iter; left time: 28.2850s
[36m(_train_fn pid=779534)[0m 	iters: 200, epoch: 3 | loss: 0.5511993
[36m(_train_fn pid=779534)[0m 	speed: 0.0117s/iter; left time: 14.8266s
[36m(_train_fn pid=779534)[0m Updating learning rate to 0.0019233649247635636
[36m(_train_fn pid=779534)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=779534)[0m saving checkpoint...
[36m(_train_fn pid=779534)[0m Epoch: 3 cost time: 2.911684989929199
[36m(_train_fn pid=779534)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5495070 Vali Loss: 1.6572011 Best vali loss: 1.6138442
[36m(_train_fn pid=779534)[0m 	iters: 100, epoch: 4 | loss: 0.5004882
[36m(_train_fn pid=779534)[0m 	speed: 0.0207s/iter; left time: 23.1504s
[36m(_train_fn pid=779534)[0m 	iters: 200, epoch: 4 | loss: 0.4276521
[36m(_train_fn pid=779534)[0m 	speed: 0.0116s/iter; left time: 11.8683s
[36m(_train_fn pid=779534)[0m Updating learning rate to 0.0009616824623817818
[36m(_train_fn pid=779534)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=779534)[0m saving checkpoint...
[36m(_train_fn pid=779534)[0m Epoch: 4 cost time: 2.8777003288269043
[36m(_train_fn pid=779534)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5152275 Vali Loss: 1.6515010 Best vali loss: 1.6138442
[36m(_train_fn pid=779534)[0m 	iters: 100, epoch: 5 | loss: 0.4968750
[36m(_train_fn pid=779534)[0m 	speed: 0.0195s/iter; left time: 17.0975s
[36m(_train_fn pid=779534)[0m 	iters: 200, epoch: 5 | loss: 0.4482001
[36m(_train_fn pid=779534)[0m 	speed: 0.0108s/iter; left time: 8.3877s
[36m(_train_fn pid=779534)[0m Updating learning rate to 0.0004808412311908909
[36m(_train_fn pid=779534)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=779534)[0m saving checkpoint...

Trial trial-2d72a19b completed after 5 iterations at 2024-08-24 08:11:00. Total running time: 49min 51s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2d72a19b result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          2.99669 â”‚
â”‚ time_total_s                             16.51669 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.61384 â”‚
â”‚ train_loss                                0.48537 â”‚
â”‚ valid_loss                                1.70875 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=779534)[0m Epoch: 5 cost time: 2.6695396900177
[36m(_train_fn pid=779534)[0m Epoch: 5, Steps: 244 | Train Loss: 0.4853711 Vali Loss: 1.7087519 Best vali loss: 1.6138442
[36m(_train_fn pid=779534)[0m Early stopping

Trial trial-c0ddc678 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c0ddc678 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.12236 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00789 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=780027)[0m configuration
[36m(_train_fn pid=780027)[0m {'batch_size': 64, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.12236271663703867, 'e_layers': 3, 'learning_rate': 0.007889101066300197, 'd_ff': 1024}
[36m(_train_fn pid=780027)[0m Use GPU: cuda:0
[36m(_train_fn pid=780027)[0m train 7825
[36m(_train_fn pid=780027)[0m val 2161
[36m(_train_fn pid=780027)[0m start_epoch 0
[36m(_train_fn pid=780027)[0m max_epoch 8

Trial status: 60 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:11:14. Total running time: 50min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 08:11:41,300	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=780027)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ddc678_61_alpha_d_ff=2,batch_size=64,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-11-00/checkpoint_000000)
[36m(_train_fn pid=780027)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ddc678_61_alpha_d_ff=2,batch_size=64,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-11-00/checkpoint_000001)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c0ddc678   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
55 more TERMINATED
[36m(_train_fn pid=780027)[0m 	iters: 100, epoch: 1 | loss: 0.7496714
[36m(_train_fn pid=780027)[0m 	speed: 0.2848s/iter; left time: 249.8030s
[36m(_train_fn pid=780027)[0m Updating learning rate to 0.007889101066300197
[36m(_train_fn pid=780027)[0m saving checkpoint...
[36m(_train_fn pid=780027)[0m Validation loss decreased (inf --> 1.9261).  Saving model state dict ...
[36m(_train_fn pid=780027)[0m Epoch: 1 cost time: 34.44873237609863
[36m(_train_fn pid=780027)[0m Epoch: 1, Steps: 122 | Train Loss: 0.9035683 Vali Loss: 1.9260918 Best vali loss: 1.9260918
Trial status: 60 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:11:44. Total running time: 50min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c0ddc678   RUNNING           1            38.8112       0.903568        1.92609             1.92609 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
55 more TERMINATED
[36m(_train_fn pid=780027)[0m 	iters: 100, epoch: 2 | loss: 2862706851840.0000000
[36m(_train_fn pid=780027)[0m 	speed: 0.3822s/iter; left time: 288.5781s
Trial status: 60 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:12:14. Total running time: 51min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c0ddc678   RUNNING           1            38.8112       0.903568        1.92609             1.92609 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
55 more TERMINATED
[36m(_train_fn pid=780027)[0m Updating learning rate to 0.0039445505331500985
[36m(_train_fn pid=780027)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=780027)[0m saving checkpoint...
[36m(_train_fn pid=780027)[0m Epoch: 2 cost time: 34.25347685813904
[36m(_train_fn pid=780027)[0m Epoch: 2, Steps: 122 | Train Loss: 45630763390076.7031250 Vali Loss: 24794929355062.3046875 Best vali loss: 1.9260918
Trial status: 60 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:12:44. Total running time: 51min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=780027)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c0ddc678_61_alpha_d_ff=2,batch_size=64,d_model=512,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_08-11-00/checkpoint_000002)
2024-08-24 08:13:01,716	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=780674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28d3b87f_62_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1042,e_layers_2024-08-24_08-12-57/checkpoint_000000)
2024-08-24 08:13:03,185	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=780674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28d3b87f_62_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1042,e_layers_2024-08-24_08-12-57/checkpoint_000001)
2024-08-24 08:13:04,658	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=780674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28d3b87f_62_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1042,e_layers_2024-08-24_08-12-57/checkpoint_000002)
2024-08-24 08:13:06,131	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=780674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28d3b87f_62_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1042,e_layers_2024-08-24_08-12-57/checkpoint_000003)
2024-08-24 08:13:07,585	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=780674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28d3b87f_62_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1042,e_layers_2024-08-24_08-12-57/checkpoint_000004)
2024-08-24 08:13:09,050	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=780674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-28d3b87f_62_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1042,e_layers_2024-08-24_08-12-57/checkpoint_000005)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c0ddc678   RUNNING           2            76.9714    4.56308e+13    2.47949e+13             1.92609 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009    0.593321       1.59962                 1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127    0.510234       1.62942                 1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511    0.570752       1.58113                 1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635     0.600472       1.56828                 1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884    0.512451       1.683                   1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
55 more TERMINATED
[36m(_train_fn pid=780027)[0m 	iters: 100, epoch: 3 | loss: 22362650624.0000000
[36m(_train_fn pid=780027)[0m 	speed: 0.3821s/iter; left time: 241.8830s

Trial trial-c0ddc678 completed after 3 iterations at 2024-08-24 08:12:57. Total running time: 51min 48s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c0ddc678 result                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name              checkpoint_000002 â”‚
â”‚ time_this_iter_s                          38.22266 â”‚
â”‚ time_total_s                             115.19409 â”‚
â”‚ training_iteration                               3 â”‚
â”‚ best_valid_loss                            1.92609 â”‚
â”‚ train_loss                      464108913235.93445 â”‚
â”‚ valid_loss                       28794739898.18182 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=780027)[0m Updating learning rate to 0.0019722752665750493
[36m(_train_fn pid=780027)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=780027)[0m saving checkpoint...

Trial trial-28d3b87f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-28d3b87f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.10423 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.01173 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=780674)[0m configuration
[36m(_train_fn pid=780674)[0m {'batch_size': 128, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.10423444580855055, 'e_layers': 4, 'learning_rate': 0.011730062695710813, 'd_ff': 16}
[36m(_train_fn pid=780674)[0m Use GPU: cuda:0
[36m(_train_fn pid=780674)[0m train 7825
[36m(_train_fn pid=780674)[0m val 2161
[36m(_train_fn pid=780674)[0m start_epoch 0
[36m(_train_fn pid=780674)[0m max_epoch 8
[36m(_train_fn pid=780674)[0m Validation loss decreased (inf --> 1.9577).  Saving model state dict ...
[36m(_train_fn pid=780674)[0m Epoch: 1 cost time: 1.6300780773162842
[36m(_train_fn pid=780674)[0m Epoch: 1, Steps: 61 | Train Loss: 1.0345442 Vali Loss: 1.9577046 Best vali loss: 1.9577046
[36m(_train_fn pid=780674)[0m Validation loss decreased (1.9577 --> 1.6272).  Saving model state dict ...
[36m(_train_fn pid=780674)[0m Epoch: 2 cost time: 1.2231035232543945
[36m(_train_fn pid=780674)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6640907 Vali Loss: 1.6271796 Best vali loss: 1.6271796
[36m(_train_fn pid=780674)[0m Updating learning rate to 0.0058650313478554065[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=780674)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=780674)[0m Validation loss decreased (1.6272 --> 1.6037).  Saving model state dict ...
[36m(_train_fn pid=780674)[0m Epoch: 3 cost time: 1.2353012561798096
[36m(_train_fn pid=780674)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6028589 Vali Loss: 1.6036736 Best vali loss: 1.6036736
[36m(_train_fn pid=780674)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=780674)[0m Epoch: 4 cost time: 1.2395882606506348
[36m(_train_fn pid=780674)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5888697 Vali Loss: 1.6109456 Best vali loss: 1.6036736
[36m(_train_fn pid=780674)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=780674)[0m Epoch: 5 cost time: 1.229097604751587
[36m(_train_fn pid=780674)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5790953 Vali Loss: 1.6325537 Best vali loss: 1.6036736

Trial trial-28d3b87f completed after 6 iterations at 2024-08-24 08:13:09. Total running time: 52min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-28d3b87f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          1.46165 â”‚
â”‚ time_total_s                              9.59222 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.60367 â”‚
â”‚ train_loss                                0.57209 â”‚
â”‚ valid_loss                                1.60717 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=780674)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=780674)[0m Epoch: 6 cost time: 1.2294204235076904
[36m(_train_fn pid=780674)[0m Epoch: 6, Steps: 61 | Train Loss: 0.5720908 Vali Loss: 1.6071655 Best vali loss: 1.6036736
[36m(_train_fn pid=780674)[0m Early stopping
[36m(_train_fn pid=780674)[0m Updating learning rate to 0.0003665644592409629[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=780674)[0m saving checkpoint...[32m [repeated 4x across cluster][0m

Trial trial-59a195b8 started with configuration:
[36m(_train_fn pid=781217)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59a195b8_63_alpha_d_ff=4,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0921,e_layers=_2024-08-24_08-13-09/checkpoint_000000)
2024-08-24 08:13:19,729	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=781217)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59a195b8_63_alpha_d_ff=4,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0921,e_layers=_2024-08-24_08-13-09/checkpoint_000001)
2024-08-24 08:13:23,594	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=781217)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59a195b8_63_alpha_d_ff=4,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0921,e_layers=_2024-08-24_08-13-09/checkpoint_000002)
2024-08-24 08:13:27,123	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=781217)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59a195b8_63_alpha_d_ff=4,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0921,e_layers=_2024-08-24_08-13-09/checkpoint_000003)
2024-08-24 08:13:30,688	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=781217)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59a195b8_63_alpha_d_ff=4,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0921,e_layers=_2024-08-24_08-13-09/checkpoint_000004)
2024-08-24 08:13:34,508	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=781217)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59a195b8_63_alpha_d_ff=4,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0921,e_layers=_2024-08-24_08-13-09/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-59a195b8 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09211 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00358 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=781217)[0m configuration
[36m(_train_fn pid=781217)[0m {'batch_size': 32, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.09210541320015424, 'e_layers': 4, 'learning_rate': 0.003581424905629876, 'd_ff': 64}
[36m(_train_fn pid=781217)[0m Use GPU: cuda:0
[36m(_train_fn pid=781217)[0m train 7825
[36m(_train_fn pid=781217)[0m val 2161
[36m(_train_fn pid=781217)[0m start_epoch 0
[36m(_train_fn pid=781217)[0m max_epoch 8
[36m(_train_fn pid=781217)[0m 	iters: 100, epoch: 1 | loss: 0.8712468
[36m(_train_fn pid=781217)[0m 	speed: 0.0209s/iter; left time: 38.7924s

Trial status: 62 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:13:14. Total running time: 52min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-59a195b8   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
57 more TERMINATED
[36m(_train_fn pid=781217)[0m 	iters: 200, epoch: 1 | loss: 0.8199529
[36m(_train_fn pid=781217)[0m 	speed: 0.0137s/iter; left time: 23.9986s
[36m(_train_fn pid=781217)[0m Updating learning rate to 0.003581424905629876
[36m(_train_fn pid=781217)[0m saving checkpoint...
[36m(_train_fn pid=781217)[0m Validation loss decreased (inf --> 1.8116).  Saving model state dict ...
[36m(_train_fn pid=781217)[0m Epoch: 1 cost time: 3.803800344467163
[36m(_train_fn pid=781217)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8442285 Vali Loss: 1.8115895 Best vali loss: 1.8115895
[36m(_train_fn pid=781217)[0m 	iters: 100, epoch: 2 | loss: 0.6338123
[36m(_train_fn pid=781217)[0m 	speed: 0.0237s/iter; left time: 38.0586s
[36m(_train_fn pid=781217)[0m 	iters: 200, epoch: 2 | loss: 0.6540640
[36m(_train_fn pid=781217)[0m 	speed: 0.0126s/iter; left time: 19.0854s
[36m(_train_fn pid=781217)[0m Updating learning rate to 0.001790712452814938
[36m(_train_fn pid=781217)[0m saving checkpoint...
[36m(_train_fn pid=781217)[0m Validation loss decreased (1.8116 --> 1.6079).  Saving model state dict ...
[36m(_train_fn pid=781217)[0m Epoch: 2 cost time: 3.126584768295288
[36m(_train_fn pid=781217)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6174257 Vali Loss: 1.6079234 Best vali loss: 1.6079234
[36m(_train_fn pid=781217)[0m 	iters: 100, epoch: 3 | loss: 0.5168231
[36m(_train_fn pid=781217)[0m 	speed: 0.0243s/iter; left time: 33.1259s
[36m(_train_fn pid=781217)[0m 	iters: 200, epoch: 3 | loss: 0.4540263
[36m(_train_fn pid=781217)[0m 	speed: 0.0137s/iter; left time: 17.3888s
[36m(_train_fn pid=781217)[0m Updating learning rate to 0.000895356226407469
[36m(_train_fn pid=781217)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=781217)[0m saving checkpoint...
[36m(_train_fn pid=781217)[0m Epoch: 3 cost time: 3.407442092895508
[36m(_train_fn pid=781217)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5712067 Vali Loss: 1.6115681 Best vali loss: 1.6079234
[36m(_train_fn pid=781217)[0m 	iters: 100, epoch: 4 | loss: 0.6429841
[36m(_train_fn pid=781217)[0m 	speed: 0.0235s/iter; left time: 26.3447s
[36m(_train_fn pid=781217)[0m 	iters: 200, epoch: 4 | loss: 0.5742823
[36m(_train_fn pid=781217)[0m 	speed: 0.0124s/iter; left time: 12.6292s
[36m(_train_fn pid=781217)[0m Updating learning rate to 0.0004476781132037345
[36m(_train_fn pid=781217)[0m saving checkpoint...
[36m(_train_fn pid=781217)[0m Validation loss decreased (1.6079 --> 1.5967).  Saving model state dict ...
[36m(_train_fn pid=781217)[0m Epoch: 4 cost time: 3.0782575607299805
[36m(_train_fn pid=781217)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5509429 Vali Loss: 1.5966683 Best vali loss: 1.5966683
[36m(_train_fn pid=781217)[0m 	iters: 100, epoch: 5 | loss: 0.5510150
[36m(_train_fn pid=781217)[0m 	speed: 0.0231s/iter; left time: 20.2808s
[36m(_train_fn pid=781217)[0m 	iters: 200, epoch: 5 | loss: 0.4850515
[36m(_train_fn pid=781217)[0m 	speed: 0.0126s/iter; left time: 9.8199s
[36m(_train_fn pid=781217)[0m Updating learning rate to 0.00022383905660186725
[36m(_train_fn pid=781217)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=781217)[0m saving checkpoint...
[36m(_train_fn pid=781217)[0m Epoch: 5 cost time: 3.1277055740356445
[36m(_train_fn pid=781217)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5382148 Vali Loss: 1.6110376 Best vali loss: 1.5966683
[36m(_train_fn pid=781217)[0m 	iters: 100, epoch: 6 | loss: 0.5053039
[36m(_train_fn pid=781217)[0m 	speed: 0.0241s/iter; left time: 15.2438s
[36m(_train_fn pid=781217)[0m 	iters: 200, epoch: 6 | loss: 0.5532703
[36m(_train_fn pid=781217)[0m 	speed: 0.0136s/iter; left time: 7.2236s
[36m(_train_fn pid=781217)[0m Updating learning rate to 0.00011191952830093362
[36m(_train_fn pid=781217)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=781217)[0m saving checkpoint...
[36m(_train_fn pid=781217)[0m Epoch: 6 cost time: 3.362666368484497
[36m(_train_fn pid=781217)[0m Epoch: 6, Steps: 244 | Train Loss: 0.5315850 Vali Loss: 1.6054212 Best vali loss: 1.5966683
[36m(_train_fn pid=781217)[0m 	iters: 100, epoch: 7 | loss: 0.4841960
[36m(_train_fn pid=781217)[0m 	speed: 0.0234s/iter; left time: 9.0985s
[36m(_train_fn pid=781217)[0m 	iters: 200, epoch: 7 | loss: 0.5087335
[36m(_train_fn pid=781217)[0m 	speed: 0.0137s/iter; left time: 3.9516s
[36m(_train_fn pid=781217)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59a195b8_63_alpha_d_ff=4,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0921,e_layers=_2024-08-24_08-13-09/checkpoint_000006)
2024-08-24 08:13:38,210	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:14:00,435	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=781882)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d77ed42_64_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1286,e_layers_2024-08-24_08-13-38/checkpoint_000000)
[36m(_train_fn pid=781217)[0m Updating learning rate to 5.595976415046681e-05
[36m(_train_fn pid=781217)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=781217)[0m saving checkpoint...
[36m(_train_fn pid=781217)[0m Epoch: 7 cost time: 3.258155107498169
[36m(_train_fn pid=781217)[0m Epoch: 7, Steps: 244 | Train Loss: 0.5275349 Vali Loss: 1.6184772 Best vali loss: 1.5966683
[36m(_train_fn pid=781217)[0m Early stopping

Trial trial-59a195b8 completed after 7 iterations at 2024-08-24 08:13:38. Total running time: 52min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-59a195b8 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          3.69975 â”‚
â”‚ time_total_s                             26.71123 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.59667 â”‚
â”‚ train_loss                                0.52753 â”‚
â”‚ valid_loss                                1.61848 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-2d77ed42 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2d77ed42 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.12864 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0015 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=781882)[0m configuration
[36m(_train_fn pid=781882)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1286399358005137, 'e_layers': 1, 'learning_rate': 0.0015003981506438568, 'd_ff': 1536}
[36m(_train_fn pid=781882)[0m Use GPU: cuda:0
[36m(_train_fn pid=781882)[0m train 7825
[36m(_train_fn pid=781882)[0m val 2161
[36m(_train_fn pid=781882)[0m start_epoch 0
[36m(_train_fn pid=781882)[0m max_epoch 8

Trial status: 63 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:13:44. Total running time: 52min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2d77ed42   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
58 more TERMINATED
[36m(_train_fn pid=781882)[0m 	iters: 100, epoch: 1 | loss: 0.8200025
[36m(_train_fn pid=781882)[0m 	speed: 0.0761s/iter; left time: 141.0052s
[36m(_train_fn pid=781882)[0m 	iters: 200, epoch: 1 | loss: 0.6438374
[36m(_train_fn pid=781882)[0m 	speed: 0.0698s/iter; left time: 122.2747s
[36m(_train_fn pid=781882)[0m Updating learning rate to 0.0015003981506438568
[36m(_train_fn pid=781882)[0m saving checkpoint...
[36m(_train_fn pid=781882)[0m Validation loss decreased (inf --> 1.8480).  Saving model state dict ...
[36m(_train_fn pid=781882)[0m Epoch: 1 cost time: 17.397648572921753
[36m(_train_fn pid=781882)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7779763 Vali Loss: 1.8479947 Best vali loss: 1.8479947
[36m(_train_fn pid=781882)[0m 	iters: 100, epoch: 2 | loss: 0.6569215
[36m(_train_fn pid=781882)[0m 	speed: 0.1223s/iter; left time: 196.7683s
Trial status: 63 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:14:14. Total running time: 53min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=781882)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d77ed42_64_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1286,e_layers_2024-08-24_08-13-38/checkpoint_000001)
[36m(_train_fn pid=781882)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d77ed42_64_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1286,e_layers_2024-08-24_08-13-38/checkpoint_000002)
[36m(_train_fn pid=781882)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d77ed42_64_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1286,e_layers_2024-08-24_08-13-38/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2d77ed42   RUNNING           1            19.9589       0.777976        1.84799             1.84799 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
58 more TERMINATED
[36m(_train_fn pid=781882)[0m 	iters: 200, epoch: 2 | loss: 0.6986607
[36m(_train_fn pid=781882)[0m 	speed: 0.0700s/iter; left time: 105.6131s
[36m(_train_fn pid=781882)[0m Updating learning rate to 0.0007501990753219284
[36m(_train_fn pid=781882)[0m saving checkpoint...
[36m(_train_fn pid=781882)[0m Validation loss decreased (1.8480 --> 1.5766).  Saving model state dict ...
[36m(_train_fn pid=781882)[0m Epoch: 2 cost time: 17.08614206314087
[36m(_train_fn pid=781882)[0m Epoch: 2, Steps: 244 | Train Loss: 0.8054509 Vali Loss: 1.5766206 Best vali loss: 1.5766206
[36m(_train_fn pid=781882)[0m 	iters: 100, epoch: 3 | loss: 0.6690645
[36m(_train_fn pid=781882)[0m 	speed: 0.1225s/iter; left time: 167.1606s
[36m(_train_fn pid=781882)[0m 	iters: 200, epoch: 3 | loss: 0.6314748
[36m(_train_fn pid=781882)[0m 	speed: 0.0700s/iter; left time: 88.5910s
[36m(_train_fn pid=781882)[0m Updating learning rate to 0.0003750995376609642
[36m(_train_fn pid=781882)[0m saving checkpoint...
[36m(_train_fn pid=781882)[0m Validation loss decreased (1.5766 --> 1.5702).  Saving model state dict ...
[36m(_train_fn pid=781882)[0m Epoch: 3 cost time: 17.099507093429565
[36m(_train_fn pid=781882)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6168663 Vali Loss: 1.5702237 Best vali loss: 1.5702237
Trial status: 63 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:14:44. Total running time: 53min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2d77ed42   RUNNING           3            58.4561       0.616866        1.57022             1.57022 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
58 more TERMINATED
[36m(_train_fn pid=781882)[0m 	iters: 100, epoch: 4 | loss: 0.6328080
[36m(_train_fn pid=781882)[0m 	speed: 0.1227s/iter; left time: 137.5711s
[36m(_train_fn pid=781882)[0m 	iters: 200, epoch: 4 | loss: 0.6391479
[36m(_train_fn pid=781882)[0m 	speed: 0.0702s/iter; left time: 71.6528s
[36m(_train_fn pid=781882)[0m Updating learning rate to 0.0001875497688304821
[36m(_train_fn pid=781882)[0m saving checkpoint...
[36m(_train_fn pid=781882)[0m Validation loss decreased (1.5702 --> 1.5673).  Saving model state dict ...
[36m(_train_fn pid=781882)[0m Epoch: 4 cost time: 17.12689757347107
[36m(_train_fn pid=781882)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6129972 Vali Loss: 1.5673417 Best vali loss: 1.5673417
[36m(_train_fn pid=781882)[0m 	iters: 100, epoch: 5 | loss: 0.6045520
[36m(_train_fn pid=781882)[0m 	speed: 0.1229s/iter; left time: 107.7803s
[36m(_train_fn pid=781882)[0m 	iters: 200, epoch: 5 | loss: 0.5458937
[36m(_train_fn pid=781882)[0m 	speed: 0.0702s/iter; left time: 54.5806s
Trial status: 63 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:15:14. Total running time: 54min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=781882)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d77ed42_64_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1286,e_layers_2024-08-24_08-13-38/checkpoint_000004)
[36m(_train_fn pid=781882)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2d77ed42_64_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1286,e_layers_2024-08-24_08-13-38/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2d77ed42   RUNNING           4            77.7537       0.612997        1.56734             1.56734 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
58 more TERMINATED
[36m(_train_fn pid=781882)[0m Updating learning rate to 9.377488441524105e-05
[36m(_train_fn pid=781882)[0m saving checkpoint...
[36m(_train_fn pid=781882)[0m Validation loss decreased (1.5673 --> 1.5653).  Saving model state dict ...
[36m(_train_fn pid=781882)[0m Epoch: 5 cost time: 17.138048887252808
[36m(_train_fn pid=781882)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6113527 Vali Loss: 1.5652766 Best vali loss: 1.5652766
[36m(_train_fn pid=781882)[0m 	iters: 100, epoch: 6 | loss: 0.5845758
[36m(_train_fn pid=781882)[0m 	speed: 0.1228s/iter; left time: 77.7350s
[36m(_train_fn pid=781882)[0m 	iters: 200, epoch: 6 | loss: 0.5964696
[36m(_train_fn pid=781882)[0m 	speed: 0.0702s/iter; left time: 37.4393s
[36m(_train_fn pid=781882)[0m Updating learning rate to 4.6887442207620524e-05
[36m(_train_fn pid=781882)[0m saving checkpoint...
[36m(_train_fn pid=781882)[0m Validation loss decreased (1.5653 --> 1.5651).  Saving model state dict ...

Trial trial-2d77ed42 completed after 6 iterations at 2024-08-24 08:15:36. Total running time: 54min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2d77ed42 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.31381 â”‚
â”‚ time_total_s                            116.36965 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56512 â”‚
â”‚ train_loss                                0.61065 â”‚
â”‚ valid_loss                                1.56512 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-51af8c6c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-51af8c6c config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10193 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00875 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=782740)[0m configuration
[36m(_train_fn pid=782740)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.10193002653481252, 'e_layers': 4, 'learning_rate': 0.008752640842527344, 'd_ff': 256}
[36m(_train_fn pid=782740)[0m Use GPU: cuda:0
[36m(_train_fn pid=782740)[0m train 7825
[36m(_train_fn pid=782740)[0m val 2161
[36m(_train_fn pid=782740)[0m start_epoch 0
[36m(_train_fn pid=782740)[0m max_epoch 8
[36m(_train_fn pid=782740)[0m 	iters: 100, epoch: 1 | loss: 0.6499199
[36m(_train_fn pid=782740)[0m 	speed: 0.0293s/iter; left time: 54.2136s
[36m(_train_fn pid=782740)[0m 	iters: 200, epoch: 1 | loss: 0.5835775
[36m(_train_fn pid=782740)[0m 	speed: 0.0221s/iter; left time: 38.7944s

Trial status: 64 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:15:44. Total running time: 54min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-51af8c6c   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
59 more TERMINATED
[36m(_train_fn pid=782740)[0m Updating learning rate to 0.008752640842527344
[36m(_train_fn pid=782740)[0m saving checkpoint...
[36m(_train_fn pid=782740)[0m Validation loss decreased (inf --> 1.5814).  Saving model state dict ...
[36m(_train_fn pid=782740)[0m Epoch: 1 cost time: 5.8573033809661865
[36m(_train_fn pid=782740)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51af8c6c_65_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1019,e_layers=_2024-08-24_08-15-36/checkpoint_000000)
[36m(_train_fn pid=782740)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51af8c6c_65_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1019,e_layers=_2024-08-24_08-15-36/checkpoint_000001)
[36m(_train_fn pid=782740)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51af8c6c_65_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1019,e_layers=_2024-08-24_08-15-36/checkpoint_000002)
[36m(_train_fn pid=782740)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51af8c6c_65_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1019,e_layers=_2024-08-24_08-15-36/checkpoint_000003)
[36m(_train_fn pid=782740)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51af8c6c_65_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1019,e_layers=_2024-08-24_08-15-36/checkpoint_000004)
[36m(_train_fn pid=782740)[0m Epoch: 1, Steps: 244 | Train Loss: 0.6890919 Vali Loss: 1.5813623 Best vali loss: 1.5813623
[36m(_train_fn pid=782740)[0m 	iters: 100, epoch: 2 | loss: 0.8023518
[36m(_train_fn pid=782740)[0m 	speed: 0.0406s/iter; left time: 65.3042s
[36m(_train_fn pid=782740)[0m 	iters: 200, epoch: 2 | loss: 0.5834840
[36m(_train_fn pid=782740)[0m 	speed: 0.0221s/iter; left time: 33.3086s
[36m(_train_fn pid=782740)[0m Updating learning rate to 0.004376320421263672
[36m(_train_fn pid=782740)[0m saving checkpoint...
[36m(_train_fn pid=782740)[0m Validation loss decreased (1.5814 --> 1.5645).  Saving model state dict ...
[36m(_train_fn pid=782740)[0m Epoch: 2 cost time: 5.429432153701782
[36m(_train_fn pid=782740)[0m Epoch: 2, Steps: 244 | Train Loss: 0.9452485 Vali Loss: 1.5644891 Best vali loss: 1.5644891
[36m(_train_fn pid=782740)[0m 	iters: 100, epoch: 3 | loss: 0.5525841
[36m(_train_fn pid=782740)[0m 	speed: 0.0405s/iter; left time: 55.3282s
[36m(_train_fn pid=782740)[0m 	iters: 200, epoch: 3 | loss: 0.6056518
[36m(_train_fn pid=782740)[0m 	speed: 0.0221s/iter; left time: 27.9287s
[36m(_train_fn pid=782740)[0m Updating learning rate to 0.002188160210631836
[36m(_train_fn pid=782740)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=782740)[0m saving checkpoint...
[36m(_train_fn pid=782740)[0m Epoch: 3 cost time: 5.426830768585205
[36m(_train_fn pid=782740)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6069145 Vali Loss: 1.5679462 Best vali loss: 1.5644891
[36m(_train_fn pid=782740)[0m 	iters: 100, epoch: 4 | loss: 0.5541585
[36m(_train_fn pid=782740)[0m 	speed: 0.0405s/iter; left time: 45.3747s
[36m(_train_fn pid=782740)[0m 	iters: 200, epoch: 4 | loss: 0.6604850
[36m(_train_fn pid=782740)[0m 	speed: 0.0220s/iter; left time: 22.4877s
[36m(_train_fn pid=782740)[0m Updating learning rate to 0.001094080105315918
[36m(_train_fn pid=782740)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=782740)[0m saving checkpoint...
[36m(_train_fn pid=782740)[0m Epoch: 4 cost time: 5.41612696647644
[36m(_train_fn pid=782740)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5982917 Vali Loss: 1.5932966 Best vali loss: 1.5644891
[36m(_train_fn pid=782740)[0m 	iters: 100, epoch: 5 | loss: 0.6318908
[36m(_train_fn pid=782740)[0m 	speed: 0.0405s/iter; left time: 35.5282s
[36m(_train_fn pid=782740)[0m 	iters: 200, epoch: 5 | loss: 0.6090772
[36m(_train_fn pid=782740)[0m 	speed: 0.0222s/iter; left time: 17.2122s

Trial trial-51af8c6c completed after 5 iterations at 2024-08-24 08:16:10. Total running time: 55min 1s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-51af8c6c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          6.26865 â”‚
â”‚ time_total_s                             32.11461 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56449 â”‚
â”‚ train_loss                                0.58512 â”‚
â”‚ valid_loss                                1.61114 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=782740)[0m Updating learning rate to 0.000547040052657959
[36m(_train_fn pid=782740)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=782740)[0m saving checkpoint...
[36m(_train_fn pid=782740)[0m Epoch: 5 cost time: 5.443864822387695
[36m(_train_fn pid=782740)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5851188 Vali Loss: 1.6111450 Best vali loss: 1.5644891
[36m(_train_fn pid=782740)[0m Early stopping

Trial trial-24c877e8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-24c877e8 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09659 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00103 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=783275)[0m configuration
[36m(_train_fn pid=783275)[0m {'batch_size': 16, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'avg', 'dropout': 0.09658967127602267, 'e_layers': 4, 'learning_rate': 0.0010272149694260965, 'd_ff': 32}
[36m(_train_fn pid=783275)[0m Use GPU: cuda:0
[36m(_train_fn pid=783275)[0m train 7825
[36m(_train_fn pid=783275)[0m val 2161
[36m(_train_fn pid=783275)[0m start_epoch 0
[36m(_train_fn pid=783275)[0m max_epoch 8
[36m(_train_fn pid=783275)[0m 	iters: 100, epoch: 1 | loss: 0.9849853
[36m(_train_fn pid=783275)[0m 	speed: 0.0182s/iter; left time: 69.3068s

Trial status: 65 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:16:14. Total running time: 55min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-24c877e8   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
60 more TERMINATED
[36m(_train_fn pid=783275)[0m 	iters: 200, epoch: 1 | loss: 0.9576879
[36m(_train_fn pid=783275)[0m 	speed: 0.0130s/iter; left time: 48.3791s
[36m(_train_fn pid=783275)[0m 	iters: 300, epoch: 1 | loss: 0.9364727
[36m(_train_fn pid=783275)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-24c877e8_66_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0.0_2024-08-24_08-16-10/checkpoint_000000)
[36m(_train_fn pid=783275)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-24c877e8_66_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0.0_2024-08-24_08-16-10/checkpoint_000001)
[36m(_train_fn pid=783275)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-24c877e8_66_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0.0_2024-08-24_08-16-10/checkpoint_000002)
[36m(_train_fn pid=783275)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-24c877e8_66_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0.0_2024-08-24_08-16-10/checkpoint_000003)
[36m(_train_fn pid=783275)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-24c877e8_66_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0.0_2024-08-24_08-16-10/checkpoint_000004)
[36m(_train_fn pid=783275)[0m 	speed: 0.0130s/iter; left time: 46.9881s
[36m(_train_fn pid=783275)[0m 	iters: 400, epoch: 1 | loss: 0.7683087
[36m(_train_fn pid=783275)[0m 	speed: 0.0132s/iter; left time: 46.3069s
[36m(_train_fn pid=783275)[0m Updating learning rate to 0.0010272149694260965
[36m(_train_fn pid=783275)[0m saving checkpoint...
[36m(_train_fn pid=783275)[0m Validation loss decreased (inf --> 1.8976).  Saving model state dict ...
[36m(_train_fn pid=783275)[0m Epoch: 1 cost time: 6.650363445281982
[36m(_train_fn pid=783275)[0m Epoch: 1, Steps: 489 | Train Loss: 0.9959073 Vali Loss: 1.8976307 Best vali loss: 1.8976307
[36m(_train_fn pid=783275)[0m 	iters: 100, epoch: 2 | loss: 0.7509829
[36m(_train_fn pid=783275)[0m 	speed: 0.0317s/iter; left time: 105.3321s
[36m(_train_fn pid=783275)[0m 	iters: 200, epoch: 2 | loss: 0.6239693
[36m(_train_fn pid=783275)[0m 	speed: 0.0131s/iter; left time: 42.2424s
[36m(_train_fn pid=783275)[0m 	iters: 300, epoch: 2 | loss: 0.5796570
[36m(_train_fn pid=783275)[0m 	speed: 0.0131s/iter; left time: 41.0438s
[36m(_train_fn pid=783275)[0m 	iters: 400, epoch: 2 | loss: 0.7534280
[36m(_train_fn pid=783275)[0m 	speed: 0.0131s/iter; left time: 39.7324s
[36m(_train_fn pid=783275)[0m Updating learning rate to 0.0005136074847130483
[36m(_train_fn pid=783275)[0m saving checkpoint...
[36m(_train_fn pid=783275)[0m Validation loss decreased (1.8976 --> 1.5844).  Saving model state dict ...
[36m(_train_fn pid=783275)[0m Epoch: 2 cost time: 6.472758054733276
[36m(_train_fn pid=783275)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6309797 Vali Loss: 1.5843623 Best vali loss: 1.5843623
[36m(_train_fn pid=783275)[0m 	iters: 100, epoch: 3 | loss: 0.6520180
[36m(_train_fn pid=783275)[0m 	speed: 0.0314s/iter; left time: 89.1578s
[36m(_train_fn pid=783275)[0m 	iters: 200, epoch: 3 | loss: 0.6561885
[36m(_train_fn pid=783275)[0m 	speed: 0.0123s/iter; left time: 33.6761s
[36m(_train_fn pid=783275)[0m 	iters: 300, epoch: 3 | loss: 0.4806761
[36m(_train_fn pid=783275)[0m 	speed: 0.0118s/iter; left time: 31.0310s
[36m(_train_fn pid=783275)[0m 	iters: 400, epoch: 3 | loss: 0.5935359
[36m(_train_fn pid=783275)[0m 	speed: 0.0118s/iter; left time: 29.7957s
[36m(_train_fn pid=783275)[0m Updating learning rate to 0.0002568037423565241
[36m(_train_fn pid=783275)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=783275)[0m saving checkpoint...
[36m(_train_fn pid=783275)[0m Epoch: 3 cost time: 5.970390319824219
[36m(_train_fn pid=783275)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5903871 Vali Loss: 1.5861486 Best vali loss: 1.5843623
[36m(_train_fn pid=783275)[0m 	iters: 100, epoch: 4 | loss: 0.6803854
[36m(_train_fn pid=783275)[0m 	speed: 0.0301s/iter; left time: 70.7171s
[36m(_train_fn pid=783275)[0m 	iters: 200, epoch: 4 | loss: 0.5844841
[36m(_train_fn pid=783275)[0m 	speed: 0.0133s/iter; left time: 29.8192s
[36m(_train_fn pid=783275)[0m 	iters: 300, epoch: 4 | loss: 0.5240956
[36m(_train_fn pid=783275)[0m 	speed: 0.0133s/iter; left time: 28.5018s
[36m(_train_fn pid=783275)[0m 	iters: 400, epoch: 4 | loss: 0.4569697
[36m(_train_fn pid=783275)[0m 	speed: 0.0132s/iter; left time: 26.9707s
[36m(_train_fn pid=783275)[0m Updating learning rate to 0.00012840187117826206
[36m(_train_fn pid=783275)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=783275)[0m saving checkpoint...
[36m(_train_fn pid=783275)[0m Epoch: 4 cost time: 6.531100273132324
[36m(_train_fn pid=783275)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5777265 Vali Loss: 1.6265585 Best vali loss: 1.5843623
[36m(_train_fn pid=783275)[0m 	iters: 100, epoch: 5 | loss: 0.5239041
[36m(_train_fn pid=783275)[0m 	speed: 0.0302s/iter; left time: 56.0735s
[36m(_train_fn pid=783275)[0m 	iters: 200, epoch: 5 | loss: 0.5576814
[36m(_train_fn pid=783275)[0m 	speed: 0.0118s/iter; left time: 20.7349s
Trial status: 65 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:16:44. Total running time: 55min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-24c877e8   RUNNING           4            28.4902       0.577726        1.62656             1.58436 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
60 more TERMINATED
[36m(_train_fn pid=783275)[0m 	iters: 300, epoch: 5 | loss: 0.6380786
[36m(_train_fn pid=783275)[0m 	speed: 0.0117s/iter; left time: 19.4177s
[36m(_train_fn pid=783275)[0m 	iters: 400, epoch: 5 | loss: 0.5904681
[36m(_train_fn pid=783275)[0m 	speed: 0.0117s/iter; left time: 18.2897s
[36m(_train_fn pid=783275)[0m Updating learning rate to 6.420093558913103e-05
[36m(_train_fn pid=783275)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=783275)[0m saving checkpoint...
[36m(_train_fn pid=783275)[0m Epoch: 5 cost time: 5.804909706115723
[36m(_train_fn pid=783275)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5707350 Vali Loss: 1.6178523 Best vali loss: 1.5843623
[36m(_train_fn pid=783275)[0m Early stopping

Trial trial-24c877e8 completed after 5 iterations at 2024-08-24 08:16:47. Total running time: 55min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-24c877e8 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          6.40156 â”‚
â”‚ time_total_s                             34.89176 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58436 â”‚
â”‚ train_loss                                0.57074 â”‚
â”‚ valid_loss                                1.61785 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-b1cf6dc9 started with configuration:
[36m(_train_fn pid=783822)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b1cf6dc9_67_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1383,e_layer_2024-08-24_08-16-47/checkpoint_000000)
2024-08-24 08:17:16,313	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=783822)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b1cf6dc9_67_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1383,e_layer_2024-08-24_08-16-47/checkpoint_000001)
2024-08-24 08:17:29,339	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=783822)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b1cf6dc9_67_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1383,e_layer_2024-08-24_08-16-47/checkpoint_000002)
2024-08-24 08:17:42,381	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b1cf6dc9 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.13831 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00412 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=783822)[0m configuration
[36m(_train_fn pid=783822)[0m {'batch_size': 16, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.1383110860126323, 'e_layers': 2, 'learning_rate': 0.004122946989083842, 'd_ff': 512}
[36m(_train_fn pid=783822)[0m Use GPU: cuda:0
[36m(_train_fn pid=783822)[0m train 7825
[36m(_train_fn pid=783822)[0m val 2161
[36m(_train_fn pid=783822)[0m start_epoch 0
[36m(_train_fn pid=783822)[0m max_epoch 8
[36m(_train_fn pid=783822)[0m 	iters: 100, epoch: 1 | loss: 0.7720292
[36m(_train_fn pid=783822)[0m 	speed: 0.0304s/iter; left time: 116.0618s
[36m(_train_fn pid=783822)[0m 	iters: 200, epoch: 1 | loss: 0.7008951
[36m(_train_fn pid=783822)[0m 	speed: 0.0233s/iter; left time: 86.5064s
[36m(_train_fn pid=783822)[0m 	iters: 300, epoch: 1 | loss: 0.7216721
[36m(_train_fn pid=783822)[0m 	speed: 0.0233s/iter; left time: 84.2983s
[36m(_train_fn pid=783822)[0m 	iters: 400, epoch: 1 | loss: 0.7089407
[36m(_train_fn pid=783822)[0m 	speed: 0.0234s/iter; left time: 82.0870s
[36m(_train_fn pid=783822)[0m Updating learning rate to 0.004122946989083842
[36m(_train_fn pid=783822)[0m saving checkpoint...
[36m(_train_fn pid=783822)[0m Validation loss decreased (inf --> 1.6260).  Saving model state dict ...
[36m(_train_fn pid=783822)[0m Epoch: 1 cost time: 11.860552549362183
[36m(_train_fn pid=783822)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7105729 Vali Loss: 1.6260252 Best vali loss: 1.6260252
[36m(_train_fn pid=783822)[0m 	iters: 100, epoch: 2 | loss: 1.2222862
[36m(_train_fn pid=783822)[0m 	speed: 0.0602s/iter; left time: 200.2659s
[36m(_train_fn pid=783822)[0m 	iters: 200, epoch: 2 | loss: 24.1695995
[36m(_train_fn pid=783822)[0m 	speed: 0.0233s/iter; left time: 75.1965s
[36m(_train_fn pid=783822)[0m 	iters: 300, epoch: 2 | loss: 546.6835327
[36m(_train_fn pid=783822)[0m 	speed: 0.0233s/iter; left time: 72.8417s
[36m(_train_fn pid=783822)[0m 	iters: 400, epoch: 2 | loss: 4.9126720
[36m(_train_fn pid=783822)[0m 	speed: 0.0233s/iter; left time: 70.3325s

Trial status: 66 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:17:14. Total running time: 56min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b1cf6dc9   RUNNING           1            13.8391       0.710573        1.62603             1.62603 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
61 more TERMINATED
[36m(_train_fn pid=783822)[0m Updating learning rate to 0.002061473494541921
[36m(_train_fn pid=783822)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=783822)[0m saving checkpoint...
[36m(_train_fn pid=783822)[0m Epoch: 2 cost time: 11.435758829116821
[36m(_train_fn pid=783822)[0m Epoch: 2, Steps: 489 | Train Loss: 2036.6963048 Vali Loss: 5.0048785 Best vali loss: 1.6260252
[36m(_train_fn pid=783822)[0m 	iters: 100, epoch: 3 | loss: 1.8780351
[36m(_train_fn pid=783822)[0m 	speed: 0.0599s/iter; left time: 169.9158s
[36m(_train_fn pid=783822)[0m 	iters: 200, epoch: 3 | loss: 1.2801011
[36m(_train_fn pid=783822)[0m 	speed: 0.0233s/iter; left time: 63.7933s
[36m(_train_fn pid=783822)[0m 	iters: 300, epoch: 3 | loss: 1.5502304
[36m(_train_fn pid=783822)[0m 	speed: 0.0234s/iter; left time: 61.5334s
[36m(_train_fn pid=783822)[0m 	iters: 400, epoch: 3 | loss: 1.8743001
[36m(_train_fn pid=783822)[0m 	speed: 0.0234s/iter; left time: 59.2235s
[36m(_train_fn pid=783822)[0m Updating learning rate to 0.0010307367472709606
[36m(_train_fn pid=783822)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=783822)[0m saving checkpoint...
[36m(_train_fn pid=783822)[0m Epoch: 3 cost time: 11.45038104057312
[36m(_train_fn pid=783822)[0m Epoch: 3, Steps: 489 | Train Loss: 1.7066647 Vali Loss: 3.0567538 Best vali loss: 1.6260252
[36m(_train_fn pid=783822)[0m 	iters: 100, epoch: 4 | loss: 1.4802881
[36m(_train_fn pid=783822)[0m 	speed: 0.0603s/iter; left time: 141.4243s
[36m(_train_fn pid=783822)[0m 	iters: 200, epoch: 4 | loss: 1.2044282
[36m(_train_fn pid=783822)[0m 	speed: 0.0234s/iter; left time: 52.4993s
[36m(_train_fn pid=783822)[0m 	iters: 300, epoch: 4 | loss: 1.1526312
[36m(_train_fn pid=783822)[0m 	speed: 0.0234s/iter; left time: 50.2374s
[36m(_train_fn pid=783822)[0m 	iters: 400, epoch: 4 | loss: 1.1682755
[36m(_train_fn pid=783822)[0m 	speed: 0.0234s/iter; left time: 47.9084s

Trial trial-b1cf6dc9 completed after 4 iterations at 2024-08-24 08:17:42. Total running time: 56min 33s
[36m(_train_fn pid=783822)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b1cf6dc9_67_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1383,e_layer_2024-08-24_08-16-47/checkpoint_000003)
2024-08-24 08:17:47,307	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=784353)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18d7d013_68_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1028,e_layers=_2024-08-24_08-17-42/checkpoint_000000)
2024-08-24 08:17:49,290	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=784353)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18d7d013_68_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1028,e_layers=_2024-08-24_08-17-42/checkpoint_000001)
2024-08-24 08:17:51,281	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=784353)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18d7d013_68_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1028,e_layers=_2024-08-24_08-17-42/checkpoint_000002)
2024-08-24 08:17:53,277	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=784353)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18d7d013_68_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1028,e_layers=_2024-08-24_08-17-42/checkpoint_000003)
2024-08-24 08:17:55,292	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=784353)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18d7d013_68_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1028,e_layers=_2024-08-24_08-17-42/checkpoint_000004)
2024-08-24 08:17:57,271	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b1cf6dc9 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         13.03064 â”‚
â”‚ time_total_s                             52.88259 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.62603 â”‚
â”‚ train_loss                                1.30921 â”‚
â”‚ valid_loss                                2.78008 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=783822)[0m Updating learning rate to 0.0005153683736354803
[36m(_train_fn pid=783822)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=783822)[0m saving checkpoint...
[36m(_train_fn pid=783822)[0m Epoch: 4 cost time: 11.474501371383667
[36m(_train_fn pid=783822)[0m Epoch: 4, Steps: 489 | Train Loss: 1.3092083 Vali Loss: 2.7800752 Best vali loss: 1.6260252
[36m(_train_fn pid=783822)[0m Early stopping

Trial trial-18d7d013 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-18d7d013 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10284 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00191 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=784353)[0m configuration
[36m(_train_fn pid=784353)[0m {'batch_size': 64, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.10284409143677496, 'e_layers': 2, 'learning_rate': 0.0019072927480386914, 'd_ff': 128}
[36m(_train_fn pid=784353)[0m Use GPU: cuda:0

Trial status: 67 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:17:44. Total running time: 56min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-18d7d013   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
62 more TERMINATED
[36m(_train_fn pid=784353)[0m train 7825
[36m(_train_fn pid=784353)[0m val 2161
[36m(_train_fn pid=784353)[0m start_epoch 0
[36m(_train_fn pid=784353)[0m max_epoch 8
[36m(_train_fn pid=784353)[0m 	iters: 100, epoch: 1 | loss: 0.9206108
[36m(_train_fn pid=784353)[0m 	speed: 0.0207s/iter; left time: 18.1790s
[36m(_train_fn pid=784353)[0m Validation loss decreased (inf --> 2.0884).  Saving model state dict ...
[36m(_train_fn pid=784353)[0m 	iters: 100, epoch: 2 | loss: 0.5816068
[36m(_train_fn pid=784353)[0m 	speed: 0.0199s/iter; left time: 15.0374s
[36m(_train_fn pid=784353)[0m Updating learning rate to 0.0019072927480386914
[36m(_train_fn pid=784353)[0m saving checkpoint...
[36m(_train_fn pid=784353)[0m Epoch: 1 cost time: 2.1137712001800537
[36m(_train_fn pid=784353)[0m Epoch: 1, Steps: 122 | Train Loss: 0.9679062 Vali Loss: 2.0883500 Best vali loss: 2.0883500
[36m(_train_fn pid=784353)[0m Updating learning rate to 0.0009536463740193457
[36m(_train_fn pid=784353)[0m saving checkpoint...
[36m(_train_fn pid=784353)[0m Validation loss decreased (2.0884 --> 1.6097).  Saving model state dict ...
[36m(_train_fn pid=784353)[0m Epoch: 2 cost time: 1.6811726093292236
[36m(_train_fn pid=784353)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6665920 Vali Loss: 1.6096877 Best vali loss: 1.6096877
[36m(_train_fn pid=784353)[0m 	iters: 100, epoch: 3 | loss: 0.5937563
[36m(_train_fn pid=784353)[0m 	speed: 0.0199s/iter; left time: 12.5872s
[36m(_train_fn pid=784353)[0m Updating learning rate to 0.00047682318700967286
[36m(_train_fn pid=784353)[0m saving checkpoint...
[36m(_train_fn pid=784353)[0m Validation loss decreased (1.6097 --> 1.6018).  Saving model state dict ...
[36m(_train_fn pid=784353)[0m Epoch: 3 cost time: 1.688004493713379
[36m(_train_fn pid=784353)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6074913 Vali Loss: 1.6017572 Best vali loss: 1.6017572
[36m(_train_fn pid=784353)[0m 	iters: 100, epoch: 4 | loss: 0.5536001
[36m(_train_fn pid=784353)[0m 	speed: 0.0199s/iter; left time: 10.1497s
[36m(_train_fn pid=784353)[0m Updating learning rate to 0.00023841159350483643
[36m(_train_fn pid=784353)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=784353)[0m saving checkpoint...
[36m(_train_fn pid=784353)[0m Epoch: 4 cost time: 1.6824254989624023
[36m(_train_fn pid=784353)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5977650 Vali Loss: 1.6189823 Best vali loss: 1.6017572
[36m(_train_fn pid=784353)[0m 	iters: 100, epoch: 5 | loss: 0.5766316
[36m(_train_fn pid=784353)[0m 	speed: 0.0200s/iter; left time: 7.7928s
[36m(_train_fn pid=784353)[0m Updating learning rate to 0.00011920579675241821
[36m(_train_fn pid=784353)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=784353)[0m saving checkpoint...
[36m(_train_fn pid=784353)[0m Epoch: 5 cost time: 1.7028446197509766
[36m(_train_fn pid=784353)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5909097 Vali Loss: 1.6075181 Best vali loss: 1.6017572
[36m(_train_fn pid=784353)[0m 	iters: 100, epoch: 6 | loss: 0.5727394
[36m(_train_fn pid=784353)[0m 	speed: 0.0200s/iter; left time: 5.3465s

Trial trial-18d7d013 completed after 6 iterations at 2024-08-24 08:17:57. Total running time: 56min 48s
[36m(_train_fn pid=784353)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18d7d013_68_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1028,e_layers=_2024-08-24_08-17-42/checkpoint_000005)
2024-08-24 08:18:27,620	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=784906)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0dfdff43_69_alpha_d_ff=2,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1015,e_layers_2024-08-24_08-17-57/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-18d7d013 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          1.98568 â”‚
â”‚ time_total_s                             12.76761 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.60176 â”‚
â”‚ train_loss                                0.58626 â”‚
â”‚ valid_loss                                1.60413 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=784353)[0m Updating learning rate to 5.960289837620911e-05
[36m(_train_fn pid=784353)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=784353)[0m saving checkpoint...
[36m(_train_fn pid=784353)[0m Epoch: 6 cost time: 1.6870312690734863
[36m(_train_fn pid=784353)[0m Epoch: 6, Steps: 122 | Train Loss: 0.5862559 Vali Loss: 1.6041289 Best vali loss: 1.6017572
[36m(_train_fn pid=784353)[0m Early stopping

Trial trial-0dfdff43 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0dfdff43 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10151 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00295 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=784906)[0m configuration
[36m(_train_fn pid=784906)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.10151330483480743, 'e_layers': 2, 'learning_rate': 0.002953227510155627, 'd_ff': 1024}
[36m(_train_fn pid=784906)[0m Use GPU: cuda:0
[36m(_train_fn pid=784906)[0m train 7825
[36m(_train_fn pid=784906)[0m val 2161
[36m(_train_fn pid=784906)[0m start_epoch 0
[36m(_train_fn pid=784906)[0m max_epoch 8
[36m(_train_fn pid=784906)[0m 	iters: 100, epoch: 1 | loss: 0.6937257
[36m(_train_fn pid=784906)[0m 	speed: 0.0564s/iter; left time: 215.0719s
[36m(_train_fn pid=784906)[0m 	iters: 200, epoch: 1 | loss: 0.6360119
[36m(_train_fn pid=784906)[0m 	speed: 0.0495s/iter; left time: 183.8256s

Trial status: 68 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:18:14. Total running time: 57min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0dfdff43   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
63 more TERMINATED
[36m(_train_fn pid=784906)[0m 	iters: 300, epoch: 1 | loss: 0.6984346
[36m(_train_fn pid=784906)[0m 	speed: 0.0496s/iter; left time: 179.1988s
[36m(_train_fn pid=784906)[0m 	iters: 400, epoch: 1 | loss: 0.5780253
[36m(_train_fn pid=784906)[0m 	speed: 0.0496s/iter; left time: 174.1937s
[36m(_train_fn pid=784906)[0m Updating learning rate to 0.002953227510155627
[36m(_train_fn pid=784906)[0m saving checkpoint...
[36m(_train_fn pid=784906)[0m Validation loss decreased (inf --> 1.6234).  Saving model state dict ...
[36m(_train_fn pid=784906)[0m Epoch: 1 cost time: 24.667205572128296
[36m(_train_fn pid=784906)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7126191 Vali Loss: 1.6233848 Best vali loss: 1.6233848
[36m(_train_fn pid=784906)[0m 	iters: 100, epoch: 2 | loss: 11.0017252
[36m(_train_fn pid=784906)[0m 	speed: 0.1243s/iter; left time: 413.0908s
[36m(_train_fn pid=784906)[0m 	iters: 200, epoch: 2 | loss: 0.9544017
[36m(_train_fn pid=784906)[0m 	speed: 0.0492s/iter; left time: 158.4647s
[36m(_train_fn pid=784906)[0m 	iters: 300, epoch: 2 | loss: 0.6515114
[36m(_train_fn pid=784906)[0m 	speed: 0.0491s/iter; left time: 153.4521s
Trial status: 68 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:18:44. Total running time: 57min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=784906)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0dfdff43_69_alpha_d_ff=2,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1015,e_layers_2024-08-24_08-17-57/checkpoint_000001)
[36m(_train_fn pid=784906)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0dfdff43_69_alpha_d_ff=2,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1015,e_layers_2024-08-24_08-17-57/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0dfdff43   RUNNING           1            28.1545       0.712619        1.62338             1.62338 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
63 more TERMINATED
[36m(_train_fn pid=784906)[0m 	iters: 400, epoch: 2 | loss: 0.9317597
[36m(_train_fn pid=784906)[0m 	speed: 0.0491s/iter; left time: 148.5295s
[36m(_train_fn pid=784906)[0m Updating learning rate to 0.0014766137550778135
[36m(_train_fn pid=784906)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=784906)[0m saving checkpoint...
[36m(_train_fn pid=784906)[0m Epoch: 2 cost time: 24.05548667907715
[36m(_train_fn pid=784906)[0m Epoch: 2, Steps: 489 | Train Loss: 109.8546489 Vali Loss: 1.9526987 Best vali loss: 1.6233848
[36m(_train_fn pid=784906)[0m 	iters: 100, epoch: 3 | loss: 0.7387066
[36m(_train_fn pid=784906)[0m 	speed: 0.1236s/iter; left time: 350.4928s
[36m(_train_fn pid=784906)[0m 	iters: 200, epoch: 3 | loss: 0.6768762
[36m(_train_fn pid=784906)[0m 	speed: 0.0492s/iter; left time: 134.5569s
[36m(_train_fn pid=784906)[0m 	iters: 300, epoch: 3 | loss: 0.8403079
[36m(_train_fn pid=784906)[0m 	speed: 0.0492s/iter; left time: 129.6231s
[36m(_train_fn pid=784906)[0m 	iters: 400, epoch: 3 | loss: 0.6778252
[36m(_train_fn pid=784906)[0m 	speed: 0.0492s/iter; left time: 124.6282s
Trial status: 68 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:19:14. Total running time: 58min 5s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0dfdff43   RUNNING           2            55.2592     109.855           1.9527              1.62338 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
63 more TERMINATED
[36m(_train_fn pid=784906)[0m Updating learning rate to 0.0007383068775389068
[36m(_train_fn pid=784906)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=784906)[0m saving checkpoint...
[36m(_train_fn pid=784906)[0m Epoch: 3 cost time: 24.067733764648438
[36m(_train_fn pid=784906)[0m Epoch: 3, Steps: 489 | Train Loss: 0.7666931 Vali Loss: 1.9394551 Best vali loss: 1.6233848
[36m(_train_fn pid=784906)[0m 	iters: 100, epoch: 4 | loss: 0.7150931
[36m(_train_fn pid=784906)[0m 	speed: 0.1236s/iter; left time: 290.0370s
[36m(_train_fn pid=784906)[0m 	iters: 200, epoch: 4 | loss: 0.7981993
[36m(_train_fn pid=784906)[0m 	speed: 0.0492s/iter; left time: 110.4849s
[36m(_train_fn pid=784906)[0m 	iters: 300, epoch: 4 | loss: 0.6880296
[36m(_train_fn pid=784906)[0m 	speed: 0.0492s/iter; left time: 105.6869s
[36m(_train_fn pid=784906)[0m 	iters: 400, epoch: 4 | loss: 0.7079539
[36m(_train_fn pid=784906)[0m 	speed: 0.0492s/iter; left time: 100.6455s
Trial status: 68 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:19:44. Total running time: 58min 35s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=784906)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0dfdff43_69_alpha_d_ff=2,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1015,e_layers_2024-08-24_08-17-57/checkpoint_000003)
[36m(_train_fn pid=785606)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6cf6ed84_70_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-19-48/checkpoint_000000)
[36m(_train_fn pid=785606)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6cf6ed84_70_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-19-48/checkpoint_000001)
[36m(_train_fn pid=785606)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6cf6ed84_70_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-19-48/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0dfdff43   RUNNING           3            82.3687       0.766693        1.93946             1.62338 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
63 more TERMINATED

Trial trial-0dfdff43 completed after 4 iterations at 2024-08-24 08:19:48. Total running time: 58min 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0dfdff43 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         27.14267 â”‚
â”‚ time_total_s                            109.51136 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.62338 â”‚
â”‚ train_loss                                0.76177 â”‚
â”‚ valid_loss                                1.93262 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=784906)[0m Updating learning rate to 0.0003691534387694534
[36m(_train_fn pid=784906)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=784906)[0m saving checkpoint...

Trial trial-6cf6ed84 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6cf6ed84 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09093 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00186 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=785606)[0m configuration
[36m(_train_fn pid=785606)[0m {'batch_size': 64, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.09093474567057505, 'e_layers': 3, 'learning_rate': 0.0018596654024630474, 'd_ff': 512}
[36m(_train_fn pid=785606)[0m Use GPU: cuda:0
[36m(_train_fn pid=785606)[0m train 7825
[36m(_train_fn pid=785606)[0m val 2161
[36m(_train_fn pid=785606)[0m start_epoch 0
[36m(_train_fn pid=785606)[0m max_epoch 8
[36m(_train_fn pid=785606)[0m 	iters: 100, epoch: 1 | loss: 0.7987451
[36m(_train_fn pid=785606)[0m 	speed: 0.1236s/iter; left time: 108.4311s
[36m(_train_fn pid=785606)[0m Updating learning rate to 0.0018596654024630474
[36m(_train_fn pid=785606)[0m saving checkpoint...
[36m(_train_fn pid=785606)[0m Validation loss decreased (inf --> 1.9198).  Saving model state dict ...
[36m(_train_fn pid=785606)[0m Epoch: 1 cost time: 14.744120597839355
[36m(_train_fn pid=785606)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8160339 Vali Loss: 1.9197517 Best vali loss: 1.9197517

Trial status: 69 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:20:14. Total running time: 59min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6cf6ed84   RUNNING           1            16.8302       0.816034        1.91975             1.91975 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
64 more TERMINATED
[36m(_train_fn pid=785606)[0m 	iters: 100, epoch: 2 | loss: 0.6264293
[36m(_train_fn pid=785606)[0m 	speed: 0.1625s/iter; left time: 122.6744s
[36m(_train_fn pid=785606)[0m Updating learning rate to 0.0009298327012315237
[36m(_train_fn pid=785606)[0m saving checkpoint...
[36m(_train_fn pid=785606)[0m Validation loss decreased (1.9198 --> 1.5949).  Saving model state dict ...
[36m(_train_fn pid=785606)[0m Epoch: 2 cost time: 14.547044515609741
[36m(_train_fn pid=785606)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6488013 Vali Loss: 1.5948842 Best vali loss: 1.5948842
[36m(_train_fn pid=785606)[0m 	iters: 100, epoch: 3 | loss: 0.5985071
[36m(_train_fn pid=785606)[0m 	speed: 0.1623s/iter; left time: 102.7169s
[36m(_train_fn pid=785606)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6cf6ed84_70_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-19-48/checkpoint_000003)
[36m(_train_fn pid=785606)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6cf6ed84_70_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-19-48/checkpoint_000004)
[36m(_train_fn pid=785606)[0m Updating learning rate to 0.00046491635061576185
[36m(_train_fn pid=785606)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=785606)[0m saving checkpoint...
[36m(_train_fn pid=785606)[0m Epoch: 3 cost time: 14.53373646736145
[36m(_train_fn pid=785606)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6038305 Vali Loss: 1.6038377 Best vali loss: 1.5948842
Trial status: 69 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:20:44. Total running time: 59min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6cf6ed84   RUNNING           3            49.2729       0.60383         1.60384             1.59488 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
64 more TERMINATED
[36m(_train_fn pid=785606)[0m 	iters: 100, epoch: 4 | loss: 0.5437692
[36m(_train_fn pid=785606)[0m 	speed: 0.1623s/iter; left time: 82.9290s
[36m(_train_fn pid=785606)[0m Updating learning rate to 0.00023245817530788093
[36m(_train_fn pid=785606)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=785606)[0m saving checkpoint...
[36m(_train_fn pid=785606)[0m Epoch: 4 cost time: 14.56348204612732
[36m(_train_fn pid=785606)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5846893 Vali Loss: 1.6391510 Best vali loss: 1.5948842
[36m(_train_fn pid=785606)[0m 	iters: 100, epoch: 5 | loss: 0.5342919
[36m(_train_fn pid=785606)[0m 	speed: 0.1624s/iter; left time: 63.1736s

Trial trial-6cf6ed84 completed after 5 iterations at 2024-08-24 08:21:13. Total running time: 1hr 0min 4s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6cf6ed84 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         16.23925 â”‚
â”‚ time_total_s                              81.7447 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59488 â”‚
â”‚ train_loss                                 0.5728 â”‚
â”‚ valid_loss                                 1.6976 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=785606)[0m Updating learning rate to 0.00011622908765394046
[36m(_train_fn pid=785606)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=785606)[0m saving checkpoint...
[36m(_train_fn pid=785606)[0m Epoch: 5 cost time: 14.566122055053711
[36m(_train_fn pid=785606)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5728013 Vali Loss: 1.6976034 Best vali loss: 1.5948842
[36m(_train_fn pid=785606)[0m Early stopping

Trial status: 70 TERMINATED | 1 PENDING
Current time: 2024-08-24 08:21:14. Total running time: 1hr 0min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-3eebd77e   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
65 more TERMINATED

Trial trial-3eebd77e started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3eebd77e config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.08509 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00144 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=786649)[0m configuration
[36m(_train_fn pid=786649)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3eebd77e_71_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0851,e_layer_2024-08-24_08-21-13/checkpoint_000000)
2024-08-24 08:21:24,996	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=786649)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3eebd77e_71_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0851,e_layer_2024-08-24_08-21-13/checkpoint_000001)
2024-08-24 08:21:29,336	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=786649)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3eebd77e_71_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0851,e_layer_2024-08-24_08-21-13/checkpoint_000002)
2024-08-24 08:21:33,681	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=786649)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3eebd77e_71_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0851,e_layer_2024-08-24_08-21-13/checkpoint_000003)
2024-08-24 08:21:38,019	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=786649)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3eebd77e_71_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0851,e_layer_2024-08-24_08-21-13/checkpoint_000004)
2024-08-24 08:21:42,342	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=786649)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3eebd77e_71_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0851,e_layer_2024-08-24_08-21-13/checkpoint_000005)
2024-08-24 08:21:46,680	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=786649)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3eebd77e_71_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0851,e_layer_2024-08-24_08-21-13/checkpoint_000006)
[36m(_train_fn pid=786649)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.08509036043224426, 'e_layers': 3, 'learning_rate': 0.0014424790856009874, 'd_ff': 256}
[36m(_train_fn pid=786649)[0m Use GPU: cuda:0
[36m(_train_fn pid=786649)[0m train 7825
[36m(_train_fn pid=786649)[0m val 2161
[36m(_train_fn pid=786649)[0m start_epoch 0
[36m(_train_fn pid=786649)[0m max_epoch 8
[36m(_train_fn pid=786649)[0m Validation loss decreased (inf --> 2.1731).  Saving model state dict ...
[36m(_train_fn pid=786649)[0m Updating learning rate to 0.0014424790856009874
[36m(_train_fn pid=786649)[0m saving checkpoint...
[36m(_train_fn pid=786649)[0m Epoch: 1 cost time: 4.176751613616943
[36m(_train_fn pid=786649)[0m Epoch: 1, Steps: 61 | Train Loss: 0.9478447 Vali Loss: 2.1731163 Best vali loss: 2.1731163
[36m(_train_fn pid=786649)[0m Updating learning rate to 0.0007212395428004937
[36m(_train_fn pid=786649)[0m saving checkpoint...
[36m(_train_fn pid=786649)[0m Validation loss decreased (2.1731 --> 1.6386).  Saving model state dict ...
[36m(_train_fn pid=786649)[0m Epoch: 2 cost time: 3.757408380508423
[36m(_train_fn pid=786649)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7141434 Vali Loss: 1.6386266 Best vali loss: 1.6386266
[36m(_train_fn pid=786649)[0m Updating learning rate to 0.00036061977140024686
[36m(_train_fn pid=786649)[0m saving checkpoint...
[36m(_train_fn pid=786649)[0m Validation loss decreased (1.6386 --> 1.5972).  Saving model state dict ...
[36m(_train_fn pid=786649)[0m Epoch: 3 cost time: 3.7593953609466553
[36m(_train_fn pid=786649)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6246670 Vali Loss: 1.5971670 Best vali loss: 1.5971670
[36m(_train_fn pid=786649)[0m Updating learning rate to 0.00018030988570012343
[36m(_train_fn pid=786649)[0m saving checkpoint...
[36m(_train_fn pid=786649)[0m Validation loss decreased (1.5972 --> 1.5942).  Saving model state dict ...
[36m(_train_fn pid=786649)[0m Epoch: 4 cost time: 3.752086877822876
[36m(_train_fn pid=786649)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6136514 Vali Loss: 1.5942427 Best vali loss: 1.5942427
[36m(_train_fn pid=786649)[0m Updating learning rate to 9.015494285006171e-05
[36m(_train_fn pid=786649)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=786649)[0m saving checkpoint...
[36m(_train_fn pid=786649)[0m Epoch: 5 cost time: 3.750279188156128
[36m(_train_fn pid=786649)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6107537 Vali Loss: 1.5948278 Best vali loss: 1.5942427
[36m(_train_fn pid=786649)[0m Updating learning rate to 4.507747142503086e-05
[36m(_train_fn pid=786649)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=786649)[0m saving checkpoint...
[36m(_train_fn pid=786649)[0m Epoch: 6 cost time: 3.7574284076690674
[36m(_train_fn pid=786649)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6095501 Vali Loss: 1.5952589 Best vali loss: 1.5942427

Trial status: 70 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:21:44. Total running time: 1hr 0min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3eebd77e   RUNNING           6            26.8383       0.60955         1.59526             1.59424 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
65 more TERMINATED

Trial trial-3eebd77e completed after 7 iterations at 2024-08-24 08:21:46. Total running time: 1hr 0min 37s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3eebd77e result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          4.32674 â”‚
â”‚ time_total_s                             31.16508 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.59424 â”‚
â”‚ train_loss                                0.60849 â”‚
â”‚ valid_loss                                1.59547 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=786649)[0m Updating learning rate to 2.253873571251543e-05
[36m(_train_fn pid=786649)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=786649)[0m saving checkpoint...
[36m(_train_fn pid=786649)[0m Epoch: 7 cost time: 3.752920389175415
[36m(_train_fn pid=786649)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6084904 Vali Loss: 1.5954740 Best vali loss: 1.5942427
[36m(_train_fn pid=786649)[0m Early stopping

Trial trial-3a704acd started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3a704acd config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.14775 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.01093 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=787324)[0m configuration
[36m(_train_fn pid=787324)[0m {'batch_size': 64, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.14775375651564648, 'e_layers': 1, 'learning_rate': 0.010927217800761207, 'd_ff': 512}
[36m(_train_fn pid=787324)[0m Use GPU: cuda:0
[36m(_train_fn pid=787324)[0m train 7825
[36m(_train_fn pid=787324)[0m val 2161
[36m(_train_fn pid=787324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a704acd_72_alpha_d_ff=4,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-21-46/checkpoint_000000)
2024-08-24 08:21:58,188	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=787324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a704acd_72_alpha_d_ff=4,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-21-46/checkpoint_000001)
2024-08-24 08:22:02,747	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=787324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a704acd_72_alpha_d_ff=4,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-21-46/checkpoint_000002)
2024-08-24 08:22:07,299	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=787324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a704acd_72_alpha_d_ff=4,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-21-46/checkpoint_000003)
2024-08-24 08:22:11,856	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=787324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a704acd_72_alpha_d_ff=4,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-21-46/checkpoint_000004)
2024-08-24 08:22:16,415	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=787324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a704acd_72_alpha_d_ff=4,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-21-46/checkpoint_000005)
2024-08-24 08:22:20,987	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=787324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a704acd_72_alpha_d_ff=4,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-21-46/checkpoint_000006)
2024-08-24 08:22:25,549	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=787324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a704acd_72_alpha_d_ff=4,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-21-46/checkpoint_000007)
[36m(_train_fn pid=787324)[0m start_epoch 0
[36m(_train_fn pid=787324)[0m max_epoch 8
[36m(_train_fn pid=787324)[0m 	iters: 100, epoch: 1 | loss: 0.6966813
[36m(_train_fn pid=787324)[0m 	speed: 0.0376s/iter; left time: 33.0039s
[36m(_train_fn pid=787324)[0m Updating learning rate to 0.010927217800761207
[36m(_train_fn pid=787324)[0m saving checkpoint...
[36m(_train_fn pid=787324)[0m Validation loss decreased (inf --> 1.6431).  Saving model state dict ...
[36m(_train_fn pid=787324)[0m Epoch: 1 cost time: 4.226979970932007
[36m(_train_fn pid=787324)[0m Epoch: 1, Steps: 122 | Train Loss: 0.7579795 Vali Loss: 1.6430764 Best vali loss: 1.6430764
[36m(_train_fn pid=787324)[0m 	iters: 100, epoch: 2 | loss: 0.6745853
[36m(_train_fn pid=787324)[0m 	speed: 0.0455s/iter; left time: 34.3750s
[36m(_train_fn pid=787324)[0m Updating learning rate to 0.005463608900380603
[36m(_train_fn pid=787324)[0m saving checkpoint...
[36m(_train_fn pid=787324)[0m Validation loss decreased (1.6431 --> 1.6159).  Saving model state dict ...
[36m(_train_fn pid=787324)[0m Epoch: 2 cost time: 4.032363176345825
[36m(_train_fn pid=787324)[0m Epoch: 2, Steps: 122 | Train Loss: 1.0671772 Vali Loss: 1.6159291 Best vali loss: 1.6159291
[36m(_train_fn pid=787324)[0m 	iters: 100, epoch: 3 | loss: 0.5953224
[36m(_train_fn pid=787324)[0m 	speed: 0.0455s/iter; left time: 28.7991s
[36m(_train_fn pid=787324)[0m Updating learning rate to 0.0027318044501903017
[36m(_train_fn pid=787324)[0m saving checkpoint...
[36m(_train_fn pid=787324)[0m Validation loss decreased (1.6159 --> 1.5820).  Saving model state dict ...
[36m(_train_fn pid=787324)[0m Epoch: 3 cost time: 4.024077653884888
[36m(_train_fn pid=787324)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6198970 Vali Loss: 1.5820130 Best vali loss: 1.5820130
[36m(_train_fn pid=787324)[0m 	iters: 100, epoch: 4 | loss: 0.6583411
[36m(_train_fn pid=787324)[0m 	speed: 0.0455s/iter; left time: 23.2679s
[36m(_train_fn pid=787324)[0m Updating learning rate to 0.0013659022250951509
[36m(_train_fn pid=787324)[0m saving checkpoint...
[36m(_train_fn pid=787324)[0m Validation loss decreased (1.5820 --> 1.5788).  Saving model state dict ...
[36m(_train_fn pid=787324)[0m Epoch: 4 cost time: 4.030038833618164
[36m(_train_fn pid=787324)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6128963 Vali Loss: 1.5788090 Best vali loss: 1.5788090
[36m(_train_fn pid=787324)[0m 	iters: 100, epoch: 5 | loss: 0.6770626
[36m(_train_fn pid=787324)[0m 	speed: 0.0455s/iter; left time: 17.7180s
[36m(_train_fn pid=787324)[0m Updating learning rate to 0.0006829511125475754
[36m(_train_fn pid=787324)[0m saving checkpoint...
[36m(_train_fn pid=787324)[0m Validation loss decreased (1.5788 --> 1.5775).  Saving model state dict ...
[36m(_train_fn pid=787324)[0m Epoch: 5 cost time: 4.031318664550781
[36m(_train_fn pid=787324)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6105866 Vali Loss: 1.5775052 Best vali loss: 1.5775052

Trial status: 71 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:22:14. Total running time: 1hr 1min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3a704acd   RUNNING           5            23.3441       0.610587        1.57751             1.57751 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
66 more TERMINATED
[36m(_train_fn pid=787324)[0m 	iters: 100, epoch: 6 | loss: 0.5987920
[36m(_train_fn pid=787324)[0m 	speed: 0.0456s/iter; left time: 12.1757s
[36m(_train_fn pid=787324)[0m Updating learning rate to 0.0003414755562737877
[36m(_train_fn pid=787324)[0m saving checkpoint...
[36m(_train_fn pid=787324)[0m Validation loss decreased (1.5775 --> 1.5767).  Saving model state dict ...
[36m(_train_fn pid=787324)[0m Epoch: 6 cost time: 4.036010503768921
[36m(_train_fn pid=787324)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6100587 Vali Loss: 1.5766684 Best vali loss: 1.5766684
[36m(_train_fn pid=787324)[0m 	iters: 100, epoch: 7 | loss: 0.6080559
[36m(_train_fn pid=787324)[0m 	speed: 0.0457s/iter; left time: 6.6240s
[36m(_train_fn pid=787324)[0m Updating learning rate to 0.00017073777813689386
[36m(_train_fn pid=787324)[0m saving checkpoint...
[36m(_train_fn pid=787324)[0m Validation loss decreased (1.5767 --> 1.5755).  Saving model state dict ...
[36m(_train_fn pid=787324)[0m Epoch: 7 cost time: 4.037107706069946
[36m(_train_fn pid=787324)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6094031 Vali Loss: 1.5754920 Best vali loss: 1.5754920
[36m(_train_fn pid=787324)[0m 	iters: 100, epoch: 8 | loss: 0.5922610
[36m(_train_fn pid=787324)[0m 	speed: 0.0456s/iter; left time: 1.0496s

Trial trial-3a704acd completed after 8 iterations at 2024-08-24 08:22:25. Total running time: 1hr 1min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3a704acd result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          4.55974 â”‚
â”‚ time_total_s                              37.0287 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.57537 â”‚
â”‚ train_loss                                0.60856 â”‚
â”‚ valid_loss                                1.57537 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=787324)[0m Updating learning rate to 8.536888906844693e-05
[36m(_train_fn pid=787324)[0m saving checkpoint...
[36m(_train_fn pid=787324)[0m Validation loss decreased (1.5755 --> 1.5754).  Saving model state dict ...
[36m(_train_fn pid=787324)[0m Epoch: 8 cost time: 4.035421133041382
[36m(_train_fn pid=787324)[0m Epoch: 8, Steps: 122 | Train Loss: 0.6085623 Vali Loss: 1.5753690 Best vali loss: 1.5753690

Trial trial-661f88f0 started with configuration:
2024-08-24 08:22:50,377	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=788087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-661f88f0_73_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0927,e_laye_2024-08-24_08-22-25/checkpoint_000000)
2024-08-24 08:23:12,440	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=788087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-661f88f0_73_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0927,e_laye_2024-08-24_08-22-25/checkpoint_000001)
[36m(_train_fn pid=788087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-661f88f0_73_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0927,e_laye_2024-08-24_08-22-25/checkpoint_000002)
2024-08-24 08:23:34,511	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-661f88f0 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09269 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00367 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=788087)[0m configuration
[36m(_train_fn pid=788087)[0m {'batch_size': 128, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.09268921828752735, 'e_layers': 4, 'learning_rate': 0.0036669534986245845, 'd_ff': 1024}
[36m(_train_fn pid=788087)[0m Use GPU: cuda:0
[36m(_train_fn pid=788087)[0m train 7825
[36m(_train_fn pid=788087)[0m val 2161
[36m(_train_fn pid=788087)[0m start_epoch 0
[36m(_train_fn pid=788087)[0m max_epoch 8

Trial status: 72 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:22:45. Total running time: 1hr 1min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-661f88f0   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
67 more TERMINATED
[36m(_train_fn pid=788087)[0m Updating learning rate to 0.0036669534986245845
[36m(_train_fn pid=788087)[0m saving checkpoint...
[36m(_train_fn pid=788087)[0m Validation loss decreased (inf --> 2.0071).  Saving model state dict ...
[36m(_train_fn pid=788087)[0m Epoch: 1 cost time: 19.891040802001953
[36m(_train_fn pid=788087)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8876259 Vali Loss: 2.0070996 Best vali loss: 2.0070996
[36m(_train_fn pid=788087)[0m Updating learning rate to 0.0018334767493122922
[36m(_train_fn pid=788087)[0m saving checkpoint...
[36m(_train_fn pid=788087)[0m Validation loss decreased (2.0071 --> 1.6035).  Saving model state dict ...
[36m(_train_fn pid=788087)[0m Epoch: 2 cost time: 19.486671924591064
[36m(_train_fn pid=788087)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6762903 Vali Loss: 1.6034646 Best vali loss: 1.6034646
Trial status: 72 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:23:15. Total running time: 1hr 2min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-661f88f0   RUNNING           2            44.9364       0.67629         1.60346             1.60346 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
67 more TERMINATED
[36m(_train_fn pid=788087)[0m Updating learning rate to 0.0009167383746561461
[36m(_train_fn pid=788087)[0m saving checkpoint...
[36m(_train_fn pid=788087)[0m Validation loss decreased (1.6035 --> 1.6028).  Saving model state dict ...
[36m(_train_fn pid=788087)[0m Epoch: 3 cost time: 19.506125688552856
[36m(_train_fn pid=788087)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6119854 Vali Loss: 1.6028095 Best vali loss: 1.6028095
Trial status: 72 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:23:45. Total running time: 1hr 2min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=788087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-661f88f0_73_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0927,e_laye_2024-08-24_08-22-25/checkpoint_000003)
2024-08-24 08:23:56,564	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:24:18,576	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=788087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-661f88f0_73_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0927,e_laye_2024-08-24_08-22-25/checkpoint_000004)
[36m(_train_fn pid=788874)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-955594c2_74_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0._2024-08-24_08-24-18/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-661f88f0   RUNNING           3            67.0118       0.611985        1.60281             1.60281 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
67 more TERMINATED
[36m(_train_fn pid=788087)[0m Updating learning rate to 0.00045836918732807306
[36m(_train_fn pid=788087)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=788087)[0m saving checkpoint...
[36m(_train_fn pid=788087)[0m Epoch: 4 cost time: 19.49960494041443
[36m(_train_fn pid=788087)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5945897 Vali Loss: 1.6356654 Best vali loss: 1.6028095
Trial status: 72 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:24:15. Total running time: 1hr 3min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-661f88f0   RUNNING           4            89.0605       0.59459         1.63567             1.60281 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
67 more TERMINATED

Trial trial-661f88f0 completed after 5 iterations at 2024-08-24 08:24:18. Total running time: 1hr 3min 9s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-661f88f0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         22.00927 â”‚
â”‚ time_total_s                            111.06976 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.60281 â”‚
â”‚ train_loss                                0.57744 â”‚
â”‚ valid_loss                                1.64349 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=788087)[0m Updating learning rate to 0.00022918459366403653
[36m(_train_fn pid=788087)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=788087)[0m saving checkpoint...

Trial trial-955594c2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-955594c2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.04995 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00246 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=788874)[0m configuration
[36m(_train_fn pid=788874)[0m {'batch_size': 32, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'avg', 'dropout': 0.049946162386135556, 'e_layers': 4, 'learning_rate': 0.002464231651034601, 'd_ff': 96}
[36m(_train_fn pid=788874)[0m Use GPU: cuda:0
[36m(_train_fn pid=788874)[0m train 7825
[36m(_train_fn pid=788874)[0m val 2161
[36m(_train_fn pid=788874)[0m start_epoch 0
[36m(_train_fn pid=788874)[0m max_epoch 8
[36m(_train_fn pid=788874)[0m 	iters: 100, epoch: 1 | loss: 0.8413621
[36m(_train_fn pid=788874)[0m 	speed: 0.0194s/iter; left time: 35.9400s
[36m(_train_fn pid=788874)[0m 	iters: 200, epoch: 1 | loss: 0.7295439
[36m(_train_fn pid=788874)[0m 	speed: 0.0141s/iter; left time: 24.7165s
[36m(_train_fn pid=788874)[0m Updating learning rate to 0.002464231651034601
[36m(_train_fn pid=788874)[0m saving checkpoint...
[36m(_train_fn pid=788874)[0m Validation loss decreased (inf --> 1.7821).  Saving model state dict ...
[36m(_train_fn pid=788874)[0m Epoch: 1 cost time: 3.705561399459839
[36m(_train_fn pid=788874)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8224380 Vali Loss: 1.7821125 Best vali loss: 1.7821125
[36m(_train_fn pid=788874)[0m 	iters: 100, epoch: 2 | loss: 0.5858200
[36m(_train_fn pid=788874)[0m 	speed: 0.0241s/iter; left time: 38.7885s
[36m(_train_fn pid=788874)[0m 	iters: 200, epoch: 2 | loss: 0.5251457
2024-08-24 08:24:28,754	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=788874)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-955594c2_74_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0._2024-08-24_08-24-18/checkpoint_000001)
2024-08-24 08:24:32,528	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=788874)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-955594c2_74_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0._2024-08-24_08-24-18/checkpoint_000002)
2024-08-24 08:24:36,222	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=788874)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-955594c2_74_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0._2024-08-24_08-24-18/checkpoint_000003)
2024-08-24 08:24:39,875	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=788874)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-955594c2_74_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0._2024-08-24_08-24-18/checkpoint_000004)
2024-08-24 08:24:44,120	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=789373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-12948899_75_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0982,e_layers=_2024-08-24_08-24-39/checkpoint_000000)
2024-08-24 08:24:45,915	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=789373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-12948899_75_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0982,e_layers=_2024-08-24_08-24-39/checkpoint_000001)
[36m(_train_fn pid=788874)[0m 	speed: 0.0131s/iter; left time: 19.7386s
[36m(_train_fn pid=788874)[0m Updating learning rate to 0.0012321158255173006
[36m(_train_fn pid=788874)[0m saving checkpoint...
[36m(_train_fn pid=788874)[0m Validation loss decreased (1.7821 --> 1.5909).  Saving model state dict ...
[36m(_train_fn pid=788874)[0m Epoch: 2 cost time: 3.233846426010132
[36m(_train_fn pid=788874)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6144655 Vali Loss: 1.5908897 Best vali loss: 1.5908897
[36m(_train_fn pid=788874)[0m 	iters: 100, epoch: 3 | loss: 0.5920376
[36m(_train_fn pid=788874)[0m 	speed: 0.0245s/iter; left time: 33.4556s
[36m(_train_fn pid=788874)[0m 	iters: 200, epoch: 3 | loss: 0.5990944
[36m(_train_fn pid=788874)[0m 	speed: 0.0132s/iter; left time: 16.6484s
[36m(_train_fn pid=788874)[0m Updating learning rate to 0.0006160579127586503
[36m(_train_fn pid=788874)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=788874)[0m saving checkpoint...
[36m(_train_fn pid=788874)[0m Epoch: 3 cost time: 3.3409712314605713
[36m(_train_fn pid=788874)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5699494 Vali Loss: 1.5915809 Best vali loss: 1.5908897
[36m(_train_fn pid=788874)[0m 	iters: 100, epoch: 4 | loss: 0.5468114
[36m(_train_fn pid=788874)[0m 	speed: 0.0239s/iter; left time: 26.7924s
[36m(_train_fn pid=788874)[0m 	iters: 200, epoch: 4 | loss: 0.5207087
[36m(_train_fn pid=788874)[0m 	speed: 0.0131s/iter; left time: 13.3909s
[36m(_train_fn pid=788874)[0m Updating learning rate to 0.00030802895637932514
[36m(_train_fn pid=788874)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=788874)[0m saving checkpoint...
[36m(_train_fn pid=788874)[0m Epoch: 4 cost time: 3.275075674057007
[36m(_train_fn pid=788874)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5438773 Vali Loss: 1.6202660 Best vali loss: 1.5908897
[36m(_train_fn pid=788874)[0m 	iters: 100, epoch: 5 | loss: 0.5415328
[36m(_train_fn pid=788874)[0m 	speed: 0.0235s/iter; left time: 20.6062s
[36m(_train_fn pid=788874)[0m 	iters: 200, epoch: 5 | loss: 0.5315380
[36m(_train_fn pid=788874)[0m 	speed: 0.0130s/iter; left time: 10.1398s

Trial trial-955594c2 completed after 5 iterations at 2024-08-24 08:24:39. Total running time: 1hr 3min 31s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-955594c2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.65914 â”‚
â”‚ time_total_s                             19.33008 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59089 â”‚
â”‚ train_loss                                0.52884 â”‚
â”‚ valid_loss                                1.61844 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=788874)[0m Updating learning rate to 0.00015401447818966257
[36m(_train_fn pid=788874)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=788874)[0m saving checkpoint...
[36m(_train_fn pid=788874)[0m Epoch: 5 cost time: 3.2413201332092285
[36m(_train_fn pid=788874)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5288411 Vali Loss: 1.6184400 Best vali loss: 1.5908897
[36m(_train_fn pid=788874)[0m Early stopping

Trial trial-12948899 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-12948899 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09822 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00895 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=789373)[0m configuration
[36m(_train_fn pid=789373)[0m {'batch_size': 64, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.09822044105055014, 'e_layers': 3, 'learning_rate': 0.008948035755000357, 'd_ff': 16}
[36m(_train_fn pid=789373)[0m Use GPU: cuda:0
[36m(_train_fn pid=789373)[0m train 7825
[36m(_train_fn pid=789373)[0m val 2161
[36m(_train_fn pid=789373)[0m start_epoch 0
[36m(_train_fn pid=789373)[0m max_epoch 8
[36m(_train_fn pid=789373)[0m 	iters: 100, epoch: 1 | loss: 0.8624120
[36m(_train_fn pid=789373)[0m 	speed: 0.0194s/iter; left time: 17.0563s
[36m(_train_fn pid=789373)[0m Validation loss decreased (inf --> 1.7612).  Saving model state dict ...

Trial status: 74 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:24:45. Total running time: 1hr 3min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-12948899   RUNNING           1            2.59952       1.27405         1.76118             1.76118 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
69 more TERMINATED
[36m(_train_fn pid=789373)[0m 	iters: 100, epoch: 2 | loss: 0.5792393
[36m(_train_fn pid=789373)[0m 	speed: 0.0180s/iter; left time: 13.6116s
[36m(_train_fn pid=789373)[0m Updating learning rate to 0.008948035755000357
[36m(_train_fn pid=789373)[0m saving checkpoint...
[36m(_train_fn pid=789373)[0m Epoch: 1 cost time: 1.9566047191619873
[36m(_train_fn pid=789373)[0m Epoch: 1, Steps: 122 | Train Loss: 1.2740482 Vali Loss: 1.7611797 Best vali loss: 1.7611797
[36m(_train_fn pid=789373)[0m Updating learning rate to 0.004474017877500179
2024-08-24 08:24:47,696	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=789373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-12948899_75_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0982,e_layers=_2024-08-24_08-24-39/checkpoint_000002)
2024-08-24 08:24:49,472	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=789373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-12948899_75_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0982,e_layers=_2024-08-24_08-24-39/checkpoint_000003)
2024-08-24 08:24:51,235	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=789373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-12948899_75_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0982,e_layers=_2024-08-24_08-24-39/checkpoint_000004)
[36m(_train_fn pid=789848)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a7e77534_76_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0_2024-08-24_08-24-51/checkpoint_000000)
[36m(_train_fn pid=789848)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a7e77534_76_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0_2024-08-24_08-24-51/checkpoint_000001)
[36m(_train_fn pid=789848)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a7e77534_76_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0_2024-08-24_08-24-51/checkpoint_000002)
[36m(_train_fn pid=789373)[0m saving checkpoint...
[36m(_train_fn pid=789373)[0m Validation loss decreased (1.7612 --> 1.5957).  Saving model state dict ...
[36m(_train_fn pid=789373)[0m Epoch: 2 cost time: 1.5605316162109375
[36m(_train_fn pid=789373)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6427365 Vali Loss: 1.5957336 Best vali loss: 1.5957336
[36m(_train_fn pid=789373)[0m 	iters: 100, epoch: 3 | loss: 0.5675914
[36m(_train_fn pid=789373)[0m 	speed: 0.0179s/iter; left time: 11.3197s
[36m(_train_fn pid=789373)[0m Updating learning rate to 0.0022370089387500893
[36m(_train_fn pid=789373)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=789373)[0m saving checkpoint...
[36m(_train_fn pid=789373)[0m Epoch: 3 cost time: 1.5426647663116455
[36m(_train_fn pid=789373)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5820991 Vali Loss: 1.6027019 Best vali loss: 1.5957336
[36m(_train_fn pid=789373)[0m 	iters: 100, epoch: 4 | loss: 0.6172665
[36m(_train_fn pid=789373)[0m 	speed: 0.0178s/iter; left time: 9.0942s
[36m(_train_fn pid=789373)[0m Updating learning rate to 0.0011185044693750447
[36m(_train_fn pid=789373)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=789373)[0m saving checkpoint...
[36m(_train_fn pid=789373)[0m Epoch: 4 cost time: 1.5394117832183838
[36m(_train_fn pid=789373)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5570107 Vali Loss: 1.6385440 Best vali loss: 1.5957336
[36m(_train_fn pid=789373)[0m 	iters: 100, epoch: 5 | loss: 0.4966700
[36m(_train_fn pid=789373)[0m 	speed: 0.0177s/iter; left time: 6.8924s

Trial trial-12948899 completed after 5 iterations at 2024-08-24 08:24:51. Total running time: 1hr 3min 42s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-12948899 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.76071 â”‚
â”‚ time_total_s                              9.71221 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59573 â”‚
â”‚ train_loss                                0.54016 â”‚
â”‚ valid_loss                                1.63548 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=789373)[0m Updating learning rate to 0.0005592522346875223
[36m(_train_fn pid=789373)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=789373)[0m saving checkpoint...
[36m(_train_fn pid=789373)[0m Epoch: 5 cost time: 1.523132562637329
[36m(_train_fn pid=789373)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5401636 Vali Loss: 1.6354753 Best vali loss: 1.5957336
[36m(_train_fn pid=789373)[0m Early stopping

Trial trial-a7e77534 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a7e77534 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.1148 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00053 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=789848)[0m configuration
[36m(_train_fn pid=789848)[0m {'batch_size': 64, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'avg', 'dropout': 0.11480461233636301, 'e_layers': 3, 'learning_rate': 0.0005301611529169136, 'd_ff': 512}
[36m(_train_fn pid=789848)[0m Use GPU: cuda:0
[36m(_train_fn pid=789848)[0m train 7825
[36m(_train_fn pid=789848)[0m val 2161
[36m(_train_fn pid=789848)[0m start_epoch 0
[36m(_train_fn pid=789848)[0m max_epoch 8
[36m(_train_fn pid=789848)[0m 	iters: 100, epoch: 1 | loss: 0.8342811
[36m(_train_fn pid=789848)[0m 	speed: 0.1160s/iter; left time: 101.7673s
[36m(_train_fn pid=789848)[0m Updating learning rate to 0.0005301611529169136
[36m(_train_fn pid=789848)[0m saving checkpoint...
[36m(_train_fn pid=789848)[0m Validation loss decreased (inf --> 1.9718).  Saving model state dict ...
[36m(_train_fn pid=789848)[0m Epoch: 1 cost time: 13.813655853271484
[36m(_train_fn pid=789848)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8673172 Vali Loss: 1.9718310 Best vali loss: 1.9718310

Trial status: 75 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:25:15. Total running time: 1hr 4min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a7e77534   RUNNING           1            15.8489       0.867317        1.97183             1.97183 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
70 more TERMINATED
[36m(_train_fn pid=789848)[0m 	iters: 100, epoch: 2 | loss: 0.6558093
[36m(_train_fn pid=789848)[0m 	speed: 0.1530s/iter; left time: 115.4801s
[36m(_train_fn pid=789848)[0m Updating learning rate to 0.0002650805764584568
[36m(_train_fn pid=789848)[0m saving checkpoint...
[36m(_train_fn pid=789848)[0m Validation loss decreased (1.9718 --> 1.6079).  Saving model state dict ...
[36m(_train_fn pid=789848)[0m Epoch: 2 cost time: 13.66987681388855
[36m(_train_fn pid=789848)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6835411 Vali Loss: 1.6078777 Best vali loss: 1.6078777
[36m(_train_fn pid=789848)[0m 	iters: 100, epoch: 3 | loss: 0.6126201
[36m(_train_fn pid=789848)[0m 	speed: 0.1533s/iter; left time: 97.0142s
[36m(_train_fn pid=789848)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a7e77534_76_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0_2024-08-24_08-24-51/checkpoint_000003)
[36m(_train_fn pid=789848)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a7e77534_76_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0_2024-08-24_08-24-51/checkpoint_000004)
[36m(_train_fn pid=789848)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a7e77534_76_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0_2024-08-24_08-24-51/checkpoint_000005)
[36m(_train_fn pid=789848)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a7e77534_76_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=0_2024-08-24_08-24-51/checkpoint_000006)
[36m(_train_fn pid=789848)[0m Updating learning rate to 0.0001325402882292284
[36m(_train_fn pid=789848)[0m saving checkpoint...
[36m(_train_fn pid=789848)[0m Validation loss decreased (1.6079 --> 1.5790).  Saving model state dict ...
[36m(_train_fn pid=789848)[0m Epoch: 3 cost time: 13.694601058959961
[36m(_train_fn pid=789848)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6235955 Vali Loss: 1.5789628 Best vali loss: 1.5789628
Trial status: 75 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:25:45. Total running time: 1hr 4min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a7e77534   RUNNING           3            46.4806       0.623596        1.57896             1.57896 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
70 more TERMINATED
[36m(_train_fn pid=789848)[0m 	iters: 100, epoch: 4 | loss: 0.5851361
[36m(_train_fn pid=789848)[0m 	speed: 0.1533s/iter; left time: 78.3591s
[36m(_train_fn pid=789848)[0m Updating learning rate to 6.62701441146142e-05
[36m(_train_fn pid=789848)[0m saving checkpoint...
[36m(_train_fn pid=789848)[0m Validation loss decreased (1.5790 --> 1.5754).  Saving model state dict ...
[36m(_train_fn pid=789848)[0m Epoch: 4 cost time: 13.699061870574951
[36m(_train_fn pid=789848)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6146837 Vali Loss: 1.5754077 Best vali loss: 1.5754077
[36m(_train_fn pid=789848)[0m 	iters: 100, epoch: 5 | loss: 0.5575391
[36m(_train_fn pid=789848)[0m 	speed: 0.1536s/iter; left time: 59.7358s
[36m(_train_fn pid=789848)[0m Updating learning rate to 3.31350720573071e-05
[36m(_train_fn pid=789848)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=789848)[0m saving checkpoint...
[36m(_train_fn pid=789848)[0m Epoch: 5 cost time: 13.714728832244873
[36m(_train_fn pid=789848)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6121089 Vali Loss: 1.5776034 Best vali loss: 1.5754077
Trial status: 75 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:26:15. Total running time: 1hr 5min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a7e77534   RUNNING           5            77.155        0.612109        1.5776              1.57541 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
70 more TERMINATED
[36m(_train_fn pid=789848)[0m 	iters: 100, epoch: 6 | loss: 0.5575059
[36m(_train_fn pid=789848)[0m 	speed: 0.1535s/iter; left time: 40.9900s
[36m(_train_fn pid=789848)[0m Updating learning rate to 1.656753602865355e-05
[36m(_train_fn pid=789848)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=789848)[0m saving checkpoint...
[36m(_train_fn pid=789848)[0m Epoch: 6 cost time: 13.728619575500488
[36m(_train_fn pid=789848)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6105027 Vali Loss: 1.5765497 Best vali loss: 1.5754077
[36m(_train_fn pid=789848)[0m 	iters: 100, epoch: 7 | loss: 0.5602879
[36m(_train_fn pid=789848)[0m 	speed: 0.1536s/iter; left time: 22.2693s

Trial trial-a7e77534 completed after 7 iterations at 2024-08-24 08:26:41. Total running time: 1hr 5min 32s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a7e77534 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                         15.35573 â”‚
â”‚ time_total_s                            107.86393 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.57541 â”‚
â”‚ train_loss                                0.61025 â”‚
â”‚ valid_loss                                1.57655 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=789848)[0m Updating learning rate to 8.283768014326776e-06
[36m(_train_fn pid=789848)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=789848)[0m saving checkpoint...

Trial trial-29bec89e started with configuration:
2024-08-24 08:27:02,815	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=790751)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-29bec89e_77_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_08-26-41/checkpoint_000000)
[36m(_train_fn pid=790751)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-29bec89e_77_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_08-26-41/checkpoint_000001)
[36m(_train_fn pid=790751)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-29bec89e_77_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_08-26-41/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-29bec89e config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.05751 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00192 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=790751)[0m configuration
[36m(_train_fn pid=790751)[0m {'batch_size': 64, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'conv', 'dropout': 0.05750937654096277, 'e_layers': 4, 'learning_rate': 0.0019244181646453514, 'd_ff': 512}
[36m(_train_fn pid=790751)[0m Use GPU: cuda:0
[36m(_train_fn pid=790751)[0m train 7825
[36m(_train_fn pid=790751)[0m val 2161
[36m(_train_fn pid=790751)[0m start_epoch 0
[36m(_train_fn pid=790751)[0m max_epoch 8

Trial status: 76 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:26:45. Total running time: 1hr 5min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-29bec89e   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
71 more TERMINATED
[36m(_train_fn pid=790751)[0m 	iters: 100, epoch: 1 | loss: 0.7883238
[36m(_train_fn pid=790751)[0m 	speed: 0.1411s/iter; left time: 123.7626s
[36m(_train_fn pid=790751)[0m Updating learning rate to 0.0019244181646453514
[36m(_train_fn pid=790751)[0m saving checkpoint...
[36m(_train_fn pid=790751)[0m Validation loss decreased (inf --> 1.9587).  Saving model state dict ...
[36m(_train_fn pid=790751)[0m Epoch: 1 cost time: 16.883126258850098
[36m(_train_fn pid=790751)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8203081 Vali Loss: 1.9586682 Best vali loss: 1.9586682
Trial status: 76 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:27:15. Total running time: 1hr 6min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-29bec89e   RUNNING           1            19.2995       0.820308        1.95867             1.95867 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
71 more TERMINATED
[36m(_train_fn pid=790751)[0m 	iters: 100, epoch: 2 | loss: 0.6219956
[36m(_train_fn pid=790751)[0m 	speed: 0.1867s/iter; left time: 140.9300s
[36m(_train_fn pid=790751)[0m Updating learning rate to 0.0009622090823226757
[36m(_train_fn pid=790751)[0m saving checkpoint...
[36m(_train_fn pid=790751)[0m Validation loss decreased (1.9587 --> 1.6151).  Saving model state dict ...
[36m(_train_fn pid=790751)[0m Epoch: 2 cost time: 16.662941217422485
[36m(_train_fn pid=790751)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6514045 Vali Loss: 1.6150670 Best vali loss: 1.6150670
[36m(_train_fn pid=790751)[0m 	iters: 100, epoch: 3 | loss: 0.5175012
[36m(_train_fn pid=790751)[0m 	speed: 0.1869s/iter; left time: 118.2861s
[36m(_train_fn pid=790751)[0m Updating learning rate to 0.00048110454116133785
[36m(_train_fn pid=790751)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=790751)[0m saving checkpoint...
[36m(_train_fn pid=790751)[0m Epoch: 3 cost time: 16.700260639190674
[36m(_train_fn pid=790751)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5824380 Vali Loss: 1.6791808 Best vali loss: 1.6150670
Trial status: 76 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:27:45. Total running time: 1hr 6min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=790751)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-29bec89e_77_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_08-26-41/checkpoint_000003)
[36m(_train_fn pid=790751)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-29bec89e_77_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout=_2024-08-24_08-26-41/checkpoint_000004)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-29bec89e   RUNNING           3            56.6333       0.582438        1.67918             1.61507 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
71 more TERMINATED
[36m(_train_fn pid=790751)[0m 	iters: 100, epoch: 4 | loss: 0.5097875
[36m(_train_fn pid=790751)[0m 	speed: 0.1867s/iter; left time: 95.4092s
[36m(_train_fn pid=790751)[0m Updating learning rate to 0.00024055227058066892
[36m(_train_fn pid=790751)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=790751)[0m saving checkpoint...
[36m(_train_fn pid=790751)[0m Epoch: 4 cost time: 16.681903839111328
[36m(_train_fn pid=790751)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5483563 Vali Loss: 1.6822966 Best vali loss: 1.6150670
[36m(_train_fn pid=790751)[0m 	iters: 100, epoch: 5 | loss: 0.5803536
[36m(_train_fn pid=790751)[0m 	speed: 0.1866s/iter; left time: 72.5801s
Trial status: 76 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:28:15. Total running time: 1hr 7min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-29bec89e   RUNNING           4            75.2885       0.548356        1.6823              1.61507 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
71 more TERMINATED

Trial trial-29bec89e completed after 5 iterations at 2024-08-24 08:28:17. Total running time: 1hr 7min 8s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-29bec89e result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         18.65653 â”‚
â”‚ time_total_s                             93.94507 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.61507 â”‚
â”‚ train_loss                                0.52894 â”‚
â”‚ valid_loss                                1.67805 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=790751)[0m Updating learning rate to 0.00012027613529033446
[36m(_train_fn pid=790751)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=790751)[0m saving checkpoint...
[36m(_train_fn pid=790751)[0m Epoch: 5 cost time: 16.679725646972656
[36m(_train_fn pid=790751)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5289412 Vali Loss: 1.6780498 Best vali loss: 1.6150670
[36m(_train_fn pid=790751)[0m Early stopping

Trial trial-c310e66c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c310e66c config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11998 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.01057 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=791472)[0m configuration
[36m(_train_fn pid=791472)[0m {'batch_size': 64, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'avg', 'dropout': 0.11997984342752875, 'e_layers': 4, 'learning_rate': 0.01056755204255239, 'd_ff': 192}
[36m(_train_fn pid=791472)[0m Use GPU: cuda:0
[36m(_train_fn pid=791472)[0m train 7825
[36m(_train_fn pid=791472)[0m val 2161
[36m(_train_fn pid=791472)[0m start_epoch 0
[36m(_train_fn pid=791472)[0m max_epoch 8
[36m(_train_fn pid=791472)[0m 	iters: 100, epoch: 1 | loss: 0.7034217
[36m(_train_fn pid=791472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c310e66c_78_alpha_d_ff=3,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-28-17/checkpoint_000000)
[36m(_train_fn pid=791472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c310e66c_78_alpha_d_ff=3,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-28-17/checkpoint_000001)
2024-08-24 08:28:29,783	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=791472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c310e66c_78_alpha_d_ff=3,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-28-17/checkpoint_000002)
2024-08-24 08:28:34,594	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:28:39,409	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=791472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c310e66c_78_alpha_d_ff=3,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-28-17/checkpoint_000003)
2024-08-24 08:28:44,224	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=791472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c310e66c_78_alpha_d_ff=3,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-28-17/checkpoint_000004)
2024-08-24 08:28:49,015	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=791472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c310e66c_78_alpha_d_ff=3,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-28-17/checkpoint_000005)
2024-08-24 08:28:53,836	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=791472)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c310e66c_78_alpha_d_ff=3,batch_size=64,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-28-17/checkpoint_000006)
[36m(_train_fn pid=791472)[0m 	speed: 0.0395s/iter; left time: 34.6577s
[36m(_train_fn pid=791472)[0m Updating learning rate to 0.01056755204255239
[36m(_train_fn pid=791472)[0m saving checkpoint...
[36m(_train_fn pid=791472)[0m Validation loss decreased (inf --> 1.6618).  Saving model state dict ...
[36m(_train_fn pid=791472)[0m Epoch: 1 cost time: 4.453127861022949
[36m(_train_fn pid=791472)[0m Epoch: 1, Steps: 122 | Train Loss: 0.7555475 Vali Loss: 1.6617952 Best vali loss: 1.6617952
[36m(_train_fn pid=791472)[0m 	iters: 100, epoch: 2 | loss: 0.6450574
[36m(_train_fn pid=791472)[0m 	speed: 0.0481s/iter; left time: 36.3198s
[36m(_train_fn pid=791472)[0m Updating learning rate to 0.005283776021276195
[36m(_train_fn pid=791472)[0m saving checkpoint...
[36m(_train_fn pid=791472)[0m Validation loss decreased (1.6618 --> 1.6196).  Saving model state dict ...
[36m(_train_fn pid=791472)[0m Epoch: 2 cost time: 4.245619535446167
[36m(_train_fn pid=791472)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6269552 Vali Loss: 1.6196049 Best vali loss: 1.6196049
[36m(_train_fn pid=791472)[0m 	iters: 100, epoch: 3 | loss: 0.5223626
[36m(_train_fn pid=791472)[0m 	speed: 0.0481s/iter; left time: 30.4463s
[36m(_train_fn pid=791472)[0m Updating learning rate to 0.0026418880106380974
[36m(_train_fn pid=791472)[0m saving checkpoint...
[36m(_train_fn pid=791472)[0m Validation loss decreased (1.6196 --> 1.6189).  Saving model state dict ...
[36m(_train_fn pid=791472)[0m Epoch: 3 cost time: 4.232368230819702
[36m(_train_fn pid=791472)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5721688 Vali Loss: 1.6188825 Best vali loss: 1.6188825
[36m(_train_fn pid=791472)[0m 	iters: 100, epoch: 4 | loss: 0.5194505
[36m(_train_fn pid=791472)[0m 	speed: 0.0482s/iter; left time: 24.6250s
[36m(_train_fn pid=791472)[0m Updating learning rate to 0.0013209440053190487
[36m(_train_fn pid=791472)[0m saving checkpoint...
[36m(_train_fn pid=791472)[0m Validation loss decreased (1.6189 --> 1.5896).  Saving model state dict ...
[36m(_train_fn pid=791472)[0m Epoch: 4 cost time: 4.24395751953125
[36m(_train_fn pid=791472)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5365010 Vali Loss: 1.5895660 Best vali loss: 1.5895660
[36m(_train_fn pid=791472)[0m 	iters: 100, epoch: 5 | loss: 0.5080104
[36m(_train_fn pid=791472)[0m 	speed: 0.0481s/iter; left time: 18.7077s
[36m(_train_fn pid=791472)[0m Updating learning rate to 0.0006604720026595243
[36m(_train_fn pid=791472)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=791472)[0m saving checkpoint...
[36m(_train_fn pid=791472)[0m Epoch: 5 cost time: 4.2372729778289795
[36m(_train_fn pid=791472)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5077439 Vali Loss: 1.6391939 Best vali loss: 1.5895660

Trial status: 77 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:28:45. Total running time: 1hr 7min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c310e66c   RUNNING           5            24.6897       0.507744        1.63919             1.58957 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
72 more TERMINATED
[36m(_train_fn pid=791472)[0m 	iters: 100, epoch: 6 | loss: 0.5181913
[36m(_train_fn pid=791472)[0m 	speed: 0.0481s/iter; left time: 12.8383s
[36m(_train_fn pid=791472)[0m Updating learning rate to 0.0003302360013297622
[36m(_train_fn pid=791472)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=791472)[0m saving checkpoint...
[36m(_train_fn pid=791472)[0m Epoch: 6 cost time: 4.238625526428223
[36m(_train_fn pid=791472)[0m Epoch: 6, Steps: 122 | Train Loss: 0.4828645 Vali Loss: 1.6373862 Best vali loss: 1.5895660
[36m(_train_fn pid=791472)[0m 	iters: 100, epoch: 7 | loss: 0.4617073
[36m(_train_fn pid=791472)[0m 	speed: 0.0481s/iter; left time: 6.9700s

Trial trial-c310e66c completed after 7 iterations at 2024-08-24 08:28:53. Total running time: 1hr 7min 45s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c310e66c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          4.80974 â”‚
â”‚ time_total_s                             34.29849 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58957 â”‚
â”‚ train_loss                                0.46751 â”‚
â”‚ valid_loss                                1.64164 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=791472)[0m Updating learning rate to 0.0001651180006648811
[36m(_train_fn pid=791472)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=791472)[0m saving checkpoint...
[36m(_train_fn pid=791472)[0m Epoch: 7 cost time: 4.2441747188568115
[36m(_train_fn pid=791472)[0m Epoch: 7, Steps: 122 | Train Loss: 0.4675064 Vali Loss: 1.6416446 Best vali loss: 1.5895660
[36m(_train_fn pid=791472)[0m Early stopping

Trial trial-54067546 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-54067546 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13889 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0008 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
2024-08-24 08:28:57,137	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:28:57,922	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:28:58,717	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:28:59,487	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=792157)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-54067546_79_alpha_d_ff=3,batch_size=128,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1389,e_layers=_2024-08-24_08-28-53/checkpoint_000003)[32m [repeated 4x across cluster][0m
2024-08-24 08:29:00,253	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:29:01,055	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:29:01,843	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:29:02,596	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=792836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56f9ecfb_80_alpha_d_ff=2,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-29-02/checkpoint_000000)[32m [repeated 5x across cluster][0m
[36m(_train_fn pid=792157)[0m configuration
[36m(_train_fn pid=792157)[0m {'batch_size': 128, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.13888529580534215, 'e_layers': 1, 'learning_rate': 0.0008017167791319943, 'd_ff': 24}
[36m(_train_fn pid=792157)[0m Use GPU: cuda:0
[36m(_train_fn pid=792157)[0m train 7825
[36m(_train_fn pid=792157)[0m val 2161
[36m(_train_fn pid=792157)[0m start_epoch 0
[36m(_train_fn pid=792157)[0m max_epoch 8
[36m(_train_fn pid=792157)[0m Validation loss decreased (inf --> 2.5059).  Saving model state dict ...
[36m(_train_fn pid=792157)[0m Validation loss decreased (2.5059 --> 1.7256).  Saving model state dict ...
[36m(_train_fn pid=792157)[0m Validation loss decreased (1.7256 --> 1.6427).  Saving model state dict ...
[36m(_train_fn pid=792157)[0m Validation loss decreased (1.6427 --> 1.6281).  Saving model state dict ...
[36m(_train_fn pid=792157)[0m Updating learning rate to 0.00010021459739149929[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=792157)[0m saving checkpoint...[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=792157)[0m Epoch: 4 cost time: 0.6073927879333496[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=792157)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6603692 Vali Loss: 1.6280991 Best vali loss: 1.6280991[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=792157)[0m Validation loss decreased (1.6281 --> 1.6248).  Saving model state dict ...
[36m(_train_fn pid=792157)[0m Validation loss decreased (1.6248 --> 1.6215).  Saving model state dict ...
[36m(_train_fn pid=792157)[0m Validation loss decreased (1.6215 --> 1.6205).  Saving model state dict ...

Trial trial-54067546 completed after 8 iterations at 2024-08-24 08:29:02. Total running time: 1hr 7min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-54067546 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          0.74992 â”‚
â”‚ time_total_s                              7.08236 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.62001 â”‚
â”‚ train_loss                                0.64834 â”‚
â”‚ valid_loss                                1.62001 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=792157)[0m Validation loss decreased (1.6205 --> 1.6200).  Saving model state dict ...

Trial trial-56f9ecfb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-56f9ecfb config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.14017 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00121 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=792836)[0m configuration
[36m(_train_fn pid=792836)[0m {'batch_size': 32, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.1401663720493701, 'e_layers': 3, 'learning_rate': 0.0012050595914788397, 'd_ff': 512}
[36m(_train_fn pid=792836)[0m Use GPU: cuda:0
[36m(_train_fn pid=792157)[0m Updating learning rate to 6.263412336968706e-06[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=792157)[0m saving checkpoint...[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=792157)[0m Epoch: 8 cost time: 0.5992317199707031[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=792157)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6483412 Vali Loss: 1.6200071 Best vali loss: 1.6200071[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=792836)[0m train 7825
[36m(_train_fn pid=792836)[0m val 2161
[36m(_train_fn pid=792836)[0m start_epoch 0
[36m(_train_fn pid=792836)[0m max_epoch 8
[36m(_train_fn pid=792836)[0m 	iters: 100, epoch: 1 | loss: 0.7285647
[36m(_train_fn pid=792836)[0m 	speed: 0.0665s/iter; left time: 123.2757s

Trial status: 79 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:29:15. Total running time: 1hr 8min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-56f9ecfb   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
74 more TERMINATED
[36m(_train_fn pid=792836)[0m 	iters: 200, epoch: 1 | loss: 0.8089803
[36m(_train_fn pid=792836)[0m 	speed: 0.0617s/iter; left time: 108.2011s
[36m(_train_fn pid=792836)[0m Updating learning rate to 0.0012050595914788397
[36m(_train_fn pid=792836)[0m saving checkpoint...
[36m(_train_fn pid=792836)[0m Validation loss decreased (inf --> 1.8813).  Saving model state dict ...
[36m(_train_fn pid=792836)[0m Epoch: 1 cost time: 15.27999758720398
[36m(_train_fn pid=792836)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8048555 Vali Loss: 1.8812504 Best vali loss: 1.8812504
[36m(_train_fn pid=792836)[0m 	iters: 100, epoch: 2 | loss: 0.6137286
[36m(_train_fn pid=792836)[0m 	speed: 0.1068s/iter; left time: 171.7763s
[36m(_train_fn pid=792836)[0m 	iters: 200, epoch: 2 | loss: 0.6374312
[36m(_train_fn pid=792836)[0m 	speed: 0.0618s/iter; left time: 93.3210s
[36m(_train_fn pid=792836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56f9ecfb_80_alpha_d_ff=2,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-29-02/checkpoint_000001)
[36m(_train_fn pid=792836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56f9ecfb_80_alpha_d_ff=2,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-29-02/checkpoint_000002)
[36m(_train_fn pid=792836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56f9ecfb_80_alpha_d_ff=2,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-29-02/checkpoint_000003)
[36m(_train_fn pid=792836)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-56f9ecfb_80_alpha_d_ff=2,batch_size=32,d_model=256,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_08-29-02/checkpoint_000004)
[36m(_train_fn pid=792836)[0m Updating learning rate to 0.0006025297957394199
[36m(_train_fn pid=792836)[0m saving checkpoint...
[36m(_train_fn pid=792836)[0m Validation loss decreased (1.8813 --> 1.5813).  Saving model state dict ...
[36m(_train_fn pid=792836)[0m Epoch: 2 cost time: 15.104066133499146
[36m(_train_fn pid=792836)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6408417 Vali Loss: 1.5813403 Best vali loss: 1.5813403
[36m(_train_fn pid=792836)[0m 	iters: 100, epoch: 3 | loss: 0.5888368
[36m(_train_fn pid=792836)[0m 	speed: 0.1068s/iter; left time: 145.7171s
Trial status: 79 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:29:45. Total running time: 1hr 8min 36s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-56f9ecfb   RUNNING           2            34.3015       0.640842        1.58134             1.58134 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
74 more TERMINATED
[36m(_train_fn pid=792836)[0m 	iters: 200, epoch: 3 | loss: 0.6244076
[36m(_train_fn pid=792836)[0m 	speed: 0.0620s/iter; left time: 78.3887s
[36m(_train_fn pid=792836)[0m Updating learning rate to 0.00030126489786970993
[36m(_train_fn pid=792836)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=792836)[0m saving checkpoint...
[36m(_train_fn pid=792836)[0m Epoch: 3 cost time: 15.122511863708496
[36m(_train_fn pid=792836)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5993173 Vali Loss: 1.5878267 Best vali loss: 1.5813403
[36m(_train_fn pid=792836)[0m 	iters: 100, epoch: 4 | loss: 0.5777344
[36m(_train_fn pid=792836)[0m 	speed: 0.1067s/iter; left time: 119.6325s
[36m(_train_fn pid=792836)[0m 	iters: 200, epoch: 4 | loss: 0.5488223
[36m(_train_fn pid=792836)[0m 	speed: 0.0620s/iter; left time: 63.2669s
[36m(_train_fn pid=792836)[0m Updating learning rate to 0.00015063244893485497
[36m(_train_fn pid=792836)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=792836)[0m saving checkpoint...
[36m(_train_fn pid=792836)[0m Epoch: 4 cost time: 15.132558584213257
[36m(_train_fn pid=792836)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5770140 Vali Loss: 1.6223943 Best vali loss: 1.5813403
Trial status: 79 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:30:15. Total running time: 1hr 9min 6s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-56f9ecfb   RUNNING           4            68.0253       0.577014        1.62239             1.58134 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
74 more TERMINATED
[36m(_train_fn pid=792836)[0m 	iters: 100, epoch: 5 | loss: 0.5586753
[36m(_train_fn pid=792836)[0m 	speed: 0.1068s/iter; left time: 93.6854s
[36m(_train_fn pid=792836)[0m 	iters: 200, epoch: 5 | loss: 0.5382709
[36m(_train_fn pid=792836)[0m 	speed: 0.0621s/iter; left time: 48.2542s

Trial trial-56f9ecfb completed after 5 iterations at 2024-08-24 08:30:29. Total running time: 1hr 9min 20s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-56f9ecfb result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         16.89436 â”‚
â”‚ time_total_s                             84.91966 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58134 â”‚
â”‚ train_loss                                0.56563 â”‚
â”‚ valid_loss                                1.63296 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=792836)[0m Updating learning rate to 7.531622446742748e-05
[36m(_train_fn pid=792836)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=792836)[0m saving checkpoint...
[36m(_train_fn pid=792836)[0m Epoch: 5 cost time: 15.15912127494812
[36m(_train_fn pid=792836)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5656336 Vali Loss: 1.6329626 Best vali loss: 1.5813403
[36m(_train_fn pid=792836)[0m Early stopping

[36m(_train_fn pid=793538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1a61e553_81_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1024,e_layers_2024-08-24_08-30-29/checkpoint_000000)
2024-08-24 08:30:37,452	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=793538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1a61e553_81_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1024,e_layers_2024-08-24_08-30-29/checkpoint_000001)
2024-08-24 08:30:40,008	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=793538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1a61e553_81_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1024,e_layers_2024-08-24_08-30-29/checkpoint_000002)
[36m(_train_fn pid=793538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1a61e553_81_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1024,e_layers_2024-08-24_08-30-29/checkpoint_000003)
2024-08-24 08:30:42,571	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=793538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1a61e553_81_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1024,e_layers_2024-08-24_08-30-29/checkpoint_000004)
2024-08-24 08:30:45,117	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=793538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1a61e553_81_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1024,e_layers_2024-08-24_08-30-29/checkpoint_000005)
2024-08-24 08:30:47,683	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=793538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1a61e553_81_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1024,e_layers_2024-08-24_08-30-29/checkpoint_000006)
2024-08-24 08:30:50,230	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
Trial trial-1a61e553 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1a61e553 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.10238 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00062 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=793538)[0m configuration
[36m(_train_fn pid=793538)[0m {'batch_size': 64, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.10237868527751404, 'e_layers': 3, 'learning_rate': 0.000618013980510775, 'd_ff': 64}
[36m(_train_fn pid=793538)[0m Use GPU: cuda:0
[36m(_train_fn pid=793538)[0m train 7825
[36m(_train_fn pid=793538)[0m val 2161
[36m(_train_fn pid=793538)[0m start_epoch 0
[36m(_train_fn pid=793538)[0m max_epoch 8
[36m(_train_fn pid=793538)[0m 	iters: 100, epoch: 1 | loss: 1.0126549
[36m(_train_fn pid=793538)[0m 	speed: 0.0245s/iter; left time: 21.5287s
[36m(_train_fn pid=793538)[0m Updating learning rate to 0.000618013980510775
[36m(_train_fn pid=793538)[0m saving checkpoint...
[36m(_train_fn pid=793538)[0m Validation loss decreased (inf --> 2.2384).  Saving model state dict ...
[36m(_train_fn pid=793538)[0m Epoch: 1 cost time: 2.5790536403656006
[36m(_train_fn pid=793538)[0m Epoch: 1, Steps: 122 | Train Loss: 1.2002409 Vali Loss: 2.2383599 Best vali loss: 2.2383599
[36m(_train_fn pid=793538)[0m 	iters: 100, epoch: 2 | loss: 0.7012762
[36m(_train_fn pid=793538)[0m 	speed: 0.0256s/iter; left time: 19.2927s
[36m(_train_fn pid=793538)[0m Updating learning rate to 0.0003090069902553875
[36m(_train_fn pid=793538)[0m saving checkpoint...
[36m(_train_fn pid=793538)[0m Validation loss decreased (2.2384 --> 1.6463).  Saving model state dict ...
[36m(_train_fn pid=793538)[0m Epoch: 2 cost time: 2.1661245822906494
[36m(_train_fn pid=793538)[0m Epoch: 2, Steps: 122 | Train Loss: 0.7606089 Vali Loss: 1.6462797 Best vali loss: 1.6462797
[36m(_train_fn pid=793538)[0m 	iters: 100, epoch: 3 | loss: 0.6931894
[36m(_train_fn pid=793538)[0m 	speed: 0.0256s/iter; left time: 16.1958s
[36m(_train_fn pid=793538)[0m Updating learning rate to 0.00015450349512769376
[36m(_train_fn pid=793538)[0m saving checkpoint...
[36m(_train_fn pid=793538)[0m Validation loss decreased (1.6463 --> 1.6238).  Saving model state dict ...
[36m(_train_fn pid=793538)[0m Epoch: 3 cost time: 2.1687803268432617
[36m(_train_fn pid=793538)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6466372 Vali Loss: 1.6237736 Best vali loss: 1.6237736
[36m(_train_fn pid=793538)[0m 	iters: 100, epoch: 4 | loss: 0.6413223
[36m(_train_fn pid=793538)[0m 	speed: 0.0256s/iter; left time: 13.0945s
[36m(_train_fn pid=793538)[0m Updating learning rate to 7.725174756384688e-05
[36m(_train_fn pid=793538)[0m saving checkpoint...
[36m(_train_fn pid=793538)[0m Validation loss decreased (1.6238 --> 1.6113).  Saving model state dict ...
[36m(_train_fn pid=793538)[0m Epoch: 4 cost time: 2.1553149223327637
[36m(_train_fn pid=793538)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6352578 Vali Loss: 1.6113095 Best vali loss: 1.6113095
[36m(_train_fn pid=793538)[0m 	iters: 100, epoch: 5 | loss: 0.6156766
[36m(_train_fn pid=793538)[0m 	speed: 0.0256s/iter; left time: 9.9441s
[36m(_train_fn pid=793538)[0m Updating learning rate to 3.862587378192344e-05
[36m(_train_fn pid=793538)[0m saving checkpoint...
[36m(_train_fn pid=793538)[0m Validation loss decreased (1.6113 --> 1.6053).  Saving model state dict ...
[36m(_train_fn pid=793538)[0m Epoch: 5 cost time: 2.164827585220337
[36m(_train_fn pid=793538)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6288638 Vali Loss: 1.6053289 Best vali loss: 1.6053289

Trial status: 80 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:30:45. Total running time: 1hr 9min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1a61e553   RUNNING           5            13.6011       0.628864        1.60533             1.60533 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
75 more TERMINATED
[36m(_train_fn pid=793538)[0m 	iters: 100, epoch: 6 | loss: 0.6190321
[36m(_train_fn pid=793538)[0m 	speed: 0.0256s/iter; left time: 6.8339s
[36m(_train_fn pid=793538)[0m Updating learning rate to 1.931293689096172e-05
[36m(_train_fn pid=793538)[0m saving checkpoint...
[36m(_train_fn pid=793538)[0m Validation loss decreased (1.6053 --> 1.6031).  Saving model state dict ...
[36m(_train_fn pid=793538)[0m Epoch: 6 cost time: 2.1642398834228516
[36m(_train_fn pid=793538)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6251704 Vali Loss: 1.6030803 Best vali loss: 1.6030803
[36m(_train_fn pid=793538)[0m 	iters: 100, epoch: 7 | loss: 0.6252192
[36m(_train_fn pid=793538)[0m 	speed: 0.0255s/iter; left time: 3.6930s
[36m(_train_fn pid=793538)[0m Updating learning rate to 9.65646844548086e-06
[36m(_train_fn pid=793538)[0m saving checkpoint...
[36m(_train_fn pid=793538)[0m Validation loss decreased (1.6031 --> 1.6019).  Saving model state dict ...
[36m(_train_fn pid=793538)[0m Epoch: 7 cost time: 2.1557669639587402
[36m(_train_fn pid=793538)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6236087 Vali Loss: 1.6018921 Best vali loss: 1.6018921
[36m(_train_fn pid=793538)[0m 	iters: 100, epoch: 8 | loss: 0.6281572
[36m(_train_fn pid=793538)[0m 	speed: 0.0256s/iter; left time: 0.5878s
[36m(_train_fn pid=793538)[0m Updating learning rate to 4.82823422274043e-06
[36m(_train_fn pid=793538)[0m saving checkpoint...
[36m(_train_fn pid=793538)[0m Validation loss decreased (1.6019 --> 1.6014).  Saving model state dict ...
[36m(_train_fn pid=793538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1a61e553_81_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1024,e_layers_2024-08-24_08-30-29/checkpoint_000007)
2024-08-24 08:30:52,797	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:30:56,388	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:30:57,654	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:30:58,901	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=794256)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-894051e7_82_alpha_d_ff=3,batch_size=128,d_model=32,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_08-30-52/checkpoint_000002)[32m [repeated 3x across cluster][0m
2024-08-24 08:31:00,156	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:31:01,407	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:31:02,649	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:31:07,090	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=794793)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6e9c3025_83_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=0_2024-08-24_08-31-02/checkpoint_000000)[32m [repeated 4x across cluster][0m
2024-08-24 08:31:08,950	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=793538)[0m Epoch: 8 cost time: 2.1550660133361816
[36m(_train_fn pid=793538)[0m Epoch: 8, Steps: 122 | Train Loss: 0.6230837 Vali Loss: 1.6013753 Best vali loss: 1.6013753

Trial trial-1a61e553 completed after 8 iterations at 2024-08-24 08:30:52. Total running time: 1hr 9min 44s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1a61e553 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          2.55535 â”‚
â”‚ time_total_s                             21.26386 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.60138 â”‚
â”‚ train_loss                                0.62308 â”‚
â”‚ valid_loss                                1.60138 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-894051e7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-894051e7 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.06945 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.01154 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=794256)[0m configuration
[36m(_train_fn pid=794256)[0m {'batch_size': 128, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'conv', 'dropout': 0.06945066126799361, 'e_layers': 1, 'learning_rate': 0.01153911809822625, 'd_ff': 96}
[36m(_train_fn pid=794256)[0m Use GPU: cuda:0
[36m(_train_fn pid=794256)[0m train 7825
[36m(_train_fn pid=794256)[0m val 2161
[36m(_train_fn pid=794256)[0m start_epoch 0
[36m(_train_fn pid=794256)[0m max_epoch 8
[36m(_train_fn pid=794256)[0m Validation loss decreased (inf --> 1.8992).  Saving model state dict ...
[36m(_train_fn pid=794256)[0m Epoch: 1 cost time: 1.275364875793457
[36m(_train_fn pid=794256)[0m Epoch: 1, Steps: 61 | Train Loss: 0.9241420 Vali Loss: 1.8991923 Best vali loss: 1.8991923
[36m(_train_fn pid=794256)[0m Epoch: 2 cost time: 1.0577759742736816
[36m(_train_fn pid=794256)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6669082 Vali Loss: 1.6238419 Best vali loss: 1.6238419
[36m(_train_fn pid=794256)[0m Epoch: 3 cost time: 1.0604979991912842
[36m(_train_fn pid=794256)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6098790 Vali Loss: 1.5974793 Best vali loss: 1.5974793
[36m(_train_fn pid=794256)[0m Updating learning rate to 0.0028847795245565623[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=794256)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=794256)[0m Validation loss decreased (1.6238 --> 1.5975).  Saving model state dict ...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=794256)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=794256)[0m Epoch: 4 cost time: 1.059161901473999
[36m(_train_fn pid=794256)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5904586 Vali Loss: 1.6291578 Best vali loss: 1.5974793
[36m(_train_fn pid=794256)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=794256)[0m Epoch: 5 cost time: 1.0561251640319824
[36m(_train_fn pid=794256)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5751327 Vali Loss: 1.6359808 Best vali loss: 1.5974793

Trial trial-894051e7 completed after 6 iterations at 2024-08-24 08:31:02. Total running time: 1hr 9min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-894051e7 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          1.24216 â”‚
â”‚ time_total_s                              8.12102 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.59748 â”‚
â”‚ train_loss                                0.56689 â”‚
â”‚ valid_loss                                1.64767 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=794256)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=794256)[0m Epoch: 6 cost time: 1.0544862747192383
[36m(_train_fn pid=794256)[0m Epoch: 6, Steps: 61 | Train Loss: 0.5668859 Vali Loss: 1.6476653 Best vali loss: 1.5974793
[36m(_train_fn pid=794256)[0m Early stopping

Trial trial-6e9c3025 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6e9c3025 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07773 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00347 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=794793)[0m configuration
[36m(_train_fn pid=794793)[0m {'batch_size': 64, 'd_model': 16, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'conv', 'dropout': 0.07772600884978405, 'e_layers': 3, 'learning_rate': 0.0034705600299796916, 'd_ff': 64}
[36m(_train_fn pid=794793)[0m Use GPU: cuda:0
[36m(_train_fn pid=794256)[0m Updating learning rate to 0.0003605974405695703[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=794256)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=794793)[0m train 7825
[36m(_train_fn pid=794793)[0m val 2161
[36m(_train_fn pid=794793)[0m start_epoch 0
[36m(_train_fn pid=794793)[0m max_epoch 8
[36m(_train_fn pid=794793)[0m 	iters: 100, epoch: 1 | loss: 0.9481775
[36m(_train_fn pid=794793)[0m 	speed: 0.0183s/iter; left time: 16.0505s
[36m(_train_fn pid=794793)[0m Validation loss decreased (inf --> 2.0146).  Saving model state dict ...
[36m(_train_fn pid=794793)[0m Epoch: 1 cost time: 1.880305290222168
[36m(_train_fn pid=794793)[0m Epoch: 1, Steps: 122 | Train Loss: 1.0363865 Vali Loss: 2.0146399 Best vali loss: 2.0146399
[36m(_train_fn pid=794793)[0m 	iters: 100, epoch: 2 | loss: 0.6188478
[36m(_train_fn pid=794793)[0m 	speed: 0.0189s/iter; left time: 14.2611s
[36m(_train_fn pid=794793)[0m Validation loss decreased (2.0146 --> 1.5994).  Saving model state dict ...
[36m(_train_fn pid=794793)[0m Epoch: 2 cost time: 1.626044511795044
2024-08-24 08:31:10,832	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:31:12,710	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=794793)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6e9c3025_83_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=0_2024-08-24_08-31-02/checkpoint_000003)[32m [repeated 3x across cluster][0m
2024-08-24 08:31:14,504	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795268)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4ce91de3_84_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_08-31-14/checkpoint_000000)[32m [repeated 2x across cluster][0m
2024-08-24 08:31:25,401	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:31:29,536	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795268)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4ce91de3_84_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_08-31-14/checkpoint_000002)[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=794793)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6412635 Vali Loss: 1.5993547 Best vali loss: 1.5993547
[36m(_train_fn pid=794793)[0m 	iters: 100, epoch: 3 | loss: 0.6382336
[36m(_train_fn pid=794793)[0m 	speed: 0.0187s/iter; left time: 11.8478s
[36m(_train_fn pid=794793)[0m Updating learning rate to 0.0017352800149898458[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=794793)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=794793)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=794793)[0m Epoch: 3 cost time: 1.6337063312530518
[36m(_train_fn pid=794793)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5824295 Vali Loss: 1.6327899 Best vali loss: 1.5993547
[36m(_train_fn pid=794793)[0m 	iters: 100, epoch: 4 | loss: 0.5357495
[36m(_train_fn pid=794793)[0m 	speed: 0.0188s/iter; left time: 9.6013s
[36m(_train_fn pid=794793)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=794793)[0m Epoch: 4 cost time: 1.6240768432617188
[36m(_train_fn pid=794793)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5682892 Vali Loss: 1.6334417 Best vali loss: 1.5993547
[36m(_train_fn pid=794793)[0m 	iters: 100, epoch: 5 | loss: 0.5496178
[36m(_train_fn pid=794793)[0m 	speed: 0.0181s/iter; left time: 7.0406s

Trial trial-6e9c3025 completed after 5 iterations at 2024-08-24 08:31:14. Total running time: 1hr 10min 5s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6e9c3025 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.79316 â”‚
â”‚ time_total_s                              9.96499 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59935 â”‚
â”‚ train_loss                                0.56095 â”‚
â”‚ valid_loss                                1.63151 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=794793)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=794793)[0m Epoch: 5 cost time: 1.55257248878479
[36m(_train_fn pid=794793)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5609546 Vali Loss: 1.6315148 Best vali loss: 1.5993547
[36m(_train_fn pid=794793)[0m Early stopping

Trial status: 83 TERMINATED | 1 PENDING
Current time: 2024-08-24 08:31:15. Total running time: 1hr 10min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-4ce91de3   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
78 more TERMINATED

Trial trial-4ce91de3 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4ce91de3 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.06741 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0008 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=795268)[0m configuration
[36m(_train_fn pid=795268)[0m {'batch_size': 64, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'avg', 'dropout': 0.06741081840287032, 'e_layers': 1, 'learning_rate': 0.0008013598029162535, 'd_ff': 384}
[36m(_train_fn pid=795268)[0m Use GPU: cuda:0
[36m(_train_fn pid=794793)[0m Updating learning rate to 0.00021691000187373073[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=794793)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=795268)[0m train 7825
[36m(_train_fn pid=795268)[0m val 2161
[36m(_train_fn pid=795268)[0m start_epoch 0
[36m(_train_fn pid=795268)[0m max_epoch 8
[36m(_train_fn pid=795268)[0m 	iters: 100, epoch: 1 | loss: 0.8113561
[36m(_train_fn pid=795268)[0m 	speed: 0.0345s/iter; left time: 30.2599s
[36m(_train_fn pid=795268)[0m Validation loss decreased (inf --> 1.9519).  Saving model state dict ...
[36m(_train_fn pid=795268)[0m Epoch: 1 cost time: 3.8415565490722656
[36m(_train_fn pid=795268)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8002924 Vali Loss: 1.9519172 Best vali loss: 1.9519172
[36m(_train_fn pid=795268)[0m 	iters: 100, epoch: 2 | loss: 0.6489648
[36m(_train_fn pid=795268)[0m 	speed: 0.0414s/iter; left time: 31.2657s
[36m(_train_fn pid=795268)[0m Updating learning rate to 0.0008013598029162535
[36m(_train_fn pid=795268)[0m saving checkpoint...
[36m(_train_fn pid=795268)[0m Updating learning rate to 0.00040067990145812676
[36m(_train_fn pid=795268)[0m saving checkpoint...
[36m(_train_fn pid=795268)[0m Validation loss decreased (1.9519 --> 1.5846).  Saving model state dict ...
[36m(_train_fn pid=795268)[0m Epoch: 2 cost time: 3.644167184829712
[36m(_train_fn pid=795268)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6669285 Vali Loss: 1.5845533 Best vali loss: 1.5845533
[36m(_train_fn pid=795268)[0m 	iters: 100, epoch: 3 | loss: 0.5875812
[36m(_train_fn pid=795268)[0m 	speed: 0.0414s/iter; left time: 26.2221s
[36m(_train_fn pid=795268)[0m Updating learning rate to 0.00020033995072906338
[36m(_train_fn pid=795268)[0m saving checkpoint...
[36m(_train_fn pid=795268)[0m Validation loss decreased (1.5846 --> 1.5806).  Saving model state dict ...
2024-08-24 08:31:33,691	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:31:37,828	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795268)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4ce91de3_84_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_08-31-14/checkpoint_000004)[32m [repeated 2x across cluster][0m
2024-08-24 08:31:41,964	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:31:46,115	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795268)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4ce91de3_84_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_08-31-14/checkpoint_000006)[32m [repeated 2x across cluster][0m
2024-08-24 08:32:10,542	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795268)[0m Epoch: 3 cost time: 3.6504228115081787
[36m(_train_fn pid=795268)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6174289 Vali Loss: 1.5805856 Best vali loss: 1.5805856
[36m(_train_fn pid=795268)[0m 	iters: 100, epoch: 4 | loss: 0.6079794
[36m(_train_fn pid=795268)[0m 	speed: 0.0415s/iter; left time: 21.1871s
[36m(_train_fn pid=795268)[0m Updating learning rate to 0.00010016997536453169
[36m(_train_fn pid=795268)[0m saving checkpoint...
[36m(_train_fn pid=795268)[0m Validation loss decreased (1.5806 --> 1.5773).  Saving model state dict ...
[36m(_train_fn pid=795268)[0m Epoch: 4 cost time: 3.651136636734009
[36m(_train_fn pid=795268)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6143448 Vali Loss: 1.5772815 Best vali loss: 1.5772815
[36m(_train_fn pid=795268)[0m 	iters: 100, epoch: 5 | loss: 0.6361577
[36m(_train_fn pid=795268)[0m 	speed: 0.0414s/iter; left time: 16.1107s
[36m(_train_fn pid=795268)[0m Updating learning rate to 5.0084987682265845e-05
[36m(_train_fn pid=795268)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=795268)[0m saving checkpoint...
[36m(_train_fn pid=795268)[0m Epoch: 5 cost time: 3.6497254371643066
[36m(_train_fn pid=795268)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6132017 Vali Loss: 1.5786585 Best vali loss: 1.5772815
[36m(_train_fn pid=795268)[0m 	iters: 100, epoch: 6 | loss: 0.6445915
[36m(_train_fn pid=795268)[0m 	speed: 0.0414s/iter; left time: 11.0592s
[36m(_train_fn pid=795268)[0m Updating learning rate to 2.5042493841132923e-05
[36m(_train_fn pid=795268)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=795268)[0m saving checkpoint...
[36m(_train_fn pid=795268)[0m Epoch: 6 cost time: 3.655245065689087
[36m(_train_fn pid=795268)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6121938 Vali Loss: 1.5779533 Best vali loss: 1.5772815
[36m(_train_fn pid=795268)[0m 	iters: 100, epoch: 7 | loss: 0.6458628
[36m(_train_fn pid=795268)[0m 	speed: 0.0415s/iter; left time: 6.0114s

Trial status: 83 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:31:45. Total running time: 1hr 10min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4ce91de3   RUNNING           6            25.4358       0.612194        1.57795             1.57728 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
78 more TERMINATED

Trial trial-4ce91de3 completed after 7 iterations at 2024-08-24 08:31:46. Total running time: 1hr 10min 37s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4ce91de3 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          4.14196 â”‚
â”‚ time_total_s                             29.57779 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.57728 â”‚
â”‚ train_loss                                 0.6118 â”‚
â”‚ valid_loss                                1.57817 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=795268)[0m Updating learning rate to 1.2521246920566461e-05
[36m(_train_fn pid=795268)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=795268)[0m saving checkpoint...
[36m(_train_fn pid=795268)[0m Epoch: 7 cost time: 3.6563124656677246
[36m(_train_fn pid=795268)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6118019 Vali Loss: 1.5781677 Best vali loss: 1.5772815
[36m(_train_fn pid=795268)[0m Early stopping

Trial trial-ca404878 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ca404878 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09947 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00054 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=795939)[0m configuration
[36m(_train_fn pid=795939)[0m {'batch_size': 16, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.09947178905355052, 'e_layers': 4, 'learning_rate': 0.0005415875300512141, 'd_ff': 512}
[36m(_train_fn pid=795939)[0m Use GPU: cuda:0
[36m(_train_fn pid=795939)[0m train 7825
[36m(_train_fn pid=795939)[0m val 2161
[36m(_train_fn pid=795939)[0m start_epoch 0
[36m(_train_fn pid=795939)[0m max_epoch 8
[36m(_train_fn pid=795939)[0m 	iters: 100, epoch: 1 | loss: 0.8645089
[36m(_train_fn pid=795939)[0m 	speed: 0.0451s/iter; left time: 172.0037s
[36m(_train_fn pid=795939)[0m 	iters: 200, epoch: 1 | loss: 0.7898171
[36m(_train_fn pid=795939)[0m 	speed: 0.0382s/iter; left time: 141.7249s
[36m(_train_fn pid=795939)[0m 	iters: 300, epoch: 1 | loss: 0.7585540
[36m(_train_fn pid=795939)[0m 	speed: 0.0382s/iter; left time: 137.9251s
[36m(_train_fn pid=795939)[0m 	iters: 400, epoch: 1 | loss: 0.7341688
[36m(_train_fn pid=795939)[0m 	speed: 0.0382s/iter; left time: 134.1577s
[36m(_train_fn pid=795939)[0m Updating learning rate to 0.0005415875300512141
[36m(_train_fn pid=795939)[0m saving checkpoint...
[36m(_train_fn pid=795939)[0m Validation loss decreased (inf --> 1.9341).  Saving model state dict ...
[36m(_train_fn pid=795939)[0m Epoch: 1 cost time: 19.10978651046753
[36m(_train_fn pid=795939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ca404878_85_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0995,e_layers_2024-08-24_08-31-46/checkpoint_000000)
2024-08-24 08:32:31,837	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ca404878_85_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0995,e_layers_2024-08-24_08-31-46/checkpoint_000001)
2024-08-24 08:32:53,181	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ca404878_85_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0995,e_layers_2024-08-24_08-31-46/checkpoint_000002)
2024-08-24 08:33:14,513	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ca404878_85_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0995,e_layers_2024-08-24_08-31-46/checkpoint_000003)
[36m(_train_fn pid=795939)[0m Epoch: 1, Steps: 489 | Train Loss: 0.8058843 Vali Loss: 1.9341472 Best vali loss: 1.9341472
[36m(_train_fn pid=795939)[0m 	iters: 100, epoch: 2 | loss: 0.5072255
[36m(_train_fn pid=795939)[0m 	speed: 0.0979s/iter; left time: 325.2856s

Trial status: 84 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:32:16. Total running time: 1hr 11min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ca404878   RUNNING           1            22.0373       0.805884        1.93415             1.93415 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
79 more TERMINATED
[36m(_train_fn pid=795939)[0m 	iters: 200, epoch: 2 | loss: 0.6822186
[36m(_train_fn pid=795939)[0m 	speed: 0.0383s/iter; left time: 123.5367s
[36m(_train_fn pid=795939)[0m 	iters: 300, epoch: 2 | loss: 0.4911174
[36m(_train_fn pid=795939)[0m 	speed: 0.0383s/iter; left time: 119.5121s
[36m(_train_fn pid=795939)[0m 	iters: 400, epoch: 2 | loss: 0.5982210
[36m(_train_fn pid=795939)[0m 	speed: 0.0383s/iter; left time: 115.8347s
[36m(_train_fn pid=795939)[0m Updating learning rate to 0.00027079376502560707
[36m(_train_fn pid=795939)[0m saving checkpoint...
[36m(_train_fn pid=795939)[0m Validation loss decreased (1.9341 --> 1.5907).  Saving model state dict ...
[36m(_train_fn pid=795939)[0m Epoch: 2 cost time: 18.75890350341797
[36m(_train_fn pid=795939)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6317959 Vali Loss: 1.5907421 Best vali loss: 1.5907421
[36m(_train_fn pid=795939)[0m 	iters: 100, epoch: 3 | loss: 0.6847441
[36m(_train_fn pid=795939)[0m 	speed: 0.0981s/iter; left time: 278.1668s
[36m(_train_fn pid=795939)[0m 	iters: 200, epoch: 3 | loss: 0.6348478
[36m(_train_fn pid=795939)[0m 	speed: 0.0383s/iter; left time: 104.6732s
[36m(_train_fn pid=795939)[0m 	iters: 300, epoch: 3 | loss: 0.6629941
[36m(_train_fn pid=795939)[0m 	speed: 0.0383s/iter; left time: 100.8768s
Trial status: 84 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:32:46. Total running time: 1hr 11min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ca404878   RUNNING           2            43.3377       0.631796        1.59074             1.59074 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
79 more TERMINATED
[36m(_train_fn pid=795939)[0m 	iters: 400, epoch: 3 | loss: 0.6482365
[36m(_train_fn pid=795939)[0m 	speed: 0.0384s/iter; left time: 97.2931s
[36m(_train_fn pid=795939)[0m Updating learning rate to 0.00013539688251280353
[36m(_train_fn pid=795939)[0m saving checkpoint...
[36m(_train_fn pid=795939)[0m Validation loss decreased (1.5907 --> 1.5706).  Saving model state dict ...
[36m(_train_fn pid=795939)[0m Epoch: 3 cost time: 18.771364450454712
[36m(_train_fn pid=795939)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5996366 Vali Loss: 1.5705931 Best vali loss: 1.5705931
[36m(_train_fn pid=795939)[0m 	iters: 100, epoch: 4 | loss: 0.5850527
[36m(_train_fn pid=795939)[0m 	speed: 0.0985s/iter; left time: 231.1232s
[36m(_train_fn pid=795939)[0m 	iters: 200, epoch: 4 | loss: 0.5721622
[36m(_train_fn pid=795939)[0m 	speed: 0.0383s/iter; left time: 86.0741s
[36m(_train_fn pid=795939)[0m 	iters: 300, epoch: 4 | loss: 0.5307757
[36m(_train_fn pid=795939)[0m 	speed: 0.0383s/iter; left time: 82.2269s
[36m(_train_fn pid=795939)[0m 	iters: 400, epoch: 4 | loss: 0.6995435
[36m(_train_fn pid=795939)[0m 	speed: 0.0383s/iter; left time: 78.4062s
[36m(_train_fn pid=795939)[0m Updating learning rate to 6.769844125640177e-05
[36m(_train_fn pid=795939)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=795939)[0m saving checkpoint...
[36m(_train_fn pid=795939)[0m Epoch: 4 cost time: 18.78527283668518
[36m(_train_fn pid=795939)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5832528 Vali Loss: 1.5771576 Best vali loss: 1.5705931
Trial status: 84 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:33:16. Total running time: 1hr 12min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 08:33:35,937	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=795939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ca404878_85_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0995,e_layers_2024-08-24_08-31-46/checkpoint_000004)
[36m(_train_fn pid=796703)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3dae9915_86_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=0_2024-08-24_08-33-35/checkpoint_000000)
[36m(_train_fn pid=796703)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3dae9915_86_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=0_2024-08-24_08-33-35/checkpoint_000001)
2024-08-24 08:33:43,012	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:33:44,945	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=796703)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3dae9915_86_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=0_2024-08-24_08-33-35/checkpoint_000002)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ca404878   RUNNING           4            85.9952       0.583253        1.57716             1.57059 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
79 more TERMINATED
[36m(_train_fn pid=795939)[0m 	iters: 100, epoch: 5 | loss: 0.6208233
[36m(_train_fn pid=795939)[0m 	speed: 0.0984s/iter; left time: 182.7015s
[36m(_train_fn pid=795939)[0m 	iters: 200, epoch: 5 | loss: 0.5394356
[36m(_train_fn pid=795939)[0m 	speed: 0.0385s/iter; left time: 67.6656s
[36m(_train_fn pid=795939)[0m 	iters: 300, epoch: 5 | loss: 0.6484244
[36m(_train_fn pid=795939)[0m 	speed: 0.0385s/iter; left time: 63.7964s
[36m(_train_fn pid=795939)[0m 	iters: 400, epoch: 5 | loss: 0.6239251
[36m(_train_fn pid=795939)[0m 	speed: 0.0385s/iter; left time: 59.9858s
[36m(_train_fn pid=795939)[0m Updating learning rate to 3.384922062820088e-05
[36m(_train_fn pid=795939)[0m saving checkpoint...
[36m(_train_fn pid=795939)[0m Validation loss decreased (1.5706 --> 1.5700).  Saving model state dict ...

Trial trial-ca404878 completed after 5 iterations at 2024-08-24 08:33:35. Total running time: 1hr 12min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ca404878 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                           21.422 â”‚
â”‚ time_total_s                            107.41723 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.57004 â”‚
â”‚ train_loss                                0.57043 â”‚
â”‚ valid_loss                                1.57004 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-3dae9915 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3dae9915 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.12025 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00132 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=796703)[0m configuration
[36m(_train_fn pid=796703)[0m {'batch_size': 64, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'conv', 'dropout': 0.12025209973288069, 'e_layers': 2, 'learning_rate': 0.0013174860472418518, 'd_ff': 128}
[36m(_train_fn pid=796703)[0m Use GPU: cuda:0
[36m(_train_fn pid=796703)[0m train 7825
[36m(_train_fn pid=796703)[0m val 2161
[36m(_train_fn pid=796703)[0m start_epoch 0
[36m(_train_fn pid=796703)[0m max_epoch 8
[36m(_train_fn pid=796703)[0m 	iters: 100, epoch: 1 | loss: 0.8898296
[36m(_train_fn pid=796703)[0m 	speed: 0.0186s/iter; left time: 16.3147s
[36m(_train_fn pid=796703)[0m Validation loss decreased (inf --> 2.1903).  Saving model state dict ...
[36m(_train_fn pid=796703)[0m Epoch: 1 cost time: 1.8921759128570557
[36m(_train_fn pid=796703)[0m Epoch: 1, Steps: 122 | Train Loss: 1.0108425 Vali Loss: 2.1902811 Best vali loss: 2.1902811
[36m(_train_fn pid=796703)[0m Updating learning rate to 0.0013174860472418518
[36m(_train_fn pid=796703)[0m saving checkpoint...
[36m(_train_fn pid=796703)[0m 	iters: 100, epoch: 2 | loss: 0.5823579
[36m(_train_fn pid=796703)[0m 	speed: 0.0192s/iter; left time: 14.5069s
[36m(_train_fn pid=796703)[0m Updating learning rate to 0.0006587430236209259
[36m(_train_fn pid=796703)[0m saving checkpoint...
[36m(_train_fn pid=796703)[0m Validation loss decreased (2.1903 --> 1.6034).  Saving model state dict ...
[36m(_train_fn pid=796703)[0m Epoch: 2 cost time: 1.6471474170684814
[36m(_train_fn pid=796703)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6977319 Vali Loss: 1.6034420 Best vali loss: 1.6034420
[36m(_train_fn pid=796703)[0m 	iters: 100, epoch: 3 | loss: 0.6395042
[36m(_train_fn pid=796703)[0m 	speed: 0.0193s/iter; left time: 12.2454s
[36m(_train_fn pid=796703)[0m Updating learning rate to 0.00032937151181046295
[36m(_train_fn pid=796703)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=796703)[0m saving checkpoint...
[36m(_train_fn pid=796703)[0m Epoch: 3 cost time: 1.6627683639526367
[36m(_train_fn pid=796703)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6078739 Vali Loss: 1.6083004 Best vali loss: 1.6034420

Trial status: 85 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:33:46. Total running time: 1hr 12min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:33:46,854	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=796703)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3dae9915_86_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=0_2024-08-24_08-33-35/checkpoint_000003)
2024-08-24 08:33:48,770	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=796703)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3dae9915_86_alpha_d_ff=4,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=0_2024-08-24_08-33-35/checkpoint_000004)
[36m(_train_fn pid=797178)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-da8c1684_87_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.0_2024-08-24_08-33-48/checkpoint_000000)
2024-08-24 08:33:58,032	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=797178)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-da8c1684_87_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.0_2024-08-24_08-33-48/checkpoint_000001)
2024-08-24 08:34:01,484	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=797178)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-da8c1684_87_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.0_2024-08-24_08-33-48/checkpoint_000002)
2024-08-24 08:34:04,975	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=797178)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-da8c1684_87_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.0_2024-08-24_08-33-48/checkpoint_000003)
2024-08-24 08:34:08,420	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3dae9915   RUNNING           3            6.40889       0.607874        1.6083              1.60344 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
80 more TERMINATED
[36m(_train_fn pid=796703)[0m 	iters: 100, epoch: 4 | loss: 0.5825737
[36m(_train_fn pid=796703)[0m 	speed: 0.0192s/iter; left time: 9.8031s
[36m(_train_fn pid=796703)[0m Updating learning rate to 0.00016468575590523147
[36m(_train_fn pid=796703)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=796703)[0m saving checkpoint...
[36m(_train_fn pid=796703)[0m Epoch: 4 cost time: 1.6411337852478027
[36m(_train_fn pid=796703)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5945705 Vali Loss: 1.6119184 Best vali loss: 1.6034420
[36m(_train_fn pid=796703)[0m 	iters: 100, epoch: 5 | loss: 0.5877858
[36m(_train_fn pid=796703)[0m 	speed: 0.0191s/iter; left time: 7.4255s

Trial trial-3dae9915 completed after 5 iterations at 2024-08-24 08:33:48. Total running time: 1hr 12min 39s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3dae9915 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.92413 â”‚
â”‚ time_total_s                              10.2391 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.60344 â”‚
â”‚ train_loss                                0.59078 â”‚
â”‚ valid_loss                                1.62003 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=796703)[0m Updating learning rate to 8.234287795261574e-05
[36m(_train_fn pid=796703)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=796703)[0m saving checkpoint...
[36m(_train_fn pid=796703)[0m Epoch: 5 cost time: 1.643341302871704
[36m(_train_fn pid=796703)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5907774 Vali Loss: 1.6200262 Best vali loss: 1.6034420
[36m(_train_fn pid=796703)[0m Early stopping

Trial trial-da8c1684 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-da8c1684 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.05991 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00095 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=797178)[0m configuration
[36m(_train_fn pid=797178)[0m {'batch_size': 16, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.05990626439268894, 'e_layers': 1, 'learning_rate': 0.0009455928931254776, 'd_ff': 32}
[36m(_train_fn pid=797178)[0m Use GPU: cuda:0
[36m(_train_fn pid=797178)[0m train 7825
[36m(_train_fn pid=797178)[0m val 2161
[36m(_train_fn pid=797178)[0m start_epoch 0
[36m(_train_fn pid=797178)[0m max_epoch 8
[36m(_train_fn pid=797178)[0m 	iters: 400, epoch: 1 | loss: 0.8308697[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=797178)[0m 	speed: 0.0062s/iter; left time: 21.9401s[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=797178)[0m Validation loss decreased (inf --> 1.9326).  Saving model state dict ...
[36m(_train_fn pid=797178)[0m Epoch: 1 cost time: 3.296163558959961
[36m(_train_fn pid=797178)[0m Epoch: 1, Steps: 489 | Train Loss: 1.0254168 Vali Loss: 1.9325911 Best vali loss: 1.9325911
[36m(_train_fn pid=797178)[0m Updating learning rate to 0.0009455928931254776
[36m(_train_fn pid=797178)[0m saving checkpoint...
[36m(_train_fn pid=797178)[0m Updating learning rate to 0.0004727964465627388
[36m(_train_fn pid=797178)[0m saving checkpoint...
[36m(_train_fn pid=797178)[0m Validation loss decreased (1.9326 --> 1.5674).  Saving model state dict ...
[36m(_train_fn pid=797178)[0m Epoch: 2 cost time: 3.0691051483154297
[36m(_train_fn pid=797178)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6301838 Vali Loss: 1.5674363 Best vali loss: 1.5674363
[36m(_train_fn pid=797178)[0m 	iters: 100, epoch: 3 | loss: 0.5755271[32m [repeated 5x across cluster][0m
[36m(_train_fn pid=797178)[0m 	speed: 0.0159s/iter; left time: 45.1004s[32m [repeated 5x across cluster][0m
[36m(_train_fn pid=797178)[0m Updating learning rate to 0.0002363982232813694
[36m(_train_fn pid=797178)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=797178)[0m saving checkpoint...
[36m(_train_fn pid=797178)[0m Epoch: 3 cost time: 3.1013150215148926
[36m(_train_fn pid=797178)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5971569 Vali Loss: 1.5770892 Best vali loss: 1.5674363
[36m(_train_fn pid=797178)[0m 	iters: 400, epoch: 4 | loss: 0.5413019[32m [repeated 7x across cluster][0m
[36m(_train_fn pid=797178)[0m 	speed: 0.0063s/iter; left time: 12.9875s[32m [repeated 7x across cluster][0m
[36m(_train_fn pid=797178)[0m Updating learning rate to 0.0001181991116406847
[36m(_train_fn pid=797178)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=797178)[0m saving checkpoint...
[36m(_train_fn pid=797178)[0m Epoch: 4 cost time: 3.1195852756500244
[36m(_train_fn pid=797178)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5867283 Vali Loss: 1.5851481 Best vali loss: 1.5674363

Trial trial-da8c1684 completed after 5 iterations at 2024-08-24 08:34:08. Total running time: 1hr 12min 59s
[36m(_train_fn pid=797178)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-da8c1684_87_alpha_d_ff=4,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0.0_2024-08-24_08-33-48/checkpoint_000004)
[36m(_train_fn pid=797674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b8c443a6_88_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0902,e_layers=3_2024-08-24_08-34-08/checkpoint_000000)
2024-08-24 08:34:17,327	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=797674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b8c443a6_88_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0902,e_layers=3_2024-08-24_08-34-08/checkpoint_000001)
2024-08-24 08:34:20,137	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=797674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b8c443a6_88_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0902,e_layers=3_2024-08-24_08-34-08/checkpoint_000002)
2024-08-24 08:34:23,211	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=797674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b8c443a6_88_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0902,e_layers=3_2024-08-24_08-34-08/checkpoint_000003)
[36m(_train_fn pid=797674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b8c443a6_88_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0902,e_layers=3_2024-08-24_08-34-08/checkpoint_000004)
2024-08-24 08:34:26,301	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-da8c1684 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.45316 â”‚
â”‚ time_total_s                              17.8898 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56744 â”‚
â”‚ train_loss                                0.58313 â”‚
â”‚ valid_loss                                1.58246 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=797178)[0m Updating learning rate to 5.909955582034235e-05
[36m(_train_fn pid=797178)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=797178)[0m saving checkpoint...
[36m(_train_fn pid=797178)[0m Epoch: 5 cost time: 3.0959277153015137
[36m(_train_fn pid=797178)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5831284 Vali Loss: 1.5824584 Best vali loss: 1.5674363
[36m(_train_fn pid=797178)[0m Early stopping

Trial trial-b8c443a6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b8c443a6 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09017 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00131 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=797674)[0m configuration
[36m(_train_fn pid=797674)[0m {'batch_size': 32, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.09017473851698089, 'e_layers': 3, 'learning_rate': 0.0013085404576072411, 'd_ff': 32}
[36m(_train_fn pid=797674)[0m Use GPU: cuda:0
[36m(_train_fn pid=797178)[0m 	iters: 400, epoch: 5 | loss: 0.6563496[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=797178)[0m 	speed: 0.0062s/iter; left time: 9.6936s[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=797674)[0m train 7825
[36m(_train_fn pid=797674)[0m val 2161
[36m(_train_fn pid=797674)[0m start_epoch 0
[36m(_train_fn pid=797674)[0m max_epoch 8
[36m(_train_fn pid=797674)[0m Updating learning rate to 0.0013085404576072411
[36m(_train_fn pid=797674)[0m saving checkpoint...
[36m(_train_fn pid=797674)[0m Validation loss decreased (inf --> 2.1160).  Saving model state dict ...
[36m(_train_fn pid=797674)[0m Epoch: 1 cost time: 3.1845450401306152
[36m(_train_fn pid=797674)[0m Epoch: 1, Steps: 244 | Train Loss: 1.1661893 Vali Loss: 2.1159759 Best vali loss: 2.1159759

Trial status: 87 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:34:16. Total running time: 1hr 13min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b8c443a6   RUNNING           1            3.92643       1.16619         2.11598             2.11598 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
82 more TERMINATED
[36m(_train_fn pid=797674)[0m 	iters: 200, epoch: 2 | loss: 0.6211193[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=797674)[0m 	speed: 0.0103s/iter; left time: 15.4815s[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=797674)[0m Updating learning rate to 0.0006542702288036206
[36m(_train_fn pid=797674)[0m saving checkpoint...
[36m(_train_fn pid=797674)[0m Validation loss decreased (2.1160 --> 1.5960).  Saving model state dict ...
[36m(_train_fn pid=797674)[0m Epoch: 2 cost time: 2.542431354522705
[36m(_train_fn pid=797674)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6636732 Vali Loss: 1.5960266 Best vali loss: 1.5960266
[36m(_train_fn pid=797674)[0m Updating learning rate to 0.0003271351144018103
[36m(_train_fn pid=797674)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=797674)[0m saving checkpoint...
[36m(_train_fn pid=797674)[0m Epoch: 3 cost time: 2.4789037704467773
[36m(_train_fn pid=797674)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6017642 Vali Loss: 1.6121414 Best vali loss: 1.5960266
[36m(_train_fn pid=797674)[0m 	iters: 200, epoch: 4 | loss: 0.5547572[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=797674)[0m 	speed: 0.0110s/iter; left time: 11.2410s[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=797674)[0m Updating learning rate to 0.00016356755720090514
[36m(_train_fn pid=797674)[0m saving checkpoint...
[36m(_train_fn pid=797674)[0m Validation loss decreased (1.5960 --> 1.5897).  Saving model state dict ...
[36m(_train_fn pid=797674)[0m Epoch: 4 cost time: 2.7374961376190186
[36m(_train_fn pid=797674)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5913342 Vali Loss: 1.5897158 Best vali loss: 1.5897158
[36m(_train_fn pid=797674)[0m Updating learning rate to 8.178377860045257e-05
[36m(_train_fn pid=797674)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=797674)[0m saving checkpoint...
[36m(_train_fn pid=797674)[0m Epoch: 5 cost time: 2.7465624809265137
[36m(_train_fn pid=797674)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5860813 Vali Loss: 1.5920969 Best vali loss: 1.5897158
[36m(_train_fn pid=797674)[0m 	iters: 100, epoch: 6 | loss: 0.5130737[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=797674)[0m 	speed: 0.0199s/iter; left time: 12.5836s[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=797674)[0m Updating learning rate to 4.0891889300226285e-05
[36m(_train_fn pid=797674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b8c443a6_88_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0902,e_layers=3_2024-08-24_08-34-08/checkpoint_000005)
2024-08-24 08:34:29,373	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:34:32,417	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=797674)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b8c443a6_88_alpha_d_ff=4,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0902,e_layers=3_2024-08-24_08-34-08/checkpoint_000006)
[36m(_train_fn pid=797674)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=797674)[0m saving checkpoint...
[36m(_train_fn pid=797674)[0m Epoch: 6 cost time: 2.7499659061431885
[36m(_train_fn pid=797674)[0m Epoch: 6, Steps: 244 | Train Loss: 0.5836497 Vali Loss: 1.5917385 Best vali loss: 1.5897158

Trial trial-b8c443a6 completed after 7 iterations at 2024-08-24 08:34:32. Total running time: 1hr 13min 23s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b8c443a6 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          3.03342 â”‚
â”‚ time_total_s                             21.88524 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58972 â”‚
â”‚ train_loss                                0.58212 â”‚
â”‚ valid_loss                                 1.5913 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=797674)[0m Updating learning rate to 2.0445944650113143e-05
[36m(_train_fn pid=797674)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=797674)[0m saving checkpoint...
[36m(_train_fn pid=797674)[0m Epoch: 7 cost time: 2.6970102787017822
[36m(_train_fn pid=797674)[0m Epoch: 7, Steps: 244 | Train Loss: 0.5821234 Vali Loss: 1.5912981 Best vali loss: 1.5897158
[36m(_train_fn pid=797674)[0m Early stopping
[36m(_train_fn pid=797674)[0m 	iters: 200, epoch: 7 | loss: 0.5442244[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=797674)[0m 	speed: 0.0112s/iter; left time: 3.2332s[32m [repeated 3x across cluster][0m

Trial trial-6f6d7e6d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6f6d7e6d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.12743 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00217 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=798324)[0m configuration
[36m(_train_fn pid=798324)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.12742574873841694, 'e_layers': 4, 'learning_rate': 0.002165198012778008, 'd_ff': 1024}
[36m(_train_fn pid=798324)[0m Use GPU: cuda:0
[36m(_train_fn pid=798324)[0m train 7825
[36m(_train_fn pid=798324)[0m val 2161
[36m(_train_fn pid=798324)[0m start_epoch 0
[36m(_train_fn pid=798324)[0m max_epoch 8

Trial status: 88 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:34:46. Total running time: 1hr 13min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6f6d7e6d   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
83 more TERMINATED
[36m(_train_fn pid=798324)[0m 	iters: 100, epoch: 1 | loss: 0.7637233
[36m(_train_fn pid=798324)[0m 	speed: 0.1625s/iter; left time: 301.1804s
[36m(_train_fn pid=798324)[0m 	iters: 200, epoch: 1 | loss: 0.8075585
[36m(_train_fn pid=798324)[0m 	speed: 0.1570s/iter; left time: 275.2475s
Trial status: 88 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:35:16. Total running time: 1hr 14min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=798324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6f6d7e6d_89_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1274,e_layer_2024-08-24_08-34-32/checkpoint_000000)
2024-08-24 08:36:01,547	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=798324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6f6d7e6d_89_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1274,e_layer_2024-08-24_08-34-32/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6f6d7e6d   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
83 more TERMINATED
[36m(_train_fn pid=798324)[0m Updating learning rate to 0.002165198012778008
[36m(_train_fn pid=798324)[0m saving checkpoint...
[36m(_train_fn pid=798324)[0m Validation loss decreased (inf --> 1.8448).  Saving model state dict ...
[36m(_train_fn pid=798324)[0m Epoch: 1 cost time: 38.626874685287476
[36m(_train_fn pid=798324)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7856722 Vali Loss: 1.8447774 Best vali loss: 1.8447774
[36m(_train_fn pid=798324)[0m 	iters: 100, epoch: 2 | loss: 925096.8750000
[36m(_train_fn pid=798324)[0m 	speed: 0.2749s/iter; left time: 442.2743s
Trial status: 88 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:35:46. Total running time: 1hr 14min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6f6d7e6d   RUNNING           1            43.9623       0.785672        1.84478             1.84478 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
83 more TERMINATED
[36m(_train_fn pid=798324)[0m 	iters: 200, epoch: 2 | loss: 749.2131348
[36m(_train_fn pid=798324)[0m 	speed: 0.1564s/iter; left time: 235.9972s
[36m(_train_fn pid=798324)[0m Updating learning rate to 0.001082599006389004
[36m(_train_fn pid=798324)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=798324)[0m saving checkpoint...
[36m(_train_fn pid=798324)[0m Epoch: 2 cost time: 38.183629751205444
[36m(_train_fn pid=798324)[0m Epoch: 2, Steps: 244 | Train Loss: 202844.2840574 Vali Loss: 478.8978096 Best vali loss: 1.8447774
Trial status: 88 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:36:16. Total running time: 1hr 15min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)      train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6f6d7e6d   RUNNING           2            87.0123   202844             478.898               1.84478 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
83 more TERMINATED
[36m(_train_fn pid=798324)[0m 	iters: 100, epoch: 3 | loss: 116.4565506
[36m(_train_fn pid=798324)[0m 	speed: 0.2741s/iter; left time: 374.1450s
[36m(_train_fn pid=798324)[0m 	iters: 200, epoch: 3 | loss: 97.7827377
[36m(_train_fn pid=798324)[0m 	speed: 0.1566s/iter; left time: 198.1598s

Trial trial-6f6d7e6d completed after 3 iterations at 2024-08-24 08:36:44. Total running time: 1hr 15min 35s
2024-08-24 08:36:44,625	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=798324)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6f6d7e6d_89_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1274,e_layer_2024-08-24_08-34-32/checkpoint_000002)
[36m(_train_fn pid=799013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-062edc2f_90_alpha_d_ff=2,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-36-44/checkpoint_000000)
2024-08-24 08:36:53,606	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=799013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-062edc2f_90_alpha_d_ff=2,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-36-44/checkpoint_000001)
2024-08-24 08:36:56,685	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=799013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-062edc2f_90_alpha_d_ff=2,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-36-44/checkpoint_000002)
2024-08-24 08:36:59,753	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6f6d7e6d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000002 â”‚
â”‚ time_this_iter_s                          43.0752 â”‚
â”‚ time_total_s                            130.08748 â”‚
â”‚ training_iteration                              3 â”‚
â”‚ best_valid_loss                           1.84478 â”‚
â”‚ train_loss                              170.55696 â”‚
â”‚ valid_loss                              426.94567 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=798324)[0m Updating learning rate to 0.000541299503194502
[36m(_train_fn pid=798324)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=798324)[0m saving checkpoint...

Trial status: 89 TERMINATED | 1 PENDING
Current time: 2024-08-24 08:36:46. Total running time: 1hr 15min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-062edc2f   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
84 more TERMINATED

Trial trial-062edc2f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-062edc2f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10112 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00921 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=799013)[0m configuration
[36m(_train_fn pid=799013)[0m {'batch_size': 32, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'avg', 'dropout': 0.10112196568344434, 'e_layers': 3, 'learning_rate': 0.009210178044600057, 'd_ff': 64}
[36m(_train_fn pid=799013)[0m Use GPU: cuda:0
[36m(_train_fn pid=799013)[0m train 7825
[36m(_train_fn pid=799013)[0m val 2161
[36m(_train_fn pid=799013)[0m start_epoch 0
[36m(_train_fn pid=799013)[0m max_epoch 8
[36m(_train_fn pid=799013)[0m 	iters: 100, epoch: 1 | loss: 0.7213448
[36m(_train_fn pid=799013)[0m 	speed: 0.0169s/iter; left time: 31.3004s
[36m(_train_fn pid=799013)[0m 	iters: 200, epoch: 1 | loss: 0.7123765
[36m(_train_fn pid=799013)[0m 	speed: 0.0118s/iter; left time: 20.6072s
[36m(_train_fn pid=799013)[0m Validation loss decreased (inf --> 1.6042).  Saving model state dict ...
[36m(_train_fn pid=799013)[0m Epoch: 1 cost time: 3.125547409057617
[36m(_train_fn pid=799013)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7293333 Vali Loss: 1.6042236 Best vali loss: 1.6042236
[36m(_train_fn pid=799013)[0m Updating learning rate to 0.009210178044600057
[36m(_train_fn pid=799013)[0m saving checkpoint...
[36m(_train_fn pid=799013)[0m 	iters: 100, epoch: 2 | loss: 0.5535843
[36m(_train_fn pid=799013)[0m 	speed: 0.0211s/iter; left time: 33.9013s
[36m(_train_fn pid=799013)[0m 	iters: 200, epoch: 2 | loss: 0.5411226
[36m(_train_fn pid=799013)[0m 	speed: 0.0111s/iter; left time: 16.6851s
[36m(_train_fn pid=799013)[0m Updating learning rate to 0.004605089022300029
[36m(_train_fn pid=799013)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=799013)[0m saving checkpoint...
[36m(_train_fn pid=799013)[0m Epoch: 2 cost time: 2.7991929054260254
[36m(_train_fn pid=799013)[0m Epoch: 2, Steps: 244 | Train Loss: 0.5966322 Vali Loss: 1.6139274 Best vali loss: 1.6042236
[36m(_train_fn pid=799013)[0m 	iters: 100, epoch: 3 | loss: 0.5896968
[36m(_train_fn pid=799013)[0m 	speed: 0.0199s/iter; left time: 27.2179s
[36m(_train_fn pid=799013)[0m 	iters: 200, epoch: 3 | loss: 0.5014847
[36m(_train_fn pid=799013)[0m 	speed: 0.0109s/iter; left time: 13.8389s
[36m(_train_fn pid=799013)[0m Updating learning rate to 0.0023025445111500144
[36m(_train_fn pid=799013)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=799013)[0m saving checkpoint...
[36m(_train_fn pid=799013)[0m Epoch: 3 cost time: 2.714301347732544
[36m(_train_fn pid=799013)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5498852 Vali Loss: 1.6170508 Best vali loss: 1.6042236
[36m(_train_fn pid=799013)[0m 	iters: 100, epoch: 4 | loss: 0.4534634
[36m(_train_fn pid=799013)[0m 	speed: 0.0198s/iter; left time: 22.2496s
[36m(_train_fn pid=799013)[0m 	iters: 200, epoch: 4 | loss: 0.4937013
[36m(_train_fn pid=799013)[0m 	speed: 0.0108s/iter; left time: 11.0710s

Trial trial-062edc2f completed after 4 iterations at 2024-08-24 08:36:59. Total running time: 1hr 15min 50s
[36m(_train_fn pid=799013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-062edc2f_90_alpha_d_ff=2,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0._2024-08-24_08-36-44/checkpoint_000003)
[36m(_train_fn pid=799423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-394da6a5_91_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0975,e_layer_2024-08-24_08-36-59/checkpoint_000000)
2024-08-24 08:37:03,539	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:37:04,735	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=799423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-394da6a5_91_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0975,e_layer_2024-08-24_08-36-59/checkpoint_000001)
2024-08-24 08:37:05,928	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=799423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-394da6a5_91_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0975,e_layer_2024-08-24_08-36-59/checkpoint_000002)
[36m(_train_fn pid=799423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-394da6a5_91_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0975,e_layer_2024-08-24_08-36-59/checkpoint_000003)
2024-08-24 08:37:07,119	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:37:08,329	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=799423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-394da6a5_91_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0975,e_layer_2024-08-24_08-36-59/checkpoint_000004)
2024-08-24 08:37:09,548	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=799423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-394da6a5_91_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0975,e_layer_2024-08-24_08-36-59/checkpoint_000005)
2024-08-24 08:37:10,745	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=799423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-394da6a5_91_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0975,e_layer_2024-08-24_08-36-59/checkpoint_000006)
2024-08-24 08:37:11,963	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=799423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-394da6a5_91_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0975,e_layer_2024-08-24_08-36-59/checkpoint_000007)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-062edc2f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                          3.06645 â”‚
â”‚ time_total_s                             13.21767 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.60422 â”‚
â”‚ train_loss                                 0.5115 â”‚
â”‚ valid_loss                                1.62473 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=799013)[0m Updating learning rate to 0.0011512722555750072
[36m(_train_fn pid=799013)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=799013)[0m saving checkpoint...
[36m(_train_fn pid=799013)[0m Epoch: 4 cost time: 2.703606128692627
[36m(_train_fn pid=799013)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5114979 Vali Loss: 1.6247322 Best vali loss: 1.6042236
[36m(_train_fn pid=799013)[0m Early stopping

Trial trial-394da6a5 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-394da6a5 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09753 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00065 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=799423)[0m configuration
[36m(_train_fn pid=799423)[0m {'batch_size': 128, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.09753448178488207, 'e_layers': 2, 'learning_rate': 0.0006536115856950669, 'd_ff': 32}
[36m(_train_fn pid=799423)[0m Use GPU: cuda:0
[36m(_train_fn pid=799423)[0m train 7825
[36m(_train_fn pid=799423)[0m val 2161
[36m(_train_fn pid=799423)[0m start_epoch 0
[36m(_train_fn pid=799423)[0m max_epoch 8
[36m(_train_fn pid=799423)[0m Validation loss decreased (inf --> 2.6609).  Saving model state dict ...
[36m(_train_fn pid=799423)[0m Epoch: 1 cost time: 1.3942508697509766
[36m(_train_fn pid=799423)[0m Epoch: 1, Steps: 61 | Train Loss: 1.2328744 Vali Loss: 2.6609419 Best vali loss: 2.6609419
[36m(_train_fn pid=799423)[0m Validation loss decreased (2.6609 --> 1.8004).  Saving model state dict ...
[36m(_train_fn pid=799423)[0m Epoch: 2 cost time: 0.9778561592102051
[36m(_train_fn pid=799423)[0m Epoch: 2, Steps: 61 | Train Loss: 0.8658080 Vali Loss: 1.8004437 Best vali loss: 1.8004437
[36m(_train_fn pid=799423)[0m Validation loss decreased (1.8004 --> 1.6670).  Saving model state dict ...
[36m(_train_fn pid=799423)[0m Epoch: 3 cost time: 0.9742937088012695
[36m(_train_fn pid=799423)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6802855 Vali Loss: 1.6670406 Best vali loss: 1.6670406
[36m(_train_fn pid=799423)[0m Updating learning rate to 0.00016340289642376672[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=799423)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=799423)[0m Validation loss decreased (1.6670 --> 1.6462).  Saving model state dict ...
[36m(_train_fn pid=799423)[0m Epoch: 4 cost time: 0.9763598442077637
[36m(_train_fn pid=799423)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6487651 Vali Loss: 1.6461652 Best vali loss: 1.6461652
[36m(_train_fn pid=799423)[0m Validation loss decreased (1.6462 --> 1.6392).  Saving model state dict ...
[36m(_train_fn pid=799423)[0m Epoch: 5 cost time: 0.9941308498382568
[36m(_train_fn pid=799423)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6405784 Vali Loss: 1.6391982 Best vali loss: 1.6391982
[36m(_train_fn pid=799423)[0m Validation loss decreased (1.6392 --> 1.6360).  Saving model state dict ...
[36m(_train_fn pid=799423)[0m Epoch: 6 cost time: 1.0009732246398926
[36m(_train_fn pid=799423)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6370259 Vali Loss: 1.6359947 Best vali loss: 1.6359947
[36m(_train_fn pid=799423)[0m Validation loss decreased (1.6360 --> 1.6345).  Saving model state dict ...
[36m(_train_fn pid=799423)[0m Epoch: 7 cost time: 0.9770638942718506
[36m(_train_fn pid=799423)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6354954 Vali Loss: 1.6344838 Best vali loss: 1.6344838

Trial trial-394da6a5 completed after 8 iterations at 2024-08-24 08:37:11. Total running time: 1hr 16min 3s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-394da6a5 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          1.21513 â”‚
â”‚ time_total_s                              10.4349 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.63374 â”‚
â”‚ train_loss                                0.63507 â”‚
â”‚ valid_loss                                1.63374 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=799423)[0m Validation loss decreased (1.6345 --> 1.6337).  Saving model state dict ...
[36m(_train_fn pid=799423)[0m Epoch: 8 cost time: 0.9875280857086182
[36m(_train_fn pid=799423)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6350732 Vali Loss: 1.6337430 Best vali loss: 1.6337430
[36m(_train_fn pid=799423)[0m Updating learning rate to 5.10634051324271e-06[32m [repeated 5x across cluster][0m
[36m(_train_fn pid=799423)[0m saving checkpoint...[32m [repeated 5x across cluster][0m

Trial trial-8eb45462 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8eb45462 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.12445 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00859 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=800114)[0m configuration
[36m(_train_fn pid=800114)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.12445435519986181, 'e_layers': 2, 'learning_rate': 0.008585430000351696, 'd_ff': 1536}
[36m(_train_fn pid=800114)[0m Use GPU: cuda:0
[36m(_train_fn pid=800114)[0m train 7825
[36m(_train_fn pid=800114)[0m val 2161
[36m(_train_fn pid=800114)[0m start_epoch 0
[36m(_train_fn pid=800114)[0m max_epoch 8

Trial status: 91 TERMINATED | 1 RUNNING
2024-08-24 08:37:46,873	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=800114)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8eb45462_92_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1245,e_layers_2024-08-24_08-37-11/checkpoint_000000)
Current time: 2024-08-24 08:37:16. Total running time: 1hr 16min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8eb45462   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
86 more TERMINATED
[36m(_train_fn pid=800114)[0m 	iters: 100, epoch: 1 | loss: 0.7431272
[36m(_train_fn pid=800114)[0m 	speed: 0.0639s/iter; left time: 243.8126s
[36m(_train_fn pid=800114)[0m 	iters: 200, epoch: 1 | loss: 0.7515418
[36m(_train_fn pid=800114)[0m 	speed: 0.0573s/iter; left time: 212.7845s
[36m(_train_fn pid=800114)[0m 	iters: 300, epoch: 1 | loss: 0.7000111
[36m(_train_fn pid=800114)[0m 	speed: 0.0573s/iter; left time: 207.1496s
[36m(_train_fn pid=800114)[0m 	iters: 400, epoch: 1 | loss: 0.6677996
[36m(_train_fn pid=800114)[0m 	speed: 0.0574s/iter; left time: 201.5511s
Trial status: 91 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:37:46. Total running time: 1hr 16min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8eb45462   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
86 more TERMINATED
[36m(_train_fn pid=800114)[0m Updating learning rate to 0.008585430000351696
[36m(_train_fn pid=800114)[0m saving checkpoint...
[36m(_train_fn pid=800114)[0m Validation loss decreased (inf --> 1.6113).  Saving model state dict ...
[36m(_train_fn pid=800114)[0m Epoch: 1 cost time: 28.44265055656433
[36m(_train_fn pid=800114)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7497518 Vali Loss: 1.6113136 Best vali loss: 1.6113136
[36m(_train_fn pid=800114)[0m 	iters: 100, epoch: 2 | loss: 25354127278080.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.1430s/iter; left time: 475.3746s
[36m(_train_fn pid=800114)[0m 	iters: 200, epoch: 2 | loss: 11607578624.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0566s/iter; left time: 182.5664s
[36m(_train_fn pid=800114)[0m 	iters: 300, epoch: 2 | loss: 3148247552.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0566s/iter; left time: 176.8108s
[36m(_train_fn pid=800114)[0m 	iters: 400, epoch: 2 | loss: 1796909312.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0566s/iter; left time: 171.1017s
Trial status: 91 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:38:16. Total running time: 1hr 17min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=800114)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8eb45462_92_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1245,e_layers_2024-08-24_08-37-11/checkpoint_000001)
2024-08-24 08:38:18,060	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:38:49,278	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=800114)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8eb45462_92_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1245,e_layers_2024-08-24_08-37-11/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8eb45462   RUNNING           1            32.3558       0.749752        1.61131             1.61131 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
86 more TERMINATED
[36m(_train_fn pid=800114)[0m Updating learning rate to 0.004292715000175848
[36m(_train_fn pid=800114)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=800114)[0m saving checkpoint...
[36m(_train_fn pid=800114)[0m Epoch: 2 cost time: 27.724785566329956
[36m(_train_fn pid=800114)[0m Epoch: 2, Steps: 489 | Train Loss: 11099428566121.2304688 Vali Loss: 4224753605.2148147 Best vali loss: 1.6113136
[36m(_train_fn pid=800114)[0m 	iters: 100, epoch: 3 | loss: 882965888.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.1420s/iter; left time: 402.6812s
[36m(_train_fn pid=800114)[0m 	iters: 200, epoch: 3 | loss: 690856384.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0568s/iter; left time: 155.2885s
[36m(_train_fn pid=800114)[0m 	iters: 300, epoch: 3 | loss: 604400960.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0567s/iter; left time: 149.3265s
[36m(_train_fn pid=800114)[0m 	iters: 400, epoch: 3 | loss: 577060416.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0567s/iter; left time: 143.7694s
Trial status: 91 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:38:46. Total running time: 1hr 17min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8eb45462   RUNNING           2            63.5409    1.10994e+13    4.22475e+09             1.61131 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009    0.593321       1.59962                 1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127    0.510234       1.62942                 1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511    0.570752       1.58113                 1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635     0.600472       1.56828                 1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884    0.512451       1.683                   1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
86 more TERMINATED
[36m(_train_fn pid=800114)[0m Updating learning rate to 0.002146357500087924
[36m(_train_fn pid=800114)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=800114)[0m saving checkpoint...
[36m(_train_fn pid=800114)[0m Epoch: 3 cost time: 27.762152194976807
[36m(_train_fn pid=800114)[0m Epoch: 3, Steps: 489 | Train Loss: 871905553.7995909 Vali Loss: 2637321606.2814813 Best vali loss: 1.6113136
[36m(_train_fn pid=800114)[0m 	iters: 100, epoch: 4 | loss: 368912640.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.1420s/iter; left time: 333.1608s
[36m(_train_fn pid=800114)[0m 	iters: 200, epoch: 4 | loss: 274546176.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0568s/iter; left time: 127.5800s
[36m(_train_fn pid=800114)[0m 	iters: 300, epoch: 4 | loss: 298084192.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0568s/iter; left time: 121.8220s
[36m(_train_fn pid=800114)[0m 	iters: 400, epoch: 4 | loss: 475070880.0000000
[36m(_train_fn pid=800114)[0m 	speed: 0.0568s/iter; left time: 116.1380s
Trial status: 91 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:39:16. Total running time: 1hr 18min 7s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:39:20,514	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=800114)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8eb45462_92_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1245,e_layers_2024-08-24_08-37-11/checkpoint_000003)
2024-08-24 08:39:25,405	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:39:27,365	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=800863)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59b61781_93_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0577,e_layers=4_2024-08-24_08-39-20/checkpoint_000001)[32m [repeated 2x across cluster][0m
2024-08-24 08:39:29,326	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:39:31,448	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=800863)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-59b61781_93_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0577,e_layers=4_2024-08-24_08-39-20/checkpoint_000004)[32m [repeated 3x across cluster][0m
2024-08-24 08:39:33,399	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:39:35,360	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8eb45462   RUNNING           3            94.7562    8.71906e+08    2.63732e+09             1.61131 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009    0.593321       1.59962                 1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127    0.510234       1.62942                 1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511    0.570752       1.58113                 1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635     0.600472       1.56828                 1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884    0.512451       1.683                   1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
86 more TERMINATED

Trial trial-8eb45462 completed after 4 iterations at 2024-08-24 08:39:20. Total running time: 1hr 18min 11s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8eb45462 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         31.23842 â”‚
â”‚ time_total_s                            125.99466 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.61131 â”‚
â”‚ train_loss                        447283240.34356 â”‚
â”‚ valid_loss                       2068368828.02963 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=800114)[0m Updating learning rate to 0.001073178750043962
[36m(_train_fn pid=800114)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=800114)[0m saving checkpoint...

Trial trial-59b61781 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-59b61781 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.05774 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                       0.0015 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=800863)[0m configuration
[36m(_train_fn pid=800863)[0m {'batch_size': 64, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.0577378622317878, 'e_layers': 4, 'learning_rate': 0.001497383692010717, 'd_ff': 16}
[36m(_train_fn pid=800863)[0m Use GPU: cuda:0
[36m(_train_fn pid=800863)[0m train 7825
[36m(_train_fn pid=800863)[0m val 2161
[36m(_train_fn pid=800863)[0m start_epoch 0
[36m(_train_fn pid=800863)[0m max_epoch 8
[36m(_train_fn pid=800863)[0m 	iters: 100, epoch: 1 | loss: 1.1806282
[36m(_train_fn pid=800863)[0m 	speed: 0.0215s/iter; left time: 18.8972s
[36m(_train_fn pid=800863)[0m Validation loss decreased (inf --> 2.5936).  Saving model state dict ...
[36m(_train_fn pid=800863)[0m Epoch: 1 cost time: 2.213616371154785
[36m(_train_fn pid=800863)[0m Epoch: 1, Steps: 122 | Train Loss: 1.3234108 Vali Loss: 2.5935954 Best vali loss: 2.5935954
[36m(_train_fn pid=800863)[0m 	iters: 100, epoch: 2 | loss: 0.6357660
[36m(_train_fn pid=800863)[0m 	speed: 0.0198s/iter; left time: 14.9493s
[36m(_train_fn pid=800863)[0m Updating learning rate to 0.001497383692010717
[36m(_train_fn pid=800863)[0m saving checkpoint...
[36m(_train_fn pid=800863)[0m Updating learning rate to 0.0007486918460053585
[36m(_train_fn pid=800863)[0m saving checkpoint...
[36m(_train_fn pid=800863)[0m Validation loss decreased (2.5936 --> 1.6182).  Saving model state dict ...
[36m(_train_fn pid=800863)[0m Epoch: 2 cost time: 1.6844019889831543
[36m(_train_fn pid=800863)[0m Epoch: 2, Steps: 122 | Train Loss: 0.7330004 Vali Loss: 1.6182019 Best vali loss: 1.6182019
[36m(_train_fn pid=800863)[0m 	iters: 100, epoch: 3 | loss: 0.6019312
[36m(_train_fn pid=800863)[0m 	speed: 0.0196s/iter; left time: 12.4287s
[36m(_train_fn pid=800863)[0m Updating learning rate to 0.0003743459230026793
[36m(_train_fn pid=800863)[0m saving checkpoint...
[36m(_train_fn pid=800863)[0m Validation loss decreased (1.6182 --> 1.5929).  Saving model state dict ...
[36m(_train_fn pid=800863)[0m Epoch: 3 cost time: 1.6936075687408447
[36m(_train_fn pid=800863)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6264063 Vali Loss: 1.5929070 Best vali loss: 1.5929070
[36m(_train_fn pid=800863)[0m 	iters: 100, epoch: 4 | loss: 0.6583634
[36m(_train_fn pid=800863)[0m 	speed: 0.0209s/iter; left time: 10.6571s
[36m(_train_fn pid=800863)[0m Updating learning rate to 0.00018717296150133964
[36m(_train_fn pid=800863)[0m saving checkpoint...
[36m(_train_fn pid=800863)[0m Validation loss decreased (1.5929 --> 1.5890).  Saving model state dict ...
[36m(_train_fn pid=800863)[0m Epoch: 4 cost time: 1.8379082679748535
[36m(_train_fn pid=800863)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6139167 Vali Loss: 1.5890180 Best vali loss: 1.5890180
[36m(_train_fn pid=800863)[0m 	iters: 100, epoch: 5 | loss: 0.5913530
[36m(_train_fn pid=800863)[0m 	speed: 0.0199s/iter; left time: 7.7428s
[36m(_train_fn pid=800863)[0m Updating learning rate to 9.358648075066982e-05
[36m(_train_fn pid=800863)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=800863)[0m saving checkpoint...
[36m(_train_fn pid=800863)[0m Epoch: 5 cost time: 1.6782596111297607
[36m(_train_fn pid=800863)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6097345 Vali Loss: 1.5896437 Best vali loss: 1.5890180
[36m(_train_fn pid=800863)[0m 	iters: 100, epoch: 6 | loss: 0.6096992
[36m(_train_fn pid=800863)[0m 	speed: 0.0196s/iter; left time: 5.2246s
[36m(_train_fn pid=800863)[0m Updating learning rate to 4.679324037533491e-05
[36m(_train_fn pid=800863)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=800863)[0m saving checkpoint...
[36m(_train_fn pid=800863)[0m Epoch: 6 cost time: 1.6921112537384033
[36m(_train_fn pid=800863)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6072466 Vali Loss: 1.5897387 Best vali loss: 1.5890180
[36m(_train_fn pid=800863)[0m 	iters: 100, epoch: 7 | loss: 0.6354043
[36m(_train_fn pid=800863)[0m 	speed: 0.0194s/iter; left time: 2.8194s
[36m(_train_fn pid=800863)[0m Updating learning rate to 2.3396620187667455e-05
[36m(_train_fn pid=800863)[0m EarlyStopping counter: 3 out of 3
2024-08-24 08:39:37,295	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:39:41,279	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=801493)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-89b09162_94_alpha_d_ff=3,batch_size=64,d_model=8,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0.1_2024-08-24_08-39-37/checkpoint_000000)[32m [repeated 3x across cluster][0m
2024-08-24 08:39:42,374	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:39:43,467	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:39:44,505	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:39:45,518	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=800863)[0m saving checkpoint...
[36m(_train_fn pid=800863)[0m Epoch: 7 cost time: 1.6663765907287598
[36m(_train_fn pid=800863)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6064089 Vali Loss: 1.5896349 Best vali loss: 1.5890180
[36m(_train_fn pid=800863)[0m Early stopping

Trial trial-59b61781 completed after 7 iterations at 2024-08-24 08:39:37. Total running time: 1hr 18min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-59b61781 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          1.93308 â”‚
â”‚ time_total_s                             14.76375 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58902 â”‚
â”‚ train_loss                                0.60641 â”‚
â”‚ valid_loss                                1.58963 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-89b09162 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-89b09162 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.1038 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00496 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=801493)[0m configuration
[36m(_train_fn pid=801493)[0m {'batch_size': 64, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'avg', 'dropout': 0.10380125012461677, 'e_layers': 1, 'learning_rate': 0.004961952295012584, 'd_ff': 24}
[36m(_train_fn pid=801493)[0m Use GPU: cuda:0
[36m(_train_fn pid=801493)[0m train 7825
[36m(_train_fn pid=801493)[0m val 2161
[36m(_train_fn pid=801493)[0m start_epoch 0
[36m(_train_fn pid=801493)[0m max_epoch 8
[36m(_train_fn pid=801493)[0m 	iters: 100, epoch: 1 | loss: 0.8721315
[36m(_train_fn pid=801493)[0m 	speed: 0.0125s/iter; left time: 10.9438s
[36m(_train_fn pid=801493)[0m Updating learning rate to 0.004961952295012584
[36m(_train_fn pid=801493)[0m saving checkpoint...
[36m(_train_fn pid=801493)[0m Validation loss decreased (inf --> 1.9136).  Saving model state dict ...
[36m(_train_fn pid=801493)[0m 	iters: 100, epoch: 2 | loss: 0.5961537
[36m(_train_fn pid=801493)[0m 	speed: 0.0109s/iter; left time: 8.2660s
[36m(_train_fn pid=801493)[0m Updating learning rate to 0.002480976147506292
[36m(_train_fn pid=801493)[0m saving checkpoint...
[36m(_train_fn pid=801493)[0m Validation loss decreased (1.9136 --> 1.5859).  Saving model state dict ...
[36m(_train_fn pid=801493)[0m Epoch: 2 cost time: 0.9308838844299316[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=801493)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6342327 Vali Loss: 1.5859491 Best vali loss: 1.5859491[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=801493)[0m 	iters: 100, epoch: 3 | loss: 0.5660748
[36m(_train_fn pid=801493)[0m 	speed: 0.0110s/iter; left time: 6.9773s
[36m(_train_fn pid=801493)[0m Updating learning rate to 0.001240488073753146
[36m(_train_fn pid=801493)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=801493)[0m saving checkpoint...
[36m(_train_fn pid=801493)[0m 	iters: 100, epoch: 4 | loss: 0.5717019
[36m(_train_fn pid=801493)[0m 	speed: 0.0104s/iter; left time: 5.3229s
[36m(_train_fn pid=801493)[0m Updating learning rate to 0.000620244036876573
[36m(_train_fn pid=801493)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=801493)[0m saving checkpoint...
[36m(_train_fn pid=801493)[0m 	iters: 100, epoch: 5 | loss: 0.6074426
[36m(_train_fn pid=801493)[0m 	speed: 0.0103s/iter; left time: 4.0024s

Trial trial-89b09162 completed after 5 iterations at 2024-08-24 08:39:45. Total running time: 1hr 18min 36s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-89b09162 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.02015 â”‚
â”‚ time_total_s                              5.96169 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58595 â”‚
â”‚ train_loss                                0.57271 â”‚
â”‚ valid_loss                                1.61251 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=801493)[0m Updating learning rate to 0.0003101220184382865
[36m(_train_fn pid=801493)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=801493)[0m saving checkpoint...
[36m(_train_fn pid=801493)[0m Early stopping

Trial status: 94 TERMINATED | 1 PENDING
Current time: 2024-08-24 08:39:46. Total running time: 1hr 18min 37s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=801956)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-91ee4d56_95_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-39-45/checkpoint_000000)[32m [repeated 5x across cluster][0m
2024-08-24 08:39:57,476	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:40:02,182	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=801956)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-91ee4d56_95_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-39-45/checkpoint_000002)[32m [repeated 2x across cluster][0m
2024-08-24 08:40:06,872	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=801956)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-91ee4d56_95_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-39-45/checkpoint_000004)[32m [repeated 2x across cluster][0m
2024-08-24 08:40:11,592	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:40:16,290	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-91ee4d56   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
89 more TERMINATED

Trial trial-91ee4d56 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-91ee4d56 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.06125 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00755 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=801956)[0m configuration
[36m(_train_fn pid=801956)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.061254542598500876, 'e_layers': 3, 'learning_rate': 0.007552255384666034, 'd_ff': 128}
[36m(_train_fn pid=801956)[0m Use GPU: cuda:0
[36m(_train_fn pid=801493)[0m Epoch: 5 cost time: 0.8609354496002197[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=801493)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5727074 Vali Loss: 1.6125126 Best vali loss: 1.5859491[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=801956)[0m train 7825
[36m(_train_fn pid=801956)[0m val 2161
[36m(_train_fn pid=801956)[0m start_epoch 0
[36m(_train_fn pid=801956)[0m max_epoch 8
[36m(_train_fn pid=801956)[0m 	iters: 100, epoch: 1 | loss: 0.6441537
[36m(_train_fn pid=801956)[0m 	speed: 0.0218s/iter; left time: 40.4854s
[36m(_train_fn pid=801956)[0m 	iters: 200, epoch: 1 | loss: 0.6623726
[36m(_train_fn pid=801956)[0m 	speed: 0.0167s/iter; left time: 29.2137s
[36m(_train_fn pid=801956)[0m Updating learning rate to 0.007552255384666034
[36m(_train_fn pid=801956)[0m saving checkpoint...
[36m(_train_fn pid=801956)[0m Validation loss decreased (inf --> 1.5867).  Saving model state dict ...
[36m(_train_fn pid=801956)[0m Epoch: 1 cost time: 4.32372522354126
[36m(_train_fn pid=801956)[0m Epoch: 1, Steps: 244 | Train Loss: 0.6909080 Vali Loss: 1.5867241 Best vali loss: 1.5867241
[36m(_train_fn pid=801956)[0m 	iters: 100, epoch: 2 | loss: 0.5602983
[36m(_train_fn pid=801956)[0m 	speed: 0.0300s/iter; left time: 48.2016s
[36m(_train_fn pid=801956)[0m 	iters: 200, epoch: 2 | loss: 0.4928986
[36m(_train_fn pid=801956)[0m 	speed: 0.0168s/iter; left time: 25.3173s
[36m(_train_fn pid=801956)[0m Updating learning rate to 0.003776127692333017
[36m(_train_fn pid=801956)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=801956)[0m saving checkpoint...
[36m(_train_fn pid=801956)[0m Epoch: 2 cost time: 4.136373996734619
[36m(_train_fn pid=801956)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6160794 Vali Loss: 1.5979967 Best vali loss: 1.5867241
[36m(_train_fn pid=801956)[0m 	iters: 100, epoch: 3 | loss: 0.6105395
[36m(_train_fn pid=801956)[0m 	speed: 0.0300s/iter; left time: 40.9481s
[36m(_train_fn pid=801956)[0m 	iters: 200, epoch: 3 | loss: 0.5737884
[36m(_train_fn pid=801956)[0m 	speed: 0.0170s/iter; left time: 21.4967s
[36m(_train_fn pid=801956)[0m Updating learning rate to 0.0018880638461665085
[36m(_train_fn pid=801956)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=801956)[0m saving checkpoint...
[36m(_train_fn pid=801956)[0m Epoch: 3 cost time: 4.161640167236328
[36m(_train_fn pid=801956)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5640645 Vali Loss: 1.5953580 Best vali loss: 1.5867241
[36m(_train_fn pid=801956)[0m 	iters: 100, epoch: 4 | loss: 0.4899857
[36m(_train_fn pid=801956)[0m 	speed: 0.0302s/iter; left time: 33.8174s
[36m(_train_fn pid=801956)[0m 	iters: 200, epoch: 4 | loss: 0.5107519
[36m(_train_fn pid=801956)[0m 	speed: 0.0168s/iter; left time: 17.1359s
[36m(_train_fn pid=801956)[0m Updating learning rate to 0.0009440319230832543
[36m(_train_fn pid=801956)[0m saving checkpoint...
[36m(_train_fn pid=801956)[0m Validation loss decreased (1.5867 --> 1.5811).  Saving model state dict ...
[36m(_train_fn pid=801956)[0m Epoch: 4 cost time: 4.144784688949585
[36m(_train_fn pid=801956)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5296504 Vali Loss: 1.5810865 Best vali loss: 1.5810865
[36m(_train_fn pid=801956)[0m 	iters: 100, epoch: 5 | loss: 0.5025712
[36m(_train_fn pid=801956)[0m 	speed: 0.0301s/iter; left time: 26.3961s
[36m(_train_fn pid=801956)[0m 	iters: 200, epoch: 5 | loss: 0.4943513
[36m(_train_fn pid=801956)[0m 	speed: 0.0169s/iter; left time: 13.1296s
[36m(_train_fn pid=801956)[0m Updating learning rate to 0.00047201596154162714
[36m(_train_fn pid=801956)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=801956)[0m saving checkpoint...
[36m(_train_fn pid=801956)[0m Epoch: 5 cost time: 4.150816917419434
[36m(_train_fn pid=801956)[0m Epoch: 5, Steps: 244 | Train Loss: 0.4931832 Vali Loss: 1.5974608 Best vali loss: 1.5810865
[36m(_train_fn pid=801956)[0m 	iters: 100, epoch: 6 | loss: 0.4393589
[36m(_train_fn pid=801956)[0m 	speed: 0.0303s/iter; left time: 19.1924s
[36m(_train_fn pid=801956)[0m 	iters: 200, epoch: 6 | loss: 0.4554949
[36m(_train_fn pid=801956)[0m 	speed: 0.0169s/iter; left time: 8.9812s
[36m(_train_fn pid=801956)[0m Updating learning rate to 0.00023600798077081357
[36m(_train_fn pid=801956)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=801956)[0m saving checkpoint...
[36m(_train_fn pid=801956)[0m Epoch: 6 cost time: 4.156196117401123
[36m(_train_fn pid=801956)[0m Epoch: 6, Steps: 244 | Train Loss: 0.4579829 Vali Loss: 1.6090209 Best vali loss: 1.5810865

Trial status: 94 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:40:16. Total running time: 1hr 19min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 08:40:20,992	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=801956)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-91ee4d56_95_alpha_d_ff=2,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-39-45/checkpoint_000006)[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=802640)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8dd63f0d_96_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0.1_2024-08-24_08-40-20/checkpoint_000000)
2024-08-24 08:40:30,982	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=802640)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8dd63f0d_96_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0.1_2024-08-24_08-40-20/checkpoint_000001)
2024-08-24 08:40:34,435	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-91ee4d56   RUNNING           6            28.7482       0.457983        1.60902             1.58109 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
89 more TERMINATED
[36m(_train_fn pid=801956)[0m 	iters: 100, epoch: 7 | loss: 0.4149804
[36m(_train_fn pid=801956)[0m 	speed: 0.0301s/iter; left time: 11.7032s
[36m(_train_fn pid=801956)[0m 	iters: 200, epoch: 7 | loss: 0.4438334
[36m(_train_fn pid=801956)[0m 	speed: 0.0169s/iter; left time: 4.8859s

Trial trial-91ee4d56 completed after 7 iterations at 2024-08-24 08:40:20. Total running time: 1hr 19min 12s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-91ee4d56 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          4.70086 â”‚
â”‚ time_total_s                             33.44909 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58109 â”‚
â”‚ train_loss                                0.43282 â”‚
â”‚ valid_loss                                1.62733 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=801956)[0m Updating learning rate to 0.00011800399038540678
[36m(_train_fn pid=801956)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=801956)[0m saving checkpoint...
[36m(_train_fn pid=801956)[0m Epoch: 7 cost time: 4.165069341659546
[36m(_train_fn pid=801956)[0m Epoch: 7, Steps: 244 | Train Loss: 0.4328231 Vali Loss: 1.6273309 Best vali loss: 1.5810865
[36m(_train_fn pid=801956)[0m Early stopping

Trial trial-8dd63f0d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8dd63f0d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10582 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00059 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=802640)[0m configuration
[36m(_train_fn pid=802640)[0m {'batch_size': 16, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'avg', 'dropout': 0.1058210579248684, 'e_layers': 1, 'learning_rate': 0.0005855010684821077, 'd_ff': 24}
[36m(_train_fn pid=802640)[0m Use GPU: cuda:0
[36m(_train_fn pid=802640)[0m train 7825
[36m(_train_fn pid=802640)[0m val 2161
[36m(_train_fn pid=802640)[0m start_epoch 0
[36m(_train_fn pid=802640)[0m max_epoch 8
[36m(_train_fn pid=802640)[0m 	iters: 100, epoch: 1 | loss: 1.1408154
[36m(_train_fn pid=802640)[0m 	speed: 0.0112s/iter; left time: 42.7955s
[36m(_train_fn pid=802640)[0m 	iters: 200, epoch: 1 | loss: 0.8963274
[36m(_train_fn pid=802640)[0m 	speed: 0.0062s/iter; left time: 22.9495s
[36m(_train_fn pid=802640)[0m 	iters: 300, epoch: 1 | loss: 1.0737277
[36m(_train_fn pid=802640)[0m 	speed: 0.0062s/iter; left time: 22.4814s
[36m(_train_fn pid=802640)[0m 	iters: 400, epoch: 1 | loss: 1.0946416
[36m(_train_fn pid=802640)[0m 	speed: 0.0062s/iter; left time: 21.6302s
[36m(_train_fn pid=802640)[0m Updating learning rate to 0.0005855010684821077
[36m(_train_fn pid=802640)[0m saving checkpoint...
[36m(_train_fn pid=802640)[0m Validation loss decreased (inf --> 2.2051).  Saving model state dict ...
[36m(_train_fn pid=802640)[0m Epoch: 1 cost time: 3.26882266998291
[36m(_train_fn pid=802640)[0m Epoch: 1, Steps: 489 | Train Loss: 1.0320544 Vali Loss: 2.2051430 Best vali loss: 2.2051430
[36m(_train_fn pid=802640)[0m 	iters: 100, epoch: 2 | loss: 0.6283239
[36m(_train_fn pid=802640)[0m 	speed: 0.0159s/iter; left time: 52.7632s
[36m(_train_fn pid=802640)[0m 	iters: 200, epoch: 2 | loss: 0.6154048
[36m(_train_fn pid=802640)[0m 	speed: 0.0064s/iter; left time: 20.4988s
[36m(_train_fn pid=802640)[0m 	iters: 300, epoch: 2 | loss: 0.6545914
[36m(_train_fn pid=802640)[0m 	speed: 0.0063s/iter; left time: 19.7959s
[36m(_train_fn pid=802640)[0m 	iters: 400, epoch: 2 | loss: 0.5269376
[36m(_train_fn pid=802640)[0m 	speed: 0.0061s/iter; left time: 18.4557s
[36m(_train_fn pid=802640)[0m Updating learning rate to 0.00029275053424105384
[36m(_train_fn pid=802640)[0m saving checkpoint...
[36m(_train_fn pid=802640)[0m Validation loss decreased (2.2051 --> 1.5822).  Saving model state dict ...
[36m(_train_fn pid=802640)[0m Epoch: 2 cost time: 3.047494411468506
[36m(_train_fn pid=802640)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6659277 Vali Loss: 1.5821783 Best vali loss: 1.5821783
[36m(_train_fn pid=802640)[0m 	iters: 100, epoch: 3 | loss: 0.6125149
[36m(_train_fn pid=802640)[0m 	speed: 0.0154s/iter; left time: 43.7923s
[36m(_train_fn pid=802640)[0m 	iters: 200, epoch: 3 | loss: 0.6861659
[36m(_train_fn pid=802640)[0m 	speed: 0.0062s/iter; left time: 17.0188s
[36m(_train_fn pid=802640)[0m 	iters: 300, epoch: 3 | loss: 0.5469313
[36m(_train_fn pid=802640)[0m 	speed: 0.0062s/iter; left time: 16.3862s
[36m(_train_fn pid=802640)[0m 	iters: 400, epoch: 3 | loss: 0.6451509
[36m(_train_fn pid=802640)[0m 	speed: 0.0062s/iter; left time: 15.5924s
[36m(_train_fn pid=802640)[0m Updating learning rate to 0.00014637526712052692
[36m(_train_fn pid=802640)[0m saving checkpoint...
[36m(_train_fn pid=802640)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8dd63f0d_96_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0.1_2024-08-24_08-40-20/checkpoint_000002)
[36m(_train_fn pid=802640)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8dd63f0d_96_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0.1_2024-08-24_08-40-20/checkpoint_000003)
2024-08-24 08:40:37,620	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=802640)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8dd63f0d_96_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0.1_2024-08-24_08-40-20/checkpoint_000004)
2024-08-24 08:40:40,797	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:40:44,003	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=802640)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8dd63f0d_96_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0.1_2024-08-24_08-40-20/checkpoint_000005)
2024-08-24 08:40:47,218	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=802640)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8dd63f0d_96_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0.1_2024-08-24_08-40-20/checkpoint_000006)
[36m(_train_fn pid=802640)[0m Validation loss decreased (1.5822 --> 1.5816).  Saving model state dict ...
[36m(_train_fn pid=802640)[0m Epoch: 3 cost time: 3.089473247528076
[36m(_train_fn pid=802640)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6135503 Vali Loss: 1.5815887 Best vali loss: 1.5815887
[36m(_train_fn pid=802640)[0m 	iters: 100, epoch: 4 | loss: 0.5818543
[36m(_train_fn pid=802640)[0m 	speed: 0.0153s/iter; left time: 35.8283s
[36m(_train_fn pid=802640)[0m 	iters: 200, epoch: 4 | loss: 0.6406308
[36m(_train_fn pid=802640)[0m 	speed: 0.0056s/iter; left time: 12.6088s
[36m(_train_fn pid=802640)[0m 	iters: 300, epoch: 4 | loss: 0.6827837
[36m(_train_fn pid=802640)[0m 	speed: 0.0057s/iter; left time: 12.1821s
[36m(_train_fn pid=802640)[0m 	iters: 400, epoch: 4 | loss: 0.5142090
[36m(_train_fn pid=802640)[0m 	speed: 0.0056s/iter; left time: 11.5569s
[36m(_train_fn pid=802640)[0m Updating learning rate to 7.318763356026346e-05
[36m(_train_fn pid=802640)[0m saving checkpoint...
[36m(_train_fn pid=802640)[0m Validation loss decreased (1.5816 --> 1.5803).  Saving model state dict ...
[36m(_train_fn pid=802640)[0m Epoch: 4 cost time: 2.8028383255004883
[36m(_train_fn pid=802640)[0m Epoch: 4, Steps: 489 | Train Loss: 0.6060412 Vali Loss: 1.5803300 Best vali loss: 1.5803300
[36m(_train_fn pid=802640)[0m 	iters: 100, epoch: 5 | loss: 0.6441780
[36m(_train_fn pid=802640)[0m 	speed: 0.0149s/iter; left time: 27.6235s
[36m(_train_fn pid=802640)[0m 	iters: 200, epoch: 5 | loss: 0.6716693
[36m(_train_fn pid=802640)[0m 	speed: 0.0056s/iter; left time: 9.7646s
[36m(_train_fn pid=802640)[0m 	iters: 300, epoch: 5 | loss: 0.6702606
[36m(_train_fn pid=802640)[0m 	speed: 0.0056s/iter; left time: 9.2173s
[36m(_train_fn pid=802640)[0m 	iters: 400, epoch: 5 | loss: 0.8255385
[36m(_train_fn pid=802640)[0m 	speed: 0.0057s/iter; left time: 8.8172s
[36m(_train_fn pid=802640)[0m Updating learning rate to 3.659381678013173e-05
[36m(_train_fn pid=802640)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=802640)[0m saving checkpoint...
[36m(_train_fn pid=802640)[0m Epoch: 5 cost time: 2.7939348220825195
[36m(_train_fn pid=802640)[0m Epoch: 5, Steps: 489 | Train Loss: 0.6023784 Vali Loss: 1.5842071 Best vali loss: 1.5803300
[36m(_train_fn pid=802640)[0m 	iters: 100, epoch: 6 | loss: 0.6155285
[36m(_train_fn pid=802640)[0m 	speed: 0.0151s/iter; left time: 20.6858s
[36m(_train_fn pid=802640)[0m 	iters: 200, epoch: 6 | loss: 0.5942881
[36m(_train_fn pid=802640)[0m 	speed: 0.0057s/iter; left time: 7.1767s
[36m(_train_fn pid=802640)[0m 	iters: 300, epoch: 6 | loss: 0.5889220
[36m(_train_fn pid=802640)[0m 	speed: 0.0057s/iter; left time: 6.6987s
[36m(_train_fn pid=802640)[0m 	iters: 400, epoch: 6 | loss: 0.6788515
[36m(_train_fn pid=802640)[0m 	speed: 0.0057s/iter; left time: 6.1240s
[36m(_train_fn pid=802640)[0m Updating learning rate to 1.8296908390065865e-05
[36m(_train_fn pid=802640)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=802640)[0m saving checkpoint...
[36m(_train_fn pid=802640)[0m Epoch: 6 cost time: 2.844764232635498
[36m(_train_fn pid=802640)[0m Epoch: 6, Steps: 489 | Train Loss: 0.6004692 Vali Loss: 1.5824639 Best vali loss: 1.5803300
[36m(_train_fn pid=802640)[0m 	iters: 100, epoch: 7 | loss: 0.5685964
[36m(_train_fn pid=802640)[0m 	speed: 0.0149s/iter; left time: 13.0825s
[36m(_train_fn pid=802640)[0m 	iters: 200, epoch: 7 | loss: 0.6654207
[36m(_train_fn pid=802640)[0m 	speed: 0.0057s/iter; left time: 4.4658s
[36m(_train_fn pid=802640)[0m 	iters: 300, epoch: 7 | loss: 0.5257542
[36m(_train_fn pid=802640)[0m 	speed: 0.0059s/iter; left time: 3.9764s
[36m(_train_fn pid=802640)[0m 	iters: 400, epoch: 7 | loss: 0.6624604
[36m(_train_fn pid=802640)[0m 	speed: 0.0057s/iter; left time: 3.2763s

Trial status: 95 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:40:46. Total running time: 1hr 19min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8dd63f0d   RUNNING           6            20.4606       0.600469        1.58246             1.58033 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
90 more TERMINATED

Trial trial-8dd63f0d completed after 7 iterations at 2024-08-24 08:40:47. Total running time: 1hr 19min 38s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8dd63f0d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          3.21204 â”‚
â”‚ time_total_s                             23.67266 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58033 â”‚
â”‚ train_loss                                0.59959 â”‚
â”‚ valid_loss                                1.58256 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=802640)[0m Updating learning rate to 9.148454195032932e-06
[36m(_train_fn pid=802640)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=802640)[0m saving checkpoint...
[36m(_train_fn pid=802640)[0m Epoch: 7 cost time: 2.8394229412078857
[36m(_train_fn pid=802640)[0m Epoch: 7, Steps: 489 | Train Loss: 0.5995919 Vali Loss: 1.5825556 Best vali loss: 1.5803300
[36m(_train_fn pid=802640)[0m Early stopping

Trial trial-73041521 started with configuration:
2024-08-24 08:40:59,930	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=803297)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-73041521_97_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_08-40-47/checkpoint_000000)
[36m(_train_fn pid=803297)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-73041521_97_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_08-40-47/checkpoint_000001)
[36m(_train_fn pid=803297)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-73041521_97_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_08-40-47/checkpoint_000002)
[36m(_train_fn pid=803297)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-73041521_97_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_08-40-47/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-73041521 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09411 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00059 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=803297)[0m configuration
[36m(_train_fn pid=803297)[0m {'batch_size': 16, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'conv', 'dropout': 0.0941096522493171, 'e_layers': 3, 'learning_rate': 0.0005876641879851464, 'd_ff': 384}
[36m(_train_fn pid=803297)[0m Use GPU: cuda:0
[36m(_train_fn pid=803297)[0m train 7825
[36m(_train_fn pid=803297)[0m val 2161
[36m(_train_fn pid=803297)[0m start_epoch 0
[36m(_train_fn pid=803297)[0m max_epoch 8
[36m(_train_fn pid=803297)[0m 	iters: 100, epoch: 1 | loss: 0.7925106
[36m(_train_fn pid=803297)[0m 	speed: 0.0230s/iter; left time: 87.7771s
[36m(_train_fn pid=803297)[0m 	iters: 200, epoch: 1 | loss: 0.8988438
[36m(_train_fn pid=803297)[0m 	speed: 0.0177s/iter; left time: 65.7317s
[36m(_train_fn pid=803297)[0m 	iters: 300, epoch: 1 | loss: 0.6599213
[36m(_train_fn pid=803297)[0m 	speed: 0.0177s/iter; left time: 63.9531s
[36m(_train_fn pid=803297)[0m 	iters: 400, epoch: 1 | loss: 0.7815642
[36m(_train_fn pid=803297)[0m 	speed: 0.0177s/iter; left time: 62.2367s
[36m(_train_fn pid=803297)[0m Updating learning rate to 0.0005876641879851464
[36m(_train_fn pid=803297)[0m saving checkpoint...
[36m(_train_fn pid=803297)[0m Validation loss decreased (inf --> 1.9118).  Saving model state dict ...
[36m(_train_fn pid=803297)[0m Epoch: 1 cost time: 8.924437046051025
[36m(_train_fn pid=803297)[0m Epoch: 1, Steps: 489 | Train Loss: 0.8105223 Vali Loss: 1.9117664 Best vali loss: 1.9117664
[36m(_train_fn pid=803297)[0m 	iters: 100, epoch: 2 | loss: 0.7141230
[36m(_train_fn pid=803297)[0m 	speed: 0.0446s/iter; left time: 148.0871s
[36m(_train_fn pid=803297)[0m 	iters: 200, epoch: 2 | loss: 0.6171511
[36m(_train_fn pid=803297)[0m 	speed: 0.0177s/iter; left time: 57.2180s
[36m(_train_fn pid=803297)[0m 	iters: 300, epoch: 2 | loss: 0.6013938
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 55.5593s
[36m(_train_fn pid=803297)[0m 	iters: 400, epoch: 2 | loss: 0.5556819
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 53.8192s
[36m(_train_fn pid=803297)[0m Updating learning rate to 0.0002938320939925732
[36m(_train_fn pid=803297)[0m saving checkpoint...
[36m(_train_fn pid=803297)[0m Validation loss decreased (1.9118 --> 1.5908).  Saving model state dict ...
[36m(_train_fn pid=803297)[0m Epoch: 2 cost time: 8.736714363098145
[36m(_train_fn pid=803297)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6377262 Vali Loss: 1.5908228 Best vali loss: 1.5908228
[36m(_train_fn pid=803297)[0m 	iters: 100, epoch: 3 | loss: 0.6481971
[36m(_train_fn pid=803297)[0m 	speed: 0.0447s/iter; left time: 126.8596s
[36m(_train_fn pid=803297)[0m 	iters: 200, epoch: 3 | loss: 0.6271729
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 48.6472s
[36m(_train_fn pid=803297)[0m 	iters: 300, epoch: 3 | loss: 0.8104550
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 46.8495s

Trial status: 96 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:41:16. Total running time: 1hr 20min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-73041521   RUNNING           2            20.2015       0.637726        1.59082             1.59082 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
91 more TERMINATED
[36m(_train_fn pid=803297)[0m 	iters: 400, epoch: 3 | loss: 0.5187688
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 45.1315s
[36m(_train_fn pid=803297)[0m Updating learning rate to 0.0001469160469962866
[36m(_train_fn pid=803297)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=803297)[0m saving checkpoint...
[36m(_train_fn pid=803297)[0m Epoch: 3 cost time: 8.74013638496399
[36m(_train_fn pid=803297)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6065161 Vali Loss: 1.6145448 Best vali loss: 1.5908228
[36m(_train_fn pid=803297)[0m 	iters: 100, epoch: 4 | loss: 0.6136858
[36m(_train_fn pid=803297)[0m 	speed: 0.0447s/iter; left time: 104.8097s
[36m(_train_fn pid=803297)[0m 	iters: 200, epoch: 4 | loss: 0.6913765
[36m(_train_fn pid=803297)[0m 	speed: 0.0179s/iter; left time: 40.1290s
[36m(_train_fn pid=803297)[0m 	iters: 300, epoch: 4 | loss: 0.6023067
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 38.2146s
[36m(_train_fn pid=803297)[0m 	iters: 400, epoch: 4 | loss: 0.5636417
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 36.4400s
[36m(_train_fn pid=803297)[0m Updating learning rate to 7.34580234981433e-05
[36m(_train_fn pid=803297)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=803297)[0m saving checkpoint...
[36m(_train_fn pid=803297)[0m Epoch: 4 cost time: 8.759015321731567
[36m(_train_fn pid=803297)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5771328 Vali Loss: 1.6356349 Best vali loss: 1.5908228
[36m(_train_fn pid=803297)[0m 	iters: 100, epoch: 5 | loss: 0.5629280
[36m(_train_fn pid=803297)[0m 	speed: 0.0448s/iter; left time: 83.1929s
[36m(_train_fn pid=803297)[0m 	iters: 200, epoch: 5 | loss: 0.6297197
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 31.3193s
[36m(_train_fn pid=803297)[0m 	iters: 300, epoch: 5 | loss: 0.5956193
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 29.5432s
[36m(_train_fn pid=803297)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-73041521_97_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_08-40-47/checkpoint_000004)
2024-08-24 08:41:51,797	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=803887)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e4fa3c2_98_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1441,e_laye_2024-08-24_08-41-39/checkpoint_000000)
[36m(_train_fn pid=803887)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e4fa3c2_98_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1441,e_laye_2024-08-24_08-41-39/checkpoint_000001)
[36m(_train_fn pid=803887)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e4fa3c2_98_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1441,e_laye_2024-08-24_08-41-39/checkpoint_000002)
[36m(_train_fn pid=803297)[0m 	iters: 400, epoch: 5 | loss: 0.6554390
[36m(_train_fn pid=803297)[0m 	speed: 0.0178s/iter; left time: 27.7478s

Trial trial-73041521 completed after 5 iterations at 2024-08-24 08:41:39. Total running time: 1hr 20min 30s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-73041521 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          9.81699 â”‚
â”‚ time_total_s                             49.64097 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59082 â”‚
â”‚ train_loss                                 0.5638 â”‚
â”‚ valid_loss                                1.61605 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=803297)[0m Updating learning rate to 3.672901174907165e-05
[36m(_train_fn pid=803297)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=803297)[0m saving checkpoint...
[36m(_train_fn pid=803297)[0m Epoch: 5 cost time: 8.759080171585083
[36m(_train_fn pid=803297)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5638010 Vali Loss: 1.6160548 Best vali loss: 1.5908228
[36m(_train_fn pid=803297)[0m Early stopping

Trial trial-8e4fa3c2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8e4fa3c2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.14408 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00707 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=803887)[0m configuration
[36m(_train_fn pid=803887)[0m {'batch_size': 128, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.1440822349199314, 'e_layers': 4, 'learning_rate': 0.007072370336890442, 'd_ff': 384}
[36m(_train_fn pid=803887)[0m Use GPU: cuda:0
[36m(_train_fn pid=803887)[0m train 7825
[36m(_train_fn pid=803887)[0m val 2161
[36m(_train_fn pid=803887)[0m start_epoch 0
[36m(_train_fn pid=803887)[0m max_epoch 8

Trial status: 97 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:41:46. Total running time: 1hr 20min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8e4fa3c2   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
92 more TERMINATED
[36m(_train_fn pid=803887)[0m Validation loss decreased (inf --> 1.9366).  Saving model state dict ...
[36m(_train_fn pid=803887)[0m Updating learning rate to 0.007072370336890442
[36m(_train_fn pid=803887)[0m saving checkpoint...
[36m(_train_fn pid=803887)[0m Epoch: 1 cost time: 8.699757814407349
[36m(_train_fn pid=803887)[0m Epoch: 1, Steps: 61 | Train Loss: 0.7911119 Vali Loss: 1.9365914 Best vali loss: 1.9365914
[36m(_train_fn pid=803887)[0m Updating learning rate to 0.003536185168445221
[36m(_train_fn pid=803887)[0m saving checkpoint...
[36m(_train_fn pid=803887)[0m Validation loss decreased (1.9366 --> 1.5984).  Saving model state dict ...
[36m(_train_fn pid=803887)[0m Epoch: 2 cost time: 8.312494039535522
[36m(_train_fn pid=803887)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6454754 Vali Loss: 1.5983811 Best vali loss: 1.5983811
[36m(_train_fn pid=803887)[0m Updating learning rate to 0.0017680925842226106
[36m(_train_fn pid=803887)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=803887)[0m saving checkpoint...
[36m(_train_fn pid=803887)[0m Epoch: 3 cost time: 8.299856662750244
[36m(_train_fn pid=803887)[0m Epoch: 3, Steps: 61 | Train Loss: 0.5939165 Vali Loss: 1.6185818 Best vali loss: 1.5983811
Trial status: 97 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:42:17. Total running time: 1hr 21min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=803887)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e4fa3c2_98_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1441,e_laye_2024-08-24_08-41-39/checkpoint_000003)
[36m(_train_fn pid=803887)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e4fa3c2_98_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1441,e_laye_2024-08-24_08-41-39/checkpoint_000004)
[36m(_train_fn pid=803887)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e4fa3c2_98_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1441,e_laye_2024-08-24_08-41-39/checkpoint_000005)
[36m(_train_fn pid=803887)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e4fa3c2_98_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1441,e_laye_2024-08-24_08-41-39/checkpoint_000006)
[36m(_train_fn pid=803887)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-8e4fa3c2_98_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1441,e_laye_2024-08-24_08-41-39/checkpoint_000007)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8e4fa3c2   RUNNING           3            29.1742       0.593917        1.61858             1.59838 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
92 more TERMINATED
[36m(_train_fn pid=803887)[0m Updating learning rate to 0.0008840462921113053
[36m(_train_fn pid=803887)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=803887)[0m saving checkpoint...
[36m(_train_fn pid=803887)[0m Epoch: 4 cost time: 8.306609630584717
[36m(_train_fn pid=803887)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5680269 Vali Loss: 1.6208350 Best vali loss: 1.5983811
[36m(_train_fn pid=803887)[0m Updating learning rate to 0.00044202314605565265
[36m(_train_fn pid=803887)[0m saving checkpoint...
[36m(_train_fn pid=803887)[0m Validation loss decreased (1.5984 --> 1.5957).  Saving model state dict ...
[36m(_train_fn pid=803887)[0m Epoch: 5 cost time: 8.31294322013855
[36m(_train_fn pid=803887)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5486136 Vali Loss: 1.5957135 Best vali loss: 1.5957135
[36m(_train_fn pid=803887)[0m Updating learning rate to 0.00022101157302782632
[36m(_train_fn pid=803887)[0m saving checkpoint...
[36m(_train_fn pid=803887)[0m Validation loss decreased (1.5957 --> 1.5886).  Saving model state dict ...
[36m(_train_fn pid=803887)[0m Epoch: 6 cost time: 8.314810037612915
[36m(_train_fn pid=803887)[0m Epoch: 6, Steps: 61 | Train Loss: 0.5331144 Vali Loss: 1.5886443 Best vali loss: 1.5886443
Trial status: 97 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:42:47. Total running time: 1hr 21min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-8e4fa3c2   RUNNING           6            57.5948       0.533114        1.58864             1.58864 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
92 more TERMINATED
[36m(_train_fn pid=803887)[0m Updating learning rate to 0.00011050578651391316
[36m(_train_fn pid=803887)[0m saving checkpoint...
[36m(_train_fn pid=803887)[0m Validation loss decreased (1.5886 --> 1.5781).  Saving model state dict ...
[36m(_train_fn pid=803887)[0m Epoch: 7 cost time: 8.321669101715088
[36m(_train_fn pid=803887)[0m Epoch: 7, Steps: 61 | Train Loss: 0.5226395 Vali Loss: 1.5781273 Best vali loss: 1.5781273

Trial trial-8e4fa3c2 completed after 8 iterations at 2024-08-24 08:42:58. Total running time: 1hr 21min 49s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-8e4fa3c2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          9.47824 â”‚
â”‚ time_total_s                             76.56647 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.57813 â”‚
â”‚ train_loss                                0.51475 â”‚
â”‚ valid_loss                                1.61419 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=803887)[0m Updating learning rate to 5.525289325695658e-05
[36m(_train_fn pid=803887)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=803887)[0m saving checkpoint...
[36m(_train_fn pid=803887)[0m Epoch: 8 cost time: 8.317918539047241
[36m(_train_fn pid=803887)[0m Epoch: 8, Steps: 61 | Train Loss: 0.5147545 Vali Loss: 1.6141918 Best vali loss: 1.5781273

Trial trial-fdfebfbc started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fdfebfbc config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                             0.0892 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00099 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=804768)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fdfebfbc_99_alpha_d_ff=2,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0892,e_layer_2024-08-24_08-42-58/checkpoint_000000)
2024-08-24 08:43:12,564	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:43:23,839	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=804768)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fdfebfbc_99_alpha_d_ff=2,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0892,e_layer_2024-08-24_08-42-58/checkpoint_000001)
2024-08-24 08:43:35,118	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=804768)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fdfebfbc_99_alpha_d_ff=2,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0892,e_layer_2024-08-24_08-42-58/checkpoint_000002)
2024-08-24 08:43:46,400	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=804768)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fdfebfbc_99_alpha_d_ff=2,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0892,e_layer_2024-08-24_08-42-58/checkpoint_000003)
[36m(_train_fn pid=804768)[0m configuration
[36m(_train_fn pid=804768)[0m {'batch_size': 16, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.08919503784518429, 'e_layers': 4, 'learning_rate': 0.0009882286857185421, 'd_ff': 256}
[36m(_train_fn pid=804768)[0m Use GPU: cuda:0
[36m(_train_fn pid=804768)[0m train 7825
[36m(_train_fn pid=804768)[0m val 2161
[36m(_train_fn pid=804768)[0m start_epoch 0
[36m(_train_fn pid=804768)[0m max_epoch 8
[36m(_train_fn pid=804768)[0m 	iters: 100, epoch: 1 | loss: 0.8169516
[36m(_train_fn pid=804768)[0m 	speed: 0.0272s/iter; left time: 103.6176s
[36m(_train_fn pid=804768)[0m 	iters: 200, epoch: 1 | loss: 0.8029513
[36m(_train_fn pid=804768)[0m 	speed: 0.0200s/iter; left time: 74.2379s
[36m(_train_fn pid=804768)[0m 	iters: 300, epoch: 1 | loss: 0.8389392
[36m(_train_fn pid=804768)[0m 	speed: 0.0200s/iter; left time: 72.4280s
[36m(_train_fn pid=804768)[0m 	iters: 400, epoch: 1 | loss: 0.6793795
[36m(_train_fn pid=804768)[0m 	speed: 0.0200s/iter; left time: 70.4350s
[36m(_train_fn pid=804768)[0m Updating learning rate to 0.0009882286857185421
[36m(_train_fn pid=804768)[0m saving checkpoint...
[36m(_train_fn pid=804768)[0m Validation loss decreased (inf --> 1.8739).  Saving model state dict ...
[36m(_train_fn pid=804768)[0m Epoch: 1 cost time: 10.258793830871582
[36m(_train_fn pid=804768)[0m Epoch: 1, Steps: 489 | Train Loss: 0.8061628 Vali Loss: 1.8738803 Best vali loss: 1.8738803
[36m(_train_fn pid=804768)[0m 	iters: 100, epoch: 2 | loss: 0.6463423
[36m(_train_fn pid=804768)[0m 	speed: 0.0524s/iter; left time: 174.1038s
[36m(_train_fn pid=804768)[0m 	iters: 200, epoch: 2 | loss: 0.6404088
[36m(_train_fn pid=804768)[0m 	speed: 0.0201s/iter; left time: 64.8082s

Trial status: 98 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:43:17. Total running time: 1hr 22min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fdfebfbc   RUNNING           1            12.0576       0.806163        1.87388             1.87388 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
93 more TERMINATED
[36m(_train_fn pid=804768)[0m 	iters: 300, epoch: 2 | loss: 0.6102629
[36m(_train_fn pid=804768)[0m 	speed: 0.0201s/iter; left time: 62.8372s
[36m(_train_fn pid=804768)[0m 	iters: 400, epoch: 2 | loss: 0.5811002
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 60.9498s
[36m(_train_fn pid=804768)[0m Updating learning rate to 0.0004941143428592711
[36m(_train_fn pid=804768)[0m saving checkpoint...
[36m(_train_fn pid=804768)[0m Validation loss decreased (1.8739 --> 1.5906).  Saving model state dict ...
[36m(_train_fn pid=804768)[0m Epoch: 2 cost time: 9.877576112747192
[36m(_train_fn pid=804768)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6193882 Vali Loss: 1.5905915 Best vali loss: 1.5905915
[36m(_train_fn pid=804768)[0m 	iters: 100, epoch: 3 | loss: 0.4856989
[36m(_train_fn pid=804768)[0m 	speed: 0.0524s/iter; left time: 148.5288s
[36m(_train_fn pid=804768)[0m 	iters: 200, epoch: 3 | loss: 0.5203149
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 55.1432s
[36m(_train_fn pid=804768)[0m 	iters: 300, epoch: 3 | loss: 0.5446375
[36m(_train_fn pid=804768)[0m 	speed: 0.0201s/iter; left time: 53.0783s
[36m(_train_fn pid=804768)[0m 	iters: 400, epoch: 3 | loss: 0.5156152
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 51.1778s
[36m(_train_fn pid=804768)[0m Updating learning rate to 0.00024705717142963553
[36m(_train_fn pid=804768)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=804768)[0m saving checkpoint...
[36m(_train_fn pid=804768)[0m Epoch: 3 cost time: 9.899259567260742
[36m(_train_fn pid=804768)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5651337 Vali Loss: 1.6019726 Best vali loss: 1.5905915
[36m(_train_fn pid=804768)[0m 	iters: 100, epoch: 4 | loss: 0.5438237
[36m(_train_fn pid=804768)[0m 	speed: 0.0523s/iter; left time: 122.7272s
[36m(_train_fn pid=804768)[0m 	iters: 200, epoch: 4 | loss: 0.5640110
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 45.3094s
[36m(_train_fn pid=804768)[0m 	iters: 300, epoch: 4 | loss: 0.4455813
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 43.2452s
[36m(_train_fn pid=804768)[0m 	iters: 400, epoch: 4 | loss: 0.5004714
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 41.3142s
[36m(_train_fn pid=804768)[0m Updating learning rate to 0.00012352858571481777
[36m(_train_fn pid=804768)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=804768)[0m saving checkpoint...
[36m(_train_fn pid=804768)[0m Epoch: 4 cost time: 9.904855012893677
[36m(_train_fn pid=804768)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5399319 Vali Loss: 1.6247748 Best vali loss: 1.5905915
Trial status: 98 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:43:47. Total running time: 1hr 22min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:43:57,705	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=804768)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fdfebfbc_99_alpha_d_ff=2,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0892,e_layer_2024-08-24_08-42-58/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fdfebfbc   RUNNING           4            45.8796       0.539932        1.62477             1.59059 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
93 more TERMINATED
[36m(_train_fn pid=804768)[0m 	iters: 100, epoch: 5 | loss: 0.6081660
[36m(_train_fn pid=804768)[0m 	speed: 0.0523s/iter; left time: 97.0816s
[36m(_train_fn pid=804768)[0m 	iters: 200, epoch: 5 | loss: 0.5457110
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 35.4043s
[36m(_train_fn pid=804768)[0m 	iters: 300, epoch: 5 | loss: 0.4884966
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 33.4238s
[36m(_train_fn pid=804768)[0m 	iters: 400, epoch: 5 | loss: 0.5342451
[36m(_train_fn pid=804768)[0m 	speed: 0.0202s/iter; left time: 31.4154s

Trial trial-fdfebfbc completed after 5 iterations at 2024-08-24 08:43:57. Total running time: 1hr 22min 48s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fdfebfbc result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         11.30318 â”‚
â”‚ time_total_s                             57.18278 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59059 â”‚
â”‚ train_loss                                0.52473 â”‚
â”‚ valid_loss                                1.62222 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=804768)[0m Updating learning rate to 6.176429285740888e-05
[36m(_train_fn pid=804768)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=804768)[0m saving checkpoint...
[36m(_train_fn pid=804768)[0m Epoch: 5 cost time: 9.914862632751465
[36m(_train_fn pid=804768)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5247308 Vali Loss: 1.6222231 Best vali loss: 1.5905915
[36m(_train_fn pid=804768)[0m Early stopping

Trial trial-2f1c5109 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2f1c5109 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.10927 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00074 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=805383)[0m configuration
[36m(_train_fn pid=805383)[0m {'batch_size': 16, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'conv', 'dropout': 0.1092704135803585, 'e_layers': 3, 'learning_rate': 0.0007399944334290523, 'd_ff': 768}
[36m(_train_fn pid=805383)[0m Use GPU: cuda:0
[36m(_train_fn pid=805383)[0m train 7825
[36m(_train_fn pid=805383)[0m val 2161
[36m(_train_fn pid=805383)[0m start_epoch 0
[36m(_train_fn pid=805383)[0m max_epoch 8
[36m(_train_fn pid=805383)[0m 	iters: 100, epoch: 1 | loss: 0.7943253
[36m(_train_fn pid=805383)[0m 	speed: 0.0406s/iter; left time: 154.7572s
[36m(_train_fn pid=805383)[0m 	iters: 200, epoch: 1 | loss: 0.8093703
[36m(_train_fn pid=805383)[0m 	speed: 0.0356s/iter; left time: 132.0240s
[36m(_train_fn pid=805383)[0m 	iters: 300, epoch: 1 | loss: 0.7106856
[36m(_train_fn pid=805383)[0m 	speed: 0.0356s/iter; left time: 128.5743s
[36m(_train_fn pid=805383)[0m 	iters: 400, epoch: 1 | loss: 0.7466138
[36m(_train_fn pid=805383)[0m 	speed: 0.0356s/iter; left time: 124.9140s

Trial status: 99 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:44:17. Total running time: 1hr 23min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:44:19,603	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=805383)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2f1c5109_100_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout_2024-08-24_08-43-57/checkpoint_000000)
[36m(_train_fn pid=805383)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2f1c5109_100_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout_2024-08-24_08-43-57/checkpoint_000001)
[36m(_train_fn pid=805383)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2f1c5109_100_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout_2024-08-24_08-43-57/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2f1c5109   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
94 more TERMINATED
[36m(_train_fn pid=805383)[0m Updating learning rate to 0.0007399944334290523
[36m(_train_fn pid=805383)[0m saving checkpoint...
[36m(_train_fn pid=805383)[0m Validation loss decreased (inf --> 1.8049).  Saving model state dict ...
[36m(_train_fn pid=805383)[0m Epoch: 1 cost time: 17.63389825820923
[36m(_train_fn pid=805383)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7598446 Vali Loss: 1.8048822 Best vali loss: 1.8048822
[36m(_train_fn pid=805383)[0m 	iters: 100, epoch: 2 | loss: 0.6488366
[36m(_train_fn pid=805383)[0m 	speed: 0.0878s/iter; left time: 291.7541s
[36m(_train_fn pid=805383)[0m 	iters: 200, epoch: 2 | loss: 0.5920084
[36m(_train_fn pid=805383)[0m 	speed: 0.0355s/iter; left time: 114.5815s
[36m(_train_fn pid=805383)[0m 	iters: 300, epoch: 2 | loss: 0.6050981
[36m(_train_fn pid=805383)[0m 	speed: 0.0356s/iter; left time: 111.1647s
[36m(_train_fn pid=805383)[0m 	iters: 400, epoch: 2 | loss: 0.6486018
[36m(_train_fn pid=805383)[0m 	speed: 0.0356s/iter; left time: 107.7524s
[36m(_train_fn pid=805383)[0m Updating learning rate to 0.00036999721671452615
[36m(_train_fn pid=805383)[0m saving checkpoint...
[36m(_train_fn pid=805383)[0m Validation loss decreased (1.8049 --> 1.5697).  Saving model state dict ...
[36m(_train_fn pid=805383)[0m Epoch: 2 cost time: 17.43056058883667
[36m(_train_fn pid=805383)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6261109 Vali Loss: 1.5696869 Best vali loss: 1.5696869
[36m(_train_fn pid=805383)[0m 	iters: 100, epoch: 3 | loss: 0.4702118
[36m(_train_fn pid=805383)[0m 	speed: 0.0881s/iter; left time: 249.8313s
[36m(_train_fn pid=805383)[0m 	iters: 200, epoch: 3 | loss: 0.5433566
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 97.6732s
Trial status: 99 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:44:47. Total running time: 1hr 23min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2f1c5109   RUNNING           2            39.5422       0.626111        1.56969             1.56969 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
94 more TERMINATED
[36m(_train_fn pid=805383)[0m 	iters: 300, epoch: 3 | loss: 0.5937144
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 93.9959s
[36m(_train_fn pid=805383)[0m 	iters: 400, epoch: 3 | loss: 0.5800675
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 90.4681s
[36m(_train_fn pid=805383)[0m Updating learning rate to 0.00018499860835726308
[36m(_train_fn pid=805383)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=805383)[0m saving checkpoint...
[36m(_train_fn pid=805383)[0m Epoch: 3 cost time: 17.489190816879272
[36m(_train_fn pid=805383)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5881710 Vali Loss: 1.6576287 Best vali loss: 1.5696869
[36m(_train_fn pid=805383)[0m 	iters: 100, epoch: 4 | loss: 0.4237013
[36m(_train_fn pid=805383)[0m 	speed: 0.0881s/iter; left time: 206.7411s
[36m(_train_fn pid=805383)[0m 	iters: 200, epoch: 4 | loss: 0.5105456
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 80.2313s
[36m(_train_fn pid=805383)[0m 	iters: 300, epoch: 4 | loss: 0.6139537
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 76.6628s
[36m(_train_fn pid=805383)[0m 	iters: 400, epoch: 4 | loss: 0.5807758
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 73.0137s
Trial status: 99 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:45:17. Total running time: 1hr 24min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=805383)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2f1c5109_100_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout_2024-08-24_08-43-57/checkpoint_000003)
[36m(_train_fn pid=805383)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2f1c5109_100_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout_2024-08-24_08-43-57/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-2f1c5109   RUNNING           3            59.0562       0.588171        1.65763             1.56969 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
94 more TERMINATED
[36m(_train_fn pid=805383)[0m Updating learning rate to 9.249930417863154e-05
[36m(_train_fn pid=805383)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=805383)[0m saving checkpoint...
[36m(_train_fn pid=805383)[0m Epoch: 4 cost time: 17.493054151535034
[36m(_train_fn pid=805383)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5599143 Vali Loss: 1.6423706 Best vali loss: 1.5696869
[36m(_train_fn pid=805383)[0m 	iters: 100, epoch: 5 | loss: 0.6131667
[36m(_train_fn pid=805383)[0m 	speed: 0.0880s/iter; left time: 163.3882s
[36m(_train_fn pid=805383)[0m 	iters: 200, epoch: 5 | loss: 0.4166245
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 62.6757s
[36m(_train_fn pid=805383)[0m 	iters: 300, epoch: 5 | loss: 0.4981949
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 59.1062s
[36m(_train_fn pid=805383)[0m 	iters: 400, epoch: 5 | loss: 0.4732087
[36m(_train_fn pid=805383)[0m 	speed: 0.0357s/iter; left time: 55.5886s

Trial trial-2f1c5109 completed after 5 iterations at 2024-08-24 08:45:37. Total running time: 1hr 24min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2f1c5109 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         19.49196 â”‚
â”‚ time_total_s                             98.06466 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56969 â”‚
â”‚ train_loss                                0.54514 â”‚
â”‚ valid_loss                                1.64417 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=805383)[0m Updating learning rate to 4.624965208931577e-05
[36m(_train_fn pid=805383)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=805383)[0m saving checkpoint...
[36m(_train_fn pid=805383)[0m Epoch: 5 cost time: 17.475812435150146
[36m(_train_fn pid=805383)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5451401 Vali Loss: 1.6441674 Best vali loss: 1.5696869
[36m(_train_fn pid=805383)[0m Early stopping

Trial trial-f99d2acd started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f99d2acd config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09586 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.01109 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=806113)[0m configuration
[36m(_train_fn pid=806113)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'avg', 'dropout': 0.09585654740867444, 'e_layers': 2, 'learning_rate': 0.01109178431621061, 'd_ff': 1536}
[36m(_train_fn pid=806113)[0m Use GPU: cuda:0
[36m(_train_fn pid=806113)[0m train 7825
[36m(_train_fn pid=806113)[0m val 2161
[36m(_train_fn pid=806113)[0m start_epoch 0
[36m(_train_fn pid=806113)[0m max_epoch 8
[36m(_train_fn pid=806113)[0m 	iters: 100, epoch: 1 | loss: 0.7367026
[36m(_train_fn pid=806113)[0m 	speed: 0.0619s/iter; left time: 236.0394s

Trial status: 100 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:45:47. Total running time: 1hr 24min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f99d2acd   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=806113)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f99d2acd_101_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_08-45-37/checkpoint_000000)
2024-08-24 08:46:11,507	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:46:42,477	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=806113)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f99d2acd_101_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_08-45-37/checkpoint_000001)
[36m(_train_fn pid=806113)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f99d2acd_101_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_08-45-37/checkpoint_000002)
2024-08-24 08:47:13,444	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
95 more TERMINATED
[36m(_train_fn pid=806113)[0m 	iters: 200, epoch: 1 | loss: 0.7499357
[36m(_train_fn pid=806113)[0m 	speed: 0.0573s/iter; left time: 212.7418s
[36m(_train_fn pid=806113)[0m 	iters: 300, epoch: 1 | loss: 0.6981390
[36m(_train_fn pid=806113)[0m 	speed: 0.0572s/iter; left time: 206.8190s
[36m(_train_fn pid=806113)[0m 	iters: 400, epoch: 1 | loss: 0.6648514
[36m(_train_fn pid=806113)[0m 	speed: 0.0572s/iter; left time: 201.1137s
[36m(_train_fn pid=806113)[0m Updating learning rate to 0.01109178431621061
[36m(_train_fn pid=806113)[0m saving checkpoint...
[36m(_train_fn pid=806113)[0m Validation loss decreased (inf --> 1.6000).  Saving model state dict ...
[36m(_train_fn pid=806113)[0m Epoch: 1 cost time: 28.206619024276733
[36m(_train_fn pid=806113)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7709400 Vali Loss: 1.5999635 Best vali loss: 1.5999635
[36m(_train_fn pid=806113)[0m 	iters: 100, epoch: 2 | loss: 162291932725248.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.1409s/iter; left time: 468.4838s
Trial status: 100 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:46:17. Total running time: 1hr 25min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f99d2acd   RUNNING           1            31.9678       0.77094         1.59996             1.59996 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
95 more TERMINATED
[36m(_train_fn pid=806113)[0m 	iters: 200, epoch: 2 | loss: 106795917312.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0566s/iter; left time: 182.4074s
[36m(_train_fn pid=806113)[0m 	iters: 300, epoch: 2 | loss: 244501086208.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0566s/iter; left time: 176.7780s
[36m(_train_fn pid=806113)[0m 	iters: 400, epoch: 2 | loss: 30919284736.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0566s/iter; left time: 171.0518s
[36m(_train_fn pid=806113)[0m Updating learning rate to 0.005545892158105305
[36m(_train_fn pid=806113)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=806113)[0m saving checkpoint...
[36m(_train_fn pid=806113)[0m Epoch: 2 cost time: 27.700071573257446
[36m(_train_fn pid=806113)[0m Epoch: 2, Steps: 489 | Train Loss: 295823663465033.1250000 Vali Loss: 57531633876.3851852 Best vali loss: 1.5999635
Trial status: 100 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:46:47. Total running time: 1hr 25min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f99d2acd   RUNNING           2            62.931     2.95824e+14    5.75316e+10             1.59996 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009    0.593321       1.59962                 1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127    0.510234       1.62942                 1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511    0.570752       1.58113                 1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635     0.600472       1.56828                 1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884    0.512451       1.683                   1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
95 more TERMINATED
[36m(_train_fn pid=806113)[0m 	iters: 100, epoch: 3 | loss: 11138402304.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.1398s/iter; left time: 396.4623s
[36m(_train_fn pid=806113)[0m 	iters: 200, epoch: 3 | loss: 14613497856.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0566s/iter; left time: 154.9162s
[36m(_train_fn pid=806113)[0m 	iters: 300, epoch: 3 | loss: 12476729344.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0566s/iter; left time: 149.2265s
[36m(_train_fn pid=806113)[0m 	iters: 400, epoch: 3 | loss: 11664455680.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0567s/iter; left time: 143.6217s
[36m(_train_fn pid=806113)[0m Updating learning rate to 0.0027729460790526525
[36m(_train_fn pid=806113)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=806113)[0m saving checkpoint...
[36m(_train_fn pid=806113)[0m Epoch: 3 cost time: 27.716607570648193
[36m(_train_fn pid=806113)[0m Epoch: 3, Steps: 489 | Train Loss: 16369250486.1840496 Vali Loss: 49906227124.1481476 Best vali loss: 1.5999635
Trial status: 100 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:47:17. Total running time: 1hr 26min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:47:44,426	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=806113)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f99d2acd_101_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_08-45-37/checkpoint_000003)
[36m(_train_fn pid=806861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-90a1a1f3_102_alpha_d_ff=4,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0776,e_layers_2024-08-24_08-47-44/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f99d2acd   RUNNING           3            93.9018    1.63693e+10    4.99062e+10             1.59996 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009    0.593321       1.59962                 1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127    0.510234       1.62942                 1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511    0.570752       1.58113                 1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635     0.600472       1.56828                 1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884    0.512451       1.683                   1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
95 more TERMINATED
[36m(_train_fn pid=806113)[0m 	iters: 100, epoch: 4 | loss: 7671428608.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.1398s/iter; left time: 327.8623s
[36m(_train_fn pid=806113)[0m 	iters: 200, epoch: 4 | loss: 4902372352.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0567s/iter; left time: 127.2483s
[36m(_train_fn pid=806113)[0m 	iters: 300, epoch: 4 | loss: 9377165312.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0566s/iter; left time: 121.5529s
[36m(_train_fn pid=806113)[0m 	iters: 400, epoch: 4 | loss: 15261391872.0000000
[36m(_train_fn pid=806113)[0m 	speed: 0.0567s/iter; left time: 115.9197s

Trial trial-f99d2acd completed after 4 iterations at 2024-08-24 08:47:44. Total running time: 1hr 26min 35s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f99d2acd result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         30.97551 â”‚
â”‚ time_total_s                             124.8773 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.59996 â”‚
â”‚ train_loss                      10998048091.61554 â”‚
â”‚ valid_loss                      29965965585.06667 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=806113)[0m Updating learning rate to 0.0013864730395263263
[36m(_train_fn pid=806113)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=806113)[0m saving checkpoint...

Trial trial-90a1a1f3 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-90a1a1f3 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.0776 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00052 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=806861)[0m configuration
[36m(_train_fn pid=806861)[0m {'batch_size': 16, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.07760039953201595, 'e_layers': 3, 'learning_rate': 0.0005240405639586418, 'd_ff': 64}
[36m(_train_fn pid=806861)[0m Use GPU: cuda:0
[36m(_train_fn pid=806861)[0m train 7825
[36m(_train_fn pid=806861)[0m val 2161
[36m(_train_fn pid=806861)[0m start_epoch 0
[36m(_train_fn pid=806861)[0m max_epoch 8

Trial status: 101 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:47:47. Total running time: 1hr 26min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-90a1a1f3   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
96 more TERMINATED
[36m(_train_fn pid=806861)[0m 	iters: 100, epoch: 1 | loss: 1.2156613
[36m(_train_fn pid=806861)[0m 	speed: 0.0179s/iter; left time: 68.0914s
[36m(_train_fn pid=806861)[0m 	iters: 200, epoch: 1 | loss: 1.1901420
[36m(_train_fn pid=806861)[0m 	speed: 0.0108s/iter; left time: 40.0762s
[36m(_train_fn pid=806861)[0m 	iters: 300, epoch: 1 | loss: 0.9936746
[36m(_train_fn pid=806861)[0m 	speed: 0.0109s/iter; left time: 39.4290s
[36m(_train_fn pid=806861)[0m 	iters: 400, epoch: 1 | loss: 0.8914934
[36m(_train_fn pid=806861)[0m 	speed: 0.0105s/iter; left time: 36.9305s
[36m(_train_fn pid=806861)[0m Updating learning rate to 0.0005240405639586418
[36m(_train_fn pid=806861)[0m saving checkpoint...
[36m(_train_fn pid=806861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-90a1a1f3_102_alpha_d_ff=4,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0776,e_layers_2024-08-24_08-47-44/checkpoint_000001)
[36m(_train_fn pid=806861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-90a1a1f3_102_alpha_d_ff=4,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0776,e_layers_2024-08-24_08-47-44/checkpoint_000002)
[36m(_train_fn pid=806861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-90a1a1f3_102_alpha_d_ff=4,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0776,e_layers_2024-08-24_08-47-44/checkpoint_000003)
[36m(_train_fn pid=806861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-90a1a1f3_102_alpha_d_ff=4,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0776,e_layers_2024-08-24_08-47-44/checkpoint_000004)
[36m(_train_fn pid=806861)[0m Validation loss decreased (inf --> 2.3523).  Saving model state dict ...
[36m(_train_fn pid=806861)[0m Epoch: 1 cost time: 5.630713701248169
[36m(_train_fn pid=806861)[0m Epoch: 1, Steps: 489 | Train Loss: 1.1284769 Vali Loss: 2.3522862 Best vali loss: 2.3522862
[36m(_train_fn pid=806861)[0m 	iters: 100, epoch: 2 | loss: 0.5887381
[36m(_train_fn pid=806861)[0m 	speed: 0.0260s/iter; left time: 86.3974s
[36m(_train_fn pid=806861)[0m 	iters: 200, epoch: 2 | loss: 0.5715894
[36m(_train_fn pid=806861)[0m 	speed: 0.0108s/iter; left time: 34.8250s
[36m(_train_fn pid=806861)[0m 	iters: 300, epoch: 2 | loss: 0.6332152
[36m(_train_fn pid=806861)[0m 	speed: 0.0108s/iter; left time: 33.7562s
[36m(_train_fn pid=806861)[0m 	iters: 400, epoch: 2 | loss: 0.5650296
[36m(_train_fn pid=806861)[0m 	speed: 0.0108s/iter; left time: 32.6703s
[36m(_train_fn pid=806861)[0m Updating learning rate to 0.0002620202819793209
[36m(_train_fn pid=806861)[0m saving checkpoint...
[36m(_train_fn pid=806861)[0m Validation loss decreased (2.3523 --> 1.5715).  Saving model state dict ...
[36m(_train_fn pid=806861)[0m Epoch: 2 cost time: 5.3299643993377686
[36m(_train_fn pid=806861)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6504226 Vali Loss: 1.5714772 Best vali loss: 1.5714772
[36m(_train_fn pid=806861)[0m 	iters: 100, epoch: 3 | loss: 0.6899483
[36m(_train_fn pid=806861)[0m 	speed: 0.0259s/iter; left time: 73.4977s
[36m(_train_fn pid=806861)[0m 	iters: 200, epoch: 3 | loss: 0.5858362
[36m(_train_fn pid=806861)[0m 	speed: 0.0099s/iter; left time: 27.0714s
[36m(_train_fn pid=806861)[0m 	iters: 300, epoch: 3 | loss: 0.5737285
[36m(_train_fn pid=806861)[0m 	speed: 0.0099s/iter; left time: 26.0480s
[36m(_train_fn pid=806861)[0m 	iters: 400, epoch: 3 | loss: 0.5925308
[36m(_train_fn pid=806861)[0m 	speed: 0.0099s/iter; left time: 25.0845s
[36m(_train_fn pid=806861)[0m Updating learning rate to 0.00013101014098966044
[36m(_train_fn pid=806861)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=806861)[0m saving checkpoint...
[36m(_train_fn pid=806861)[0m Epoch: 3 cost time: 4.882343530654907
[36m(_train_fn pid=806861)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5926316 Vali Loss: 1.5947150 Best vali loss: 1.5714772
[36m(_train_fn pid=806861)[0m 	iters: 100, epoch: 4 | loss: 0.5872256
[36m(_train_fn pid=806861)[0m 	speed: 0.0249s/iter; left time: 58.3260s
[36m(_train_fn pid=806861)[0m 	iters: 200, epoch: 4 | loss: 0.4297567
[36m(_train_fn pid=806861)[0m 	speed: 0.0097s/iter; left time: 21.8591s
[36m(_train_fn pid=806861)[0m 	iters: 300, epoch: 4 | loss: 0.5367154
[36m(_train_fn pid=806861)[0m 	speed: 0.0097s/iter; left time: 20.9075s
[36m(_train_fn pid=806861)[0m 	iters: 400, epoch: 4 | loss: 0.4094103
[36m(_train_fn pid=806861)[0m 	speed: 0.0099s/iter; left time: 20.1811s
[36m(_train_fn pid=806861)[0m Updating learning rate to 6.550507049483022e-05
[36m(_train_fn pid=806861)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=806861)[0m saving checkpoint...
[36m(_train_fn pid=806861)[0m Epoch: 4 cost time: 4.831882476806641
[36m(_train_fn pid=806861)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5833911 Vali Loss: 1.5928799 Best vali loss: 1.5714772
[36m(_train_fn pid=806861)[0m 	iters: 100, epoch: 5 | loss: 0.5373256
[36m(_train_fn pid=806861)[0m 	speed: 0.0250s/iter; left time: 46.3811s
[36m(_train_fn pid=806861)[0m 	iters: 200, epoch: 5 | loss: 0.5003760
[36m(_train_fn pid=806861)[0m 	speed: 0.0098s/iter; left time: 17.1912s
[36m(_train_fn pid=806861)[0m 	iters: 300, epoch: 5 | loss: 0.5338009
[36m(_train_fn pid=806861)[0m 	speed: 0.0097s/iter; left time: 16.0284s
[36m(_train_fn pid=806861)[0m 	iters: 400, epoch: 5 | loss: 0.5443867
[36m(_train_fn pid=806861)[0m 	speed: 0.0098s/iter; left time: 15.3168s
[36m(_train_fn pid=806861)[0m Updating learning rate to 3.275253524741511e-05
[36m(_train_fn pid=806861)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=806861)[0m saving checkpoint...
[36m(_train_fn pid=806861)[0m Epoch: 5 cost time: 4.833113670349121
[36m(_train_fn pid=806861)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5795881 Vali Loss: 1.5853027 Best vali loss: 1.5714772
[36m(_train_fn pid=806861)[0m Early stopping

Trial trial-90a1a1f3 completed after 5 iterations at 2024-08-24 08:48:15. Total running time: 1hr 27min 6s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-90a1a1f3 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          5.42277 â”‚
â”‚ time_total_s                             28.85874 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.57148 â”‚
â”‚ train_loss                                0.57959 â”‚
â”‚ valid_loss                                 1.5853 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-5b764f93 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5b764f93 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13449 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00075 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=807387)[0m configuration
[36m(_train_fn pid=807387)[0m {'batch_size': 128, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'avg', 'dropout': 0.13449261103955432, 'e_layers': 1, 'learning_rate': 0.000747835261622063, 'd_ff': 1024}
[36m(_train_fn pid=807387)[0m Use GPU: cuda:0

Trial status: 102 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:48:17. Total running time: 1hr 27min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=807387)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5b764f93_103_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout_2024-08-24_08-48-15/checkpoint_000000)
[36m(_train_fn pid=807387)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5b764f93_103_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout_2024-08-24_08-48-15/checkpoint_000001)
[36m(_train_fn pid=807387)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5b764f93_103_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout_2024-08-24_08-48-15/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5b764f93   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
97 more TERMINATED
[36m(_train_fn pid=807387)[0m train 7825
[36m(_train_fn pid=807387)[0m val 2161
[36m(_train_fn pid=807387)[0m start_epoch 0
[36m(_train_fn pid=807387)[0m max_epoch 8
[36m(_train_fn pid=807387)[0m Validation loss decreased (inf --> 2.0009).  Saving model state dict ...
[36m(_train_fn pid=807387)[0m Updating learning rate to 0.000747835261622063
[36m(_train_fn pid=807387)[0m saving checkpoint...
[36m(_train_fn pid=807387)[0m Epoch: 1 cost time: 14.762227296829224
[36m(_train_fn pid=807387)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8289384 Vali Loss: 2.0009016 Best vali loss: 2.0009016
Trial status: 102 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:48:47. Total running time: 1hr 27min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5b764f93   RUNNING           1            17.047        0.828938        2.0009              2.0009  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
97 more TERMINATED
[36m(_train_fn pid=807387)[0m Updating learning rate to 0.0003739176308110315
[36m(_train_fn pid=807387)[0m saving checkpoint...
[36m(_train_fn pid=807387)[0m Validation loss decreased (2.0009 --> 1.6572).  Saving model state dict ...
[36m(_train_fn pid=807387)[0m Epoch: 2 cost time: 14.626957654953003
[36m(_train_fn pid=807387)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7268479 Vali Loss: 1.6571950 Best vali loss: 1.6571950
[36m(_train_fn pid=807387)[0m Updating learning rate to 0.00018695881540551574
[36m(_train_fn pid=807387)[0m saving checkpoint...
[36m(_train_fn pid=807387)[0m Validation loss decreased (1.6572 --> 1.6064).  Saving model state dict ...
[36m(_train_fn pid=807387)[0m Epoch: 3 cost time: 14.649385690689087
[36m(_train_fn pid=807387)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6323561 Vali Loss: 1.6063904 Best vali loss: 1.6063904
Trial status: 102 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:49:17. Total running time: 1hr 28min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5b764f93   RUNNING           3            50.083        0.632356        1.60639             1.60639 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
97 more TERMINATED
[36m(_train_fn pid=807387)[0m Updating learning rate to 9.347940770275787e-05
[36m(_train_fn pid=807387)[0m saving checkpoint...
[36m(_train_fn pid=807387)[0m Validation loss decreased (1.6064 --> 1.5994).  Saving model state dict ...
[36m(_train_fn pid=807387)[0m Epoch: 4 cost time: 14.661409139633179
[36m(_train_fn pid=807387)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5b764f93_103_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout_2024-08-24_08-48-15/checkpoint_000003)
[36m(_train_fn pid=807387)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5b764f93_103_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout_2024-08-24_08-48-15/checkpoint_000004)
[36m(_train_fn pid=807387)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5b764f93_103_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout_2024-08-24_08-48-15/checkpoint_000005)
[36m(_train_fn pid=807387)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5b764f93_103_alpha_d_ff=2,batch_size=128,d_model=512,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout_2024-08-24_08-48-15/checkpoint_000006)
[36m(_train_fn pid=807387)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6215018 Vali Loss: 1.5994489 Best vali loss: 1.5994489
[36m(_train_fn pid=807387)[0m Updating learning rate to 4.6739703851378935e-05
[36m(_train_fn pid=807387)[0m saving checkpoint...
[36m(_train_fn pid=807387)[0m Validation loss decreased (1.5994 --> 1.5979).  Saving model state dict ...
[36m(_train_fn pid=807387)[0m Epoch: 5 cost time: 14.691725254058838
[36m(_train_fn pid=807387)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6179131 Vali Loss: 1.5978862 Best vali loss: 1.5978862
Trial status: 102 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:49:47. Total running time: 1hr 28min 38s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5b764f93   RUNNING           5            83.1973       0.617913        1.59789             1.59789 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
97 more TERMINATED
[36m(_train_fn pid=807387)[0m Updating learning rate to 2.3369851925689468e-05
[36m(_train_fn pid=807387)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=807387)[0m saving checkpoint...
[36m(_train_fn pid=807387)[0m Epoch: 6 cost time: 14.708404779434204
[36m(_train_fn pid=807387)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6167268 Vali Loss: 1.5980854 Best vali loss: 1.5978862
[36m(_train_fn pid=807387)[0m Updating learning rate to 1.1684925962844734e-05
[36m(_train_fn pid=807387)[0m saving checkpoint...
[36m(_train_fn pid=807387)[0m Validation loss decreased (1.5979 --> 1.5958).  Saving model state dict ...

Trial trial-5b764f93 completed after 7 iterations at 2024-08-24 08:50:13. Total running time: 1hr 29min 5s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5b764f93 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                         16.59285 â”‚
â”‚ time_total_s                            116.36209 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.59582 â”‚
â”‚ train_loss                                0.61643 â”‚
â”‚ valid_loss                                1.59582 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-e7fa1c44 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e7fa1c44 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.08927 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00258 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=808318)[0m configuration
[36m(_train_fn pid=808318)[0m {'batch_size': 64, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'conv', 'dropout': 0.08926722595254746, 'e_layers': 1, 'learning_rate': 0.0025776786667019306, 'd_ff': 512}
[36m(_train_fn pid=808318)[0m Use GPU: cuda:0
[36m(_train_fn pid=808318)[0m train 7825
[36m(_train_fn pid=808318)[0m val 2161
[36m(_train_fn pid=808318)[0m start_epoch 0
[36m(_train_fn pid=808318)[0m max_epoch 8

Trial status: 103 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:50:17. Total running time: 1hr 29min 8s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:50:24,882	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=808318)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e7fa1c44_104_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_08-50-13/checkpoint_000000)
[36m(_train_fn pid=808318)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e7fa1c44_104_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_08-50-13/checkpoint_000001)
[36m(_train_fn pid=808318)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e7fa1c44_104_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_08-50-13/checkpoint_000002)
[36m(_train_fn pid=808318)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e7fa1c44_104_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_08-50-13/checkpoint_000003)
[36m(_train_fn pid=808318)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e7fa1c44_104_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_08-50-13/checkpoint_000004)
[36m(_train_fn pid=808318)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e7fa1c44_104_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_08-50-13/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e7fa1c44   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
98 more TERMINATED
[36m(_train_fn pid=808318)[0m 	iters: 100, epoch: 1 | loss: 0.7701408
[36m(_train_fn pid=808318)[0m 	speed: 0.0683s/iter; left time: 59.8683s
[36m(_train_fn pid=808318)[0m Updating learning rate to 0.0025776786667019306
[36m(_train_fn pid=808318)[0m saving checkpoint...
[36m(_train_fn pid=808318)[0m Validation loss decreased (inf --> 1.8934).  Saving model state dict ...
[36m(_train_fn pid=808318)[0m Epoch: 1 cost time: 7.9621055126190186
[36m(_train_fn pid=808318)[0m Epoch: 1, Steps: 122 | Train Loss: 0.7884134 Vali Loss: 1.8934412 Best vali loss: 1.8934412
[36m(_train_fn pid=808318)[0m 	iters: 100, epoch: 2 | loss: 0.6145259
[36m(_train_fn pid=808318)[0m 	speed: 0.0871s/iter; left time: 65.7579s
[36m(_train_fn pid=808318)[0m Updating learning rate to 0.0012888393333509653
[36m(_train_fn pid=808318)[0m saving checkpoint...
[36m(_train_fn pid=808318)[0m Validation loss decreased (1.8934 --> 1.5953).  Saving model state dict ...
[36m(_train_fn pid=808318)[0m Epoch: 2 cost time: 7.763046979904175
[36m(_train_fn pid=808318)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6522771 Vali Loss: 1.5952953 Best vali loss: 1.5952953
[36m(_train_fn pid=808318)[0m 	iters: 100, epoch: 3 | loss: 0.6137925
[36m(_train_fn pid=808318)[0m 	speed: 0.0870s/iter; left time: 55.0806s
[36m(_train_fn pid=808318)[0m Updating learning rate to 0.0006444196666754826
[36m(_train_fn pid=808318)[0m saving checkpoint...
[36m(_train_fn pid=808318)[0m Validation loss decreased (1.5953 --> 1.5690).  Saving model state dict ...
[36m(_train_fn pid=808318)[0m Epoch: 3 cost time: 7.758671283721924
[36m(_train_fn pid=808318)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6070116 Vali Loss: 1.5689840 Best vali loss: 1.5689840
Trial status: 103 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:50:47. Total running time: 1hr 29min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e7fa1c44   RUNNING           3            26.7148       0.607012        1.56898             1.56898 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
98 more TERMINATED
[36m(_train_fn pid=808318)[0m 	iters: 100, epoch: 4 | loss: 0.6170629
[36m(_train_fn pid=808318)[0m 	speed: 0.0871s/iter; left time: 44.5115s
[36m(_train_fn pid=808318)[0m Updating learning rate to 0.0003222098333377413
[36m(_train_fn pid=808318)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=808318)[0m saving checkpoint...
[36m(_train_fn pid=808318)[0m Epoch: 4 cost time: 7.761507034301758
[36m(_train_fn pid=808318)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5910519 Vali Loss: 1.5873635 Best vali loss: 1.5689840
[36m(_train_fn pid=808318)[0m 	iters: 100, epoch: 5 | loss: 0.5464724
[36m(_train_fn pid=808318)[0m 	speed: 0.0869s/iter; left time: 33.7967s
[36m(_train_fn pid=808318)[0m Updating learning rate to 0.00016110491666887066
[36m(_train_fn pid=808318)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=808318)[0m saving checkpoint...
[36m(_train_fn pid=808318)[0m Epoch: 5 cost time: 7.757258653640747
[36m(_train_fn pid=808318)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5752001 Vali Loss: 1.5964415 Best vali loss: 1.5689840
[36m(_train_fn pid=808318)[0m 	iters: 100, epoch: 6 | loss: 0.5790886
[36m(_train_fn pid=808318)[0m 	speed: 0.0869s/iter; left time: 23.1933s

Trial trial-e7fa1c44 completed after 6 iterations at 2024-08-24 08:51:08. Total running time: 1hr 29min 59s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e7fa1c44 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                           8.6886 â”‚
â”‚ time_total_s                              52.7791 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56898 â”‚
â”‚ train_loss                                 0.5676 â”‚
â”‚ valid_loss                                1.60089 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=808318)[0m Updating learning rate to 8.055245833443533e-05
[36m(_train_fn pid=809230)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d536d72f_105_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-51-08/checkpoint_000000)
[36m(_train_fn pid=809230)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d536d72f_105_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-51-08/checkpoint_000001)
[36m(_train_fn pid=809230)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d536d72f_105_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-51-08/checkpoint_000002)
[36m(_train_fn pid=809230)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d536d72f_105_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-51-08/checkpoint_000003)
[36m(_train_fn pid=808318)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=808318)[0m saving checkpoint...
[36m(_train_fn pid=808318)[0m Epoch: 6 cost time: 7.759079456329346
[36m(_train_fn pid=808318)[0m Epoch: 6, Steps: 122 | Train Loss: 0.5676037 Vali Loss: 1.6008876 Best vali loss: 1.5689840
[36m(_train_fn pid=808318)[0m Early stopping

Trial trial-d536d72f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d536d72f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09545 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00067 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=809230)[0m configuration
[36m(_train_fn pid=809230)[0m {'batch_size': 16, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.0954497389626388, 'e_layers': 4, 'learning_rate': 0.0006739687774501915, 'd_ff': 24}
[36m(_train_fn pid=809230)[0m Use GPU: cuda:0
[36m(_train_fn pid=809230)[0m train 7825
[36m(_train_fn pid=809230)[0m val 2161
[36m(_train_fn pid=809230)[0m start_epoch 0
[36m(_train_fn pid=809230)[0m max_epoch 8
[36m(_train_fn pid=809230)[0m 	iters: 100, epoch: 1 | loss: 1.5933651
[36m(_train_fn pid=809230)[0m 	speed: 0.0182s/iter; left time: 69.2306s
[36m(_train_fn pid=809230)[0m 	iters: 200, epoch: 1 | loss: 1.4298491
[36m(_train_fn pid=809230)[0m 	speed: 0.0131s/iter; left time: 48.7791s
[36m(_train_fn pid=809230)[0m 	iters: 300, epoch: 1 | loss: 1.1791636
[36m(_train_fn pid=809230)[0m 	speed: 0.0132s/iter; left time: 47.8688s
[36m(_train_fn pid=809230)[0m 	iters: 400, epoch: 1 | loss: 1.2532681
[36m(_train_fn pid=809230)[0m 	speed: 0.0132s/iter; left time: 46.4823s

Trial status: 104 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:51:17. Total running time: 1hr 30min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d536d72f   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
99 more TERMINATED
[36m(_train_fn pid=809230)[0m Updating learning rate to 0.0006739687774501915
[36m(_train_fn pid=809230)[0m saving checkpoint...
[36m(_train_fn pid=809230)[0m Validation loss decreased (inf --> 2.5675).  Saving model state dict ...
[36m(_train_fn pid=809230)[0m Epoch: 1 cost time: 6.701770544052124
[36m(_train_fn pid=809230)[0m Epoch: 1, Steps: 489 | Train Loss: 1.3886139 Vali Loss: 2.5675067 Best vali loss: 2.5675067
[36m(_train_fn pid=809230)[0m 	iters: 100, epoch: 2 | loss: 0.6506213
[36m(_train_fn pid=809230)[0m 	speed: 0.0301s/iter; left time: 100.0161s
[36m(_train_fn pid=809230)[0m 	iters: 200, epoch: 2 | loss: 0.5849681
[36m(_train_fn pid=809230)[0m 	speed: 0.0117s/iter; left time: 37.5864s
[36m(_train_fn pid=809230)[0m 	iters: 300, epoch: 2 | loss: 0.5778404
[36m(_train_fn pid=809230)[0m 	speed: 0.0116s/iter; left time: 36.3417s
[36m(_train_fn pid=809230)[0m 	iters: 400, epoch: 2 | loss: 0.6452544
[36m(_train_fn pid=809230)[0m 	speed: 0.0116s/iter; left time: 35.1880s
[36m(_train_fn pid=809230)[0m Updating learning rate to 0.00033698438872509576
[36m(_train_fn pid=809230)[0m saving checkpoint...
[36m(_train_fn pid=809230)[0m Validation loss decreased (2.5675 --> 1.5824).  Saving model state dict ...
[36m(_train_fn pid=809230)[0m Epoch: 2 cost time: 5.7343080043792725
[36m(_train_fn pid=809230)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6525209 Vali Loss: 1.5823890 Best vali loss: 1.5823890
[36m(_train_fn pid=809230)[0m 	iters: 100, epoch: 3 | loss: 0.5440616
[36m(_train_fn pid=809230)[0m 	speed: 0.0286s/iter; left time: 81.1089s
[36m(_train_fn pid=809230)[0m 	iters: 200, epoch: 3 | loss: 0.4914750
[36m(_train_fn pid=809230)[0m 	speed: 0.0117s/iter; left time: 31.9941s
[36m(_train_fn pid=809230)[0m 	iters: 300, epoch: 3 | loss: 0.5736982
[36m(_train_fn pid=809230)[0m 	speed: 0.0119s/iter; left time: 31.3049s
[36m(_train_fn pid=809230)[0m 	iters: 400, epoch: 3 | loss: 0.7287062
[36m(_train_fn pid=809230)[0m 	speed: 0.0118s/iter; left time: 30.0288s
[36m(_train_fn pid=809230)[0m Updating learning rate to 0.00016849219436254788
[36m(_train_fn pid=809230)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=809230)[0m saving checkpoint...
[36m(_train_fn pid=809230)[0m Epoch: 3 cost time: 5.8130011558532715
[36m(_train_fn pid=809230)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5981980 Vali Loss: 1.5940738 Best vali loss: 1.5823890
[36m(_train_fn pid=809230)[0m 	iters: 100, epoch: 4 | loss: 0.5794402
[36m(_train_fn pid=809230)[0m 	speed: 0.0290s/iter; left time: 68.1301s
[36m(_train_fn pid=809230)[0m 	iters: 200, epoch: 4 | loss: 0.6057037
[36m(_train_fn pid=809230)[0m 	speed: 0.0118s/iter; left time: 26.4831s
[36m(_train_fn pid=809230)[0m 	iters: 300, epoch: 4 | loss: 0.5953903
[36m(_train_fn pid=809230)[0m 	speed: 0.0117s/iter; left time: 25.0609s
[36m(_train_fn pid=809230)[0m 	iters: 400, epoch: 4 | loss: 0.5698822
[36m(_train_fn pid=809230)[0m 	speed: 0.0118s/iter; left time: 24.1292s
[36m(_train_fn pid=809230)[0m Updating learning rate to 8.424609718127394e-05
[36m(_train_fn pid=809230)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=809230)[0m saving checkpoint...
[36m(_train_fn pid=809230)[0m Epoch: 4 cost time: 5.800343751907349
[36m(_train_fn pid=809230)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5852414 Vali Loss: 1.5887789 Best vali loss: 1.5823890
[36m(_train_fn pid=809230)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d536d72f_105_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0._2024-08-24_08-51-08/checkpoint_000004)
[36m(_train_fn pid=809230)[0m 	iters: 100, epoch: 5 | loss: 0.6249210
[36m(_train_fn pid=809230)[0m 	speed: 0.0287s/iter; left time: 53.2706s
[36m(_train_fn pid=809230)[0m 	iters: 200, epoch: 5 | loss: 0.5605693
[36m(_train_fn pid=809230)[0m 	speed: 0.0116s/iter; left time: 20.3527s
[36m(_train_fn pid=809230)[0m 	iters: 300, epoch: 5 | loss: 0.5801117
[36m(_train_fn pid=809230)[0m 	speed: 0.0118s/iter; left time: 19.4773s
[36m(_train_fn pid=809230)[0m 	iters: 400, epoch: 5 | loss: 0.5505493
[36m(_train_fn pid=809230)[0m 	speed: 0.0118s/iter; left time: 18.2965s

Trial trial-d536d72f completed after 5 iterations at 2024-08-24 08:51:43. Total running time: 1hr 30min 35s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d536d72f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          6.35049 â”‚
â”‚ time_total_s                             33.25451 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58239 â”‚
â”‚ train_loss                                0.57941 â”‚
â”‚ valid_loss                                1.59009 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=809230)[0m Updating learning rate to 4.212304859063697e-05
[36m(_train_fn pid=809230)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=809230)[0m saving checkpoint...
[36m(_train_fn pid=809230)[0m Epoch: 5 cost time: 5.753648519515991
[36m(_train_fn pid=809230)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5794086 Vali Loss: 1.5900944 Best vali loss: 1.5823890
[36m(_train_fn pid=809230)[0m Early stopping

Trial trial-6ccf7050 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6ccf7050 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09003 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00094 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=809771)[0m configuration
[36m(_train_fn pid=809771)[0m {'batch_size': 128, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.09002529609508823, 'e_layers': 3, 'learning_rate': 0.0009350210348466902, 'd_ff': 2048}
[36m(_train_fn pid=809771)[0m Use GPU: cuda:0
[36m(_train_fn pid=809771)[0m train 7825
[36m(_train_fn pid=809771)[0m val 2161
[36m(_train_fn pid=809771)[0m start_epoch 0
[36m(_train_fn pid=809771)[0m max_epoch 8

Trial status: 105 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:51:47. Total running time: 1hr 30min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6ccf7050   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100 more TERMINATED
Trial status: 105 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:52:17. Total running time: 1hr 31min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6ccf7050   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100 more TERMINATED
[36m(_train_fn pid=809771)[0m Validation loss decreased (inf --> 2.0322).  Saving model state dict ...
[36m(_train_fn pid=809771)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6ccf7050_106_alpha_d_ff=4,batch_size=128,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0900,e_laye_2024-08-24_08-51-43/checkpoint_000000)
2024-08-24 08:53:13,345	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=809771)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6ccf7050_106_alpha_d_ff=4,batch_size=128,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0900,e_laye_2024-08-24_08-51-43/checkpoint_000001)
[36m(_train_fn pid=809771)[0m Updating learning rate to 0.0009350210348466902
[36m(_train_fn pid=809771)[0m saving checkpoint...
[36m(_train_fn pid=809771)[0m Epoch: 1 cost time: 38.75740575790405
[36m(_train_fn pid=809771)[0m Epoch: 1, Steps: 61 | Train Loss: 0.9091592 Vali Loss: 2.0321547 Best vali loss: 2.0321547
Trial status: 105 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:52:47. Total running time: 1hr 31min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6ccf7050   RUNNING           1            44.1533       0.909159        2.03215             2.03215 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100 more TERMINATED
[36m(_train_fn pid=809771)[0m Updating learning rate to 0.0004675105174233451
[36m(_train_fn pid=809771)[0m saving checkpoint...
[36m(_train_fn pid=809771)[0m Validation loss decreased (2.0322 --> 1.6975).  Saving model state dict ...
[36m(_train_fn pid=809771)[0m Epoch: 2 cost time: 38.643579721450806
[36m(_train_fn pid=809771)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7309443 Vali Loss: 1.6974792 Best vali loss: 1.6974792
Trial status: 105 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:53:17. Total running time: 1hr 32min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6ccf7050   RUNNING           2            87.7932       0.730944        1.69748             1.69748 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100 more TERMINATED
Trial status: 105 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:53:47. Total running time: 1hr 32min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6ccf7050   RUNNING           2            87.7932       0.730944        1.69748             1.69748 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
100 more TERMINATED
[36m(_train_fn pid=809771)[0m Updating learning rate to 0.00023375525871167254
[36m(_train_fn pid=809771)[0m saving checkpoint...
[36m(_train_fn pid=809771)[0m Validation loss decreased (1.6975 --> 1.6409).  Saving model state dict ...

Trial trial-6ccf7050 completed after 3 iterations at 2024-08-24 08:53:57. Total running time: 1hr 32min 48s
2024-08-24 08:53:57,078	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=809771)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6ccf7050_106_alpha_d_ff=4,batch_size=128,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0900,e_laye_2024-08-24_08-51-43/checkpoint_000002)
[36m(_train_fn pid=810465)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b96c443f_107_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_08-53-57/checkpoint_000000)
[36m(_train_fn pid=810465)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b96c443f_107_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_08-53-57/checkpoint_000001)
2024-08-24 08:54:29,521	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:54:44,215	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=810465)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b96c443f_107_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_08-53-57/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6ccf7050 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000002 â”‚
â”‚ time_this_iter_s                         43.73522 â”‚
â”‚ time_total_s                            131.52839 â”‚
â”‚ training_iteration                              3 â”‚
â”‚ best_valid_loss                           1.64092 â”‚
â”‚ train_loss                                0.64521 â”‚
â”‚ valid_loss                                1.64092 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-b96c443f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b96c443f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09945 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00301 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=810465)[0m configuration
[36m(_train_fn pid=810465)[0m {'batch_size': 128, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.09944672586422061, 'e_layers': 2, 'learning_rate': 0.003006840335290314, 'd_ff': 1024}
[36m(_train_fn pid=810465)[0m Use GPU: cuda:0
[36m(_train_fn pid=810465)[0m train 7825
[36m(_train_fn pid=810465)[0m val 2161
[36m(_train_fn pid=810465)[0m start_epoch 0
[36m(_train_fn pid=810465)[0m max_epoch 8
[36m(_train_fn pid=810465)[0m Updating learning rate to 0.003006840335290314
[36m(_train_fn pid=810465)[0m saving checkpoint...
[36m(_train_fn pid=810465)[0m Validation loss decreased (inf --> 1.9687).  Saving model state dict ...
[36m(_train_fn pid=810465)[0m Epoch: 1 cost time: 13.318876504898071
[36m(_train_fn pid=810465)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8117029 Vali Loss: 1.9687347 Best vali loss: 1.9687347

Trial status: 106 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:54:18. Total running time: 1hr 33min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b96c443f   RUNNING           1            15.2808       0.811703        1.96873             1.96873 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
101 more TERMINATED
[36m(_train_fn pid=810465)[0m Updating learning rate to 0.001503420167645157
[36m(_train_fn pid=810465)[0m saving checkpoint...
[36m(_train_fn pid=810465)[0m Validation loss decreased (1.9687 --> 1.6192).  Saving model state dict ...
[36m(_train_fn pid=810465)[0m Epoch: 2 cost time: 13.132683515548706
[36m(_train_fn pid=810465)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7187434 Vali Loss: 1.6191889 Best vali loss: 1.6191889
[36m(_train_fn pid=810465)[0m Updating learning rate to 0.0007517100838225785
[36m(_train_fn pid=810465)[0m saving checkpoint...
[36m(_train_fn pid=810465)[0m Validation loss decreased (1.6192 --> 1.6003).  Saving model state dict ...
[36m(_train_fn pid=810465)[0m Epoch: 3 cost time: 13.144182920455933
[36m(_train_fn pid=810465)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6149301 Vali Loss: 1.6002545 Best vali loss: 1.6002545
Trial status: 106 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:54:48. Total running time: 1hr 33min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:54:58,876	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=810465)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b96c443f_107_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_08-53-57/checkpoint_000003)
2024-08-24 08:55:13,564	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=810465)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b96c443f_107_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_08-53-57/checkpoint_000004)
2024-08-24 08:55:28,232	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=810465)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b96c443f_107_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_08-53-57/checkpoint_000005)
2024-08-24 08:55:32,555	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b96c443f   RUNNING           3            44.6583       0.61493         1.60025             1.60025 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
101 more TERMINATED
[36m(_train_fn pid=810465)[0m Updating learning rate to 0.00037585504191128924
[36m(_train_fn pid=810465)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=810465)[0m saving checkpoint...
[36m(_train_fn pid=810465)[0m Epoch: 4 cost time: 13.129676342010498
[36m(_train_fn pid=810465)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6025595 Vali Loss: 1.6093031 Best vali loss: 1.6002545
[36m(_train_fn pid=810465)[0m Updating learning rate to 0.00018792752095564462
[36m(_train_fn pid=810465)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=810465)[0m saving checkpoint...
[36m(_train_fn pid=810465)[0m Epoch: 5 cost time: 13.14763617515564
[36m(_train_fn pid=810465)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5945143 Vali Loss: 1.6143731 Best vali loss: 1.6002545
Trial status: 106 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:55:18. Total running time: 1hr 34min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b96c443f   RUNNING           5            74.0031       0.594514        1.61437             1.60025 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
101 more TERMINATED

Trial trial-b96c443f completed after 6 iterations at 2024-08-24 08:55:28. Total running time: 1hr 34min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b96c443f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         14.66574 â”‚
â”‚ time_total_s                             88.66879 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.60025 â”‚
â”‚ train_loss                                0.58906 â”‚
â”‚ valid_loss                                 1.6151 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=810465)[0m Updating learning rate to 9.396376047782231e-05
[36m(_train_fn pid=810465)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=810465)[0m saving checkpoint...
[36m(_train_fn pid=810465)[0m Epoch: 6 cost time: 13.133846282958984
[36m(_train_fn pid=810465)[0m Epoch: 6, Steps: 61 | Train Loss: 0.5890566 Vali Loss: 1.6150992 Best vali loss: 1.6002545
[36m(_train_fn pid=810465)[0m Early stopping

Trial trial-45bd3b8d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-45bd3b8d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.0949 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                       0.0019 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=811245)[0m configuration
[36m(_train_fn pid=811245)[0m {'batch_size': 64, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.09490425347519124, 'e_layers': 2, 'learning_rate': 0.00189957460942835, 'd_ff': 16}
[36m(_train_fn pid=811245)[0m Use GPU: cuda:0
[36m(_train_fn pid=811245)[0m train 7825
[36m(_train_fn pid=811245)[0m val 2161
[36m(_train_fn pid=811245)[0m start_epoch 0
[36m(_train_fn pid=811245)[0m max_epoch 8
[36m(_train_fn pid=811245)[0m 	iters: 100, epoch: 1 | loss: 1.0785712
[36m(_train_fn pid=811245)[0m 	speed: 0.0146s/iter; left time: 12.8279s
[36m(_train_fn pid=811245)[0m Updating learning rate to 0.00189957460942835
[36m(_train_fn pid=811245)[0m saving checkpoint...
2024-08-24 08:55:33,897	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811245)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-45bd3b8d_108_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-55-28/checkpoint_000001)[32m [repeated 2x across cluster][0m
2024-08-24 08:55:35,283	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:55:36,695	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:55:38,039	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811245)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-45bd3b8d_108_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0._2024-08-24_08-55-28/checkpoint_000005)[32m [repeated 4x across cluster][0m
2024-08-24 08:55:39,421	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811785)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1aa52b5_109_alpha_d_ff=3,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1161,e_layer_2024-08-24_08-55-39/checkpoint_000000)
2024-08-24 08:55:47,170	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811785)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1aa52b5_109_alpha_d_ff=3,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1161,e_layer_2024-08-24_08-55-39/checkpoint_000001)
[36m(_train_fn pid=811245)[0m Validation loss decreased (inf --> 2.3978).  Saving model state dict ...
[36m(_train_fn pid=811245)[0m Epoch: 1 cost time: 1.412590503692627
[36m(_train_fn pid=811245)[0m Epoch: 1, Steps: 122 | Train Loss: 1.2486710 Vali Loss: 2.3978176 Best vali loss: 2.3978176
[36m(_train_fn pid=811245)[0m 	iters: 100, epoch: 2 | loss: 0.6095924
[36m(_train_fn pid=811245)[0m 	speed: 0.0135s/iter; left time: 10.1617s
[36m(_train_fn pid=811245)[0m Updating learning rate to 0.000949787304714175
[36m(_train_fn pid=811245)[0m saving checkpoint...
[36m(_train_fn pid=811245)[0m Validation loss decreased (2.3978 --> 1.5891).  Saving model state dict ...
[36m(_train_fn pid=811245)[0m Epoch: 2 cost time: 1.143808126449585
[36m(_train_fn pid=811245)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6680093 Vali Loss: 1.5891144 Best vali loss: 1.5891144
[36m(_train_fn pid=811245)[0m 	iters: 100, epoch: 3 | loss: 0.6279994
[36m(_train_fn pid=811245)[0m 	speed: 0.0139s/iter; left time: 8.7805s
[36m(_train_fn pid=811245)[0m Updating learning rate to 0.0004748936523570875
[36m(_train_fn pid=811245)[0m saving checkpoint...
[36m(_train_fn pid=811245)[0m Validation loss decreased (1.5891 --> 1.5869).  Saving model state dict ...
[36m(_train_fn pid=811245)[0m Epoch: 3 cost time: 1.2053816318511963
[36m(_train_fn pid=811245)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6109049 Vali Loss: 1.5869468 Best vali loss: 1.5869468
[36m(_train_fn pid=811245)[0m 	iters: 100, epoch: 4 | loss: 0.6223925
[36m(_train_fn pid=811245)[0m 	speed: 0.0141s/iter; left time: 7.2113s
[36m(_train_fn pid=811245)[0m Updating learning rate to 0.00023744682617854375
[36m(_train_fn pid=811245)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=811245)[0m saving checkpoint...
[36m(_train_fn pid=811245)[0m Epoch: 4 cost time: 1.2225570678710938
[36m(_train_fn pid=811245)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6015692 Vali Loss: 1.5880090 Best vali loss: 1.5869468
[36m(_train_fn pid=811245)[0m 	iters: 100, epoch: 5 | loss: 0.5812287
[36m(_train_fn pid=811245)[0m 	speed: 0.0135s/iter; left time: 5.2367s
[36m(_train_fn pid=811245)[0m Updating learning rate to 0.00011872341308927188
[36m(_train_fn pid=811245)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=811245)[0m saving checkpoint...
[36m(_train_fn pid=811245)[0m Epoch: 5 cost time: 1.1568028926849365
[36m(_train_fn pid=811245)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5966037 Vali Loss: 1.5942945 Best vali loss: 1.5869468
[36m(_train_fn pid=811245)[0m 	iters: 100, epoch: 6 | loss: 0.6324163
[36m(_train_fn pid=811245)[0m 	speed: 0.0139s/iter; left time: 3.7158s
[36m(_train_fn pid=811245)[0m Updating learning rate to 5.936170654463594e-05
[36m(_train_fn pid=811245)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=811245)[0m saving checkpoint...
[36m(_train_fn pid=811245)[0m Epoch: 6 cost time: 1.2152791023254395
[36m(_train_fn pid=811245)[0m Epoch: 6, Steps: 122 | Train Loss: 0.5939544 Vali Loss: 1.5920119 Best vali loss: 1.5869468
[36m(_train_fn pid=811245)[0m Early stopping

Trial trial-45bd3b8d completed after 6 iterations at 2024-08-24 08:55:39. Total running time: 1hr 34min 30s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-45bd3b8d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                            1.391 â”‚
â”‚ time_total_s                              8.86618 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.58695 â”‚
â”‚ train_loss                                0.59395 â”‚
â”‚ valid_loss                                1.59201 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-e1aa52b5 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e1aa52b5 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                             0.1161 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                       0.0006 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=811785)[0m configuration
[36m(_train_fn pid=811785)[0m {'batch_size': 64, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.11609765896251968, 'e_layers': 4, 'learning_rate': 0.0006037166867478176, 'd_ff': 48}
[36m(_train_fn pid=811785)[0m Use GPU: cuda:0
[36m(_train_fn pid=811785)[0m train 7825
[36m(_train_fn pid=811785)[0m val 2161
[36m(_train_fn pid=811785)[0m start_epoch 0
[36m(_train_fn pid=811785)[0m max_epoch 8
[36m(_train_fn pid=811785)[0m 	iters: 100, epoch: 1 | loss: 1.6837662
[36m(_train_fn pid=811785)[0m 	speed: 0.0242s/iter; left time: 21.2171s
[36m(_train_fn pid=811785)[0m Updating learning rate to 0.0006037166867478176
[36m(_train_fn pid=811785)[0m saving checkpoint...
[36m(_train_fn pid=811785)[0m Validation loss decreased (inf --> 3.4180).  Saving model state dict ...
[36m(_train_fn pid=811785)[0m Epoch: 1 cost time: 2.5321035385131836
[36m(_train_fn pid=811785)[0m Epoch: 1, Steps: 122 | Train Loss: 1.9152858 Vali Loss: 3.4180056 Best vali loss: 3.4180056
[36m(_train_fn pid=811785)[0m 	iters: 100, epoch: 2 | loss: 0.7006243
[36m(_train_fn pid=811785)[0m 	speed: 0.0236s/iter; left time: 17.8393s
[36m(_train_fn pid=811785)[0m Updating learning rate to 0.0003018583433739088
[36m(_train_fn pid=811785)[0m saving checkpoint...
[36m(_train_fn pid=811785)[0m Validation loss decreased (3.4180 --> 1.7012).  Saving model state dict ...
[36m(_train_fn pid=811785)[0m Epoch: 2 cost time: 1.9873595237731934
[36m(_train_fn pid=811785)[0m Epoch: 2, Steps: 122 | Train Loss: 0.8161048 Vali Loss: 1.7012366 Best vali loss: 1.7012366

Trial status: 108 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:55:48. Total running time: 1hr 34min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:55:49,648	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811785)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1aa52b5_109_alpha_d_ff=3,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1161,e_layer_2024-08-24_08-55-39/checkpoint_000002)
2024-08-24 08:55:52,004	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811785)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1aa52b5_109_alpha_d_ff=3,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1161,e_layer_2024-08-24_08-55-39/checkpoint_000003)
2024-08-24 08:55:54,348	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811785)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1aa52b5_109_alpha_d_ff=3,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1161,e_layer_2024-08-24_08-55-39/checkpoint_000004)
2024-08-24 08:55:56,719	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811785)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1aa52b5_109_alpha_d_ff=3,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1161,e_layer_2024-08-24_08-55-39/checkpoint_000005)
2024-08-24 08:55:59,200	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=811785)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1aa52b5_109_alpha_d_ff=3,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1161,e_layer_2024-08-24_08-55-39/checkpoint_000006)
[36m(_train_fn pid=811785)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e1aa52b5_109_alpha_d_ff=3,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1161,e_layer_2024-08-24_08-55-39/checkpoint_000007)
2024-08-24 08:56:01,711	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e1aa52b5   RUNNING           2            5.63224       0.816105        1.70124             1.70124 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
103 more TERMINATED
[36m(_train_fn pid=811785)[0m 	iters: 100, epoch: 3 | loss: 0.7162193
[36m(_train_fn pid=811785)[0m 	speed: 0.0245s/iter; left time: 15.5179s
[36m(_train_fn pid=811785)[0m Updating learning rate to 0.0001509291716869544
[36m(_train_fn pid=811785)[0m saving checkpoint...
[36m(_train_fn pid=811785)[0m Validation loss decreased (1.7012 --> 1.6309).  Saving model state dict ...
[36m(_train_fn pid=811785)[0m Epoch: 3 cost time: 2.112053155899048
[36m(_train_fn pid=811785)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6593425 Vali Loss: 1.6309451 Best vali loss: 1.6309451
[36m(_train_fn pid=811785)[0m 	iters: 100, epoch: 4 | loss: 0.6573151
[36m(_train_fn pid=811785)[0m 	speed: 0.0237s/iter; left time: 12.1350s
[36m(_train_fn pid=811785)[0m Updating learning rate to 7.54645858434772e-05
[36m(_train_fn pid=811785)[0m saving checkpoint...
[36m(_train_fn pid=811785)[0m Validation loss decreased (1.6309 --> 1.6193).  Saving model state dict ...
[36m(_train_fn pid=811785)[0m Epoch: 4 cost time: 1.9902689456939697
[36m(_train_fn pid=811785)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6429218 Vali Loss: 1.6192612 Best vali loss: 1.6192612
[36m(_train_fn pid=811785)[0m 	iters: 100, epoch: 5 | loss: 0.6732839
[36m(_train_fn pid=811785)[0m 	speed: 0.0235s/iter; left time: 9.1584s
[36m(_train_fn pid=811785)[0m Updating learning rate to 3.77322929217386e-05
[36m(_train_fn pid=811785)[0m saving checkpoint...
[36m(_train_fn pid=811785)[0m Validation loss decreased (1.6193 --> 1.6138).  Saving model state dict ...
[36m(_train_fn pid=811785)[0m Epoch: 5 cost time: 1.9873051643371582
[36m(_train_fn pid=811785)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6380873 Vali Loss: 1.6138013 Best vali loss: 1.6138013
[36m(_train_fn pid=811785)[0m 	iters: 100, epoch: 6 | loss: 0.5853287
[36m(_train_fn pid=811785)[0m 	speed: 0.0236s/iter; left time: 6.2969s
[36m(_train_fn pid=811785)[0m Updating learning rate to 1.88661464608693e-05
[36m(_train_fn pid=811785)[0m saving checkpoint...
[36m(_train_fn pid=811785)[0m Validation loss decreased (1.6138 --> 1.6113).  Saving model state dict ...
[36m(_train_fn pid=811785)[0m Epoch: 6 cost time: 2.0044126510620117
[36m(_train_fn pid=811785)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6353155 Vali Loss: 1.6112800 Best vali loss: 1.6112800
[36m(_train_fn pid=811785)[0m 	iters: 100, epoch: 7 | loss: 0.5847739
[36m(_train_fn pid=811785)[0m 	speed: 0.0247s/iter; left time: 3.5885s
[36m(_train_fn pid=811785)[0m Updating learning rate to 9.43307323043465e-06
[36m(_train_fn pid=811785)[0m saving checkpoint...
[36m(_train_fn pid=811785)[0m Validation loss decreased (1.6113 --> 1.6098).  Saving model state dict ...
[36m(_train_fn pid=811785)[0m Epoch: 7 cost time: 2.129747152328491
[36m(_train_fn pid=811785)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6341489 Vali Loss: 1.6098365 Best vali loss: 1.6098365
[36m(_train_fn pid=811785)[0m 	iters: 100, epoch: 8 | loss: 0.6168329
[36m(_train_fn pid=811785)[0m 	speed: 0.0250s/iter; left time: 0.5743s
[36m(_train_fn pid=811785)[0m Updating learning rate to 4.716536615217325e-06
[36m(_train_fn pid=811785)[0m saving checkpoint...
[36m(_train_fn pid=811785)[0m Validation loss decreased (1.6098 --> 1.6091).  Saving model state dict ...
[36m(_train_fn pid=811785)[0m Epoch: 8 cost time: 2.1479616165161133
[36m(_train_fn pid=811785)[0m Epoch: 8, Steps: 122 | Train Loss: 0.6336291 Vali Loss: 1.6091415 Best vali loss: 1.6091415

Trial trial-e1aa52b5 completed after 8 iterations at 2024-08-24 08:56:01. Total running time: 1hr 34min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e1aa52b5 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          2.50829 â”‚
â”‚ time_total_s                             20.16744 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.60914 â”‚
â”‚ train_loss                                0.63363 â”‚
â”‚ valid_loss                                1.60914 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-55bf5705 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-55bf5705 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.11601 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00107 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=812503)[0m configuration
[36m(_train_fn pid=812503)[0m {'batch_size': 64, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'conv', 'dropout': 0.11601297019240028, 'e_layers': 4, 'learning_rate': 0.0010652052474988043, 'd_ff': 1024}
[36m(_train_fn pid=812503)[0m Use GPU: cuda:0
[36m(_train_fn pid=812503)[0m train 7825
[36m(_train_fn pid=812503)[0m val 2161
[36m(_train_fn pid=812503)[0m start_epoch 0
[36m(_train_fn pid=812503)[0m max_epoch 8

Trial status: 109 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:56:18. Total running time: 1hr 35min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=812503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-55bf5705_110_alpha_d_ff=4,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-56-01/checkpoint_000000)
[36m(_train_fn pid=812503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-55bf5705_110_alpha_d_ff=4,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-56-01/checkpoint_000001)
2024-08-24 08:56:49,686	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:57:12,519	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=812503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-55bf5705_110_alpha_d_ff=4,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-56-01/checkpoint_000002)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-55bf5705   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
104 more TERMINATED
[36m(_train_fn pid=812503)[0m 	iters: 100, epoch: 1 | loss: 0.8465382
[36m(_train_fn pid=812503)[0m 	speed: 0.1709s/iter; left time: 149.8417s
[36m(_train_fn pid=812503)[0m Updating learning rate to 0.0010652052474988043
[36m(_train_fn pid=812503)[0m saving checkpoint...
[36m(_train_fn pid=812503)[0m Validation loss decreased (inf --> 1.9776).  Saving model state dict ...
[36m(_train_fn pid=812503)[0m Epoch: 1 cost time: 20.512235164642334
[36m(_train_fn pid=812503)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8584185 Vali Loss: 1.9775659 Best vali loss: 1.9775659
[36m(_train_fn pid=812503)[0m 	iters: 100, epoch: 2 | loss: 0.6000118
[36m(_train_fn pid=812503)[0m 	speed: 0.2275s/iter; left time: 171.7397s
Trial status: 109 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:56:48. Total running time: 1hr 35min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-55bf5705   RUNNING           1            23.3542       0.858419        1.97757             1.97757 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
104 more TERMINATED
[36m(_train_fn pid=812503)[0m Updating learning rate to 0.0005326026237494021
[36m(_train_fn pid=812503)[0m saving checkpoint...
[36m(_train_fn pid=812503)[0m Validation loss decreased (1.9776 --> 1.6170).  Saving model state dict ...
[36m(_train_fn pid=812503)[0m Epoch: 2 cost time: 20.37633728981018
[36m(_train_fn pid=812503)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6663878 Vali Loss: 1.6170086 Best vali loss: 1.6170086
[36m(_train_fn pid=812503)[0m 	iters: 100, epoch: 3 | loss: 0.6534494
[36m(_train_fn pid=812503)[0m 	speed: 0.2283s/iter; left time: 144.4923s
[36m(_train_fn pid=812503)[0m Updating learning rate to 0.00026630131187470107
[36m(_train_fn pid=812503)[0m saving checkpoint...
[36m(_train_fn pid=812503)[0m Validation loss decreased (1.6170 --> 1.6052).  Saving model state dict ...
[36m(_train_fn pid=812503)[0m Epoch: 3 cost time: 20.428930521011353
[36m(_train_fn pid=812503)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6158416 Vali Loss: 1.6051948 Best vali loss: 1.6051948
Trial status: 109 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:57:18. Total running time: 1hr 36min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:57:35,354	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=812503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-55bf5705_110_alpha_d_ff=4,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-56-01/checkpoint_000003)
[36m(_train_fn pid=812503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-55bf5705_110_alpha_d_ff=4,batch_size=64,d_model=256,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-56-01/checkpoint_000004)
2024-08-24 08:57:58,201	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:58:12,564	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=813285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-af10e011_111_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1120,e_laye_2024-08-24_08-57-58/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-55bf5705   RUNNING           3            68.9553       0.615842        1.60519             1.60519 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
104 more TERMINATED
[36m(_train_fn pid=812503)[0m 	iters: 100, epoch: 4 | loss: 0.5692452
[36m(_train_fn pid=812503)[0m 	speed: 0.2285s/iter; left time: 116.7465s
[36m(_train_fn pid=812503)[0m Updating learning rate to 0.00013315065593735053
[36m(_train_fn pid=812503)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=812503)[0m saving checkpoint...
[36m(_train_fn pid=812503)[0m Epoch: 4 cost time: 20.448887586593628
[36m(_train_fn pid=812503)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6033271 Vali Loss: 1.6493103 Best vali loss: 1.6051948
Trial status: 109 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:57:48. Total running time: 1hr 36min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-55bf5705   RUNNING           4            91.7834       0.603327        1.64931             1.60519 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
104 more TERMINATED
[36m(_train_fn pid=812503)[0m 	iters: 100, epoch: 5 | loss: 0.5825877
[36m(_train_fn pid=812503)[0m 	speed: 0.2285s/iter; left time: 88.8823s

Trial trial-55bf5705 completed after 5 iterations at 2024-08-24 08:57:58. Total running time: 1hr 36min 49s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-55bf5705 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         22.84643 â”‚
â”‚ time_total_s                            114.62979 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.60519 â”‚
â”‚ train_loss                                0.58884 â”‚
â”‚ valid_loss                                1.64511 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=812503)[0m Updating learning rate to 6.657532796867527e-05
[36m(_train_fn pid=812503)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=812503)[0m saving checkpoint...

Trial trial-af10e011 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-af10e011 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11205 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00158 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=813285)[0m configuration
[36m(_train_fn pid=813285)[0m {'batch_size': 128, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.11204714195512491, 'e_layers': 2, 'learning_rate': 0.0015826387023389359, 'd_ff': 512}
[36m(_train_fn pid=813285)[0m Use GPU: cuda:0
[36m(_train_fn pid=813285)[0m train 7825
[36m(_train_fn pid=813285)[0m val 2161
[36m(_train_fn pid=813285)[0m start_epoch 0
[36m(_train_fn pid=813285)[0m max_epoch 8
[36m(_train_fn pid=813285)[0m Validation loss decreased (inf --> 2.0248).  Saving model state dict ...
[36m(_train_fn pid=813285)[0m Epoch: 1 cost time: 10.24565315246582
[36m(_train_fn pid=813285)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8943967 Vali Loss: 2.0247868 Best vali loss: 2.0247868
[36m(_train_fn pid=813285)[0m Updating learning rate to 0.0015826387023389359
[36m(_train_fn pid=813285)[0m saving checkpoint...

Trial status: 110 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:58:18. Total running time: 1hr 37min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 08:58:23,766	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=813285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-af10e011_111_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1120,e_laye_2024-08-24_08-57-58/checkpoint_000001)
[36m(_train_fn pid=813285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-af10e011_111_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1120,e_laye_2024-08-24_08-57-58/checkpoint_000002)
2024-08-24 08:58:34,969	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:58:46,182	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=813285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-af10e011_111_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1120,e_laye_2024-08-24_08-57-58/checkpoint_000003)
2024-08-24 08:58:57,370	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=813285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-af10e011_111_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1120,e_laye_2024-08-24_08-57-58/checkpoint_000004)
2024-08-24 08:59:08,555	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=813285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-af10e011_111_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1120,e_laye_2024-08-24_08-57-58/checkpoint_000005)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-af10e011   RUNNING           1            12.0049       0.894397        2.02479             2.02479 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
105 more TERMINATED
[36m(_train_fn pid=813285)[0m Updating learning rate to 0.0007913193511694679
[36m(_train_fn pid=813285)[0m saving checkpoint...
[36m(_train_fn pid=813285)[0m Validation loss decreased (2.0248 --> 1.6534).  Saving model state dict ...
[36m(_train_fn pid=813285)[0m Epoch: 2 cost time: 9.857003688812256
[36m(_train_fn pid=813285)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7233129 Vali Loss: 1.6533980 Best vali loss: 1.6533980
[36m(_train_fn pid=813285)[0m Updating learning rate to 0.00039565967558473396
[36m(_train_fn pid=813285)[0m saving checkpoint...
[36m(_train_fn pid=813285)[0m Validation loss decreased (1.6534 --> 1.6003).  Saving model state dict ...
[36m(_train_fn pid=813285)[0m Epoch: 3 cost time: 9.86311960220337
[36m(_train_fn pid=813285)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6291065 Vali Loss: 1.6003384 Best vali loss: 1.6003384
[36m(_train_fn pid=813285)[0m Updating learning rate to 0.00019782983779236698
[36m(_train_fn pid=813285)[0m saving checkpoint...
[36m(_train_fn pid=813285)[0m Validation loss decreased (1.6003 --> 1.5953).  Saving model state dict ...
[36m(_train_fn pid=813285)[0m Epoch: 4 cost time: 9.855873584747314
[36m(_train_fn pid=813285)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6167518 Vali Loss: 1.5953330 Best vali loss: 1.5953330
Trial status: 110 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:58:48. Total running time: 1hr 37min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-af10e011   RUNNING           4            45.6135       0.616752        1.59533             1.59533 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
105 more TERMINATED
[36m(_train_fn pid=813285)[0m Updating learning rate to 9.891491889618349e-05
[36m(_train_fn pid=813285)[0m saving checkpoint...
[36m(_train_fn pid=813285)[0m Validation loss decreased (1.5953 --> 1.5928).  Saving model state dict ...
[36m(_train_fn pid=813285)[0m Epoch: 5 cost time: 9.84114694595337
[36m(_train_fn pid=813285)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6136830 Vali Loss: 1.5927698 Best vali loss: 1.5927698
[36m(_train_fn pid=813285)[0m Updating learning rate to 4.9457459448091745e-05
[36m(_train_fn pid=813285)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=813285)[0m saving checkpoint...
[36m(_train_fn pid=813285)[0m Epoch: 6 cost time: 9.853233575820923
[36m(_train_fn pid=813285)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6122321 Vali Loss: 1.5963745 Best vali loss: 1.5927698
Trial status: 110 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:59:18. Total running time: 1hr 38min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 08:59:19,723	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=813285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-af10e011_111_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1120,e_laye_2024-08-24_08-57-58/checkpoint_000006)
2024-08-24 08:59:30,891	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=813285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-af10e011_111_alpha_d_ff=2,batch_size=128,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1120,e_laye_2024-08-24_08-57-58/checkpoint_000007)
2024-08-24 08:59:34,249	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814211)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f702e741_112_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1103,e_layer_2024-08-24_08-59-30/checkpoint_000000)
2024-08-24 08:59:35,151	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814211)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f702e741_112_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1103,e_layer_2024-08-24_08-59-30/checkpoint_000001)
2024-08-24 08:59:36,052	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814211)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f702e741_112_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1103,e_layer_2024-08-24_08-59-30/checkpoint_000002)
[36m(_train_fn pid=814211)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f702e741_112_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1103,e_layer_2024-08-24_08-59-30/checkpoint_000003)
2024-08-24 08:59:36,937	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 08:59:37,834	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814211)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f702e741_112_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1103,e_layer_2024-08-24_08-59-30/checkpoint_000004)
2024-08-24 08:59:38,743	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814211)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f702e741_112_alpha_d_ff=2,batch_size=128,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1103,e_layer_2024-08-24_08-59-30/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-af10e011   RUNNING           6            67.9887       0.612232        1.59637             1.59277 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
105 more TERMINATED
[36m(_train_fn pid=813285)[0m Updating learning rate to 2.4728729724045873e-05
[36m(_train_fn pid=813285)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=813285)[0m saving checkpoint...
[36m(_train_fn pid=813285)[0m Epoch: 7 cost time: 9.837722539901733
[36m(_train_fn pid=813285)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6116254 Vali Loss: 1.5956095 Best vali loss: 1.5927698

Trial trial-af10e011 completed after 8 iterations at 2024-08-24 08:59:30. Total running time: 1hr 38min 22s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-af10e011 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                         11.16564 â”‚
â”‚ time_total_s                             90.31987 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.59277 â”‚
â”‚ train_loss                                0.61095 â”‚
â”‚ valid_loss                                1.59453 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=813285)[0m Updating learning rate to 1.2364364862022936e-05
[36m(_train_fn pid=813285)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=813285)[0m saving checkpoint...
[36m(_train_fn pid=813285)[0m Epoch: 8 cost time: 9.840494394302368
[36m(_train_fn pid=813285)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6109514 Vali Loss: 1.5945320 Best vali loss: 1.5927698
[36m(_train_fn pid=813285)[0m Early stopping

Trial trial-f702e741 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f702e741 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11029 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00224 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=814211)[0m configuration
[36m(_train_fn pid=814211)[0m {'batch_size': 128, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.11028591859520419, 'e_layers': 1, 'learning_rate': 0.00224471766103687, 'd_ff': 32}
[36m(_train_fn pid=814211)[0m Use GPU: cuda:0
[36m(_train_fn pid=814211)[0m train 7825
[36m(_train_fn pid=814211)[0m val 2161
[36m(_train_fn pid=814211)[0m start_epoch 0
[36m(_train_fn pid=814211)[0m max_epoch 8
[36m(_train_fn pid=814211)[0m Validation loss decreased (inf --> 2.1263).  Saving model state dict ...
[36m(_train_fn pid=814211)[0m Epoch: 1 cost time: 1.1270549297332764
[36m(_train_fn pid=814211)[0m Epoch: 1, Steps: 61 | Train Loss: 0.9970265 Vali Loss: 2.1263025 Best vali loss: 2.1263025
[36m(_train_fn pid=814211)[0m Validation loss decreased (2.1263 --> 1.6251).  Saving model state dict ...
[36m(_train_fn pid=814211)[0m Epoch: 2 cost time: 0.7233402729034424
[36m(_train_fn pid=814211)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7196257 Vali Loss: 1.6251416 Best vali loss: 1.6251416
[36m(_train_fn pid=814211)[0m Validation loss decreased (1.6251 --> 1.6061).  Saving model state dict ...
[36m(_train_fn pid=814211)[0m Epoch: 3 cost time: 0.7188031673431396
[36m(_train_fn pid=814211)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6351503 Vali Loss: 1.6061283 Best vali loss: 1.6061283
[36m(_train_fn pid=814211)[0m Updating learning rate to 0.0005611794152592175[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=814211)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=814211)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=814211)[0m Epoch: 4 cost time: 0.7095961570739746
[36m(_train_fn pid=814211)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6245603 Vali Loss: 1.6078269 Best vali loss: 1.6061283
[36m(_train_fn pid=814211)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=814211)[0m Epoch: 5 cost time: 0.7238352298736572
[36m(_train_fn pid=814211)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6211811 Vali Loss: 1.6104127 Best vali loss: 1.6061283

Trial trial-f702e741 completed after 6 iterations at 2024-08-24 08:59:38. Total running time: 1hr 38min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f702e741 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          0.90623 â”‚
â”‚ time_total_s                              6.17819 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.60613 â”‚
â”‚ train_loss                                0.61921 â”‚
â”‚ valid_loss                                1.61148 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=814211)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=814211)[0m Epoch: 6 cost time: 0.7372808456420898
[36m(_train_fn pid=814211)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6192147 Vali Loss: 1.6114761 Best vali loss: 1.6061283
[36m(_train_fn pid=814211)[0m Early stopping

Trial trial-553c7619 started with configuration:
[36m(_train_fn pid=814746)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-553c7619_113_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1260,e_layer_2024-08-24_08-59-38/checkpoint_000000)
2024-08-24 08:59:48,678	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814746)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-553c7619_113_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1260,e_layer_2024-08-24_08-59-38/checkpoint_000001)
2024-08-24 08:59:52,128	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814746)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-553c7619_113_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1260,e_layer_2024-08-24_08-59-38/checkpoint_000002)
2024-08-24 08:59:55,577	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814746)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-553c7619_113_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1260,e_layer_2024-08-24_08-59-38/checkpoint_000003)
2024-08-24 08:59:59,223	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=814746)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-553c7619_113_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1260,e_layer_2024-08-24_08-59-38/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-553c7619 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.12596 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00069 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=814746)[0m configuration
[36m(_train_fn pid=814746)[0m {'batch_size': 32, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.12596307456262443, 'e_layers': 3, 'learning_rate': 0.0006869229490368634, 'd_ff': 96}
[36m(_train_fn pid=814746)[0m Use GPU: cuda:0
[36m(_train_fn pid=814746)[0m train 7825
[36m(_train_fn pid=814746)[0m val 2161
[36m(_train_fn pid=814746)[0m start_epoch 0
[36m(_train_fn pid=814746)[0m max_epoch 8
[36m(_train_fn pid=814746)[0m 	iters: 100, epoch: 1 | loss: 0.9004283
[36m(_train_fn pid=814746)[0m 	speed: 0.0200s/iter; left time: 37.0315s
[36m(_train_fn pid=814211)[0m Updating learning rate to 7.014742690740219e-05[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=814211)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=814746)[0m 	iters: 200, epoch: 1 | loss: 0.9132156
[36m(_train_fn pid=814746)[0m 	speed: 0.0128s/iter; left time: 22.4823s
[36m(_train_fn pid=814746)[0m Validation loss decreased (inf --> 2.0745).  Saving model state dict ...
[36m(_train_fn pid=814746)[0m Epoch: 1 cost time: 3.5875401496887207
[36m(_train_fn pid=814746)[0m Epoch: 1, Steps: 244 | Train Loss: 0.9368234 Vali Loss: 2.0745357 Best vali loss: 2.0745357
[36m(_train_fn pid=814746)[0m 	iters: 100, epoch: 2 | loss: 0.6916666
[36m(_train_fn pid=814746)[0m 	speed: 0.0239s/iter; left time: 38.3906s
[36m(_train_fn pid=814746)[0m 	iters: 200, epoch: 2 | loss: 0.6751950
[36m(_train_fn pid=814746)[0m 	speed: 0.0128s/iter; left time: 19.2469s

Trial status: 112 TERMINATED | 1 RUNNING
Current time: 2024-08-24 08:59:48. Total running time: 1hr 38min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-553c7619   RUNNING           1            4.46682       0.936823        2.07454             2.07454 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
107 more TERMINATED
[36m(_train_fn pid=814746)[0m Validation loss decreased (2.0745 --> 1.5970).  Saving model state dict ...
[36m(_train_fn pid=814746)[0m Epoch: 2 cost time: 3.1908907890319824
[36m(_train_fn pid=814746)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6637961 Vali Loss: 1.5970449 Best vali loss: 1.5970449
[36m(_train_fn pid=814746)[0m Updating learning rate to 0.0003434614745184317[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=814746)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=814746)[0m 	iters: 100, epoch: 3 | loss: 0.6465245
[36m(_train_fn pid=814746)[0m 	speed: 0.0229s/iter; left time: 31.2464s
[36m(_train_fn pid=814746)[0m 	iters: 200, epoch: 3 | loss: 0.6431871
[36m(_train_fn pid=814746)[0m 	speed: 0.0120s/iter; left time: 15.2280s
[36m(_train_fn pid=814746)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=814746)[0m Epoch: 3 cost time: 2.977349042892456
[36m(_train_fn pid=814746)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6049125 Vali Loss: 1.6083722 Best vali loss: 1.5970449
[36m(_train_fn pid=814746)[0m 	iters: 100, epoch: 4 | loss: 0.4933720
[36m(_train_fn pid=814746)[0m 	speed: 0.0224s/iter; left time: 25.1317s
[36m(_train_fn pid=814746)[0m 	iters: 200, epoch: 4 | loss: 0.6001734
[36m(_train_fn pid=814746)[0m 	speed: 0.0121s/iter; left time: 12.3147s
[36m(_train_fn pid=814746)[0m Updating learning rate to 0.00017173073725921585
[36m(_train_fn pid=814746)[0m saving checkpoint...
[36m(_train_fn pid=814746)[0m Updating learning rate to 8.586536862960792e-05
[36m(_train_fn pid=814746)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=814746)[0m saving checkpoint...
[36m(_train_fn pid=814746)[0m Epoch: 4 cost time: 2.9845004081726074
[36m(_train_fn pid=814746)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5931501 Vali Loss: 1.6092179 Best vali loss: 1.5970449
[36m(_train_fn pid=814746)[0m 	iters: 100, epoch: 5 | loss: 0.5794417
[36m(_train_fn pid=814746)[0m 	speed: 0.0233s/iter; left time: 20.4218s
[36m(_train_fn pid=814746)[0m 	iters: 200, epoch: 5 | loss: 0.5954984
[36m(_train_fn pid=814746)[0m 	speed: 0.0129s/iter; left time: 10.0163s

Trial trial-553c7619 completed after 5 iterations at 2024-08-24 08:59:59. Total running time: 1hr 38min 50s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-553c7619 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.65253 â”‚
â”‚ time_total_s                             18.66862 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59704 â”‚
â”‚ train_loss                                0.58823 â”‚
â”‚ valid_loss                                1.59858 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=814746)[0m Updating learning rate to 4.293268431480396e-05
[36m(_train_fn pid=814746)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=814746)[0m saving checkpoint...
2024-08-24 09:00:13,235	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=815246)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-69363883_114_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-59-59/checkpoint_000000)
[36m(_train_fn pid=815246)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-69363883_114_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-59-59/checkpoint_000001)
2024-08-24 09:00:24,304	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:00:35,355	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=815246)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-69363883_114_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-59-59/checkpoint_000002)
2024-08-24 09:00:46,416	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=815246)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-69363883_114_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-59-59/checkpoint_000003)
[36m(_train_fn pid=814746)[0m Epoch: 5 cost time: 3.1907670497894287
[36m(_train_fn pid=814746)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5882311 Vali Loss: 1.5985829 Best vali loss: 1.5970449
[36m(_train_fn pid=814746)[0m Early stopping

Trial trial-69363883 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-69363883 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.10453 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00052 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=815246)[0m configuration
[36m(_train_fn pid=815246)[0m {'batch_size': 32, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'conv', 'dropout': 0.104528922248715, 'e_layers': 4, 'learning_rate': 0.0005224670506854545, 'd_ff': 512}
[36m(_train_fn pid=815246)[0m Use GPU: cuda:0
[36m(_train_fn pid=815246)[0m train 7825
[36m(_train_fn pid=815246)[0m val 2161
[36m(_train_fn pid=815246)[0m start_epoch 0
[36m(_train_fn pid=815246)[0m max_epoch 8
[36m(_train_fn pid=815246)[0m 	iters: 100, epoch: 1 | loss: 0.9167550
[36m(_train_fn pid=815246)[0m 	speed: 0.0452s/iter; left time: 83.8210s
[36m(_train_fn pid=815246)[0m 	iters: 200, epoch: 1 | loss: 0.7524753
[36m(_train_fn pid=815246)[0m 	speed: 0.0404s/iter; left time: 70.8230s
[36m(_train_fn pid=815246)[0m Updating learning rate to 0.0005224670506854545
[36m(_train_fn pid=815246)[0m saving checkpoint...
[36m(_train_fn pid=815246)[0m Validation loss decreased (inf --> 1.9667).  Saving model state dict ...
[36m(_train_fn pid=815246)[0m Epoch: 1 cost time: 10.076082229614258
[36m(_train_fn pid=815246)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8213185 Vali Loss: 1.9667109 Best vali loss: 1.9667109
[36m(_train_fn pid=815246)[0m 	iters: 100, epoch: 2 | loss: 0.6125254
[36m(_train_fn pid=815246)[0m 	speed: 0.0702s/iter; left time: 113.0065s

Trial status: 113 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:00:18. Total running time: 1hr 39min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-69363883   RUNNING           1            11.6719       0.821318        1.96671             1.96671 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
108 more TERMINATED
[36m(_train_fn pid=815246)[0m 	iters: 200, epoch: 2 | loss: 0.6306272
[36m(_train_fn pid=815246)[0m 	speed: 0.0404s/iter; left time: 60.9415s
[36m(_train_fn pid=815246)[0m Updating learning rate to 0.00026123352534272726
[36m(_train_fn pid=815246)[0m saving checkpoint...
[36m(_train_fn pid=815246)[0m Validation loss decreased (1.9667 --> 1.5837).  Saving model state dict ...
[36m(_train_fn pid=815246)[0m Epoch: 2 cost time: 9.881110429763794
[36m(_train_fn pid=815246)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6498783 Vali Loss: 1.5837160 Best vali loss: 1.5837160
[36m(_train_fn pid=815246)[0m 	iters: 100, epoch: 3 | loss: 0.6524401
[36m(_train_fn pid=815246)[0m 	speed: 0.0703s/iter; left time: 95.9831s
[36m(_train_fn pid=815246)[0m 	iters: 200, epoch: 3 | loss: 0.6507766
[36m(_train_fn pid=815246)[0m 	speed: 0.0404s/iter; left time: 51.1056s
[36m(_train_fn pid=815246)[0m Updating learning rate to 0.00013061676267136363
[36m(_train_fn pid=815246)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=815246)[0m saving checkpoint...
[36m(_train_fn pid=815246)[0m Epoch: 3 cost time: 9.880913257598877
[36m(_train_fn pid=815246)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6097058 Vali Loss: 1.5930408 Best vali loss: 1.5837160
[36m(_train_fn pid=815246)[0m 	iters: 100, epoch: 4 | loss: 0.5219405
[36m(_train_fn pid=815246)[0m 	speed: 0.0701s/iter; left time: 78.5893s
[36m(_train_fn pid=815246)[0m 	iters: 200, epoch: 4 | loss: 0.6156597
[36m(_train_fn pid=815246)[0m 	speed: 0.0405s/iter; left time: 41.3005s
[36m(_train_fn pid=815246)[0m Updating learning rate to 6.530838133568181e-05
[36m(_train_fn pid=815246)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=815246)[0m saving checkpoint...
[36m(_train_fn pid=815246)[0m Epoch: 4 cost time: 9.888091802597046
[36m(_train_fn pid=815246)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6007634 Vali Loss: 1.5942455 Best vali loss: 1.5837160
Trial status: 113 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:00:48. Total running time: 1hr 39min 39s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=815246)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-69363883_114_alpha_d_ff=4,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=25,down_sampling_method=conv,dropout_2024-08-24_08-59-59/checkpoint_000004)
2024-08-24 09:00:57,525	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=815855)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ea956f6_115_alpha_d_ff=2,batch_size=64,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0480,e_layers_2024-08-24_09-00-57/checkpoint_000000)
[36m(_train_fn pid=815855)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ea956f6_115_alpha_d_ff=2,batch_size=64,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0480,e_layers_2024-08-24_09-00-57/checkpoint_000001)
[36m(_train_fn pid=815855)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ea956f6_115_alpha_d_ff=2,batch_size=64,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0480,e_layers_2024-08-24_09-00-57/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-69363883   RUNNING           4            44.8552       0.600763        1.59425             1.58372 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
108 more TERMINATED
[36m(_train_fn pid=815246)[0m 	iters: 100, epoch: 5 | loss: 0.6924108
[36m(_train_fn pid=815246)[0m 	speed: 0.0704s/iter; left time: 61.7811s
[36m(_train_fn pid=815246)[0m 	iters: 200, epoch: 5 | loss: 0.5480184
[36m(_train_fn pid=815246)[0m 	speed: 0.0406s/iter; left time: 31.5224s
[36m(_train_fn pid=815246)[0m Updating learning rate to 3.265419066784091e-05
[36m(_train_fn pid=815246)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=815246)[0m saving checkpoint...

Trial trial-69363883 completed after 5 iterations at 2024-08-24 09:00:57. Total running time: 1hr 39min 48s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-69363883 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         11.10561 â”‚
â”‚ time_total_s                             55.96079 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58372 â”‚
â”‚ train_loss                                0.59019 â”‚
â”‚ valid_loss                                1.63875 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=815246)[0m Epoch: 5 cost time: 9.92598843574524
[36m(_train_fn pid=815246)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5901920 Vali Loss: 1.6387507 Best vali loss: 1.5837160
[36m(_train_fn pid=815246)[0m Early stopping

Trial trial-5ea956f6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5ea956f6 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                              0.048 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00991 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=815855)[0m configuration
[36m(_train_fn pid=815855)[0m {'batch_size': 64, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.04800427111114352, 'e_layers': 4, 'learning_rate': 0.009910489295670668, 'd_ff': 128}
[36m(_train_fn pid=815855)[0m Use GPU: cuda:0
[36m(_train_fn pid=815855)[0m train 7825
[36m(_train_fn pid=815855)[0m val 2161
[36m(_train_fn pid=815855)[0m start_epoch 0
[36m(_train_fn pid=815855)[0m max_epoch 8
[36m(_train_fn pid=815855)[0m 	iters: 100, epoch: 1 | loss: 0.6742368
[36m(_train_fn pid=815855)[0m 	speed: 0.0424s/iter; left time: 37.1926s
[36m(_train_fn pid=815855)[0m Updating learning rate to 0.009910489295670668
[36m(_train_fn pid=815855)[0m saving checkpoint...
[36m(_train_fn pid=815855)[0m Validation loss decreased (inf --> 1.6402).  Saving model state dict ...
[36m(_train_fn pid=815855)[0m Epoch: 1 cost time: 4.743083953857422
[36m(_train_fn pid=815855)[0m Epoch: 1, Steps: 122 | Train Loss: 0.7393843 Vali Loss: 1.6402136 Best vali loss: 1.6402136
[36m(_train_fn pid=815855)[0m 	iters: 100, epoch: 2 | loss: 0.6857666
[36m(_train_fn pid=815855)[0m 	speed: 0.0501s/iter; left time: 37.8040s
[36m(_train_fn pid=815855)[0m Updating learning rate to 0.004955244647835334
[36m(_train_fn pid=815855)[0m saving checkpoint...
[36m(_train_fn pid=815855)[0m Validation loss decreased (1.6402 --> 1.5869).  Saving model state dict ...
[36m(_train_fn pid=815855)[0m Epoch: 2 cost time: 4.3309242725372314
[36m(_train_fn pid=815855)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6453794 Vali Loss: 1.5869348 Best vali loss: 1.5869348
[36m(_train_fn pid=815855)[0m 	iters: 100, epoch: 3 | loss: 0.6086473
[36m(_train_fn pid=815855)[0m 	speed: 0.0501s/iter; left time: 31.7326s
[36m(_train_fn pid=815855)[0m Updating learning rate to 0.002477622323917667
[36m(_train_fn pid=815855)[0m saving checkpoint...
[36m(_train_fn pid=815855)[0m Validation loss decreased (1.5869 --> 1.5834).  Saving model state dict ...
[36m(_train_fn pid=815855)[0m Epoch: 3 cost time: 4.32806658744812
[36m(_train_fn pid=815855)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5795363 Vali Loss: 1.5833741 Best vali loss: 1.5833741

Trial status: 114 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:01:18. Total running time: 1hr 40min 9s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=815855)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ea956f6_115_alpha_d_ff=2,batch_size=64,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0480,e_layers_2024-08-24_09-00-57/checkpoint_000003)
[36m(_train_fn pid=815855)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ea956f6_115_alpha_d_ff=2,batch_size=64,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0480,e_layers_2024-08-24_09-00-57/checkpoint_000004)
[36m(_train_fn pid=815855)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5ea956f6_115_alpha_d_ff=2,batch_size=64,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0480,e_layers_2024-08-24_09-00-57/checkpoint_000005)
2024-08-24 09:01:42,459	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=816461)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f38f2860_116_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1082,e_laye_2024-08-24_09-01-30/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5ea956f6   RUNNING           3            15.8635       0.579536        1.58337             1.58337 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
109 more TERMINATED
[36m(_train_fn pid=815855)[0m 	iters: 100, epoch: 4 | loss: 0.5455304
[36m(_train_fn pid=815855)[0m 	speed: 0.0502s/iter; left time: 25.6522s
[36m(_train_fn pid=815855)[0m Updating learning rate to 0.0012388111619588335
[36m(_train_fn pid=815855)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=815855)[0m saving checkpoint...
[36m(_train_fn pid=815855)[0m Epoch: 4 cost time: 4.331179618835449
[36m(_train_fn pid=815855)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5424961 Vali Loss: 1.5950816 Best vali loss: 1.5833741
[36m(_train_fn pid=815855)[0m 	iters: 100, epoch: 5 | loss: 0.5200816
[36m(_train_fn pid=815855)[0m 	speed: 0.0500s/iter; left time: 19.4583s
[36m(_train_fn pid=815855)[0m Updating learning rate to 0.0006194055809794168
[36m(_train_fn pid=815855)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=815855)[0m saving checkpoint...
[36m(_train_fn pid=815855)[0m Epoch: 5 cost time: 4.3259851932525635
[36m(_train_fn pid=815855)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5131096 Vali Loss: 1.5892533 Best vali loss: 1.5833741
[36m(_train_fn pid=815855)[0m 	iters: 100, epoch: 6 | loss: 0.5190074
[36m(_train_fn pid=815855)[0m 	speed: 0.0501s/iter; left time: 13.3684s

Trial trial-5ea956f6 completed after 6 iterations at 2024-08-24 09:01:30. Total running time: 1hr 40min 21s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5ea956f6 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          5.01696 â”‚
â”‚ time_total_s                             30.88434 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.58337 â”‚
â”‚ train_loss                                0.48806 â”‚
â”‚ valid_loss                                1.61111 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=815855)[0m Updating learning rate to 0.0003097027904897084
[36m(_train_fn pid=815855)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=815855)[0m saving checkpoint...
[36m(_train_fn pid=815855)[0m Epoch: 6 cost time: 4.339860439300537
[36m(_train_fn pid=815855)[0m Epoch: 6, Steps: 122 | Train Loss: 0.4880564 Vali Loss: 1.6111067 Best vali loss: 1.5833741
[36m(_train_fn pid=815855)[0m Early stopping

Trial trial-f38f2860 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f38f2860 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                             0.1082 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00698 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=816461)[0m configuration
[36m(_train_fn pid=816461)[0m {'batch_size': 32, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.10820134956025347, 'e_layers': 1, 'learning_rate': 0.006982553739572405, 'd_ff': 768}
[36m(_train_fn pid=816461)[0m Use GPU: cuda:0
[36m(_train_fn pid=816461)[0m train 7825
[36m(_train_fn pid=816461)[0m val 2161
[36m(_train_fn pid=816461)[0m start_epoch 0
[36m(_train_fn pid=816461)[0m max_epoch 8
[36m(_train_fn pid=816461)[0m 	iters: 100, epoch: 1 | loss: 0.6669635
[36m(_train_fn pid=816461)[0m 	speed: 0.0396s/iter; left time: 73.4412s
[36m(_train_fn pid=816461)[0m 	iters: 200, epoch: 1 | loss: 0.7052159
[36m(_train_fn pid=816461)[0m 	speed: 0.0327s/iter; left time: 57.3261s
[36m(_train_fn pid=816461)[0m Updating learning rate to 0.006982553739572405
[36m(_train_fn pid=816461)[0m saving checkpoint...
[36m(_train_fn pid=816461)[0m Validation loss decreased (inf --> 1.6404).  Saving model state dict ...
[36m(_train_fn pid=816461)[0m Epoch: 1 cost time: 8.411020517349243
[36m(_train_fn pid=816461)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7164154 Vali Loss: 1.6403909 Best vali loss: 1.6403909
[36m(_train_fn pid=816461)[0m 	iters: 100, epoch: 2 | loss: 0.8298874
[36m(_train_fn pid=816461)[0m 	speed: 0.0582s/iter; left time: 93.5947s

Trial status: 115 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:01:48. Total running time: 1hr 40min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=816461)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f38f2860_116_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1082,e_laye_2024-08-24_09-01-30/checkpoint_000001)
[36m(_train_fn pid=816461)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f38f2860_116_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1082,e_laye_2024-08-24_09-01-30/checkpoint_000002)
[36m(_train_fn pid=816461)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f38f2860_116_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1082,e_laye_2024-08-24_09-01-30/checkpoint_000003)
[36m(_train_fn pid=816461)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f38f2860_116_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1082,e_laye_2024-08-24_09-01-30/checkpoint_000004)
[36m(_train_fn pid=816461)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f38f2860_116_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1082,e_laye_2024-08-24_09-01-30/checkpoint_000005)
[36m(_train_fn pid=816461)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f38f2860_116_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1082,e_laye_2024-08-24_09-01-30/checkpoint_000006)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f38f2860   RUNNING           1             9.9049       0.716415        1.64039             1.64039 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
110 more TERMINATED
[36m(_train_fn pid=816461)[0m 	iters: 200, epoch: 2 | loss: 0.6238865
[36m(_train_fn pid=816461)[0m 	speed: 0.0323s/iter; left time: 48.7552s
[36m(_train_fn pid=816461)[0m Updating learning rate to 0.0034912768697862025
[36m(_train_fn pid=816461)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=816461)[0m saving checkpoint...
[36m(_train_fn pid=816461)[0m Epoch: 2 cost time: 7.936715126037598
[36m(_train_fn pid=816461)[0m Epoch: 2, Steps: 244 | Train Loss: 1.5137810 Vali Loss: 1.7395510 Best vali loss: 1.6403909
[36m(_train_fn pid=816461)[0m 	iters: 100, epoch: 3 | loss: 0.6220902
[36m(_train_fn pid=816461)[0m 	speed: 0.0576s/iter; left time: 78.6140s
[36m(_train_fn pid=816461)[0m 	iters: 200, epoch: 3 | loss: 0.7061068
[36m(_train_fn pid=816461)[0m 	speed: 0.0323s/iter; left time: 40.8684s
[36m(_train_fn pid=816461)[0m Updating learning rate to 0.0017456384348931012
[36m(_train_fn pid=816461)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=816461)[0m saving checkpoint...
[36m(_train_fn pid=816461)[0m Epoch: 3 cost time: 7.914896011352539
[36m(_train_fn pid=816461)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6641520 Vali Loss: 1.6411947 Best vali loss: 1.6403909
[36m(_train_fn pid=816461)[0m 	iters: 100, epoch: 4 | loss: 0.6731970
[36m(_train_fn pid=816461)[0m 	speed: 0.0577s/iter; left time: 64.6454s
[36m(_train_fn pid=816461)[0m 	iters: 200, epoch: 4 | loss: 0.5923356
[36m(_train_fn pid=816461)[0m 	speed: 0.0323s/iter; left time: 33.0202s
[36m(_train_fn pid=816461)[0m Updating learning rate to 0.0008728192174465506
[36m(_train_fn pid=816461)[0m saving checkpoint...
[36m(_train_fn pid=816461)[0m Validation loss decreased (1.6404 --> 1.6212).  Saving model state dict ...
[36m(_train_fn pid=816461)[0m Epoch: 4 cost time: 7.927842855453491
[36m(_train_fn pid=816461)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6442618 Vali Loss: 1.6211789 Best vali loss: 1.6211789
[36m(_train_fn pid=816461)[0m 	iters: 100, epoch: 5 | loss: 0.7008166
[36m(_train_fn pid=816461)[0m 	speed: 0.0578s/iter; left time: 50.7166s
[36m(_train_fn pid=816461)[0m 	iters: 200, epoch: 5 | loss: 0.5876421
[36m(_train_fn pid=816461)[0m 	speed: 0.0323s/iter; left time: 25.0997s
[36m(_train_fn pid=816461)[0m Updating learning rate to 0.0004364096087232753
[36m(_train_fn pid=816461)[0m saving checkpoint...
[36m(_train_fn pid=816461)[0m Validation loss decreased (1.6212 --> 1.6122).  Saving model state dict ...
[36m(_train_fn pid=816461)[0m Epoch: 5 cost time: 7.919212579727173
[36m(_train_fn pid=816461)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6375223 Vali Loss: 1.6121914 Best vali loss: 1.6121914
Trial status: 115 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:02:18. Total running time: 1hr 41min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f38f2860   RUNNING           5            45.9204       0.637522        1.61219             1.61219 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
110 more TERMINATED
[36m(_train_fn pid=816461)[0m 	iters: 100, epoch: 6 | loss: 0.6736355
[36m(_train_fn pid=816461)[0m 	speed: 0.0578s/iter; left time: 36.6007s
[36m(_train_fn pid=816461)[0m 	iters: 200, epoch: 6 | loss: 0.6658488
[36m(_train_fn pid=816461)[0m 	speed: 0.0324s/iter; left time: 17.2782s
[36m(_train_fn pid=816461)[0m Updating learning rate to 0.00021820480436163765
[36m(_train_fn pid=816461)[0m saving checkpoint...
[36m(_train_fn pid=816461)[0m Validation loss decreased (1.6122 --> 1.6088).  Saving model state dict ...
[36m(_train_fn pid=816461)[0m Epoch: 6 cost time: 7.940602540969849
[36m(_train_fn pid=816461)[0m Epoch: 6, Steps: 244 | Train Loss: 0.6347127 Vali Loss: 1.6087704 Best vali loss: 1.6087704
[36m(_train_fn pid=816461)[0m 	iters: 100, epoch: 7 | loss: 0.7266560
[36m(_train_fn pid=816461)[0m 	speed: 0.0579s/iter; left time: 22.5388s
[36m(_train_fn pid=816461)[0m 	iters: 200, epoch: 7 | loss: 0.6917197
[36m(_train_fn pid=816461)[0m 	speed: 0.0324s/iter; left time: 9.3654s
[36m(_train_fn pid=816461)[0m Updating learning rate to 0.00010910240218081883
[36m(_train_fn pid=816461)[0m saving checkpoint...
[36m(_train_fn pid=816461)[0m Validation loss decreased (1.6088 --> 1.6065).  Saving model state dict ...
[36m(_train_fn pid=816461)[0m Epoch: 7 cost time: 7.9396748542785645
[36m(_train_fn pid=816461)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f38f2860_116_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1082,e_laye_2024-08-24_09-01-30/checkpoint_000007)
[36m(_train_fn pid=817331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1c202e21_117_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0585,e_layer_2024-08-24_09-02-45/checkpoint_000000)
2024-08-24 09:02:55,800	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=817331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1c202e21_117_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0585,e_layer_2024-08-24_09-02-45/checkpoint_000001)
[36m(_train_fn pid=816461)[0m Epoch: 7, Steps: 244 | Train Loss: 0.6332861 Vali Loss: 1.6065490 Best vali loss: 1.6065490
[36m(_train_fn pid=816461)[0m 	iters: 100, epoch: 8 | loss: 0.6342137
[36m(_train_fn pid=816461)[0m 	speed: 0.0579s/iter; left time: 8.3950s
[36m(_train_fn pid=816461)[0m 	iters: 200, epoch: 8 | loss: 0.6113241
[36m(_train_fn pid=816461)[0m 	speed: 0.0325s/iter; left time: 1.4605s

Trial trial-f38f2860 completed after 8 iterations at 2024-08-24 09:02:45. Total running time: 1hr 41min 36s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f38f2860 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          9.03362 â”‚
â”‚ time_total_s                             73.01387 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.60556 â”‚
â”‚ train_loss                                 0.6325 â”‚
â”‚ valid_loss                                1.60556 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=816461)[0m Updating learning rate to 5.455120109040941e-05
[36m(_train_fn pid=816461)[0m saving checkpoint...
[36m(_train_fn pid=816461)[0m Validation loss decreased (1.6065 --> 1.6056).  Saving model state dict ...
[36m(_train_fn pid=816461)[0m Epoch: 8 cost time: 7.948029279708862
[36m(_train_fn pid=816461)[0m Epoch: 8, Steps: 244 | Train Loss: 0.6325024 Vali Loss: 1.6055615 Best vali loss: 1.6055615

Trial trial-1c202e21 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1c202e21 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                             0.0585 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00347 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=817331)[0m configuration
[36m(_train_fn pid=817331)[0m {'batch_size': 16, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.058495376226156644, 'e_layers': 1, 'learning_rate': 0.00346850779267439, 'd_ff': 64}
[36m(_train_fn pid=817331)[0m Use GPU: cuda:0
[36m(_train_fn pid=817331)[0m train 7825
[36m(_train_fn pid=817331)[0m val 2161
[36m(_train_fn pid=817331)[0m start_epoch 0
[36m(_train_fn pid=817331)[0m max_epoch 8

Trial status: 116 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:02:48. Total running time: 1hr 41min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1c202e21   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
111 more TERMINATED
[36m(_train_fn pid=817331)[0m 	iters: 100, epoch: 1 | loss: 0.8450775
[36m(_train_fn pid=817331)[0m 	speed: 0.0139s/iter; left time: 52.9265s
[36m(_train_fn pid=817331)[0m 	iters: 200, epoch: 1 | loss: 0.7911307
[36m(_train_fn pid=817331)[0m 	speed: 0.0067s/iter; left time: 24.8046s
[36m(_train_fn pid=817331)[0m 	iters: 300, epoch: 1 | loss: 0.7522346
[36m(_train_fn pid=817331)[0m 	speed: 0.0065s/iter; left time: 23.5315s
[36m(_train_fn pid=817331)[0m 	iters: 400, epoch: 1 | loss: 0.6269813
[36m(_train_fn pid=817331)[0m 	speed: 0.0062s/iter; left time: 21.7060s
[36m(_train_fn pid=817331)[0m Updating learning rate to 0.00346850779267439
[36m(_train_fn pid=817331)[0m saving checkpoint...
[36m(_train_fn pid=817331)[0m Validation loss decreased (inf --> 1.6285).  Saving model state dict ...
[36m(_train_fn pid=817331)[0m Epoch: 1 cost time: 3.606058120727539
[36m(_train_fn pid=817331)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7533556 Vali Loss: 1.6284726 Best vali loss: 1.6284726
[36m(_train_fn pid=817331)[0m 	iters: 100, epoch: 2 | loss: 0.5181979
[36m(_train_fn pid=817331)[0m 	speed: 0.0171s/iter; left time: 56.9628s
[36m(_train_fn pid=817331)[0m 	iters: 200, epoch: 2 | loss: 0.6598334
[36m(_train_fn pid=817331)[0m 	speed: 0.0067s/iter; left time: 21.7325s
[36m(_train_fn pid=817331)[0m 	iters: 300, epoch: 2 | loss: 0.5089111
[36m(_train_fn pid=817331)[0m 	speed: 0.0068s/iter; left time: 21.2307s
[36m(_train_fn pid=817331)[0m 	iters: 400, epoch: 2 | loss: 0.7154889
[36m(_train_fn pid=817331)[0m 	speed: 0.0068s/iter; left time: 20.4760s
[36m(_train_fn pid=817331)[0m Updating learning rate to 0.001734253896337195
[36m(_train_fn pid=817331)[0m saving checkpoint...
[36m(_train_fn pid=817331)[0m Validation loss decreased (1.6285 --> 1.6076).  Saving model state dict ...
[36m(_train_fn pid=817331)[0m Epoch: 2 cost time: 3.3499348163604736
[36m(_train_fn pid=817331)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6043002 Vali Loss: 1.6076116 Best vali loss: 1.6076116
[36m(_train_fn pid=817331)[0m 	iters: 100, epoch: 3 | loss: 0.5639844
[36m(_train_fn pid=817331)[0m 	speed: 0.0175s/iter; left time: 49.7363s
[36m(_train_fn pid=817331)[0m 	iters: 200, epoch: 3 | loss: 0.5673203
[36m(_train_fn pid=817331)[0m 	speed: 0.0067s/iter; left time: 18.4414s
[36m(_train_fn pid=817331)[0m 	iters: 300, epoch: 3 | loss: 0.5520685
[36m(_train_fn pid=817331)[0m 	speed: 0.0067s/iter; left time: 17.5939s
[36m(_train_fn pid=817331)[0m 	iters: 400, epoch: 3 | loss: 0.6360039
2024-08-24 09:02:59,561	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=817331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1c202e21_117_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0585,e_layer_2024-08-24_09-02-45/checkpoint_000002)
2024-08-24 09:03:03,158	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=817331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1c202e21_117_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0585,e_layer_2024-08-24_09-02-45/checkpoint_000003)
[36m(_train_fn pid=817331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1c202e21_117_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0585,e_layer_2024-08-24_09-02-45/checkpoint_000004)
2024-08-24 09:03:06,890	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:03:10,676	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=817331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1c202e21_117_alpha_d_ff=2,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0585,e_layer_2024-08-24_09-02-45/checkpoint_000005)
[36m(_train_fn pid=817331)[0m 	speed: 0.0067s/iter; left time: 16.9788s
[36m(_train_fn pid=817331)[0m Updating learning rate to 0.0008671269481685975
[36m(_train_fn pid=817331)[0m saving checkpoint...
[36m(_train_fn pid=817331)[0m Validation loss decreased (1.6076 --> 1.5778).  Saving model state dict ...
[36m(_train_fn pid=817331)[0m Epoch: 3 cost time: 3.329331159591675
[36m(_train_fn pid=817331)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5586881 Vali Loss: 1.5777955 Best vali loss: 1.5777955
[36m(_train_fn pid=817331)[0m 	iters: 100, epoch: 4 | loss: 0.4703542
[36m(_train_fn pid=817331)[0m 	speed: 0.0171s/iter; left time: 40.1440s
[36m(_train_fn pid=817331)[0m 	iters: 200, epoch: 4 | loss: 0.5018832
[36m(_train_fn pid=817331)[0m 	speed: 0.0063s/iter; left time: 14.0967s
[36m(_train_fn pid=817331)[0m 	iters: 300, epoch: 4 | loss: 0.6280593
[36m(_train_fn pid=817331)[0m 	speed: 0.0062s/iter; left time: 13.4009s
[36m(_train_fn pid=817331)[0m 	iters: 400, epoch: 4 | loss: 0.5539947
[36m(_train_fn pid=817331)[0m 	speed: 0.0063s/iter; left time: 12.7917s
[36m(_train_fn pid=817331)[0m Updating learning rate to 0.00043356347408429876
[36m(_train_fn pid=817331)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=817331)[0m saving checkpoint...
[36m(_train_fn pid=817331)[0m Epoch: 4 cost time: 3.1611764430999756
[36m(_train_fn pid=817331)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5307432 Vali Loss: 1.6186375 Best vali loss: 1.5777955
[36m(_train_fn pid=817331)[0m 	iters: 100, epoch: 5 | loss: 0.6276335
[36m(_train_fn pid=817331)[0m 	speed: 0.0176s/iter; left time: 32.6539s
[36m(_train_fn pid=817331)[0m 	iters: 200, epoch: 5 | loss: 0.4122868
[36m(_train_fn pid=817331)[0m 	speed: 0.0069s/iter; left time: 12.1412s
[36m(_train_fn pid=817331)[0m 	iters: 300, epoch: 5 | loss: 0.4903432
[36m(_train_fn pid=817331)[0m 	speed: 0.0068s/iter; left time: 11.2169s
[36m(_train_fn pid=817331)[0m 	iters: 400, epoch: 5 | loss: 0.4961560
[36m(_train_fn pid=817331)[0m 	speed: 0.0063s/iter; left time: 9.8813s
[36m(_train_fn pid=817331)[0m Updating learning rate to 0.00021678173704214938
[36m(_train_fn pid=817331)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=817331)[0m saving checkpoint...
[36m(_train_fn pid=817331)[0m Epoch: 5 cost time: 3.2926154136657715
[36m(_train_fn pid=817331)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5126778 Vali Loss: 1.6199569 Best vali loss: 1.5777955
[36m(_train_fn pid=817331)[0m 	iters: 100, epoch: 6 | loss: 0.4645118
[36m(_train_fn pid=817331)[0m 	speed: 0.0172s/iter; left time: 23.5002s
[36m(_train_fn pid=817331)[0m 	iters: 200, epoch: 6 | loss: 0.4832877
[36m(_train_fn pid=817331)[0m 	speed: 0.0068s/iter; left time: 8.5620s
[36m(_train_fn pid=817331)[0m 	iters: 300, epoch: 6 | loss: 0.4621504
[36m(_train_fn pid=817331)[0m 	speed: 0.0067s/iter; left time: 7.8303s
[36m(_train_fn pid=817331)[0m 	iters: 400, epoch: 6 | loss: 0.5090507
[36m(_train_fn pid=817331)[0m 	speed: 0.0068s/iter; left time: 7.2736s

Trial trial-1c202e21 completed after 6 iterations at 2024-08-24 09:03:10. Total running time: 1hr 42min 1s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1c202e21 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          3.79246 â”‚
â”‚ time_total_s                             23.11228 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                            1.5778 â”‚
â”‚ train_loss                                0.50224 â”‚
â”‚ valid_loss                                1.63187 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=817331)[0m Updating learning rate to 0.00010839086852107469
[36m(_train_fn pid=817331)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=817331)[0m saving checkpoint...
[36m(_train_fn pid=817331)[0m Epoch: 6 cost time: 3.36069393157959
[36m(_train_fn pid=817331)[0m Epoch: 6, Steps: 489 | Train Loss: 0.5022435 Vali Loss: 1.6318666 Best vali loss: 1.5777955
[36m(_train_fn pid=817331)[0m Early stopping

Trial trial-1d2f0fd2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1d2f0fd2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07396 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00318 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=817910)[0m configuration
[36m(_train_fn pid=817910)[0m {'batch_size': 16, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'conv', 'dropout': 0.07396413936386323, 'e_layers': 4, 'learning_rate': 0.003175184084604203, 'd_ff': 512}
[36m(_train_fn pid=817910)[0m Use GPU: cuda:0
[36m(_train_fn pid=817910)[0m train 7825
[36m(_train_fn pid=817910)[0m val 2161
[36m(_train_fn pid=817910)[0m start_epoch 0
[36m(_train_fn pid=817910)[0m max_epoch 8
[36m(_train_fn pid=817910)[0m 	iters: 100, epoch: 1 | loss: 0.7905045
[36m(_train_fn pid=817910)[0m 	speed: 0.0486s/iter; left time: 185.1255s

Trial status: 117 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:03:18. Total running time: 1hr 42min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=817910)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d2f0fd2_118_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_09-03-10/checkpoint_000000)
2024-08-24 09:04:00,690	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=817910)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d2f0fd2_118_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_09-03-10/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1d2f0fd2   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
112 more TERMINATED
[36m(_train_fn pid=817910)[0m 	iters: 200, epoch: 1 | loss: 0.7237140
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 162.0285s
[36m(_train_fn pid=817910)[0m 	iters: 300, epoch: 1 | loss: 0.7099917
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 157.6690s
[36m(_train_fn pid=817910)[0m 	iters: 400, epoch: 1 | loss: 0.5970157
[36m(_train_fn pid=817910)[0m 	speed: 0.0437s/iter; left time: 153.5697s
[36m(_train_fn pid=817910)[0m Updating learning rate to 0.003175184084604203
[36m(_train_fn pid=817910)[0m saving checkpoint...
[36m(_train_fn pid=817910)[0m Validation loss decreased (inf --> 1.6246).  Saving model state dict ...
[36m(_train_fn pid=817910)[0m Epoch: 1 cost time: 21.58851957321167
[36m(_train_fn pid=817910)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7180192 Vali Loss: 1.6245920 Best vali loss: 1.6245920
[36m(_train_fn pid=817910)[0m 	iters: 100, epoch: 2 | loss: 1517.8603516
[36m(_train_fn pid=817910)[0m 	speed: 0.1069s/iter; left time: 355.2895s
[36m(_train_fn pid=817910)[0m 	iters: 200, epoch: 2 | loss: 100.2189178
[36m(_train_fn pid=817910)[0m 	speed: 0.0435s/iter; left time: 140.3768s
Trial status: 117 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:03:48. Total running time: 1hr 42min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1d2f0fd2   RUNNING           1            24.4017       0.718019        1.62459             1.62459 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
112 more TERMINATED
[36m(_train_fn pid=817910)[0m 	iters: 300, epoch: 2 | loss: 15.9907799
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 136.1384s
[36m(_train_fn pid=817910)[0m 	iters: 400, epoch: 2 | loss: 10.2759295
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 131.7474s
[36m(_train_fn pid=817910)[0m Updating learning rate to 0.0015875920423021016
[36m(_train_fn pid=817910)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=817910)[0m saving checkpoint...
[36m(_train_fn pid=817910)[0m Epoch: 2 cost time: 21.327548503875732
[36m(_train_fn pid=817910)[0m Epoch: 2, Steps: 489 | Train Loss: 8619.0925383 Vali Loss: 14.1613179 Best vali loss: 1.6245920
[36m(_train_fn pid=817910)[0m 	iters: 100, epoch: 3 | loss: 7.9522061
[36m(_train_fn pid=817910)[0m 	speed: 0.1066s/iter; left time: 302.2335s
[36m(_train_fn pid=817910)[0m 	iters: 200, epoch: 3 | loss: 6.0860143
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 119.2664s
[36m(_train_fn pid=817910)[0m 	iters: 300, epoch: 3 | loss: 7.5113964
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 114.9651s
[36m(_train_fn pid=817910)[0m 	iters: 400, epoch: 3 | loss: 5.4758935
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 110.6308s
Trial status: 117 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:04:18. Total running time: 1hr 43min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 09:04:24,460	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=817910)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d2f0fd2_118_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_09-03-10/checkpoint_000002)
2024-08-24 09:04:48,245	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=817910)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d2f0fd2_118_alpha_d_ff=2,batch_size=16,d_model=256,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout_2024-08-24_09-03-10/checkpoint_000003)
2024-08-24 09:05:10,227	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1d2f0fd2   RUNNING           2            48.1295    8619.09           14.1613              1.62459 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
112 more TERMINATED
[36m(_train_fn pid=817910)[0m Updating learning rate to 0.0007937960211510508
[36m(_train_fn pid=817910)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=817910)[0m saving checkpoint...
[36m(_train_fn pid=817910)[0m Epoch: 3 cost time: 21.357688903808594
[36m(_train_fn pid=817910)[0m Epoch: 3, Steps: 489 | Train Loss: 6.7402367 Vali Loss: 9.4037166 Best vali loss: 1.6245920
[36m(_train_fn pid=817910)[0m 	iters: 100, epoch: 4 | loss: 5.8076725
[36m(_train_fn pid=817910)[0m 	speed: 0.1069s/iter; left time: 250.8393s
[36m(_train_fn pid=817910)[0m 	iters: 200, epoch: 4 | loss: 5.6776633
[36m(_train_fn pid=817910)[0m 	speed: 0.0437s/iter; left time: 98.0930s
[36m(_train_fn pid=817910)[0m 	iters: 300, epoch: 4 | loss: 5.7755971
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 93.6260s
[36m(_train_fn pid=817910)[0m 	iters: 400, epoch: 4 | loss: 4.4397149
[36m(_train_fn pid=817910)[0m 	speed: 0.0436s/iter; left time: 89.2633s

Trial trial-1d2f0fd2 completed after 4 iterations at 2024-08-24 09:04:48. Total running time: 1hr 43min 39s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1d2f0fd2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         23.78587 â”‚
â”‚ time_total_s                             95.68071 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.62459 â”‚
â”‚ train_loss                                5.02262 â”‚
â”‚ valid_loss                                8.09344 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=817910)[0m Updating learning rate to 0.0003968980105755254
[36m(_train_fn pid=817910)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=817910)[0m saving checkpoint...
[36m(_train_fn pid=817910)[0m Epoch: 4 cost time: 21.37773036956787
[36m(_train_fn pid=817910)[0m Epoch: 4, Steps: 489 | Train Loss: 5.0226246 Vali Loss: 8.0934364 Best vali loss: 1.6245920
[36m(_train_fn pid=817910)[0m Early stopping

Trial status: 118 TERMINATED | 1 PENDING
Current time: 2024-08-24 09:04:48. Total running time: 1hr 43min 40s
Logical resource usage: 0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-9ec3bfee   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
113 more TERMINATED

Trial trial-9ec3bfee started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-9ec3bfee config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13471 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.01177 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=818570)[0m configuration
[36m(_train_fn pid=818570)[0m {'batch_size': 64, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.13471244627848167, 'e_layers': 4, 'learning_rate': 0.011770647874933744, 'd_ff': 512}
[36m(_train_fn pid=818570)[0m Use GPU: cuda:0
[36m(_train_fn pid=818570)[0m train 7825
[36m(_train_fn pid=818570)[0m val 2161
[36m(_train_fn pid=818570)[0m start_epoch 0
[36m(_train_fn pid=818570)[0m max_epoch 8
[36m(_train_fn pid=818570)[0m 	iters: 100, epoch: 1 | loss: 0.6929429
[36m(_train_fn pid=818570)[0m 	speed: 0.1427s/iter; left time: 125.1659s
[36m(_train_fn pid=818570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9ec3bfee_119_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1347,e_layer_2024-08-24_09-04-48/checkpoint_000000)
[36m(_train_fn pid=818570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9ec3bfee_119_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1347,e_layer_2024-08-24_09-04-48/checkpoint_000001)
[36m(_train_fn pid=818570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9ec3bfee_119_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1347,e_layer_2024-08-24_09-04-48/checkpoint_000002)
[36m(_train_fn pid=818570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9ec3bfee_119_alpha_d_ff=2,batch_size=64,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1347,e_layer_2024-08-24_09-04-48/checkpoint_000003)
[36m(_train_fn pid=818570)[0m Updating learning rate to 0.011770647874933744
[36m(_train_fn pid=818570)[0m saving checkpoint...
[36m(_train_fn pid=818570)[0m Validation loss decreased (inf --> 1.7203).  Saving model state dict ...
[36m(_train_fn pid=818570)[0m Epoch: 1 cost time: 17.019230842590332
[36m(_train_fn pid=818570)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8156534 Vali Loss: 1.7202766 Best vali loss: 1.7202766

Trial status: 118 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:05:19. Total running time: 1hr 44min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-9ec3bfee   RUNNING           1            19.6842       0.815653        1.72028             1.72028 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
113 more TERMINATED
[36m(_train_fn pid=818570)[0m 	iters: 100, epoch: 2 | loss: 3069825515520.0000000
[36m(_train_fn pid=818570)[0m 	speed: 0.1880s/iter; left time: 141.9307s
[36m(_train_fn pid=818570)[0m Updating learning rate to 0.005885323937466872
[36m(_train_fn pid=818570)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=818570)[0m saving checkpoint...
[36m(_train_fn pid=818570)[0m Epoch: 2 cost time: 16.515323638916016
[36m(_train_fn pid=818570)[0m Epoch: 2, Steps: 122 | Train Loss: 1818719684986.5244141 Vali Loss: 2032457950921.6970215 Best vali loss: 1.7202766
[36m(_train_fn pid=818570)[0m 	iters: 100, epoch: 3 | loss: 37316395008.0000000
[36m(_train_fn pid=818570)[0m 	speed: 0.1870s/iter; left time: 118.3645s
[36m(_train_fn pid=818570)[0m Updating learning rate to 0.002942661968733436
[36m(_train_fn pid=818570)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=818570)[0m saving checkpoint...
[36m(_train_fn pid=818570)[0m Epoch: 3 cost time: 16.47376847267151
[36m(_train_fn pid=818570)[0m Epoch: 3, Steps: 122 | Train Loss: 12607265427095.0820312 Vali Loss: 125371845352.7272797 Best vali loss: 1.7202766
Trial status: 118 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:05:49. Total running time: 1hr 44min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-9ec3bfee   RUNNING           3            57.1209    1.26073e+13    1.25372e+11             1.72028 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009    0.593321       1.59962                 1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127    0.510234       1.62942                 1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511    0.570752       1.58113                 1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635     0.600472       1.56828                 1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884    0.512451       1.683                   1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
113 more TERMINATED
[36m(_train_fn pid=818570)[0m 	iters: 100, epoch: 4 | loss: 4283484672.0000000
[36m(_train_fn pid=818570)[0m 	speed: 0.1872s/iter; left time: 95.6465s

Trial trial-9ec3bfee completed after 4 iterations at 2024-08-24 09:06:06. Total running time: 1hr 44min 57s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-9ec3bfee result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         18.71279 â”‚
â”‚ time_total_s                             75.83365 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.72028 â”‚
â”‚ train_loss                       8822664179.40984 â”‚
â”‚ valid_loss                      21517160308.36364 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=818570)[0m Updating learning rate to 0.001471330984366718
[36m(_train_fn pid=818570)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=818570)[0m saving checkpoint...
[36m(_train_fn pid=818570)[0m Epoch: 4 cost time: 16.490075826644897
[36m(_train_fn pid=818570)[0m Epoch: 4, Steps: 122 | Train Loss: 8822664179.4098358 Vali Loss: 21517160308.3636360 Best vali loss: 1.7202766
[36m(_train_fn pid=818570)[0m Early stopping

Trial trial-66587373 started with configuration:
[36m(_train_fn pid=819168)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-66587373_120_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_09-06-06/checkpoint_000000)
[36m(_train_fn pid=819168)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-66587373_120_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_09-06-06/checkpoint_000001)
[36m(_train_fn pid=819168)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-66587373_120_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_09-06-06/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-66587373 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.11753 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00364 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=819168)[0m configuration
[36m(_train_fn pid=819168)[0m {'batch_size': 16, 'd_model': 16, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'conv', 'dropout': 0.11753300606086403, 'e_layers': 4, 'learning_rate': 0.0036364470456799348, 'd_ff': 48}
[36m(_train_fn pid=819168)[0m Use GPU: cuda:0
[36m(_train_fn pid=819168)[0m train 7825
[36m(_train_fn pid=819168)[0m val 2161
[36m(_train_fn pid=819168)[0m start_epoch 0
[36m(_train_fn pid=819168)[0m max_epoch 8
[36m(_train_fn pid=819168)[0m 	iters: 100, epoch: 1 | loss: 0.8641569
[36m(_train_fn pid=819168)[0m 	speed: 0.0174s/iter; left time: 66.3255s
[36m(_train_fn pid=819168)[0m 	iters: 200, epoch: 1 | loss: 0.9346316
[36m(_train_fn pid=819168)[0m 	speed: 0.0123s/iter; left time: 45.7303s
[36m(_train_fn pid=819168)[0m 	iters: 300, epoch: 1 | loss: 0.8724788
[36m(_train_fn pid=819168)[0m 	speed: 0.0123s/iter; left time: 44.4817s
[36m(_train_fn pid=819168)[0m 	iters: 400, epoch: 1 | loss: 0.6716774
[36m(_train_fn pid=819168)[0m 	speed: 0.0123s/iter; left time: 43.1719s
[36m(_train_fn pid=819168)[0m Updating learning rate to 0.0036364470456799348
[36m(_train_fn pid=819168)[0m saving checkpoint...
[36m(_train_fn pid=819168)[0m Validation loss decreased (inf --> 1.6513).  Saving model state dict ...
[36m(_train_fn pid=819168)[0m Epoch: 1 cost time: 6.259533166885376
[36m(_train_fn pid=819168)[0m Epoch: 1, Steps: 489 | Train Loss: 0.8386382 Vali Loss: 1.6513133 Best vali loss: 1.6513133
[36m(_train_fn pid=819168)[0m 	iters: 100, epoch: 2 | loss: 0.7050067
[36m(_train_fn pid=819168)[0m 	speed: 0.0312s/iter; left time: 103.6937s
[36m(_train_fn pid=819168)[0m 	iters: 200, epoch: 2 | loss: 0.5235533
[36m(_train_fn pid=819168)[0m 	speed: 0.0136s/iter; left time: 43.8263s

Trial status: 119 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:06:19. Total running time: 1hr 45min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-66587373   RUNNING           1            7.28588       0.838638        1.65131             1.65131 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
114 more TERMINATED
[36m(_train_fn pid=819168)[0m 	iters: 300, epoch: 2 | loss: 0.5637567
[36m(_train_fn pid=819168)[0m 	speed: 0.0136s/iter; left time: 42.5431s
[36m(_train_fn pid=819168)[0m 	iters: 400, epoch: 2 | loss: 0.5852400
[36m(_train_fn pid=819168)[0m 	speed: 0.0135s/iter; left time: 40.9528s
[36m(_train_fn pid=819168)[0m Updating learning rate to 0.0018182235228399674
[36m(_train_fn pid=819168)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=819168)[0m saving checkpoint...
[36m(_train_fn pid=819168)[0m Epoch: 2 cost time: 6.693867444992065
[36m(_train_fn pid=819168)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6119925 Vali Loss: 1.7316931 Best vali loss: 1.6513133
[36m(_train_fn pid=819168)[0m 	iters: 100, epoch: 3 | loss: 0.6100406
[36m(_train_fn pid=819168)[0m 	speed: 0.0324s/iter; left time: 91.8099s
[36m(_train_fn pid=819168)[0m 	iters: 200, epoch: 3 | loss: 0.5384207
[36m(_train_fn pid=819168)[0m 	speed: 0.0124s/iter; left time: 33.9309s
[36m(_train_fn pid=819168)[0m 	iters: 300, epoch: 3 | loss: 0.5406931
[36m(_train_fn pid=819168)[0m 	speed: 0.0124s/iter; left time: 32.6638s
[36m(_train_fn pid=819168)[0m 	iters: 400, epoch: 3 | loss: 0.5790873
[36m(_train_fn pid=819168)[0m 	speed: 0.0125s/iter; left time: 31.5669s
[36m(_train_fn pid=819168)[0m Updating learning rate to 0.0009091117614199837
[36m(_train_fn pid=819168)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=819168)[0m saving checkpoint...
[36m(_train_fn pid=819168)[0m Epoch: 3 cost time: 6.217860460281372
[36m(_train_fn pid=819168)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5659593 Vali Loss: 1.6919413 Best vali loss: 1.6513133
[36m(_train_fn pid=819168)[0m 	iters: 100, epoch: 4 | loss: 0.5387741
[36m(_train_fn pid=819168)[0m 	speed: 0.0310s/iter; left time: 72.8204s
[36m(_train_fn pid=819168)[0m 	iters: 200, epoch: 4 | loss: 0.5391330
[36m(_train_fn pid=819168)[0m 	speed: 0.0135s/iter; left time: 30.3628s
[36m(_train_fn pid=819168)[0m 	iters: 300, epoch: 4 | loss: 0.4611620
[36m(_train_fn pid=819168)[0m 	speed: 0.0136s/iter; left time: 29.0792s
[36m(_train_fn pid=819168)[0m 	iters: 400, epoch: 4 | loss: 0.6783912
[36m(_train_fn pid=819168)[0m 	speed: 0.0136s/iter; left time: 27.8257s

Trial trial-66587373 completed after 4 iterations at 2024-08-24 09:06:37. Total running time: 1hr 45min 28s
[36m(_train_fn pid=819168)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-66587373_120_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=moving_avg,moving_avg=35,down_sampling_method=conv,dropout=_2024-08-24_09-06-06/checkpoint_000003)
[36m(_train_fn pid=819623)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dc2fbe9a_121_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropou_2024-08-24_09-06-37/checkpoint_000000)
[36m(_train_fn pid=819623)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dc2fbe9a_121_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropou_2024-08-24_09-06-37/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-66587373 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                          7.29984 â”‚
â”‚ time_total_s                             28.73319 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.65131 â”‚
â”‚ train_loss                                0.52955 â”‚
â”‚ valid_loss                                1.67561 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=819168)[0m Updating learning rate to 0.00045455588070999185
[36m(_train_fn pid=819168)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=819168)[0m saving checkpoint...
[36m(_train_fn pid=819168)[0m Epoch: 4 cost time: 6.668116331100464
[36m(_train_fn pid=819168)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5295450 Vali Loss: 1.6756065 Best vali loss: 1.6513133
[36m(_train_fn pid=819168)[0m Early stopping

Trial trial-dc2fbe9a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-dc2fbe9a config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09988 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00316 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=819623)[0m configuration
[36m(_train_fn pid=819623)[0m {'batch_size': 128, 'd_model': 256, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'conv', 'dropout': 0.09988315699504693, 'e_layers': 3, 'learning_rate': 0.0031572108788761057, 'd_ff': 1024}
[36m(_train_fn pid=819623)[0m Use GPU: cuda:0
[36m(_train_fn pid=819623)[0m train 7825
[36m(_train_fn pid=819623)[0m val 2161
[36m(_train_fn pid=819623)[0m start_epoch 0
[36m(_train_fn pid=819623)[0m max_epoch 8

Trial status: 120 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:06:49. Total running time: 1hr 45min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-dc2fbe9a   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
115 more TERMINATED
[36m(_train_fn pid=819623)[0m Validation loss decreased (inf --> 1.9901).  Saving model state dict ...
[36m(_train_fn pid=819623)[0m Updating learning rate to 0.0031572108788761057
[36m(_train_fn pid=819623)[0m saving checkpoint...
[36m(_train_fn pid=819623)[0m Epoch: 1 cost time: 15.434783935546875
[36m(_train_fn pid=819623)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8299066 Vali Loss: 1.9900541 Best vali loss: 1.9900541
[36m(_train_fn pid=819623)[0m Updating learning rate to 0.0015786054394380529
[36m(_train_fn pid=819623)[0m saving checkpoint...
[36m(_train_fn pid=819623)[0m Validation loss decreased (1.9901 --> 1.6244).  Saving model state dict ...
[36m(_train_fn pid=819623)[0m Epoch: 2 cost time: 15.313788890838623
[36m(_train_fn pid=819623)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7099465 Vali Loss: 1.6244136 Best vali loss: 1.6244136
Trial status: 120 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:07:19. Total running time: 1hr 46min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=819623)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dc2fbe9a_121_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropou_2024-08-24_09-06-37/checkpoint_000002)
[36m(_train_fn pid=819623)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dc2fbe9a_121_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropou_2024-08-24_09-06-37/checkpoint_000003)
[36m(_train_fn pid=819623)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dc2fbe9a_121_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropou_2024-08-24_09-06-37/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-dc2fbe9a   RUNNING           2            34.9628       0.709946        1.62441             1.62441 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
115 more TERMINATED
[36m(_train_fn pid=819623)[0m Updating learning rate to 0.0007893027197190264
[36m(_train_fn pid=819623)[0m saving checkpoint...
[36m(_train_fn pid=819623)[0m Validation loss decreased (1.6244 --> 1.6177).  Saving model state dict ...
[36m(_train_fn pid=819623)[0m Epoch: 3 cost time: 15.36248779296875
[36m(_train_fn pid=819623)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6156788 Vali Loss: 1.6176862 Best vali loss: 1.6176862
[36m(_train_fn pid=819623)[0m Updating learning rate to 0.0003946513598595132
[36m(_train_fn pid=819623)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=819623)[0m saving checkpoint...
[36m(_train_fn pid=819623)[0m Epoch: 4 cost time: 15.38934850692749
[36m(_train_fn pid=819623)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5970614 Vali Loss: 1.6535882 Best vali loss: 1.6176862
Trial status: 120 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:07:49. Total running time: 1hr 46min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-dc2fbe9a   RUNNING           4            69.4974       0.597061        1.65359             1.61769 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
115 more TERMINATED
[36m(_train_fn pid=819623)[0m Updating learning rate to 0.0001973256799297566
[36m(_train_fn pid=819623)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=819623)[0m saving checkpoint...
[36m(_train_fn pid=819623)[0m Epoch: 5 cost time: 15.404112577438354
[36m(_train_fn pid=819623)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5761888 Vali Loss: 1.6861399 Best vali loss: 1.6176862
Trial status: 120 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:08:19. Total running time: 1hr 47min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-dc2fbe9a   RUNNING           5            86.7822       0.576189        1.68614             1.61769 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
115 more TERMINATED

Trial trial-dc2fbe9a completed after 6 iterations at 2024-08-24 09:08:23. Total running time: 1hr 47min 14s
[36m(_train_fn pid=819623)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dc2fbe9a_121_alpha_d_ff=4,batch_size=128,d_model=256,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropou_2024-08-24_09-06-37/checkpoint_000005)
[36m(_train_fn pid=820443)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1e117675_122_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-08-23/checkpoint_000000)
2024-08-24 09:08:34,374	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=820443)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1e117675_122_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-08-23/checkpoint_000001)
[36m(_train_fn pid=820443)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1e117675_122_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-08-23/checkpoint_000002)
2024-08-24 09:08:38,469	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:08:42,568	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=820443)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1e117675_122_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-08-23/checkpoint_000003)
2024-08-24 09:08:46,667	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=820443)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1e117675_122_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-08-23/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-dc2fbe9a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         17.30056 â”‚
â”‚ time_total_s                            104.08272 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.61769 â”‚
â”‚ train_loss                                 0.5653 â”‚
â”‚ valid_loss                                1.70988 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=819623)[0m Updating learning rate to 9.86628399648783e-05
[36m(_train_fn pid=819623)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=819623)[0m saving checkpoint...

Trial trial-1e117675 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1e117675 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13971 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00899 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=820443)[0m configuration
[36m(_train_fn pid=820443)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'avg', 'dropout': 0.1397115265238481, 'e_layers': 3, 'learning_rate': 0.008990041852912951, 'd_ff': 256}
[36m(_train_fn pid=820443)[0m Use GPU: cuda:0
[36m(_train_fn pid=820443)[0m train 7825
[36m(_train_fn pid=820443)[0m val 2161
[36m(_train_fn pid=820443)[0m start_epoch 0
[36m(_train_fn pid=820443)[0m max_epoch 8
[36m(_train_fn pid=820443)[0m Validation loss decreased (inf --> 1.9514).  Saving model state dict ...
[36m(_train_fn pid=820443)[0m Epoch: 1 cost time: 3.814380645751953
[36m(_train_fn pid=820443)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8749913 Vali Loss: 1.9514064 Best vali loss: 1.9514064
[36m(_train_fn pid=820443)[0m Updating learning rate to 0.008990041852912951
[36m(_train_fn pid=820443)[0m saving checkpoint...
[36m(_train_fn pid=820443)[0m Updating learning rate to 0.0044950209264564755
[36m(_train_fn pid=820443)[0m saving checkpoint...
[36m(_train_fn pid=820443)[0m Validation loss decreased (1.9514 --> 1.6021).  Saving model state dict ...
[36m(_train_fn pid=820443)[0m Epoch: 2 cost time: 3.625638961791992
[36m(_train_fn pid=820443)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6499671 Vali Loss: 1.6021282 Best vali loss: 1.6021282
[36m(_train_fn pid=820443)[0m Updating learning rate to 0.0022475104632282378
[36m(_train_fn pid=820443)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=820443)[0m saving checkpoint...
[36m(_train_fn pid=820443)[0m Epoch: 3 cost time: 3.618351697921753
[36m(_train_fn pid=820443)[0m Epoch: 3, Steps: 61 | Train Loss: 0.5976498 Vali Loss: 1.6514552 Best vali loss: 1.6021282
[36m(_train_fn pid=820443)[0m Updating learning rate to 0.0011237552316141189
[36m(_train_fn pid=820443)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=820443)[0m saving checkpoint...
[36m(_train_fn pid=820443)[0m Epoch: 4 cost time: 3.622096538543701
[36m(_train_fn pid=820443)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5720029 Vali Loss: 1.6564921 Best vali loss: 1.6021282

Trial trial-1e117675 completed after 5 iterations at 2024-08-24 09:08:46. Total running time: 1hr 47min 37s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1e117675 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          4.09806 â”‚
â”‚ time_total_s                             21.08416 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.60213 â”‚
â”‚ train_loss                                0.55698 â”‚
â”‚ valid_loss                                1.65706 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=820443)[0m Updating learning rate to 0.0005618776158070594
[36m(_train_fn pid=820443)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=820443)[0m saving checkpoint...
[36m(_train_fn pid=820443)[0m Epoch: 5 cost time: 3.6283228397369385
[36m(_train_fn pid=820443)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5569816 Vali Loss: 1.6570618 Best vali loss: 1.6021282
[36m(_train_fn pid=820443)[0m Early stopping

Trial trial-7d3a60f7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7d3a60f7 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07471 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.01011 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=820948)[0m configuration
[36m(_train_fn pid=820948)[0m {'batch_size': 64, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.07470536882798648, 'e_layers': 3, 'learning_rate': 0.010114262700568073, 'd_ff': 32}
[36m(_train_fn pid=820948)[0m Use GPU: cuda:0
[36m(_train_fn pid=820948)[0m train 7825
[36m(_train_fn pid=820948)[0m val 2161
[36m(_train_fn pid=820948)[0m start_epoch 0
[36m(_train_fn pid=820948)[0m max_epoch 8

Trial status: 122 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:08:49. Total running time: 1hr 47min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 09:08:51,237	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=820948)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d3a60f7_123_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0747,e_layers_2024-08-24_09-08-46/checkpoint_000000)
[36m(_train_fn pid=820948)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d3a60f7_123_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0747,e_layers_2024-08-24_09-08-46/checkpoint_000001)
2024-08-24 09:08:52,989	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=820948)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d3a60f7_123_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0747,e_layers_2024-08-24_09-08-46/checkpoint_000002)
2024-08-24 09:08:54,722	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:08:56,556	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=820948)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d3a60f7_123_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0747,e_layers_2024-08-24_09-08-46/checkpoint_000003)
2024-08-24 09:08:58,403	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=820948)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d3a60f7_123_alpha_d_ff=4,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0747,e_layers_2024-08-24_09-08-46/checkpoint_000004)
[36m(_train_fn pid=821423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-df45f4a1_124_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_09-08-58/checkpoint_000000)
2024-08-24 09:09:07,471	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=821423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-df45f4a1_124_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_09-08-58/checkpoint_000001)
2024-08-24 09:09:10,621	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=821423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-df45f4a1_124_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_09-08-58/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7d3a60f7   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
117 more TERMINATED
[36m(_train_fn pid=820948)[0m 	iters: 100, epoch: 1 | loss: 0.7687064
[36m(_train_fn pid=820948)[0m 	speed: 0.0199s/iter; left time: 17.4301s
[36m(_train_fn pid=820948)[0m Validation loss decreased (inf --> 1.8518).  Saving model state dict ...
[36m(_train_fn pid=820948)[0m Epoch: 1 cost time: 2.0072567462921143
[36m(_train_fn pid=820948)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8886990 Vali Loss: 1.8517677 Best vali loss: 1.8517677
[36m(_train_fn pid=820948)[0m 	iters: 100, epoch: 2 | loss: 0.5950668
[36m(_train_fn pid=820948)[0m 	speed: 0.0177s/iter; left time: 13.3535s
[36m(_train_fn pid=820948)[0m Updating learning rate to 0.010114262700568073
[36m(_train_fn pid=820948)[0m saving checkpoint...
[36m(_train_fn pid=820948)[0m Updating learning rate to 0.0050571313502840365
[36m(_train_fn pid=820948)[0m saving checkpoint...
[36m(_train_fn pid=820948)[0m Validation loss decreased (1.8518 --> 1.5964).  Saving model state dict ...
[36m(_train_fn pid=820948)[0m Epoch: 2 cost time: 1.4947538375854492
[36m(_train_fn pid=820948)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6363144 Vali Loss: 1.5963649 Best vali loss: 1.5963649
[36m(_train_fn pid=820948)[0m 	iters: 100, epoch: 3 | loss: 0.6072049
[36m(_train_fn pid=820948)[0m 	speed: 0.0174s/iter; left time: 11.0083s
[36m(_train_fn pid=820948)[0m Updating learning rate to 0.0025285656751420182
[36m(_train_fn pid=820948)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=820948)[0m saving checkpoint...
[36m(_train_fn pid=820948)[0m Epoch: 3 cost time: 1.4787838459014893
[36m(_train_fn pid=820948)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5859727 Vali Loss: 1.6138321 Best vali loss: 1.5963649
[36m(_train_fn pid=820948)[0m 	iters: 100, epoch: 4 | loss: 0.5326211
[36m(_train_fn pid=820948)[0m 	speed: 0.0183s/iter; left time: 9.3560s
[36m(_train_fn pid=820948)[0m Updating learning rate to 0.0012642828375710091
[36m(_train_fn pid=820948)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=820948)[0m saving checkpoint...
[36m(_train_fn pid=820948)[0m Epoch: 4 cost time: 1.5924816131591797
[36m(_train_fn pid=820948)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5672413 Vali Loss: 1.6076952 Best vali loss: 1.5963649
[36m(_train_fn pid=820948)[0m 	iters: 100, epoch: 5 | loss: 0.5151563
[36m(_train_fn pid=820948)[0m 	speed: 0.0184s/iter; left time: 7.1581s

Trial trial-7d3a60f7 completed after 5 iterations at 2024-08-24 09:08:58. Total running time: 1hr 47min 49s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7d3a60f7 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.84477 â”‚
â”‚ time_total_s                              9.83042 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59636 â”‚
â”‚ train_loss                                0.55153 â”‚
â”‚ valid_loss                                1.62054 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=820948)[0m Updating learning rate to 0.0006321414187855046
[36m(_train_fn pid=820948)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=820948)[0m saving checkpoint...
[36m(_train_fn pid=820948)[0m Epoch: 5 cost time: 1.594346523284912
[36m(_train_fn pid=820948)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5515323 Vali Loss: 1.6205353 Best vali loss: 1.5963649
[36m(_train_fn pid=820948)[0m Early stopping

Trial trial-df45f4a1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-df45f4a1 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11088 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00282 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=821423)[0m configuration
[36m(_train_fn pid=821423)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.11087815639362279, 'e_layers': 2, 'learning_rate': 0.0028154058073656795, 'd_ff': 128}
[36m(_train_fn pid=821423)[0m Use GPU: cuda:0
[36m(_train_fn pid=821423)[0m train 7825
[36m(_train_fn pid=821423)[0m val 2161
[36m(_train_fn pid=821423)[0m start_epoch 0
[36m(_train_fn pid=821423)[0m max_epoch 8
[36m(_train_fn pid=821423)[0m Updating learning rate to 0.0028154058073656795
[36m(_train_fn pid=821423)[0m saving checkpoint...
[36m(_train_fn pid=821423)[0m Validation loss decreased (inf --> 1.9873).  Saving model state dict ...
[36m(_train_fn pid=821423)[0m Epoch: 1 cost time: 2.970571756362915
[36m(_train_fn pid=821423)[0m Epoch: 1, Steps: 61 | Train Loss: 0.9620272 Vali Loss: 1.9873347 Best vali loss: 1.9873347
[36m(_train_fn pid=821423)[0m Updating learning rate to 0.0014077029036828398
[36m(_train_fn pid=821423)[0m saving checkpoint...
[36m(_train_fn pid=821423)[0m Validation loss decreased (1.9873 --> 1.6088).  Saving model state dict ...
[36m(_train_fn pid=821423)[0m Epoch: 2 cost time: 2.7762351036071777
[36m(_train_fn pid=821423)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6740571 Vali Loss: 1.6088190 Best vali loss: 1.6088190
[36m(_train_fn pid=821423)[0m Updating learning rate to 0.0007038514518414199
[36m(_train_fn pid=821423)[0m saving checkpoint...
2024-08-24 09:09:13,780	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=821423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-df45f4a1_124_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_09-08-58/checkpoint_000003)
2024-08-24 09:09:16,936	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=821423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-df45f4a1_124_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_09-08-58/checkpoint_000004)
[36m(_train_fn pid=821423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-df45f4a1_124_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_09-08-58/checkpoint_000005)
2024-08-24 09:09:20,107	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:09:23,279	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=821423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-df45f4a1_124_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_09-08-58/checkpoint_000006)
2024-08-24 09:09:26,454	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=821423)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-df45f4a1_124_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=_2024-08-24_09-08-58/checkpoint_000007)
2024-08-24 09:09:29,941	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d43e9672_125_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-26/checkpoint_000000)
2024-08-24 09:09:30,686	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d43e9672_125_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-26/checkpoint_000001)
2024-08-24 09:09:31,414	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d43e9672_125_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-26/checkpoint_000002)
[36m(_train_fn pid=822158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d43e9672_125_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-26/checkpoint_000003)
[36m(_train_fn pid=821423)[0m Validation loss decreased (1.6088 --> 1.5914).  Saving model state dict ...
[36m(_train_fn pid=821423)[0m Epoch: 3 cost time: 2.769890308380127
[36m(_train_fn pid=821423)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6174286 Vali Loss: 1.5914421 Best vali loss: 1.5914421
[36m(_train_fn pid=821423)[0m Updating learning rate to 0.00035192572592070994
[36m(_train_fn pid=821423)[0m saving checkpoint...
[36m(_train_fn pid=821423)[0m Validation loss decreased (1.5914 --> 1.5891).  Saving model state dict ...
[36m(_train_fn pid=821423)[0m Epoch: 4 cost time: 2.787599563598633
[36m(_train_fn pid=821423)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6119805 Vali Loss: 1.5890637 Best vali loss: 1.5890637
[36m(_train_fn pid=821423)[0m Updating learning rate to 0.00017596286296035497
[36m(_train_fn pid=821423)[0m saving checkpoint...
[36m(_train_fn pid=821423)[0m Validation loss decreased (1.5891 --> 1.5881).  Saving model state dict ...
[36m(_train_fn pid=821423)[0m Epoch: 5 cost time: 2.7887790203094482
[36m(_train_fn pid=821423)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6101688 Vali Loss: 1.5881017 Best vali loss: 1.5881017

Trial status: 123 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:09:19. Total running time: 1hr 48min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-df45f4a1   RUNNING           5            16.355        0.610169        1.5881              1.5881  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
118 more TERMINATED
[36m(_train_fn pid=821423)[0m Updating learning rate to 8.798143148017748e-05
[36m(_train_fn pid=821423)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=821423)[0m saving checkpoint...
[36m(_train_fn pid=821423)[0m Epoch: 6 cost time: 2.7900612354278564
[36m(_train_fn pid=821423)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6085392 Vali Loss: 1.5888518 Best vali loss: 1.5881017
[36m(_train_fn pid=821423)[0m Updating learning rate to 4.399071574008874e-05
[36m(_train_fn pid=821423)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=821423)[0m saving checkpoint...
[36m(_train_fn pid=821423)[0m Epoch: 7 cost time: 2.800443649291992
[36m(_train_fn pid=821423)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6075920 Vali Loss: 1.5894692 Best vali loss: 1.5881017

Trial trial-df45f4a1 completed after 8 iterations at 2024-08-24 09:09:26. Total running time: 1hr 48min 17s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-df45f4a1 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          3.17294 â”‚
â”‚ time_total_s                              25.8573 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                            1.5881 â”‚
â”‚ train_loss                                0.60689 â”‚
â”‚ valid_loss                                1.58927 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=821423)[0m Updating learning rate to 2.199535787004437e-05
[36m(_train_fn pid=821423)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=821423)[0m saving checkpoint...
[36m(_train_fn pid=821423)[0m Epoch: 8 cost time: 2.8029227256774902
[36m(_train_fn pid=821423)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6068899 Vali Loss: 1.5892692 Best vali loss: 1.5881017
[36m(_train_fn pid=821423)[0m Early stopping

Trial trial-d43e9672 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d43e9672 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.06829 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00815 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=822158)[0m configuration
[36m(_train_fn pid=822158)[0m {'batch_size': 128, 'd_model': 8, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'conv', 'dropout': 0.068288547902876, 'e_layers': 1, 'learning_rate': 0.008149704200798314, 'd_ff': 16}
[36m(_train_fn pid=822158)[0m Use GPU: cuda:0
[36m(_train_fn pid=822158)[0m train 7825
[36m(_train_fn pid=822158)[0m val 2161
[36m(_train_fn pid=822158)[0m start_epoch 0
[36m(_train_fn pid=822158)[0m max_epoch 8
[36m(_train_fn pid=822158)[0m Updating learning rate to 0.008149704200798314
[36m(_train_fn pid=822158)[0m saving checkpoint...
[36m(_train_fn pid=822158)[0m Validation loss decreased (inf --> 2.1255).  Saving model state dict ...
[36m(_train_fn pid=822158)[0m Updating learning rate to 0.004074852100399157
[36m(_train_fn pid=822158)[0m saving checkpoint...
[36m(_train_fn pid=822158)[0m Validation loss decreased (2.1255 --> 1.6085).  Saving model state dict ...
[36m(_train_fn pid=822158)[0m Updating learning rate to 0.0020374260501995786
[36m(_train_fn pid=822158)[0m saving checkpoint...
[36m(_train_fn pid=822158)[0m Validation loss decreased (1.6085 --> 1.6008).  Saving model state dict ...
[36m(_train_fn pid=822158)[0m Updating learning rate to 0.0010187130250997893
[36m(_train_fn pid=822158)[0m saving checkpoint...
[36m(_train_fn pid=822158)[0m Validation loss decreased (1.6008 --> 1.5992).  Saving model state dict ...
2024-08-24 09:09:32,187	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:09:32,947	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d43e9672_125_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-26/checkpoint_000004)
2024-08-24 09:09:33,662	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d43e9672_125_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-26/checkpoint_000005)
2024-08-24 09:09:34,408	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822158)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d43e9672_125_alpha_d_ff=2,batch_size=128,d_model=8,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-26/checkpoint_000006)
[36m(_train_fn pid=822760)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fea50374_126_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-34/checkpoint_000000)
2024-08-24 09:09:39,315	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:09:41,386	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822760)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fea50374_126_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-34/checkpoint_000001)
2024-08-24 09:09:43,398	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822760)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fea50374_126_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-34/checkpoint_000002)
2024-08-24 09:09:45,539	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822760)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fea50374_126_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-34/checkpoint_000003)
[36m(_train_fn pid=822760)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fea50374_126_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-34/checkpoint_000004)
2024-08-24 09:09:47,545	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822158)[0m Epoch: 4 cost time: 0.6286160945892334[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=822158)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6070933 Vali Loss: 1.5991721 Best vali loss: 1.5991721[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=822158)[0m Updating learning rate to 0.0005093565125498947
[36m(_train_fn pid=822158)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=822158)[0m saving checkpoint...
[36m(_train_fn pid=822158)[0m Updating learning rate to 0.0002546782562749473
[36m(_train_fn pid=822158)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=822158)[0m saving checkpoint...

Trial trial-d43e9672 completed after 7 iterations at 2024-08-24 09:09:34. Total running time: 1hr 48min 25s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d43e9672 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          0.74349 â”‚
â”‚ time_total_s                              5.83327 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.59917 â”‚
â”‚ train_loss                                0.59633 â”‚
â”‚ valid_loss                                1.60125 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=822158)[0m Updating learning rate to 0.00012733912813747366
[36m(_train_fn pid=822158)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=822158)[0m saving checkpoint...
[36m(_train_fn pid=822158)[0m Early stopping

Trial trial-fea50374 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fea50374 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07817 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00095 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=822760)[0m configuration
[36m(_train_fn pid=822760)[0m {'batch_size': 64, 'd_model': 16, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'conv', 'dropout': 0.07816615857558665, 'e_layers': 4, 'learning_rate': 0.0009512932959729855, 'd_ff': 32}
[36m(_train_fn pid=822760)[0m Use GPU: cuda:0
[36m(_train_fn pid=822760)[0m train 7825
[36m(_train_fn pid=822760)[0m val 2161
[36m(_train_fn pid=822760)[0m start_epoch 0
[36m(_train_fn pid=822760)[0m max_epoch 8
[36m(_train_fn pid=822760)[0m 	iters: 100, epoch: 1 | loss: 1.1101413
[36m(_train_fn pid=822760)[0m 	speed: 0.0203s/iter; left time: 17.7665s
[36m(_train_fn pid=822158)[0m Epoch: 7 cost time: 0.6130757331848145[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=822158)[0m Epoch: 7, Steps: 61 | Train Loss: 0.5963332 Vali Loss: 1.6012517 Best vali loss: 1.5991721[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=822760)[0m Updating learning rate to 0.0009512932959729855
[36m(_train_fn pid=822760)[0m saving checkpoint...
[36m(_train_fn pid=822760)[0m Validation loss decreased (inf --> 2.4391).  Saving model state dict ...
[36m(_train_fn pid=822760)[0m 	iters: 100, epoch: 2 | loss: 0.6838158
[36m(_train_fn pid=822760)[0m 	speed: 0.0207s/iter; left time: 15.6410s
[36m(_train_fn pid=822760)[0m Updating learning rate to 0.00047564664798649273
[36m(_train_fn pid=822760)[0m saving checkpoint...
[36m(_train_fn pid=822760)[0m Validation loss decreased (2.4391 --> 1.6372).  Saving model state dict ...
[36m(_train_fn pid=822760)[0m 	iters: 100, epoch: 3 | loss: 0.6236538
[36m(_train_fn pid=822760)[0m 	speed: 0.0203s/iter; left time: 12.8508s
[36m(_train_fn pid=822760)[0m Updating learning rate to 0.00023782332399324637
[36m(_train_fn pid=822760)[0m saving checkpoint...
[36m(_train_fn pid=822760)[0m Validation loss decreased (1.6372 --> 1.6115).  Saving model state dict ...
[36m(_train_fn pid=822760)[0m 	iters: 100, epoch: 4 | loss: 0.6113386
[36m(_train_fn pid=822760)[0m 	speed: 0.0212s/iter; left time: 10.8279s
[36m(_train_fn pid=822760)[0m Epoch: 3 cost time: 1.7520112991333008[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=822760)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6317121 Vali Loss: 1.6115431 Best vali loss: 1.6115431[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=822760)[0m Updating learning rate to 0.00011891166199662318
[36m(_train_fn pid=822760)[0m saving checkpoint...
[36m(_train_fn pid=822760)[0m Validation loss decreased (1.6115 --> 1.6013).  Saving model state dict ...
[36m(_train_fn pid=822760)[0m 	iters: 100, epoch: 5 | loss: 0.6086562
[36m(_train_fn pid=822760)[0m 	speed: 0.0203s/iter; left time: 7.8972s
[36m(_train_fn pid=822760)[0m Updating learning rate to 5.945583099831159e-05
[36m(_train_fn pid=822760)[0m saving checkpoint...
[36m(_train_fn pid=822760)[0m Validation loss decreased (1.6013 --> 1.5980).  Saving model state dict ...
[36m(_train_fn pid=822760)[0m 	iters: 100, epoch: 6 | loss: 0.5795518
[36m(_train_fn pid=822760)[0m 	speed: 0.0211s/iter; left time: 5.6337s

Trial status: 125 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:09:49. Total running time: 1hr 48min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 09:09:49,690	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822760)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fea50374_126_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-34/checkpoint_000005)
2024-08-24 09:09:51,725	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822760)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fea50374_126_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-34/checkpoint_000006)
2024-08-24 09:09:53,818	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=822760)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fea50374_126_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout=_2024-08-24_09-09-34/checkpoint_000007)
[36m(_train_fn pid=823471)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-263ebd2d_127_alpha_d_ff=4,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-09-53/checkpoint_000000)
2024-08-24 09:10:02,840	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=823471)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-263ebd2d_127_alpha_d_ff=4,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-09-53/checkpoint_000001)
[36m(_train_fn pid=823471)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-263ebd2d_127_alpha_d_ff=4,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-09-53/checkpoint_000002)
2024-08-24 09:10:06,244	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fea50374   RUNNING           5            10.9722       0.615888        1.59803             1.59803 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
120 more TERMINATED
[36m(_train_fn pid=822760)[0m Updating learning rate to 2.9727915499155796e-05
[36m(_train_fn pid=822760)[0m saving checkpoint...
[36m(_train_fn pid=822760)[0m Validation loss decreased (1.5980 --> 1.5972).  Saving model state dict ...
[36m(_train_fn pid=822760)[0m 	iters: 100, epoch: 7 | loss: 0.6221817
[36m(_train_fn pid=822760)[0m 	speed: 0.0206s/iter; left time: 2.9932s
[36m(_train_fn pid=822760)[0m Epoch: 6 cost time: 1.8781614303588867[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=822760)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6131465 Vali Loss: 1.5972182 Best vali loss: 1.5972182[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=822760)[0m Updating learning rate to 1.4863957749577898e-05
[36m(_train_fn pid=822760)[0m saving checkpoint...
[36m(_train_fn pid=822760)[0m Validation loss decreased (1.5972 --> 1.5965).  Saving model state dict ...
[36m(_train_fn pid=822760)[0m 	iters: 100, epoch: 8 | loss: 0.5639447
[36m(_train_fn pid=822760)[0m 	speed: 0.0209s/iter; left time: 0.4817s

Trial trial-fea50374 completed after 8 iterations at 2024-08-24 09:09:53. Total running time: 1hr 48min 45s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fea50374 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          2.09119 â”‚
â”‚ time_total_s                             17.23718 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.59624 â”‚
â”‚ train_loss                                0.61168 â”‚
â”‚ valid_loss                                1.59624 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=822760)[0m Updating learning rate to 7.431978874788949e-06
[36m(_train_fn pid=822760)[0m saving checkpoint...
[36m(_train_fn pid=822760)[0m Validation loss decreased (1.5965 --> 1.5962).  Saving model state dict ...

Trial trial-263ebd2d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-263ebd2d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.13396 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00148 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=823471)[0m configuration
[36m(_train_fn pid=823471)[0m {'batch_size': 32, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'conv', 'dropout': 0.13396397955219355, 'e_layers': 3, 'learning_rate': 0.0014768222086374012, 'd_ff': 128}
[36m(_train_fn pid=823471)[0m Use GPU: cuda:0
[36m(_train_fn pid=823471)[0m train 7825
[36m(_train_fn pid=823471)[0m val 2161
[36m(_train_fn pid=823471)[0m start_epoch 0
[36m(_train_fn pid=823471)[0m max_epoch 8
[36m(_train_fn pid=823471)[0m 	iters: 100, epoch: 1 | loss: 0.9242054
[36m(_train_fn pid=823471)[0m 	speed: 0.0168s/iter; left time: 31.1279s
[36m(_train_fn pid=822760)[0m Epoch: 8 cost time: 1.8335707187652588[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=822760)[0m Epoch: 8, Steps: 122 | Train Loss: 0.6116781 Vali Loss: 1.5962397 Best vali loss: 1.5962397[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=823471)[0m 	iters: 200, epoch: 1 | loss: 0.8565568
[36m(_train_fn pid=823471)[0m 	speed: 0.0115s/iter; left time: 20.0921s
[36m(_train_fn pid=823471)[0m Updating learning rate to 0.0014768222086374012
[36m(_train_fn pid=823471)[0m saving checkpoint...
[36m(_train_fn pid=823471)[0m Validation loss decreased (inf --> 2.0117).  Saving model state dict ...
[36m(_train_fn pid=823471)[0m 	iters: 100, epoch: 2 | loss: 0.6030219
[36m(_train_fn pid=823471)[0m 	speed: 0.0217s/iter; left time: 34.8720s
[36m(_train_fn pid=823471)[0m 	iters: 200, epoch: 2 | loss: 0.7315720
[36m(_train_fn pid=823471)[0m 	speed: 0.0121s/iter; left time: 18.3174s
[36m(_train_fn pid=823471)[0m Updating learning rate to 0.0007384111043187006
[36m(_train_fn pid=823471)[0m saving checkpoint...
[36m(_train_fn pid=823471)[0m Validation loss decreased (2.0117 --> 1.5971).  Saving model state dict ...
[36m(_train_fn pid=823471)[0m Epoch: 2 cost time: 3.015789031982422[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=823471)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6320671 Vali Loss: 1.5971300 Best vali loss: 1.5971300[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=823471)[0m 	iters: 100, epoch: 3 | loss: 0.5833107
[36m(_train_fn pid=823471)[0m 	speed: 0.0219s/iter; left time: 29.8616s
[36m(_train_fn pid=823471)[0m 	iters: 200, epoch: 3 | loss: 0.5110734
[36m(_train_fn pid=823471)[0m 	speed: 0.0122s/iter; left time: 15.4196s
[36m(_train_fn pid=823471)[0m Updating learning rate to 0.0003692055521593503
[36m(_train_fn pid=823471)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=823471)[0m saving checkpoint...
[36m(_train_fn pid=823471)[0m 	iters: 100, epoch: 4 | loss: 0.6080996
[36m(_train_fn pid=823471)[0m 	speed: 0.0219s/iter; left time: 24.5295s
[36m(_train_fn pid=823471)[0m 	iters: 200, epoch: 4 | loss: 0.6303563
[36m(_train_fn pid=823471)[0m 	speed: 0.0124s/iter; left time: 12.7006s
[36m(_train_fn pid=823471)[0m Epoch: 3 cost time: 3.0152037143707275
2024-08-24 09:10:09,690	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=823471)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-263ebd2d_127_alpha_d_ff=4,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-09-53/checkpoint_000003)
2024-08-24 09:10:13,189	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=823471)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-263ebd2d_127_alpha_d_ff=4,batch_size=32,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-09-53/checkpoint_000004)
[36m(_train_fn pid=823968)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ef22361c_128_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_09-10-13/checkpoint_000000)
2024-08-24 09:10:21,168	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=823968)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ef22361c_128_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_09-10-13/checkpoint_000001)
2024-08-24 09:10:23,613	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=823968)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ef22361c_128_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_09-10-13/checkpoint_000002)
[36m(_train_fn pid=823471)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5811111 Vali Loss: 1.6114749 Best vali loss: 1.5971300
[36m(_train_fn pid=823471)[0m Updating learning rate to 0.00018460277607967515
[36m(_train_fn pid=823471)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=823471)[0m saving checkpoint...
[36m(_train_fn pid=823471)[0m Epoch: 4 cost time: 3.0668022632598877
[36m(_train_fn pid=823471)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5656254 Vali Loss: 1.6490775 Best vali loss: 1.5971300
[36m(_train_fn pid=823471)[0m 	iters: 100, epoch: 5 | loss: 0.6451657
[36m(_train_fn pid=823471)[0m 	speed: 0.0221s/iter; left time: 19.4011s
[36m(_train_fn pid=823471)[0m 	iters: 200, epoch: 5 | loss: 0.5123150
[36m(_train_fn pid=823471)[0m 	speed: 0.0128s/iter; left time: 9.9458s

Trial trial-263ebd2d completed after 5 iterations at 2024-08-24 09:10:13. Total running time: 1hr 49min 4s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-263ebd2d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.49532 â”‚
â”‚ time_total_s                             17.61785 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59713 â”‚
â”‚ train_loss                                0.55478 â”‚
â”‚ valid_loss                                1.64756 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=823471)[0m Updating learning rate to 9.230138803983758e-05
[36m(_train_fn pid=823471)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=823471)[0m saving checkpoint...
[36m(_train_fn pid=823471)[0m Epoch: 5 cost time: 3.114579916000366
[36m(_train_fn pid=823471)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5547779 Vali Loss: 1.6475646 Best vali loss: 1.5971300
[36m(_train_fn pid=823471)[0m Early stopping

Trial trial-ef22361c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ef22361c config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13523 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00747 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=823968)[0m configuration
[36m(_train_fn pid=823968)[0m {'batch_size': 32, 'd_model': 16, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'avg', 'dropout': 0.13522604574006658, 'e_layers': 2, 'learning_rate': 0.007466139825309235, 'd_ff': 32}
[36m(_train_fn pid=823968)[0m Use GPU: cuda:0
[36m(_train_fn pid=823968)[0m train 7825
[36m(_train_fn pid=823968)[0m val 2161
[36m(_train_fn pid=823968)[0m start_epoch 0
[36m(_train_fn pid=823968)[0m max_epoch 8
[36m(_train_fn pid=823968)[0m 	iters: 100, epoch: 1 | loss: 0.7752910
[36m(_train_fn pid=823968)[0m 	speed: 0.0140s/iter; left time: 25.9186s
[36m(_train_fn pid=823968)[0m 	iters: 200, epoch: 1 | loss: 0.5957550
[36m(_train_fn pid=823968)[0m 	speed: 0.0089s/iter; left time: 15.5444s
[36m(_train_fn pid=823968)[0m Validation loss decreased (inf --> 1.6155).  Saving model state dict ...
[36m(_train_fn pid=823968)[0m Epoch: 1 cost time: 2.4135549068450928
[36m(_train_fn pid=823968)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7643103 Vali Loss: 1.6154992 Best vali loss: 1.6154992
[36m(_train_fn pid=823968)[0m Updating learning rate to 0.007466139825309235
[36m(_train_fn pid=823968)[0m saving checkpoint...

Trial status: 127 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:10:19. Total running time: 1hr 49min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ef22361c   RUNNING           1            3.10075       0.76431         1.6155              1.6155  â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
122 more TERMINATED
[36m(_train_fn pid=823968)[0m 	iters: 100, epoch: 2 | loss: 0.6110125
[36m(_train_fn pid=823968)[0m 	speed: 0.0160s/iter; left time: 25.7358s
[36m(_train_fn pid=823968)[0m 	iters: 200, epoch: 2 | loss: 0.6328142
[36m(_train_fn pid=823968)[0m 	speed: 0.0088s/iter; left time: 13.3349s
[36m(_train_fn pid=823968)[0m Updating learning rate to 0.0037330699126546176
[36m(_train_fn pid=823968)[0m saving checkpoint...
[36m(_train_fn pid=823968)[0m Validation loss decreased (1.6155 --> 1.5809).  Saving model state dict ...
[36m(_train_fn pid=823968)[0m Epoch: 2 cost time: 2.2023000717163086
[36m(_train_fn pid=823968)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6066383 Vali Loss: 1.5809083 Best vali loss: 1.5809083
[36m(_train_fn pid=823968)[0m 	iters: 100, epoch: 3 | loss: 0.6108875
[36m(_train_fn pid=823968)[0m 	speed: 0.0162s/iter; left time: 22.0957s
[36m(_train_fn pid=823968)[0m 	iters: 200, epoch: 3 | loss: 0.5479349
[36m(_train_fn pid=823968)[0m 	speed: 0.0085s/iter; left time: 10.7590s
[36m(_train_fn pid=823968)[0m Updating learning rate to 0.0018665349563273088
[36m(_train_fn pid=823968)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=823968)[0m saving checkpoint...
[36m(_train_fn pid=823968)[0m Epoch: 3 cost time: 2.168475389480591
2024-08-24 09:10:25,954	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=823968)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ef22361c_128_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_09-10-13/checkpoint_000003)
2024-08-24 09:10:28,249	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=823968)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ef22361c_128_alpha_d_ff=2,batch_size=32,d_model=16,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=0_2024-08-24_09-10-13/checkpoint_000004)
2024-08-24 09:10:33,160	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=824449)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-606a6b82_129_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1240,e_layer_2024-08-24_09-10-28/checkpoint_000000)
2024-08-24 09:10:34,929	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=824449)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-606a6b82_129_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1240,e_layer_2024-08-24_09-10-28/checkpoint_000001)
2024-08-24 09:10:36,633	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=824449)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-606a6b82_129_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1240,e_layer_2024-08-24_09-10-28/checkpoint_000002)
2024-08-24 09:10:38,340	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=824449)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-606a6b82_129_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1240,e_layer_2024-08-24_09-10-28/checkpoint_000003)
2024-08-24 09:10:40,065	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=824449)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-606a6b82_129_alpha_d_ff=4,batch_size=64,d_model=16,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1240,e_layer_2024-08-24_09-10-28/checkpoint_000004)
[36m(_train_fn pid=823968)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5634559 Vali Loss: 1.5955653 Best vali loss: 1.5809083
[36m(_train_fn pid=823968)[0m 	iters: 100, epoch: 4 | loss: 0.4893218
[36m(_train_fn pid=823968)[0m 	speed: 0.0151s/iter; left time: 16.9036s
[36m(_train_fn pid=823968)[0m 	iters: 200, epoch: 4 | loss: 0.5136124
[36m(_train_fn pid=823968)[0m 	speed: 0.0082s/iter; left time: 8.3351s
[36m(_train_fn pid=823968)[0m Updating learning rate to 0.0009332674781636544
[36m(_train_fn pid=823968)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=823968)[0m saving checkpoint...
[36m(_train_fn pid=823968)[0m Epoch: 4 cost time: 2.0619022846221924
[36m(_train_fn pid=823968)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5378636 Vali Loss: 1.6157740 Best vali loss: 1.5809083
[36m(_train_fn pid=823968)[0m 	iters: 100, epoch: 5 | loss: 0.4865244
[36m(_train_fn pid=823968)[0m 	speed: 0.0152s/iter; left time: 13.3349s
[36m(_train_fn pid=823968)[0m 	iters: 200, epoch: 5 | loss: 0.4731808
[36m(_train_fn pid=823968)[0m 	speed: 0.0081s/iter; left time: 6.3063s

Trial trial-ef22361c completed after 5 iterations at 2024-08-24 09:10:28. Total running time: 1hr 49min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ef22361c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          2.30069 â”‚
â”‚ time_total_s                             12.66672 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58091 â”‚
â”‚ train_loss                                0.52133 â”‚
â”‚ valid_loss                                1.62564 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=823968)[0m Updating learning rate to 0.0004666337390818272
[36m(_train_fn pid=823968)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=823968)[0m saving checkpoint...
[36m(_train_fn pid=823968)[0m Epoch: 5 cost time: 2.0215837955474854
[36m(_train_fn pid=823968)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5213275 Vali Loss: 1.6256399 Best vali loss: 1.5809083
[36m(_train_fn pid=823968)[0m Early stopping

Trial trial-606a6b82 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-606a6b82 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.12402 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00182 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=824449)[0m configuration
[36m(_train_fn pid=824449)[0m {'batch_size': 64, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.12401560318108323, 'e_layers': 2, 'learning_rate': 0.0018170195150553792, 'd_ff': 64}
[36m(_train_fn pid=824449)[0m Use GPU: cuda:0
[36m(_train_fn pid=824449)[0m train 7825
[36m(_train_fn pid=824449)[0m val 2161
[36m(_train_fn pid=824449)[0m start_epoch 0
[36m(_train_fn pid=824449)[0m max_epoch 8
[36m(_train_fn pid=824449)[0m 	iters: 100, epoch: 1 | loss: 0.9338048
[36m(_train_fn pid=824449)[0m 	speed: 0.0190s/iter; left time: 16.6783s
[36m(_train_fn pid=824449)[0m Validation loss decreased (inf --> 2.2013).  Saving model state dict ...
[36m(_train_fn pid=824449)[0m Epoch: 1 cost time: 1.9012172222137451
[36m(_train_fn pid=824449)[0m Epoch: 1, Steps: 122 | Train Loss: 1.0937653 Vali Loss: 2.2012854 Best vali loss: 2.2012854
[36m(_train_fn pid=824449)[0m 	iters: 100, epoch: 2 | loss: 0.5371484
[36m(_train_fn pid=824449)[0m 	speed: 0.0177s/iter; left time: 13.3335s
[36m(_train_fn pid=824449)[0m Updating learning rate to 0.0018170195150553792
[36m(_train_fn pid=824449)[0m saving checkpoint...
[36m(_train_fn pid=824449)[0m Updating learning rate to 0.0009085097575276896
[36m(_train_fn pid=824449)[0m saving checkpoint...
[36m(_train_fn pid=824449)[0m Validation loss decreased (2.2013 --> 1.5985).  Saving model state dict ...
[36m(_train_fn pid=824449)[0m Epoch: 2 cost time: 1.514883279800415
[36m(_train_fn pid=824449)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6970714 Vali Loss: 1.5985452 Best vali loss: 1.5985452
[36m(_train_fn pid=824449)[0m 	iters: 100, epoch: 3 | loss: 0.6119067
[36m(_train_fn pid=824449)[0m 	speed: 0.0173s/iter; left time: 10.9338s
[36m(_train_fn pid=824449)[0m Updating learning rate to 0.0004542548787638448
[36m(_train_fn pid=824449)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=824449)[0m saving checkpoint...
[36m(_train_fn pid=824449)[0m Epoch: 3 cost time: 1.4481127262115479
[36m(_train_fn pid=824449)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6113343 Vali Loss: 1.6051639 Best vali loss: 1.5985452
[36m(_train_fn pid=824449)[0m 	iters: 100, epoch: 4 | loss: 0.5460667
[36m(_train_fn pid=824449)[0m 	speed: 0.0169s/iter; left time: 8.6509s
[36m(_train_fn pid=824449)[0m Updating learning rate to 0.0002271274393819224
[36m(_train_fn pid=824449)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=824449)[0m saving checkpoint...
[36m(_train_fn pid=824449)[0m Epoch: 4 cost time: 1.4346997737884521
[36m(_train_fn pid=824449)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6039880 Vali Loss: 1.5991885 Best vali loss: 1.5985452
[36m(_train_fn pid=824449)[0m 	iters: 100, epoch: 5 | loss: 0.6401491
[36m(_train_fn pid=824449)[0m 	speed: 0.0173s/iter; left time: 6.7151s

Trial trial-606a6b82 completed after 5 iterations at 2024-08-24 09:10:40. Total running time: 1hr 49min 31s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-606a6b82 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.72268 â”‚
â”‚ time_total_s                              9.46695 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59855 â”‚
â”‚ train_loss                                0.59867 â”‚
â”‚ valid_loss                                1.60279 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=824449)[0m Updating learning rate to 0.0001135637196909612
[36m(_train_fn pid=824449)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=824449)[0m saving checkpoint...
[36m(_train_fn pid=824449)[0m Epoch: 5 cost time: 1.4674460887908936
[36m(_train_fn pid=824449)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5986693 Vali Loss: 1.6027938 Best vali loss: 1.5985452
[36m(_train_fn pid=824449)[0m Early stopping

Trial trial-168e79a1 started with configuration:
2024-08-24 09:10:44,876	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=824921)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-168e79a1_130_alpha_d_ff=3,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0995,e_layers_2024-08-24_09-10-40/checkpoint_000001)[32m [repeated 2x across cluster][0m
2024-08-24 09:10:46,349	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:10:47,819	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:10:49,281	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:10:50,745	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-168e79a1 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09951 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00571 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=824921)[0m configuration
[36m(_train_fn pid=824921)[0m {'batch_size': 64, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.09950895787596367, 'e_layers': 1, 'learning_rate': 0.00571266110842173, 'd_ff': 96}
[36m(_train_fn pid=824921)[0m Use GPU: cuda:0
[36m(_train_fn pid=824921)[0m train 7825
[36m(_train_fn pid=824921)[0m val 2161
[36m(_train_fn pid=824921)[0m start_epoch 0
[36m(_train_fn pid=824921)[0m max_epoch 8
[36m(_train_fn pid=824921)[0m Updating learning rate to 0.00571266110842173
[36m(_train_fn pid=824921)[0m saving checkpoint...
[36m(_train_fn pid=824921)[0m Validation loss decreased (inf --> 1.8473).  Saving model state dict ...
[36m(_train_fn pid=824921)[0m 	iters: 100, epoch: 1 | loss: 0.7795417
[36m(_train_fn pid=824921)[0m 	speed: 0.0169s/iter; left time: 14.7977s
[36m(_train_fn pid=824921)[0m 	iters: 100, epoch: 2 | loss: 0.6047831
[36m(_train_fn pid=824921)[0m 	speed: 0.0148s/iter; left time: 11.2100s
[36m(_train_fn pid=824921)[0m Epoch: 1 cost time: 1.64750337600708
[36m(_train_fn pid=824921)[0m Epoch: 1, Steps: 122 | Train Loss: 0.9239561 Vali Loss: 1.8472821 Best vali loss: 1.8472821
[36m(_train_fn pid=824921)[0m Updating learning rate to 0.002856330554210865
[36m(_train_fn pid=824921)[0m saving checkpoint...
[36m(_train_fn pid=824921)[0m Validation loss decreased (1.8473 --> 1.5828).  Saving model state dict ...
[36m(_train_fn pid=824921)[0m Epoch: 2 cost time: 1.226576328277588
[36m(_train_fn pid=824921)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6349388 Vali Loss: 1.5828049 Best vali loss: 1.5828049
[36m(_train_fn pid=824921)[0m 	iters: 100, epoch: 3 | loss: 0.5480542
[36m(_train_fn pid=824921)[0m 	speed: 0.0147s/iter; left time: 9.3285s
[36m(_train_fn pid=824921)[0m Updating learning rate to 0.0014281652771054325
[36m(_train_fn pid=824921)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=824921)[0m saving checkpoint...
[36m(_train_fn pid=824921)[0m Epoch: 3 cost time: 1.2250423431396484
[36m(_train_fn pid=824921)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5996837 Vali Loss: 1.6081781 Best vali loss: 1.5828049
[36m(_train_fn pid=824921)[0m 	iters: 100, epoch: 4 | loss: 0.5832291
[36m(_train_fn pid=824921)[0m 	speed: 0.0147s/iter; left time: 7.5292s
[36m(_train_fn pid=824921)[0m Updating learning rate to 0.0007140826385527162
[36m(_train_fn pid=824921)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=824921)[0m saving checkpoint...
[36m(_train_fn pid=824921)[0m Epoch: 4 cost time: 1.2297272682189941
[36m(_train_fn pid=824921)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5819888 Vali Loss: 1.6086391 Best vali loss: 1.5828049

Trial status: 129 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:10:49. Total running time: 1hr 49min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-168e79a1   RUNNING           4            6.69904       0.581989        1.60864             1.5828  â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
124 more TERMINATED
[36m(_train_fn pid=824921)[0m 	iters: 100, epoch: 5 | loss: 0.5868713
[36m(_train_fn pid=824921)[0m 	speed: 0.0146s/iter; left time: 5.6984s

Trial trial-168e79a1 completed after 5 iterations at 2024-08-24 09:10:50. Total running time: 1hr 49min 41s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-168e79a1 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.46101 â”‚
â”‚ time_total_s                              8.16005 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                            1.5828 â”‚
â”‚ train_loss                                0.57096 â”‚
â”‚ valid_loss                                1.63321 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=824921)[0m Updating learning rate to 0.0003570413192763581
[36m(_train_fn pid=824921)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=824921)[0m saving checkpoint...
[36m(_train_fn pid=824921)[0m Epoch: 5 cost time: 1.2207005023956299
[36m(_train_fn pid=824921)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5709602 Vali Loss: 1.6332062 Best vali loss: 1.5828049
[36m(_train_fn pid=824921)[0m Early stopping

Trial trial-01d0249a started with configuration:
[36m(_train_fn pid=825390)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-01d0249a_131_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout_2024-08-24_09-10-50/checkpoint_000000)[32m [repeated 4x across cluster][0m
2024-08-24 09:11:01,114	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=825390)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-01d0249a_131_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout_2024-08-24_09-10-50/checkpoint_000001)
[36m(_train_fn pid=825390)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-01d0249a_131_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout_2024-08-24_09-10-50/checkpoint_000002)
[36m(_train_fn pid=825390)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-01d0249a_131_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout_2024-08-24_09-10-50/checkpoint_000003)
[36m(_train_fn pid=825390)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-01d0249a_131_alpha_d_ff=3,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout_2024-08-24_09-10-50/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-01d0249a config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.10178 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00801 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=825390)[0m configuration
[36m(_train_fn pid=825390)[0m {'batch_size': 128, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.10178375340741656, 'e_layers': 3, 'learning_rate': 0.00801162422846211, 'd_ff': 384}
[36m(_train_fn pid=825390)[0m Use GPU: cuda:0
[36m(_train_fn pid=825390)[0m train 7825
[36m(_train_fn pid=825390)[0m val 2161
[36m(_train_fn pid=825390)[0m start_epoch 0
[36m(_train_fn pid=825390)[0m max_epoch 8
[36m(_train_fn pid=825390)[0m Validation loss decreased (inf --> 1.9314).  Saving model state dict ...
[36m(_train_fn pid=825390)[0m Epoch: 1 cost time: 7.297383546829224
[36m(_train_fn pid=825390)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8460901 Vali Loss: 1.9313723 Best vali loss: 1.9313723
[36m(_train_fn pid=825390)[0m Updating learning rate to 0.00801162422846211
[36m(_train_fn pid=825390)[0m saving checkpoint...
[36m(_train_fn pid=825390)[0m Updating learning rate to 0.004005812114231055
[36m(_train_fn pid=825390)[0m saving checkpoint...
[36m(_train_fn pid=825390)[0m Validation loss decreased (1.9314 --> 1.6130).  Saving model state dict ...
[36m(_train_fn pid=825390)[0m Epoch: 2 cost time: 7.124891757965088
[36m(_train_fn pid=825390)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6488445 Vali Loss: 1.6130486 Best vali loss: 1.6130486
[36m(_train_fn pid=825390)[0m Updating learning rate to 0.0020029060571155276
[36m(_train_fn pid=825390)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=825390)[0m saving checkpoint...
[36m(_train_fn pid=825390)[0m Epoch: 3 cost time: 7.125317811965942
[36m(_train_fn pid=825390)[0m Epoch: 3, Steps: 61 | Train Loss: 0.5982178 Vali Loss: 1.6597211 Best vali loss: 1.6130486

Trial status: 130 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:11:19. Total running time: 1hr 50min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-01d0249a   RUNNING           3            24.4799       0.598218        1.65972             1.61305 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
125 more TERMINATED
[36m(_train_fn pid=825390)[0m Updating learning rate to 0.0010014530285577638
[36m(_train_fn pid=825390)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=825390)[0m saving checkpoint...
[36m(_train_fn pid=825390)[0m Epoch: 4 cost time: 7.1309850215911865
[36m(_train_fn pid=825390)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5731701 Vali Loss: 1.6541933 Best vali loss: 1.6130486

Trial trial-01d0249a completed after 5 iterations at 2024-08-24 09:11:32. Total running time: 1hr 50min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-01d0249a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          7.97157 â”‚
â”‚ time_total_s                             40.41794 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.61305 â”‚
â”‚ train_loss                                0.56023 â”‚
â”‚ valid_loss                                1.64626 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=825390)[0m Updating learning rate to 0.0005007265142788819
[36m(_train_fn pid=825390)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=825390)[0m saving checkpoint...
[36m(_train_fn pid=825390)[0m Epoch: 5 cost time: 7.132580995559692
[36m(_train_fn pid=825390)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5602281 Vali Loss: 1.6462611 Best vali loss: 1.6130486
[36m(_train_fn pid=825390)[0m Early stopping

Trial trial-5e319399 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5e319399 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09591 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00159 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=825953)[0m configuration
[36m(_train_fn pid=825953)[0m {'batch_size': 16, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'conv', 'dropout': 0.09591322398448754, 'e_layers': 1, 'learning_rate': 0.0015936113602036258, 'd_ff': 256}
[36m(_train_fn pid=825953)[0m Use GPU: cuda:0
[36m(_train_fn pid=825953)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e319399_132_alpha_d_ff=4,batch_size=16,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-11-32/checkpoint_000000)
2024-08-24 09:11:44,182	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=825953)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e319399_132_alpha_d_ff=4,batch_size=16,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-11-32/checkpoint_000001)
2024-08-24 09:11:48,258	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=825953)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e319399_132_alpha_d_ff=4,batch_size=16,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-11-32/checkpoint_000002)
2024-08-24 09:11:52,341	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=825953)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e319399_132_alpha_d_ff=4,batch_size=16,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-11-32/checkpoint_000003)
2024-08-24 09:11:56,312	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=825953)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5e319399_132_alpha_d_ff=4,batch_size=16,d_model=64,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-11-32/checkpoint_000004)
[36m(_train_fn pid=825953)[0m train 7825
[36m(_train_fn pid=825953)[0m val 2161
[36m(_train_fn pid=825953)[0m start_epoch 0
[36m(_train_fn pid=825953)[0m max_epoch 8
[36m(_train_fn pid=825953)[0m 	iters: 100, epoch: 1 | loss: 0.8045572
[36m(_train_fn pid=825953)[0m 	speed: 0.0126s/iter; left time: 47.8696s
[36m(_train_fn pid=825953)[0m 	iters: 200, epoch: 1 | loss: 0.7328298
[36m(_train_fn pid=825953)[0m 	speed: 0.0072s/iter; left time: 26.8405s
[36m(_train_fn pid=825953)[0m 	iters: 300, epoch: 1 | loss: 0.8423045
[36m(_train_fn pid=825953)[0m 	speed: 0.0073s/iter; left time: 26.3060s
[36m(_train_fn pid=825953)[0m 	iters: 400, epoch: 1 | loss: 0.6869121
[36m(_train_fn pid=825953)[0m 	speed: 0.0073s/iter; left time: 25.6802s
[36m(_train_fn pid=825953)[0m Updating learning rate to 0.0015936113602036258
[36m(_train_fn pid=825953)[0m saving checkpoint...
[36m(_train_fn pid=825953)[0m Validation loss decreased (inf --> 1.7243).  Saving model state dict ...
[36m(_train_fn pid=825953)[0m Epoch: 1 cost time: 3.8281056880950928
[36m(_train_fn pid=825953)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7606196 Vali Loss: 1.7242874 Best vali loss: 1.7242874
[36m(_train_fn pid=825953)[0m 	iters: 100, epoch: 2 | loss: 0.5915628
[36m(_train_fn pid=825953)[0m 	speed: 0.0187s/iter; left time: 62.0804s
[36m(_train_fn pid=825953)[0m 	iters: 200, epoch: 2 | loss: 0.6273541
[36m(_train_fn pid=825953)[0m 	speed: 0.0068s/iter; left time: 22.0643s
[36m(_train_fn pid=825953)[0m 	iters: 300, epoch: 2 | loss: 0.5813920
[36m(_train_fn pid=825953)[0m 	speed: 0.0068s/iter; left time: 21.3738s
[36m(_train_fn pid=825953)[0m 	iters: 400, epoch: 2 | loss: 0.5975773
[36m(_train_fn pid=825953)[0m 	speed: 0.0068s/iter; left time: 20.6310s
[36m(_train_fn pid=825953)[0m Updating learning rate to 0.0007968056801018129
[36m(_train_fn pid=825953)[0m saving checkpoint...
[36m(_train_fn pid=825953)[0m Validation loss decreased (1.7243 --> 1.5723).  Saving model state dict ...
[36m(_train_fn pid=825953)[0m Epoch: 2 cost time: 3.385672092437744
[36m(_train_fn pid=825953)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6147640 Vali Loss: 1.5723338 Best vali loss: 1.5723338
[36m(_train_fn pid=825953)[0m 	iters: 100, epoch: 3 | loss: 0.4677342
[36m(_train_fn pid=825953)[0m 	speed: 0.0185s/iter; left time: 52.5385s
[36m(_train_fn pid=825953)[0m 	iters: 200, epoch: 3 | loss: 0.5888198
[36m(_train_fn pid=825953)[0m 	speed: 0.0073s/iter; left time: 20.0928s
[36m(_train_fn pid=825953)[0m 	iters: 300, epoch: 3 | loss: 0.5959617
[36m(_train_fn pid=825953)[0m 	speed: 0.0073s/iter; left time: 19.1548s
[36m(_train_fn pid=825953)[0m 	iters: 400, epoch: 3 | loss: 0.5375585
[36m(_train_fn pid=825953)[0m 	speed: 0.0073s/iter; left time: 18.3886s
[36m(_train_fn pid=825953)[0m Updating learning rate to 0.00039840284005090645
[36m(_train_fn pid=825953)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=825953)[0m saving checkpoint...
[36m(_train_fn pid=825953)[0m Epoch: 3 cost time: 3.5987043380737305
[36m(_train_fn pid=825953)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5761259 Vali Loss: 1.6157164 Best vali loss: 1.5723338
[36m(_train_fn pid=825953)[0m 	iters: 100, epoch: 4 | loss: 0.6437925
[36m(_train_fn pid=825953)[0m 	speed: 0.0189s/iter; left time: 44.4515s

Trial status: 131 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:11:49. Total running time: 1hr 50min 40s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5e319399   RUNNING           3            12.6605       0.576126        1.61572             1.57233 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
126 more TERMINATED
[36m(_train_fn pid=825953)[0m 	iters: 200, epoch: 4 | loss: 0.5063807
[36m(_train_fn pid=825953)[0m 	speed: 0.0073s/iter; left time: 16.4033s
[36m(_train_fn pid=825953)[0m 	iters: 300, epoch: 4 | loss: 0.4962785
[36m(_train_fn pid=825953)[0m 	speed: 0.0073s/iter; left time: 15.6489s
[36m(_train_fn pid=825953)[0m 	iters: 400, epoch: 4 | loss: 0.5424652
[36m(_train_fn pid=825953)[0m 	speed: 0.0073s/iter; left time: 15.0063s
[36m(_train_fn pid=825953)[0m Updating learning rate to 0.00019920142002545323
[36m(_train_fn pid=825953)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=825953)[0m saving checkpoint...
[36m(_train_fn pid=825953)[0m Epoch: 4 cost time: 3.612522602081299
[36m(_train_fn pid=825953)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5417210 Vali Loss: 1.6331947 Best vali loss: 1.5723338
[36m(_train_fn pid=825953)[0m 	iters: 100, epoch: 5 | loss: 0.4880967
[36m(_train_fn pid=825953)[0m 	speed: 0.0189s/iter; left time: 35.0610s
[36m(_train_fn pid=825953)[0m 	iters: 200, epoch: 5 | loss: 0.4984800
[36m(_train_fn pid=825953)[0m 	speed: 0.0071s/iter; left time: 12.5015s
[36m(_train_fn pid=825953)[0m 	iters: 300, epoch: 5 | loss: 0.5288315
[36m(_train_fn pid=825953)[0m 	speed: 0.0070s/iter; left time: 11.5250s
[36m(_train_fn pid=825953)[0m 	iters: 400, epoch: 5 | loss: 0.4942382
[36m(_train_fn pid=825953)[0m 	speed: 0.0070s/iter; left time: 10.8223s

Trial trial-5e319399 completed after 5 iterations at 2024-08-24 09:11:56. Total running time: 1hr 50min 47s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5e319399 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.96775 â”‚
â”‚ time_total_s                             20.71058 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.57233 â”‚
â”‚ train_loss                                0.52671 â”‚
â”‚ valid_loss                                 1.6715 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=825953)[0m Updating learning rate to 9.960071001272661e-05
2024-08-24 09:12:01,244	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:12:03,272	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=826458)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e8b2bdf5_133_alpha_d_ff=3,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_09-11-56/checkpoint_000001)[32m [repeated 2x across cluster][0m
2024-08-24 09:12:05,323	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:12:07,371	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:12:09,410	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=826458)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e8b2bdf5_133_alpha_d_ff=3,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_09-11-56/checkpoint_000004)[32m [repeated 3x across cluster][0m
2024-08-24 09:12:11,449	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:12:13,497	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:12:15,553	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=826458)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e8b2bdf5_133_alpha_d_ff=3,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout=0_2024-08-24_09-11-56/checkpoint_000007)[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=825953)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=825953)[0m saving checkpoint...
[36m(_train_fn pid=825953)[0m Epoch: 5 cost time: 3.4886133670806885
[36m(_train_fn pid=825953)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5267058 Vali Loss: 1.6715000 Best vali loss: 1.5723338
[36m(_train_fn pid=825953)[0m Early stopping

Trial trial-e8b2bdf5 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e8b2bdf5 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.12275 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00052 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=826458)[0m configuration
[36m(_train_fn pid=826458)[0m {'batch_size': 64, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.12274837854560226, 'e_layers': 2, 'learning_rate': 0.0005207710577361526, 'd_ff': 96}
[36m(_train_fn pid=826458)[0m Use GPU: cuda:0
[36m(_train_fn pid=826458)[0m train 7825
[36m(_train_fn pid=826458)[0m val 2161
[36m(_train_fn pid=826458)[0m start_epoch 0
[36m(_train_fn pid=826458)[0m max_epoch 8
[36m(_train_fn pid=826458)[0m 	iters: 100, epoch: 1 | loss: 0.9180633
[36m(_train_fn pid=826458)[0m 	speed: 0.0194s/iter; left time: 16.9801s
[36m(_train_fn pid=826458)[0m Validation loss decreased (inf --> 2.0706).  Saving model state dict ...
[36m(_train_fn pid=826458)[0m 	iters: 100, epoch: 2 | loss: 0.7019622
[36m(_train_fn pid=826458)[0m 	speed: 0.0204s/iter; left time: 15.4194s
[36m(_train_fn pid=826458)[0m Updating learning rate to 0.0005207710577361526
[36m(_train_fn pid=826458)[0m saving checkpoint...
[36m(_train_fn pid=826458)[0m Epoch: 1 cost time: 1.9937386512756348
[36m(_train_fn pid=826458)[0m Epoch: 1, Steps: 122 | Train Loss: 1.0468536 Vali Loss: 2.0705995 Best vali loss: 2.0705995
[36m(_train_fn pid=826458)[0m Updating learning rate to 0.0002603855288680763
[36m(_train_fn pid=826458)[0m saving checkpoint...
[36m(_train_fn pid=826458)[0m Validation loss decreased (2.0706 --> 1.6513).  Saving model state dict ...
[36m(_train_fn pid=826458)[0m Epoch: 2 cost time: 1.7540099620819092
[36m(_train_fn pid=826458)[0m Epoch: 2, Steps: 122 | Train Loss: 0.7477752 Vali Loss: 1.6512885 Best vali loss: 1.6512885
[36m(_train_fn pid=826458)[0m 	iters: 100, epoch: 3 | loss: 0.6266515
[36m(_train_fn pid=826458)[0m 	speed: 0.0204s/iter; left time: 12.9253s
[36m(_train_fn pid=826458)[0m Updating learning rate to 0.00013019276443403815
[36m(_train_fn pid=826458)[0m saving checkpoint...
[36m(_train_fn pid=826458)[0m Validation loss decreased (1.6513 --> 1.6255).  Saving model state dict ...
[36m(_train_fn pid=826458)[0m Epoch: 3 cost time: 1.7728145122528076
[36m(_train_fn pid=826458)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6540829 Vali Loss: 1.6255365 Best vali loss: 1.6255365
[36m(_train_fn pid=826458)[0m 	iters: 100, epoch: 4 | loss: 0.6711295
[36m(_train_fn pid=826458)[0m 	speed: 0.0205s/iter; left time: 10.4746s
[36m(_train_fn pid=826458)[0m Updating learning rate to 6.509638221701908e-05
[36m(_train_fn pid=826458)[0m saving checkpoint...
[36m(_train_fn pid=826458)[0m Validation loss decreased (1.6255 --> 1.6131).  Saving model state dict ...
[36m(_train_fn pid=826458)[0m Epoch: 4 cost time: 1.7689073085784912
[36m(_train_fn pid=826458)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6423917 Vali Loss: 1.6130640 Best vali loss: 1.6130640
[36m(_train_fn pid=826458)[0m 	iters: 100, epoch: 5 | loss: 0.6142994
[36m(_train_fn pid=826458)[0m 	speed: 0.0205s/iter; left time: 7.9711s
[36m(_train_fn pid=826458)[0m Updating learning rate to 3.254819110850954e-05
[36m(_train_fn pid=826458)[0m saving checkpoint...
[36m(_train_fn pid=826458)[0m Validation loss decreased (1.6131 --> 1.6069).  Saving model state dict ...
[36m(_train_fn pid=826458)[0m Epoch: 5 cost time: 1.7674903869628906
[36m(_train_fn pid=826458)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6366276 Vali Loss: 1.6068566 Best vali loss: 1.6068566
[36m(_train_fn pid=826458)[0m 	iters: 100, epoch: 6 | loss: 0.6669285
[36m(_train_fn pid=826458)[0m 	speed: 0.0204s/iter; left time: 5.4375s
[36m(_train_fn pid=826458)[0m Updating learning rate to 1.627409555425477e-05
[36m(_train_fn pid=826458)[0m saving checkpoint...
[36m(_train_fn pid=826458)[0m Validation loss decreased (1.6069 --> 1.6038).  Saving model state dict ...
[36m(_train_fn pid=826458)[0m Epoch: 6 cost time: 1.756361961364746
[36m(_train_fn pid=826458)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6334299 Vali Loss: 1.6037547 Best vali loss: 1.6037547
[36m(_train_fn pid=826458)[0m 	iters: 100, epoch: 7 | loss: 0.6523257
[36m(_train_fn pid=826458)[0m 	speed: 0.0205s/iter; left time: 2.9725s
[36m(_train_fn pid=826458)[0m Updating learning rate to 8.137047777127385e-06
[36m(_train_fn pid=826458)[0m saving checkpoint...
[36m(_train_fn pid=826458)[0m Validation loss decreased (1.6038 --> 1.6022).  Saving model state dict ...
[36m(_train_fn pid=826458)[0m Epoch: 7 cost time: 1.7712664604187012
[36m(_train_fn pid=826458)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6320935 Vali Loss: 1.6022268 Best vali loss: 1.6022268
[36m(_train_fn pid=826458)[0m 	iters: 100, epoch: 8 | loss: 0.6484020
[36m(_train_fn pid=826458)[0m 	speed: 0.0205s/iter; left time: 0.4724s

Trial trial-e8b2bdf5 completed after 8 iterations at 2024-08-24 09:12:15. Total running time: 1hr 51min 6s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e8b2bdf5 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          2.05296 â”‚
â”‚ time_total_s                             16.97067 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.60147 â”‚
â”‚ train_loss                                0.63138 â”‚
â”‚ valid_loss                                1.60147 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=826458)[0m Updating learning rate to 4.068523888563692e-06
[36m(_train_fn pid=826458)[0m saving checkpoint...
[36m(_train_fn pid=826458)[0m Validation loss decreased (1.6022 --> 1.6015).  Saving model state dict ...
[36m(_train_fn pid=826458)[0m Epoch: 8 cost time: 1.7776613235473633
[36m(_train_fn pid=826458)[0m Epoch: 8, Steps: 122 | Train Loss: 0.6313825 Vali Loss: 1.6014727 Best vali loss: 1.6014727

Trial trial-eec3f6b9 started with configuration:
[36m(_train_fn pid=827164)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eec3f6b9_134_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_09-12-15/checkpoint_000000)
2024-08-24 09:12:26,984	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827164)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eec3f6b9_134_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_09-12-15/checkpoint_000001)
2024-08-24 09:12:31,375	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827164)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eec3f6b9_134_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_09-12-15/checkpoint_000002)
2024-08-24 09:12:35,792	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827164)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eec3f6b9_134_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_09-12-15/checkpoint_000003)
2024-08-24 09:12:40,178	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827164)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eec3f6b9_134_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_09-12-15/checkpoint_000004)
2024-08-24 09:12:44,592	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827164)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eec3f6b9_134_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_09-12-15/checkpoint_000005)
2024-08-24 09:12:48,984	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827164)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eec3f6b9_134_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_09-12-15/checkpoint_000006)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-eec3f6b9 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                              0.064 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00097 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=827164)[0m configuration
[36m(_train_fn pid=827164)[0m {'batch_size': 64, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'conv', 'dropout': 0.06399698299173194, 'e_layers': 1, 'learning_rate': 0.0009666523990925918, 'd_ff': 384}
[36m(_train_fn pid=827164)[0m Use GPU: cuda:0
[36m(_train_fn pid=827164)[0m train 7825
[36m(_train_fn pid=827164)[0m val 2161
[36m(_train_fn pid=827164)[0m start_epoch 0
[36m(_train_fn pid=827164)[0m max_epoch 8

Trial status: 133 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:12:19. Total running time: 1hr 51min 10s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-eec3f6b9   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
128 more TERMINATED
[36m(_train_fn pid=827164)[0m 	iters: 100, epoch: 1 | loss: 0.8059747
[36m(_train_fn pid=827164)[0m 	speed: 0.0366s/iter; left time: 32.0904s
[36m(_train_fn pid=827164)[0m Updating learning rate to 0.0009666523990925918
[36m(_train_fn pid=827164)[0m saving checkpoint...
[36m(_train_fn pid=827164)[0m Validation loss decreased (inf --> 1.9557).  Saving model state dict ...
[36m(_train_fn pid=827164)[0m Epoch: 1 cost time: 4.092306137084961
[36m(_train_fn pid=827164)[0m Epoch: 1, Steps: 122 | Train Loss: 0.7982014 Vali Loss: 1.9557038 Best vali loss: 1.9557038
[36m(_train_fn pid=827164)[0m 	iters: 100, epoch: 2 | loss: 0.6131917
[36m(_train_fn pid=827164)[0m 	speed: 0.0438s/iter; left time: 33.0762s
[36m(_train_fn pid=827164)[0m Updating learning rate to 0.0004833261995462959
[36m(_train_fn pid=827164)[0m saving checkpoint...
[36m(_train_fn pid=827164)[0m Validation loss decreased (1.9557 --> 1.6099).  Saving model state dict ...
[36m(_train_fn pid=827164)[0m Epoch: 2 cost time: 3.872300386428833
[36m(_train_fn pid=827164)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6674096 Vali Loss: 1.6098740 Best vali loss: 1.6098740
[36m(_train_fn pid=827164)[0m 	iters: 100, epoch: 3 | loss: 0.5649418
[36m(_train_fn pid=827164)[0m 	speed: 0.0439s/iter; left time: 27.7914s
[36m(_train_fn pid=827164)[0m Updating learning rate to 0.00024166309977314795
[36m(_train_fn pid=827164)[0m saving checkpoint...
[36m(_train_fn pid=827164)[0m Validation loss decreased (1.6099 --> 1.6039).  Saving model state dict ...
[36m(_train_fn pid=827164)[0m Epoch: 3 cost time: 3.88310170173645
[36m(_train_fn pid=827164)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6231690 Vali Loss: 1.6039002 Best vali loss: 1.6039002
[36m(_train_fn pid=827164)[0m 	iters: 100, epoch: 4 | loss: 0.6330684
[36m(_train_fn pid=827164)[0m 	speed: 0.0441s/iter; left time: 22.5281s
[36m(_train_fn pid=827164)[0m Updating learning rate to 0.00012083154988657397
[36m(_train_fn pid=827164)[0m saving checkpoint...
[36m(_train_fn pid=827164)[0m Validation loss decreased (1.6039 --> 1.5907).  Saving model state dict ...
[36m(_train_fn pid=827164)[0m Epoch: 4 cost time: 3.9045588970184326
[36m(_train_fn pid=827164)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6175086 Vali Loss: 1.5906584 Best vali loss: 1.5906584
[36m(_train_fn pid=827164)[0m 	iters: 100, epoch: 5 | loss: 0.5633112
[36m(_train_fn pid=827164)[0m 	speed: 0.0440s/iter; left time: 17.0992s
[36m(_train_fn pid=827164)[0m Updating learning rate to 6.041577494328699e-05
[36m(_train_fn pid=827164)[0m saving checkpoint...
[36m(_train_fn pid=827164)[0m Validation loss decreased (1.5907 --> 1.5872).  Saving model state dict ...
[36m(_train_fn pid=827164)[0m Epoch: 5 cost time: 3.8874194622039795
[36m(_train_fn pid=827164)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6129149 Vali Loss: 1.5872275 Best vali loss: 1.5872275
[36m(_train_fn pid=827164)[0m 	iters: 100, epoch: 6 | loss: 0.6038496
[36m(_train_fn pid=827164)[0m 	speed: 0.0441s/iter; left time: 11.7656s
[36m(_train_fn pid=827164)[0m Updating learning rate to 3.0207887471643494e-05
[36m(_train_fn pid=827164)[0m saving checkpoint...
[36m(_train_fn pid=827164)[0m Validation loss decreased (1.5872 --> 1.5854).  Saving model state dict ...
[36m(_train_fn pid=827164)[0m Epoch: 6 cost time: 3.895167350769043
[36m(_train_fn pid=827164)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6115065 Vali Loss: 1.5853903 Best vali loss: 1.5853903
[36m(_train_fn pid=827164)[0m 	iters: 100, epoch: 7 | loss: 0.5859559
[36m(_train_fn pid=827164)[0m 	speed: 0.0440s/iter; left time: 6.3774s
[36m(_train_fn pid=827164)[0m Updating learning rate to 1.5103943735821747e-05
[36m(_train_fn pid=827164)[0m saving checkpoint...
[36m(_train_fn pid=827164)[0m Validation loss decreased (1.5854 --> 1.5847).  Saving model state dict ...
[36m(_train_fn pid=827164)[0m Epoch: 7 cost time: 3.887474775314331
[36m(_train_fn pid=827164)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6110724 Vali Loss: 1.5846674 Best vali loss: 1.5846674
Trial status: 133 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:12:49. Total running time: 1hr 51min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 09:12:53,384	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827164)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-eec3f6b9_134_alpha_d_ff=3,batch_size=64,d_model=128,decomp_method=moving_avg,moving_avg=55,down_sampling_method=conv,dropout_2024-08-24_09-12-15/checkpoint_000007)
[36m(_train_fn pid=827924)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e384540e_135_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_09-12-53/checkpoint_000000)
2024-08-24 09:13:04,177	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827924)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e384540e_135_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_09-12-53/checkpoint_000001)
2024-08-24 09:13:08,160	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827924)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e384540e_135_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_09-12-53/checkpoint_000002)
2024-08-24 09:13:12,138	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827924)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e384540e_135_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_09-12-53/checkpoint_000003)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-eec3f6b9   RUNNING           7            31.3712       0.611072        1.58467             1.58467 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
128 more TERMINATED
[36m(_train_fn pid=827164)[0m 	iters: 100, epoch: 8 | loss: 0.6116105
[36m(_train_fn pid=827164)[0m 	speed: 0.0440s/iter; left time: 1.0123s

Trial trial-eec3f6b9 completed after 8 iterations at 2024-08-24 09:12:53. Total running time: 1hr 51min 44s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-eec3f6b9 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          4.38864 â”‚
â”‚ time_total_s                             35.75986 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.58467 â”‚
â”‚ train_loss                                 0.6107 â”‚
â”‚ valid_loss                                1.58502 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=827164)[0m Updating learning rate to 7.551971867910873e-06
[36m(_train_fn pid=827164)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=827164)[0m saving checkpoint...
[36m(_train_fn pid=827164)[0m Epoch: 8 cost time: 3.887070655822754
[36m(_train_fn pid=827164)[0m Epoch: 8, Steps: 122 | Train Loss: 0.6107007 Vali Loss: 1.5850201 Best vali loss: 1.5846674

Trial trial-e384540e started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e384540e config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                55 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.11074 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00225 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=827924)[0m configuration
[36m(_train_fn pid=827924)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 55, 'down_sampling_method': 'avg', 'dropout': 0.11074491370947759, 'e_layers': 2, 'learning_rate': 0.002248868165994266, 'd_ff': 256}
[36m(_train_fn pid=827924)[0m Use GPU: cuda:0
[36m(_train_fn pid=827924)[0m train 7825
[36m(_train_fn pid=827924)[0m val 2161
[36m(_train_fn pid=827924)[0m start_epoch 0
[36m(_train_fn pid=827924)[0m max_epoch 8
[36m(_train_fn pid=827924)[0m 	iters: 100, epoch: 1 | loss: 0.7703130
[36m(_train_fn pid=827924)[0m 	speed: 0.0193s/iter; left time: 35.7230s
[36m(_train_fn pid=827924)[0m 	iters: 200, epoch: 1 | loss: 0.7613679
[36m(_train_fn pid=827924)[0m 	speed: 0.0142s/iter; left time: 24.8484s
[36m(_train_fn pid=827924)[0m Updating learning rate to 0.002248868165994266
[36m(_train_fn pid=827924)[0m saving checkpoint...
[36m(_train_fn pid=827924)[0m Validation loss decreased (inf --> 1.7163).  Saving model state dict ...
[36m(_train_fn pid=827924)[0m Epoch: 1 cost time: 3.7110283374786377
[36m(_train_fn pid=827924)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7644192 Vali Loss: 1.7163329 Best vali loss: 1.7163329
[36m(_train_fn pid=827924)[0m 	iters: 100, epoch: 2 | loss: 0.5849750
[36m(_train_fn pid=827924)[0m 	speed: 0.0257s/iter; left time: 41.3667s
[36m(_train_fn pid=827924)[0m 	iters: 200, epoch: 2 | loss: 0.6392384
[36m(_train_fn pid=827924)[0m 	speed: 0.0142s/iter; left time: 21.4499s
[36m(_train_fn pid=827924)[0m Updating learning rate to 0.001124434082997133
[36m(_train_fn pid=827924)[0m saving checkpoint...
[36m(_train_fn pid=827924)[0m Validation loss decreased (1.7163 --> 1.5944).  Saving model state dict ...
[36m(_train_fn pid=827924)[0m Epoch: 2 cost time: 3.5143163204193115
[36m(_train_fn pid=827924)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6208203 Vali Loss: 1.5943504 Best vali loss: 1.5943504
[36m(_train_fn pid=827924)[0m 	iters: 100, epoch: 3 | loss: 0.5681115
[36m(_train_fn pid=827924)[0m 	speed: 0.0256s/iter; left time: 34.9405s
[36m(_train_fn pid=827924)[0m 	iters: 200, epoch: 3 | loss: 0.5676584
[36m(_train_fn pid=827924)[0m 	speed: 0.0142s/iter; left time: 17.9937s
[36m(_train_fn pid=827924)[0m Updating learning rate to 0.0005622170414985665
[36m(_train_fn pid=827924)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=827924)[0m saving checkpoint...
[36m(_train_fn pid=827924)[0m Epoch: 3 cost time: 3.5024428367614746
[36m(_train_fn pid=827924)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5806653 Vali Loss: 1.6114724 Best vali loss: 1.5943504
[36m(_train_fn pid=827924)[0m 	iters: 100, epoch: 4 | loss: 0.5848411
[36m(_train_fn pid=827924)[0m 	speed: 0.0257s/iter; left time: 28.7913s
[36m(_train_fn pid=827924)[0m 	iters: 200, epoch: 4 | loss: 0.5585639
[36m(_train_fn pid=827924)[0m 	speed: 0.0142s/iter; left time: 14.4695s
[36m(_train_fn pid=827924)[0m Updating learning rate to 0.00028110852074928323
[36m(_train_fn pid=827924)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=827924)[0m saving checkpoint...
[36m(_train_fn pid=827924)[0m Epoch: 4 cost time: 3.508375883102417
[36m(_train_fn pid=827924)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5584218 Vali Loss: 1.6378977 Best vali loss: 1.5943504
[36m(_train_fn pid=827924)[0m 	iters: 100, epoch: 5 | loss: 0.6236274
[36m(_train_fn pid=827924)[0m 	speed: 0.0256s/iter; left time: 22.4883s
2024-08-24 09:13:16,132	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=827924)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e384540e_135_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=55,down_sampling_method=avg,dropout=0_2024-08-24_09-12-53/checkpoint_000004)
2024-08-24 09:13:29,175	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=828429)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9c638090_136_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_09-13-16/checkpoint_000000)
[36m(_train_fn pid=828429)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9c638090_136_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_09-13-16/checkpoint_000001)
[36m(_train_fn pid=828429)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9c638090_136_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_09-13-16/checkpoint_000002)
[36m(_train_fn pid=827924)[0m 	iters: 200, epoch: 5 | loss: 0.5284020
[36m(_train_fn pid=827924)[0m 	speed: 0.0142s/iter; left time: 11.0472s

Trial trial-e384540e completed after 5 iterations at 2024-08-24 09:13:16. Total running time: 1hr 52min 7s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e384540e result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.98241 â”‚
â”‚ time_total_s                             20.52723 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.59435 â”‚
â”‚ train_loss                                0.54679 â”‚
â”‚ valid_loss                                1.62528 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=827924)[0m Updating learning rate to 0.00014055426037464162
[36m(_train_fn pid=827924)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=827924)[0m saving checkpoint...
[36m(_train_fn pid=827924)[0m Epoch: 5 cost time: 3.5089850425720215
[36m(_train_fn pid=827924)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5467937 Vali Loss: 1.6252810 Best vali loss: 1.5943504
[36m(_train_fn pid=827924)[0m Early stopping

Trial trial-9c638090 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-9c638090 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.12339 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00082 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=828429)[0m configuration
[36m(_train_fn pid=828429)[0m {'batch_size': 32, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'avg', 'dropout': 0.12339388960274882, 'e_layers': 4, 'learning_rate': 0.0008177395053746841, 'd_ff': 384}
[36m(_train_fn pid=828429)[0m Use GPU: cuda:0
[36m(_train_fn pid=828429)[0m train 7825
[36m(_train_fn pid=828429)[0m val 2161
[36m(_train_fn pid=828429)[0m start_epoch 0
[36m(_train_fn pid=828429)[0m max_epoch 8

Trial status: 135 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:13:19. Total running time: 1hr 52min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-9c638090   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
130 more TERMINATED
[36m(_train_fn pid=828429)[0m 	iters: 100, epoch: 1 | loss: 0.7995946
[36m(_train_fn pid=828429)[0m 	speed: 0.0410s/iter; left time: 76.0388s
[36m(_train_fn pid=828429)[0m 	iters: 200, epoch: 1 | loss: 0.7588705
[36m(_train_fn pid=828429)[0m 	speed: 0.0362s/iter; left time: 63.4633s
[36m(_train_fn pid=828429)[0m Updating learning rate to 0.0008177395053746841
[36m(_train_fn pid=828429)[0m saving checkpoint...
[36m(_train_fn pid=828429)[0m Validation loss decreased (inf --> 1.9181).  Saving model state dict ...
[36m(_train_fn pid=828429)[0m Epoch: 1 cost time: 9.07132601737976
[36m(_train_fn pid=828429)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7770619 Vali Loss: 1.9181498 Best vali loss: 1.9181498
[36m(_train_fn pid=828429)[0m 	iters: 100, epoch: 2 | loss: 0.6598430
[36m(_train_fn pid=828429)[0m 	speed: 0.0637s/iter; left time: 102.4207s
[36m(_train_fn pid=828429)[0m 	iters: 200, epoch: 2 | loss: 0.5078900
[36m(_train_fn pid=828429)[0m 	speed: 0.0362s/iter; left time: 54.6083s
[36m(_train_fn pid=828429)[0m Updating learning rate to 0.00040886975268734205
[36m(_train_fn pid=828429)[0m saving checkpoint...
[36m(_train_fn pid=828429)[0m Validation loss decreased (1.9181 --> 1.6135).  Saving model state dict ...
[36m(_train_fn pid=828429)[0m Epoch: 2 cost time: 8.865366220474243
[36m(_train_fn pid=828429)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6229711 Vali Loss: 1.6134987 Best vali loss: 1.6134987
[36m(_train_fn pid=828429)[0m 	iters: 100, epoch: 3 | loss: 0.5717744
[36m(_train_fn pid=828429)[0m 	speed: 0.0635s/iter; left time: 86.7400s
[36m(_train_fn pid=828429)[0m 	iters: 200, epoch: 3 | loss: 0.5917853
[36m(_train_fn pid=828429)[0m 	speed: 0.0362s/iter; left time: 45.8435s
[36m(_train_fn pid=828429)[0m Updating learning rate to 0.00020443487634367103
[36m(_train_fn pid=828429)[0m saving checkpoint...
[36m(_train_fn pid=828429)[0m Validation loss decreased (1.6135 --> 1.5802).  Saving model state dict ...
[36m(_train_fn pid=828429)[0m Epoch: 3 cost time: 8.875375986099243
[36m(_train_fn pid=828429)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5796323 Vali Loss: 1.5801858 Best vali loss: 1.5801858
Trial status: 135 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:13:49. Total running time: 1hr 52min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=828429)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9c638090_136_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_09-13-16/checkpoint_000003)
[36m(_train_fn pid=828429)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9c638090_136_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_09-13-16/checkpoint_000004)
[36m(_train_fn pid=828429)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-9c638090_136_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=_2024-08-24_09-13-16/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-9c638090   RUNNING           3            30.5356       0.579632        1.58019             1.58019 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
130 more TERMINATED
[36m(_train_fn pid=828429)[0m 	iters: 100, epoch: 4 | loss: 0.5565819
[36m(_train_fn pid=828429)[0m 	speed: 0.0637s/iter; left time: 71.3640s
[36m(_train_fn pid=828429)[0m 	iters: 200, epoch: 4 | loss: 0.5596950
[36m(_train_fn pid=828429)[0m 	speed: 0.0363s/iter; left time: 37.0390s
[36m(_train_fn pid=828429)[0m Updating learning rate to 0.00010221743817183551
[36m(_train_fn pid=828429)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=828429)[0m saving checkpoint...
[36m(_train_fn pid=828429)[0m Epoch: 4 cost time: 8.884519338607788
[36m(_train_fn pid=828429)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5622577 Vali Loss: 1.5960404 Best vali loss: 1.5801858
[36m(_train_fn pid=828429)[0m 	iters: 100, epoch: 5 | loss: 0.5702143
[36m(_train_fn pid=828429)[0m 	speed: 0.0635s/iter; left time: 55.6981s
[36m(_train_fn pid=828429)[0m 	iters: 200, epoch: 5 | loss: 0.5858955
[36m(_train_fn pid=828429)[0m 	speed: 0.0362s/iter; left time: 28.1644s
[36m(_train_fn pid=828429)[0m Updating learning rate to 5.1108719085917756e-05
[36m(_train_fn pid=828429)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=828429)[0m saving checkpoint...
[36m(_train_fn pid=828429)[0m Epoch: 5 cost time: 8.888919115066528
[36m(_train_fn pid=828429)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5501121 Vali Loss: 1.6200172 Best vali loss: 1.5801858
[36m(_train_fn pid=828429)[0m 	iters: 100, epoch: 6 | loss: 0.5474892
[36m(_train_fn pid=828429)[0m 	speed: 0.0637s/iter; left time: 40.3440s
[36m(_train_fn pid=828429)[0m 	iters: 200, epoch: 6 | loss: 0.4725907
[36m(_train_fn pid=828429)[0m 	speed: 0.0363s/iter; left time: 19.3511s

Trial trial-9c638090 completed after 6 iterations at 2024-08-24 09:14:19. Total running time: 1hr 53min 10s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-9c638090 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         10.00374 â”‚
â”‚ time_total_s                             60.50534 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.58019 â”‚
â”‚ train_loss                                0.54258 â”‚
â”‚ valid_loss                                1.62863 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=828429)[0m Updating learning rate to 2.5554359542958878e-05
[36m(_train_fn pid=828429)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=828429)[0m saving checkpoint...
[36m(_train_fn pid=828429)[0m Epoch: 6 cost time: 8.902743577957153
[36m(_train_fn pid=828429)[0m Epoch: 6, Steps: 244 | Train Loss: 0.5425760 Vali Loss: 1.6286346 Best vali loss: 1.5801858
[36m(_train_fn pid=828429)[0m Early stopping

Trial status: 136 TERMINATED | 1 PENDING
Current time: 2024-08-24 09:14:20. Total running time: 1hr 53min 11s
Logical resource usage: 0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-e3a8ea16   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
131 more TERMINATED

Trial trial-e3a8ea16 started with configuration:
[36m(_train_fn pid=829125)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e3a8ea16_137_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_09-14-19/checkpoint_000000)
[36m(_train_fn pid=829125)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e3a8ea16_137_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_09-14-19/checkpoint_000001)
[36m(_train_fn pid=829125)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e3a8ea16_137_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_09-14-19/checkpoint_000002)
[36m(_train_fn pid=829125)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e3a8ea16_137_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_09-14-19/checkpoint_000003)
[36m(_train_fn pid=829125)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e3a8ea16_137_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_09-14-19/checkpoint_000004)
[36m(_train_fn pid=829125)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e3a8ea16_137_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_09-14-19/checkpoint_000005)
[36m(_train_fn pid=829125)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e3a8ea16_137_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_09-14-19/checkpoint_000006)
[36m(_train_fn pid=829125)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e3a8ea16_137_alpha_d_ff=4,batch_size=128,d_model=128,decomp_method=moving_avg,moving_avg=75,down_sampling_method=avg,dropout_2024-08-24_09-14-19/checkpoint_000007)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e3a8ea16 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.0893 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00471 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=829125)[0m configuration
[36m(_train_fn pid=829125)[0m {'batch_size': 128, 'd_model': 128, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'avg', 'dropout': 0.08930173092761647, 'e_layers': 2, 'learning_rate': 0.0047061232382614206, 'd_ff': 512}
[36m(_train_fn pid=829125)[0m Use GPU: cuda:0
[36m(_train_fn pid=829125)[0m train 7825
[36m(_train_fn pid=829125)[0m val 2161
[36m(_train_fn pid=829125)[0m start_epoch 0
[36m(_train_fn pid=829125)[0m max_epoch 8
[36m(_train_fn pid=829125)[0m Validation loss decreased (inf --> 2.0174).  Saving model state dict ...
[36m(_train_fn pid=829125)[0m Updating learning rate to 0.0047061232382614206
[36m(_train_fn pid=829125)[0m saving checkpoint...
[36m(_train_fn pid=829125)[0m Epoch: 1 cost time: 6.226150274276733
[36m(_train_fn pid=829125)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8804432 Vali Loss: 2.0173705 Best vali loss: 2.0173705
[36m(_train_fn pid=829125)[0m Updating learning rate to 0.0023530616191307103
[36m(_train_fn pid=829125)[0m saving checkpoint...
[36m(_train_fn pid=829125)[0m Validation loss decreased (2.0174 --> 1.6496).  Saving model state dict ...
[36m(_train_fn pid=829125)[0m Epoch: 2 cost time: 6.043345928192139
[36m(_train_fn pid=829125)[0m Epoch: 2, Steps: 61 | Train Loss: 0.8336451 Vali Loss: 1.6495710 Best vali loss: 1.6495710
[36m(_train_fn pid=829125)[0m Updating learning rate to 0.0011765308095653551
[36m(_train_fn pid=829125)[0m saving checkpoint...
[36m(_train_fn pid=829125)[0m Validation loss decreased (1.6496 --> 1.6072).  Saving model state dict ...
[36m(_train_fn pid=829125)[0m Epoch: 3 cost time: 6.043484210968018
[36m(_train_fn pid=829125)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6281426 Vali Loss: 1.6072128 Best vali loss: 1.6072128
[36m(_train_fn pid=829125)[0m Updating learning rate to 0.0005882654047826776
[36m(_train_fn pid=829125)[0m saving checkpoint...
[36m(_train_fn pid=829125)[0m Validation loss decreased (1.6072 --> 1.6022).  Saving model state dict ...
[36m(_train_fn pid=829125)[0m Epoch: 4 cost time: 6.03275990486145
[36m(_train_fn pid=829125)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6145017 Vali Loss: 1.6021941 Best vali loss: 1.6021941

Trial status: 136 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:14:50. Total running time: 1hr 53min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e3a8ea16   RUNNING           4            27.6019       0.614502        1.60219             1.60219 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
131 more TERMINATED
[36m(_train_fn pid=829125)[0m Updating learning rate to 0.0002941327023913388
[36m(_train_fn pid=829125)[0m saving checkpoint...
[36m(_train_fn pid=829125)[0m Validation loss decreased (1.6022 --> 1.5996).  Saving model state dict ...
[36m(_train_fn pid=829125)[0m Epoch: 5 cost time: 6.073253154754639
[36m(_train_fn pid=829125)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6099530 Vali Loss: 1.5996118 Best vali loss: 1.5996118
[36m(_train_fn pid=829125)[0m Updating learning rate to 0.0001470663511956694
[36m(_train_fn pid=829125)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=829125)[0m saving checkpoint...
[36m(_train_fn pid=829125)[0m Epoch: 6 cost time: 6.046094655990601
[36m(_train_fn pid=829125)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6075948 Vali Loss: 1.6004520 Best vali loss: 1.5996118
[36m(_train_fn pid=829125)[0m Updating learning rate to 7.35331755978347e-05
[36m(_train_fn pid=829125)[0m saving checkpoint...
[36m(_train_fn pid=829125)[0m Validation loss decreased (1.5996 --> 1.5992).  Saving model state dict ...
[36m(_train_fn pid=829125)[0m Epoch: 7 cost time: 6.049436092376709
[36m(_train_fn pid=829125)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6062671 Vali Loss: 1.5992489 Best vali loss: 1.5992489

Trial trial-e3a8ea16 completed after 8 iterations at 2024-08-24 09:15:16. Total running time: 1hr 54min 7s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e3a8ea16 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          6.74552 â”‚
â”‚ time_total_s                             54.65401 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.59925 â”‚
â”‚ train_loss                                 0.6058 â”‚
â”‚ valid_loss                                1.59941 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=829125)[0m Updating learning rate to 3.676658779891735e-05
[36m(_train_fn pid=829125)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=829125)[0m saving checkpoint...
[36m(_train_fn pid=829125)[0m Epoch: 8 cost time: 6.0461626052856445
[36m(_train_fn pid=829125)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6058007 Vali Loss: 1.5994138 Best vali loss: 1.5992489

[36m(_train_fn pid=829939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d010648f_138_alpha_d_ff=3,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0568,e_laye_2024-08-24_09-15-16/checkpoint_000000)
[36m(_train_fn pid=829939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d010648f_138_alpha_d_ff=3,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0568,e_laye_2024-08-24_09-15-16/checkpoint_000001)
[36m(_train_fn pid=829939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d010648f_138_alpha_d_ff=3,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0568,e_laye_2024-08-24_09-15-16/checkpoint_000002)
[36m(_train_fn pid=829939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d010648f_138_alpha_d_ff=3,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0568,e_laye_2024-08-24_09-15-16/checkpoint_000003)
[36m(_train_fn pid=829939)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d010648f_138_alpha_d_ff=3,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0568,e_laye_2024-08-24_09-15-16/checkpoint_000004)
Trial trial-d010648f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d010648f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.05677 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00343 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=829939)[0m configuration
[36m(_train_fn pid=829939)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.05676790158723136, 'e_layers': 4, 'learning_rate': 0.003431485440152817, 'd_ff': 192}
[36m(_train_fn pid=829939)[0m Use GPU: cuda:0
[36m(_train_fn pid=829939)[0m train 7825
[36m(_train_fn pid=829939)[0m val 2161
[36m(_train_fn pid=829939)[0m start_epoch 0
[36m(_train_fn pid=829939)[0m max_epoch 8

Trial status: 137 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:15:20. Total running time: 1hr 54min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d010648f   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
132 more TERMINATED
[36m(_train_fn pid=829939)[0m Validation loss decreased (inf --> 1.9796).  Saving model state dict ...
[36m(_train_fn pid=829939)[0m Epoch: 1 cost time: 4.847224950790405
[36m(_train_fn pid=829939)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8135492 Vali Loss: 1.9795693 Best vali loss: 1.9795693
[36m(_train_fn pid=829939)[0m Updating learning rate to 0.003431485440152817
[36m(_train_fn pid=829939)[0m saving checkpoint...
[36m(_train_fn pid=829939)[0m Updating learning rate to 0.0017157427200764086
[36m(_train_fn pid=829939)[0m saving checkpoint...
[36m(_train_fn pid=829939)[0m Validation loss decreased (1.9796 --> 1.6110).  Saving model state dict ...
[36m(_train_fn pid=829939)[0m Epoch: 2 cost time: 4.429767847061157
[36m(_train_fn pid=829939)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6578093 Vali Loss: 1.6110258 Best vali loss: 1.6110258
[36m(_train_fn pid=829939)[0m Updating learning rate to 0.0008578713600382043
[36m(_train_fn pid=829939)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=829939)[0m saving checkpoint...
[36m(_train_fn pid=829939)[0m Epoch: 3 cost time: 4.431419134140015
[36m(_train_fn pid=829939)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6076711 Vali Loss: 1.6118269 Best vali loss: 1.6110258
[36m(_train_fn pid=829939)[0m Updating learning rate to 0.00042893568001910214
[36m(_train_fn pid=829939)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=829939)[0m saving checkpoint...
[36m(_train_fn pid=829939)[0m Epoch: 4 cost time: 4.438271999359131
[36m(_train_fn pid=829939)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5916268 Vali Loss: 1.6524892 Best vali loss: 1.6110258

Trial trial-d010648f completed after 5 iterations at 2024-08-24 09:15:44. Total running time: 1hr 54min 36s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d010648f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          5.11888 â”‚
â”‚ time_total_s                             26.39029 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.61103 â”‚
â”‚ train_loss                                0.57777 â”‚
â”‚ valid_loss                                1.65521 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=829939)[0m Updating learning rate to 0.00021446784000955107
[36m(_train_fn pid=829939)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=829939)[0m saving checkpoint...
[36m(_train_fn pid=829939)[0m Epoch: 5 cost time: 4.436962842941284
[36m(_train_fn pid=829939)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5777722 Vali Loss: 1.6552135 Best vali loss: 1.6110258
[36m(_train_fn pid=829939)[0m Early stopping

Trial trial-02531bea started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-02531bea config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                35 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.0631 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00223 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=830460)[0m configuration
[36m(_train_fn pid=830460)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 35, 'down_sampling_method': 'avg', 'dropout': 0.06309906398176497, 'e_layers': 1, 'learning_rate': 0.0022306068381035414, 'd_ff': 128}
[36m(_train_fn pid=830460)[0m Use GPU: cuda:0
2024-08-24 09:15:49,226	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=830460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02531bea_139_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-15-44/checkpoint_000000)
2024-08-24 09:15:51,285	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=830460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02531bea_139_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-15-44/checkpoint_000001)
2024-08-24 09:15:53,351	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=830460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02531bea_139_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-15-44/checkpoint_000002)
[36m(_train_fn pid=830460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02531bea_139_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-15-44/checkpoint_000003)
2024-08-24 09:15:55,408	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:15:57,464	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=830460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02531bea_139_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-15-44/checkpoint_000004)
2024-08-24 09:15:59,528	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=830460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02531bea_139_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-15-44/checkpoint_000005)
2024-08-24 09:16:01,590	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=830460)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02531bea_139_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=35,down_sampling_method=avg,dropout=_2024-08-24_09-15-44/checkpoint_000006)
2024-08-24 09:16:05,375	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=831089)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0185ffd0_140_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-16-01/checkpoint_000000)
2024-08-24 09:16:06,548	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=830460)[0m train 7825
[36m(_train_fn pid=830460)[0m val 2161
[36m(_train_fn pid=830460)[0m start_epoch 0
[36m(_train_fn pid=830460)[0m max_epoch 8
[36m(_train_fn pid=830460)[0m Updating learning rate to 0.0022306068381035414
[36m(_train_fn pid=830460)[0m saving checkpoint...
[36m(_train_fn pid=830460)[0m Validation loss decreased (inf --> 2.1152).  Saving model state dict ...

Trial status: 138 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:15:50. Total running time: 1hr 54min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-02531bea   RUNNING           1            2.65115       0.948243        2.1152              2.1152  â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
133 more TERMINATED
[36m(_train_fn pid=830460)[0m Updating learning rate to 0.0011153034190517707
[36m(_train_fn pid=830460)[0m saving checkpoint...
[36m(_train_fn pid=830460)[0m Validation loss decreased (2.1152 --> 1.6397).  Saving model state dict ...
[36m(_train_fn pid=830460)[0m Epoch: 2 cost time: 1.7843883037567139[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=830460)[0m Epoch: 2, Steps: 61 | Train Loss: 0.7111647 Vali Loss: 1.6396742 Best vali loss: 1.6396742[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=830460)[0m Updating learning rate to 0.0005576517095258854
[36m(_train_fn pid=830460)[0m saving checkpoint...
[36m(_train_fn pid=830460)[0m Validation loss decreased (1.6397 --> 1.6074).  Saving model state dict ...
[36m(_train_fn pid=830460)[0m Updating learning rate to 0.0002788258547629427
[36m(_train_fn pid=830460)[0m saving checkpoint...
[36m(_train_fn pid=830460)[0m Validation loss decreased (1.6074 --> 1.5994).  Saving model state dict ...
[36m(_train_fn pid=830460)[0m Updating learning rate to 0.00013941292738147134
[36m(_train_fn pid=830460)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=830460)[0m saving checkpoint...
[36m(_train_fn pid=830460)[0m Epoch: 5 cost time: 1.7893640995025635[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=830460)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6115941 Vali Loss: 1.6032541 Best vali loss: 1.5993602[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=830460)[0m Updating learning rate to 6.970646369073567e-05
[36m(_train_fn pid=830460)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=830460)[0m saving checkpoint...

Trial trial-02531bea completed after 7 iterations at 2024-08-24 09:16:01. Total running time: 1hr 54min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-02531bea result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          2.05995 â”‚
â”‚ time_total_s                             14.99567 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.59936 â”‚
â”‚ train_loss                                0.60935 â”‚
â”‚ valid_loss                                1.60104 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=830460)[0m Updating learning rate to 3.4853231845367835e-05
[36m(_train_fn pid=830460)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=830460)[0m saving checkpoint...
[36m(_train_fn pid=830460)[0m Early stopping

Trial trial-0185ffd0 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0185ffd0 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                75 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.08695 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                        0.001 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=831089)[0m configuration
[36m(_train_fn pid=831089)[0m {'batch_size': 64, 'd_model': 16, 'decomp_method': 'moving_avg', 'moving_avg': 75, 'down_sampling_method': 'conv', 'dropout': 0.08694753145827783, 'e_layers': 1, 'learning_rate': 0.000999602394238398, 'd_ff': 32}
[36m(_train_fn pid=831089)[0m Use GPU: cuda:0
[36m(_train_fn pid=830460)[0m Epoch: 7 cost time: 1.7936296463012695[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=830460)[0m Epoch: 7, Steps: 61 | Train Loss: 0.6093515 Vali Loss: 1.6010430 Best vali loss: 1.5993602[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=831089)[0m train 7825
[36m(_train_fn pid=831089)[0m val 2161
[36m(_train_fn pid=831089)[0m start_epoch 0
[36m(_train_fn pid=831089)[0m max_epoch 8
[36m(_train_fn pid=831089)[0m 	iters: 100, epoch: 1 | loss: 0.9412295
[36m(_train_fn pid=831089)[0m 	speed: 0.0131s/iter; left time: 11.4472s
[36m(_train_fn pid=831089)[0m Updating learning rate to 0.000999602394238398
[36m(_train_fn pid=831089)[0m saving checkpoint...
[36m(_train_fn pid=831089)[0m Validation loss decreased (inf --> 2.1757).  Saving model state dict ...
[36m(_train_fn pid=831089)[0m 	iters: 100, epoch: 2 | loss: 0.7234465
[36m(_train_fn pid=831089)[0m 	speed: 0.0118s/iter; left time: 8.8743s
[36m(_train_fn pid=831089)[0m Updating learning rate to 0.000499801197119199
[36m(_train_fn pid=831089)[0m saving checkpoint...
[36m(_train_fn pid=831089)[0m Validation loss decreased (2.1757 --> 1.6233).  Saving model state dict ...
[36m(_train_fn pid=831089)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0185ffd0_140_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-16-01/checkpoint_000001)
2024-08-24 09:16:07,683	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=831089)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0185ffd0_140_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-16-01/checkpoint_000002)
2024-08-24 09:16:08,814	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=831089)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0185ffd0_140_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-16-01/checkpoint_000003)
[36m(_train_fn pid=831089)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0185ffd0_140_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-16-01/checkpoint_000004)
2024-08-24 09:16:09,987	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:16:11,138	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=831089)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0185ffd0_140_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-16-01/checkpoint_000005)
2024-08-24 09:16:12,320	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=831089)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0185ffd0_140_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-16-01/checkpoint_000006)
2024-08-24 09:16:13,507	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=831089)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0185ffd0_140_alpha_d_ff=2,batch_size=64,d_model=16,decomp_method=moving_avg,moving_avg=75,down_sampling_method=conv,dropout=_2024-08-24_09-16-01/checkpoint_000007)
2024-08-24 09:16:17,941	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:16:19,436	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=831774)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-40735eca_141_alpha_d_ff=3,batch_size=64,d_model=32,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0778,e_layer_2024-08-24_09-16-13/checkpoint_000001)[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=831089)[0m 	iters: 100, epoch: 3 | loss: 0.5555531
[36m(_train_fn pid=831089)[0m 	speed: 0.0114s/iter; left time: 7.2011s
[36m(_train_fn pid=831089)[0m Updating learning rate to 0.0002499005985595995
[36m(_train_fn pid=831089)[0m saving checkpoint...
[36m(_train_fn pid=831089)[0m Validation loss decreased (1.6233 --> 1.5958).  Saving model state dict ...
[36m(_train_fn pid=831089)[0m 	iters: 100, epoch: 4 | loss: 0.6278774
[36m(_train_fn pid=831089)[0m 	speed: 0.0114s/iter; left time: 5.8150s
[36m(_train_fn pid=831089)[0m Updating learning rate to 0.00012495029927979976
[36m(_train_fn pid=831089)[0m saving checkpoint...
[36m(_train_fn pid=831089)[0m Validation loss decreased (1.5958 --> 1.5899).  Saving model state dict ...
[36m(_train_fn pid=831089)[0m Epoch: 4 cost time: 0.9573676586151123[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=831089)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6263402 Vali Loss: 1.5899309 Best vali loss: 1.5899309[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=831089)[0m 	iters: 100, epoch: 5 | loss: 0.5862676
[36m(_train_fn pid=831089)[0m 	speed: 0.0117s/iter; left time: 4.5702s
[36m(_train_fn pid=831089)[0m Updating learning rate to 6.247514963989988e-05
[36m(_train_fn pid=831089)[0m saving checkpoint...
[36m(_train_fn pid=831089)[0m Validation loss decreased (1.5899 --> 1.5873).  Saving model state dict ...
[36m(_train_fn pid=831089)[0m 	iters: 100, epoch: 6 | loss: 0.6768955
[36m(_train_fn pid=831089)[0m 	speed: 0.0115s/iter; left time: 3.0750s
[36m(_train_fn pid=831089)[0m Updating learning rate to 3.123757481994994e-05
[36m(_train_fn pid=831089)[0m saving checkpoint...
[36m(_train_fn pid=831089)[0m Validation loss decreased (1.5873 --> 1.5863).  Saving model state dict ...
[36m(_train_fn pid=831089)[0m 	iters: 100, epoch: 7 | loss: 0.5710495
[36m(_train_fn pid=831089)[0m 	speed: 0.0117s/iter; left time: 1.6986s
[36m(_train_fn pid=831089)[0m Updating learning rate to 1.561878740997497e-05
[36m(_train_fn pid=831089)[0m saving checkpoint...
[36m(_train_fn pid=831089)[0m Validation loss decreased (1.5863 --> 1.5861).  Saving model state dict ...
[36m(_train_fn pid=831089)[0m 	iters: 100, epoch: 8 | loss: 0.5382354
[36m(_train_fn pid=831089)[0m 	speed: 0.0120s/iter; left time: 0.2761s

Trial trial-0185ffd0 completed after 8 iterations at 2024-08-24 09:16:13. Total running time: 1hr 55min 4s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0185ffd0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          1.18415 â”‚
â”‚ time_total_s                              9.91619 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.58605 â”‚
â”‚ train_loss                                0.61827 â”‚
â”‚ valid_loss                                1.58605 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=831089)[0m Updating learning rate to 7.809393704987485e-06
[36m(_train_fn pid=831089)[0m saving checkpoint...
[36m(_train_fn pid=831089)[0m Validation loss decreased (1.5861 --> 1.5861).  Saving model state dict ...

Trial trial-40735eca started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-40735eca config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.07781 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.01151 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=831774)[0m configuration
[36m(_train_fn pid=831774)[0m {'batch_size': 64, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.07780912269185028, 'e_layers': 1, 'learning_rate': 0.011512329826639377, 'd_ff': 96}
[36m(_train_fn pid=831089)[0m Epoch: 8 cost time: 1.0036556720733643[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=831089)[0m Epoch: 8, Steps: 122 | Train Loss: 0.6182695 Vali Loss: 1.5860512 Best vali loss: 1.5860512[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=831774)[0m Use GPU: cuda:0
[36m(_train_fn pid=831774)[0m train 7825
[36m(_train_fn pid=831774)[0m val 2161
[36m(_train_fn pid=831774)[0m start_epoch 0
[36m(_train_fn pid=831774)[0m max_epoch 8
[36m(_train_fn pid=831774)[0m 	iters: 100, epoch: 1 | loss: 0.7055813
[36m(_train_fn pid=831774)[0m 	speed: 0.0172s/iter; left time: 15.1250s
[36m(_train_fn pid=831774)[0m Updating learning rate to 0.011512329826639377
[36m(_train_fn pid=831774)[0m saving checkpoint...
[36m(_train_fn pid=831774)[0m Validation loss decreased (inf --> 1.6967).  Saving model state dict ...
[36m(_train_fn pid=831774)[0m 	iters: 100, epoch: 2 | loss: 0.6197041
[36m(_train_fn pid=831774)[0m 	speed: 0.0151s/iter; left time: 11.3714s
[36m(_train_fn pid=831774)[0m Updating learning rate to 0.005756164913319688
[36m(_train_fn pid=831774)[0m saving checkpoint...
[36m(_train_fn pid=831774)[0m Validation loss decreased (1.6967 --> 1.5856).  Saving model state dict ...

Trial status: 140 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:16:20. Total running time: 1hr 55min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
2024-08-24 09:16:20,948	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:16:22,443	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:16:23,949	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=832243)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-305c6745_142_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1240,e_layer_2024-08-24_09-16-23/checkpoint_000000)[32m [repeated 4x across cluster][0m
2024-08-24 09:16:32,110	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:16:34,948	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=832243)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-305c6745_142_alpha_d_ff=4,batch_size=32,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.1240,e_layer_2024-08-24_09-16-23/checkpoint_000002)[32m [repeated 2x across cluster][0m
2024-08-24 09:16:37,811	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-40735eca   RUNNING           2            3.84624       0.627087        1.58558             1.58558 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
135 more TERMINATED
[36m(_train_fn pid=831774)[0m 	iters: 100, epoch: 3 | loss: 0.5591105
[36m(_train_fn pid=831774)[0m 	speed: 0.0151s/iter; left time: 9.5824s
[36m(_train_fn pid=831774)[0m Updating learning rate to 0.002878082456659844
[36m(_train_fn pid=831774)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=831774)[0m saving checkpoint...
[36m(_train_fn pid=831774)[0m Epoch: 3 cost time: 1.264857292175293[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=831774)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5872295 Vali Loss: 1.5951611 Best vali loss: 1.5855775[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=831774)[0m 	iters: 100, epoch: 4 | loss: 0.5689898
[36m(_train_fn pid=831774)[0m 	speed: 0.0150s/iter; left time: 7.6792s
[36m(_train_fn pid=831774)[0m Updating learning rate to 0.001439041228329922
[36m(_train_fn pid=831774)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=831774)[0m saving checkpoint...
[36m(_train_fn pid=831774)[0m 	iters: 100, epoch: 5 | loss: 0.5473679
[36m(_train_fn pid=831774)[0m 	speed: 0.0150s/iter; left time: 5.8263s

Trial trial-40735eca completed after 5 iterations at 2024-08-24 09:16:23. Total running time: 1hr 55min 15s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-40735eca result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.50347 â”‚
â”‚ time_total_s                              8.35274 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58558 â”‚
â”‚ train_loss                                0.55773 â”‚
â”‚ valid_loss                                1.61038 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=831774)[0m Updating learning rate to 0.000719520614164961
[36m(_train_fn pid=831774)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=831774)[0m saving checkpoint...
[36m(_train_fn pid=831774)[0m Early stopping

Trial trial-305c6745 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-305c6745 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.12404 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.01013 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=832243)[0m configuration
[36m(_train_fn pid=832243)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.12404059780330347, 'e_layers': 1, 'learning_rate': 0.010134216186564212, 'd_ff': 256}
[36m(_train_fn pid=832243)[0m Use GPU: cuda:0
[36m(_train_fn pid=832243)[0m train 7825
[36m(_train_fn pid=832243)[0m val 2161
[36m(_train_fn pid=832243)[0m start_epoch 0
[36m(_train_fn pid=832243)[0m max_epoch 8
[36m(_train_fn pid=831774)[0m Epoch: 5 cost time: 1.2580196857452393[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=831774)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5577287 Vali Loss: 1.6103828 Best vali loss: 1.5855775[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=832243)[0m Validation loss decreased (inf --> 1.5888).  Saving model state dict ...
[36m(_train_fn pid=832243)[0m 	iters: 200, epoch: 1 | loss: 0.5400021[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=832243)[0m 	speed: 0.0097s/iter; left time: 17.0711s[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=832243)[0m Updating learning rate to 0.010134216186564212
[36m(_train_fn pid=832243)[0m saving checkpoint...
[36m(_train_fn pid=832243)[0m Epoch: 1 cost time: 2.850093126296997
[36m(_train_fn pid=832243)[0m Epoch: 1, Steps: 244 | Train Loss: 0.6861256 Vali Loss: 1.5888157 Best vali loss: 1.5888157
[36m(_train_fn pid=832243)[0m Updating learning rate to 0.005067108093282106
[36m(_train_fn pid=832243)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=832243)[0m saving checkpoint...
[36m(_train_fn pid=832243)[0m Epoch: 2 cost time: 2.4502413272857666
[36m(_train_fn pid=832243)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6142905 Vali Loss: 1.5927423 Best vali loss: 1.5888157
[36m(_train_fn pid=832243)[0m Updating learning rate to 0.002533554046641053
[36m(_train_fn pid=832243)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=832243)[0m saving checkpoint...
[36m(_train_fn pid=832243)[0m Epoch: 3 cost time: 2.431685447692871
[36m(_train_fn pid=832243)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5720557 Vali Loss: 1.6246936 Best vali loss: 1.5888157
[36m(_train_fn pid=832243)[0m 	iters: 200, epoch: 3 | loss: 0.5747803[32m [repeated 4x across cluster][0m
[36m(_train_fn pid=832243)[0m 	speed: 0.0098s/iter; left time: 12.3363s[32m [repeated 4x across cluster][0m

Trial trial-305c6745 completed after 4 iterations at 2024-08-24 09:16:37. Total running time: 1hr 55min 29s
[36m(_train_fn pid=832650)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d59398b_143_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_09-16-37/checkpoint_000000)[32m [repeated 2x across cluster][0m
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-305c6745 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                          2.85676 â”‚
â”‚ time_total_s                             12.20627 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.58882 â”‚
â”‚ train_loss                                 0.5414 â”‚
â”‚ valid_loss                                1.63593 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=832243)[0m Updating learning rate to 0.0012667770233205265
[36m(_train_fn pid=832243)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=832243)[0m saving checkpoint...
[36m(_train_fn pid=832243)[0m Epoch: 4 cost time: 2.4522387981414795
[36m(_train_fn pid=832243)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5413990 Vali Loss: 1.6359269 Best vali loss: 1.5888157
[36m(_train_fn pid=832243)[0m Early stopping

Trial trial-7d59398b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7d59398b config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                25 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09109 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00149 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=832650)[0m configuration
[36m(_train_fn pid=832650)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'moving_avg', 'moving_avg': 25, 'down_sampling_method': 'avg', 'dropout': 0.0910873549920449, 'e_layers': 2, 'learning_rate': 0.0014939974901912877, 'd_ff': 1024}
[36m(_train_fn pid=832650)[0m Use GPU: cuda:0
[36m(_train_fn pid=832650)[0m train 7825
[36m(_train_fn pid=832650)[0m val 2161
[36m(_train_fn pid=832650)[0m start_epoch 0
[36m(_train_fn pid=832650)[0m max_epoch 8
[36m(_train_fn pid=832243)[0m 	iters: 200, epoch: 4 | loss: 0.5963848[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=832243)[0m 	speed: 0.0098s/iter; left time: 10.0480s[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=832650)[0m 	iters: 100, epoch: 1 | loss: 0.6630362
[36m(_train_fn pid=832650)[0m 	speed: 0.1000s/iter; left time: 185.2383s

Trial status: 142 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:16:50. Total running time: 1hr 55min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7d59398b   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
137 more TERMINATED
[36m(_train_fn pid=832650)[0m 	iters: 200, epoch: 1 | loss: 0.7242191
[36m(_train_fn pid=832650)[0m 	speed: 0.0957s/iter; left time: 167.7143s
[36m(_train_fn pid=832650)[0m Updating learning rate to 0.0014939974901912877
[36m(_train_fn pid=832650)[0m saving checkpoint...
[36m(_train_fn pid=832650)[0m Validation loss decreased (inf --> 1.8199).  Saving model state dict ...
[36m(_train_fn pid=832650)[0m Epoch: 1 cost time: 23.52167248725891
[36m(_train_fn pid=832650)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7784179 Vali Loss: 1.8198809 Best vali loss: 1.8198809
[36m(_train_fn pid=832650)[0m 	iters: 100, epoch: 2 | loss: 0.5730485
[36m(_train_fn pid=832650)[0m 	speed: 0.1656s/iter; left time: 266.3750s
Trial status: 142 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:17:20. Total running time: 1hr 56min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=832650)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d59398b_143_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_09-16-37/checkpoint_000001)
[36m(_train_fn pid=832650)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d59398b_143_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_09-16-37/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7d59398b   RUNNING           1            26.7099       0.778418        1.81988             1.81988 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
137 more TERMINATED
[36m(_train_fn pid=832650)[0m 	iters: 200, epoch: 2 | loss: 0.6976127
[36m(_train_fn pid=832650)[0m 	speed: 0.0955s/iter; left time: 144.1616s
[36m(_train_fn pid=832650)[0m Updating learning rate to 0.0007469987450956438
[36m(_train_fn pid=832650)[0m saving checkpoint...
[36m(_train_fn pid=832650)[0m Validation loss decreased (1.8199 --> 1.5789).  Saving model state dict ...
[36m(_train_fn pid=832650)[0m Epoch: 2 cost time: 23.32051420211792
[36m(_train_fn pid=832650)[0m Epoch: 2, Steps: 244 | Train Loss: 0.8005869 Vali Loss: 1.5789375 Best vali loss: 1.5789375
[36m(_train_fn pid=832650)[0m 	iters: 100, epoch: 3 | loss: 0.5129089
[36m(_train_fn pid=832650)[0m 	speed: 0.1654s/iter; left time: 225.7447s
Trial status: 142 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:17:50. Total running time: 1hr 56min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7d59398b   RUNNING           2            52.7969       0.800587        1.57894             1.57894 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
137 more TERMINATED
[36m(_train_fn pid=832650)[0m 	iters: 200, epoch: 3 | loss: 0.5185629
[36m(_train_fn pid=832650)[0m 	speed: 0.0958s/iter; left time: 121.1717s
[36m(_train_fn pid=832650)[0m Updating learning rate to 0.0003734993725478219
[36m(_train_fn pid=832650)[0m saving checkpoint...
[36m(_train_fn pid=832650)[0m Validation loss decreased (1.5789 --> 1.5729).  Saving model state dict ...
[36m(_train_fn pid=832650)[0m Epoch: 3 cost time: 23.355759859085083
[36m(_train_fn pid=832650)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6161849 Vali Loss: 1.5729422 Best vali loss: 1.5729422
[36m(_train_fn pid=832650)[0m 	iters: 100, epoch: 4 | loss: 0.5754029
[36m(_train_fn pid=832650)[0m 	speed: 0.1655s/iter; left time: 185.5407s
[36m(_train_fn pid=832650)[0m 	iters: 200, epoch: 4 | loss: 0.6213784
[36m(_train_fn pid=832650)[0m 	speed: 0.0959s/iter; left time: 97.8693s
Trial status: 142 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:18:20. Total running time: 1hr 57min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7d59398b   RUNNING           3            78.9232       0.616185        1.57294             1.57294 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
137 more TERMINATED

Trial trial-7d59398b completed after 4 iterations at 2024-08-24 09:18:24. Total running time: 1hr 57min 15s
[36m(_train_fn pid=832650)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7d59398b_143_alpha_d_ff=2,batch_size=32,d_model=512,decomp_method=moving_avg,moving_avg=25,down_sampling_method=avg,dropout=_2024-08-24_09-16-37/checkpoint_000003)
2024-08-24 09:18:29,475	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833338)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-97342513_144_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0758,e_layers=_2024-08-24_09-18-24/checkpoint_000000)
2024-08-24 09:18:31,552	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833338)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-97342513_144_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0758,e_layers=_2024-08-24_09-18-24/checkpoint_000001)
2024-08-24 09:18:33,667	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833338)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-97342513_144_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0758,e_layers=_2024-08-24_09-18-24/checkpoint_000002)
2024-08-24 09:18:35,754	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833338)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-97342513_144_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0758,e_layers=_2024-08-24_09-18-24/checkpoint_000003)
2024-08-24 09:18:37,849	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833338)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-97342513_144_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0758,e_layers=_2024-08-24_09-18-24/checkpoint_000004)
2024-08-24 09:18:39,835	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833338)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-97342513_144_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0758,e_layers=_2024-08-24_09-18-24/checkpoint_000005)
2024-08-24 09:18:41,795	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833338)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-97342513_144_alpha_d_ff=2,batch_size=64,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0758,e_layers=_2024-08-24_09-18-24/checkpoint_000006)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7d59398b result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         26.12495 â”‚
â”‚ time_total_s                            105.04813 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.56937 â”‚
â”‚ train_loss                                0.61163 â”‚
â”‚ valid_loss                                1.56937 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=832650)[0m Updating learning rate to 0.00018674968627391096
[36m(_train_fn pid=832650)[0m saving checkpoint...
[36m(_train_fn pid=832650)[0m Validation loss decreased (1.5729 --> 1.5694).  Saving model state dict ...

Trial trial-97342513 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-97342513 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.07577 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00175 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=833338)[0m configuration
[36m(_train_fn pid=833338)[0m {'batch_size': 64, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.0757679081183352, 'e_layers': 4, 'learning_rate': 0.0017464485717382588, 'd_ff': 16}
[36m(_train_fn pid=833338)[0m Use GPU: cuda:0
[36m(_train_fn pid=833338)[0m train 7825
[36m(_train_fn pid=833338)[0m val 2161
[36m(_train_fn pid=833338)[0m start_epoch 0
[36m(_train_fn pid=833338)[0m max_epoch 8
[36m(_train_fn pid=833338)[0m 	iters: 100, epoch: 1 | loss: 1.1439756
[36m(_train_fn pid=833338)[0m 	speed: 0.0214s/iter; left time: 18.7490s
[36m(_train_fn pid=833338)[0m Validation loss decreased (inf --> 2.4751).  Saving model state dict ...
[36m(_train_fn pid=833338)[0m Epoch: 1 cost time: 2.1960363388061523
[36m(_train_fn pid=833338)[0m Epoch: 1, Steps: 122 | Train Loss: 1.3002489 Vali Loss: 2.4750660 Best vali loss: 2.4750660
[36m(_train_fn pid=833338)[0m 	iters: 100, epoch: 2 | loss: 0.6321979
[36m(_train_fn pid=833338)[0m 	speed: 0.0208s/iter; left time: 15.6833s
[36m(_train_fn pid=833338)[0m Updating learning rate to 0.0017464485717382588
[36m(_train_fn pid=833338)[0m saving checkpoint...
[36m(_train_fn pid=833338)[0m Updating learning rate to 0.0008732242858691294
[36m(_train_fn pid=833338)[0m saving checkpoint...
[36m(_train_fn pid=833338)[0m Validation loss decreased (2.4751 --> 1.6133).  Saving model state dict ...
[36m(_train_fn pid=833338)[0m Epoch: 2 cost time: 1.7983999252319336
[36m(_train_fn pid=833338)[0m Epoch: 2, Steps: 122 | Train Loss: 0.7312007 Vali Loss: 1.6133150 Best vali loss: 1.6133150
[36m(_train_fn pid=833338)[0m 	iters: 100, epoch: 3 | loss: 0.5994480
[36m(_train_fn pid=833338)[0m 	speed: 0.0210s/iter; left time: 13.2838s
[36m(_train_fn pid=833338)[0m Updating learning rate to 0.0004366121429345647
[36m(_train_fn pid=833338)[0m saving checkpoint...
[36m(_train_fn pid=833338)[0m Validation loss decreased (1.6133 --> 1.5919).  Saving model state dict ...
[36m(_train_fn pid=833338)[0m Epoch: 3 cost time: 1.8125224113464355
[36m(_train_fn pid=833338)[0m Epoch: 3, Steps: 122 | Train Loss: 0.6234478 Vali Loss: 1.5919120 Best vali loss: 1.5919120
[36m(_train_fn pid=833338)[0m 	iters: 100, epoch: 4 | loss: 0.6570309
[36m(_train_fn pid=833338)[0m 	speed: 0.0210s/iter; left time: 10.7396s
[36m(_train_fn pid=833338)[0m Updating learning rate to 0.00021830607146728235
[36m(_train_fn pid=833338)[0m saving checkpoint...
[36m(_train_fn pid=833338)[0m Validation loss decreased (1.5919 --> 1.5895).  Saving model state dict ...
[36m(_train_fn pid=833338)[0m Epoch: 4 cost time: 1.8076486587524414
[36m(_train_fn pid=833338)[0m Epoch: 4, Steps: 122 | Train Loss: 0.6119272 Vali Loss: 1.5894710 Best vali loss: 1.5894710
[36m(_train_fn pid=833338)[0m 	iters: 100, epoch: 5 | loss: 0.5903873
[36m(_train_fn pid=833338)[0m 	speed: 0.0209s/iter; left time: 8.1257s
[36m(_train_fn pid=833338)[0m Updating learning rate to 0.00010915303573364117
[36m(_train_fn pid=833338)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=833338)[0m saving checkpoint...
[36m(_train_fn pid=833338)[0m Epoch: 5 cost time: 1.7990188598632812
[36m(_train_fn pid=833338)[0m Epoch: 5, Steps: 122 | Train Loss: 0.6077249 Vali Loss: 1.5908116 Best vali loss: 1.5894710
[36m(_train_fn pid=833338)[0m 	iters: 100, epoch: 6 | loss: 0.6081273
[36m(_train_fn pid=833338)[0m 	speed: 0.0202s/iter; left time: 5.4012s
[36m(_train_fn pid=833338)[0m Updating learning rate to 5.457651786682059e-05
[36m(_train_fn pid=833338)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=833338)[0m saving checkpoint...
[36m(_train_fn pid=833338)[0m Epoch: 6 cost time: 1.7271177768707275
[36m(_train_fn pid=833338)[0m Epoch: 6, Steps: 122 | Train Loss: 0.6052514 Vali Loss: 1.5908536 Best vali loss: 1.5894710
[36m(_train_fn pid=833338)[0m 	iters: 100, epoch: 7 | loss: 0.6336369
[36m(_train_fn pid=833338)[0m 	speed: 0.0197s/iter; left time: 2.8516s

Trial trial-97342513 completed after 7 iterations at 2024-08-24 09:18:41. Total running time: 1hr 57min 33s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-97342513 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          1.95704 â”‚
â”‚ time_total_s                             15.18716 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.58947 â”‚
â”‚ train_loss                                0.60438 â”‚
â”‚ valid_loss                                1.59061 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=833338)[0m Updating learning rate to 2.7288258933410294e-05
[36m(_train_fn pid=833338)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=833338)[0m saving checkpoint...
[36m(_train_fn pid=833338)[0m Epoch: 7 cost time: 1.688004970550537
[36m(_train_fn pid=833338)[0m Epoch: 7, Steps: 122 | Train Loss: 0.6043788 Vali Loss: 1.5906112 Best vali loss: 1.5894710
[36m(_train_fn pid=833338)[0m Early stopping

Trial trial-282fda45 started with configuration:
[36m(_train_fn pid=833967)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-282fda45_145_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_09-18-41/checkpoint_000000)
2024-08-24 09:18:46,422	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:18:48,633	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833967)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-282fda45_145_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_09-18-41/checkpoint_000001)
2024-08-24 09:18:50,829	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833967)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-282fda45_145_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_09-18-41/checkpoint_000002)
2024-08-24 09:18:53,033	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833967)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-282fda45_145_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_09-18-41/checkpoint_000003)
2024-08-24 09:18:55,236	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833967)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-282fda45_145_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_09-18-41/checkpoint_000004)
[36m(_train_fn pid=833967)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-282fda45_145_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_09-18-41/checkpoint_000005)
2024-08-24 09:18:57,449	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:18:59,635	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833967)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-282fda45_145_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_09-18-41/checkpoint_000006)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-282fda45 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                              64 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.14927 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00771 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=833967)[0m configuration
[36m(_train_fn pid=833967)[0m {'batch_size': 64, 'd_model': 32, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'avg', 'dropout': 0.1492737673066615, 'e_layers': 3, 'learning_rate': 0.0077108775495299, 'd_ff': 64}
[36m(_train_fn pid=833967)[0m Use GPU: cuda:0
[36m(_train_fn pid=833967)[0m train 7825
[36m(_train_fn pid=833967)[0m val 2161
[36m(_train_fn pid=833967)[0m start_epoch 0
[36m(_train_fn pid=833967)[0m max_epoch 8
[36m(_train_fn pid=833967)[0m 	iters: 100, epoch: 1 | loss: 0.7751262
[36m(_train_fn pid=833967)[0m 	speed: 0.0205s/iter; left time: 17.9452s
[36m(_train_fn pid=833967)[0m Updating learning rate to 0.0077108775495299
[36m(_train_fn pid=833967)[0m saving checkpoint...
[36m(_train_fn pid=833967)[0m Validation loss decreased (inf --> 1.7392).  Saving model state dict ...
[36m(_train_fn pid=833967)[0m 	iters: 100, epoch: 2 | loss: 0.5531757
[36m(_train_fn pid=833967)[0m 	speed: 0.0221s/iter; left time: 16.7133s
[36m(_train_fn pid=833967)[0m Epoch: 1 cost time: 2.125054359436035
[36m(_train_fn pid=833967)[0m Epoch: 1, Steps: 122 | Train Loss: 0.8317971 Vali Loss: 1.7392049 Best vali loss: 1.7392049
[36m(_train_fn pid=833967)[0m Updating learning rate to 0.00385543877476495
[36m(_train_fn pid=833967)[0m saving checkpoint...
[36m(_train_fn pid=833967)[0m Validation loss decreased (1.7392 --> 1.6110).  Saving model state dict ...
[36m(_train_fn pid=833967)[0m Epoch: 2 cost time: 1.9082906246185303
[36m(_train_fn pid=833967)[0m Epoch: 2, Steps: 122 | Train Loss: 0.6148432 Vali Loss: 1.6109682 Best vali loss: 1.6109682
[36m(_train_fn pid=833967)[0m 	iters: 100, epoch: 3 | loss: 0.4904059
[36m(_train_fn pid=833967)[0m 	speed: 0.0221s/iter; left time: 14.0020s

Trial status: 144 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:18:50. Total running time: 1hr 57min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-282fda45   RUNNING           2            5.03196       0.614843        1.61097             1.61097 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
139 more TERMINATED
[36m(_train_fn pid=833967)[0m Updating learning rate to 0.001927719387382475
[36m(_train_fn pid=833967)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=833967)[0m saving checkpoint...
[36m(_train_fn pid=833967)[0m Epoch: 3 cost time: 1.9081206321716309
[36m(_train_fn pid=833967)[0m Epoch: 3, Steps: 122 | Train Loss: 0.5647250 Vali Loss: 1.6216121 Best vali loss: 1.6109682
[36m(_train_fn pid=833967)[0m 	iters: 100, epoch: 4 | loss: 0.5316824
[36m(_train_fn pid=833967)[0m 	speed: 0.0219s/iter; left time: 11.2108s
[36m(_train_fn pid=833967)[0m Updating learning rate to 0.0009638596936912376
[36m(_train_fn pid=833967)[0m saving checkpoint...
[36m(_train_fn pid=833967)[0m Validation loss decreased (1.6110 --> 1.5941).  Saving model state dict ...
[36m(_train_fn pid=833967)[0m Epoch: 4 cost time: 1.8920588493347168
[36m(_train_fn pid=833967)[0m Epoch: 4, Steps: 122 | Train Loss: 0.5419821 Vali Loss: 1.5940734 Best vali loss: 1.5940734
[36m(_train_fn pid=833967)[0m 	iters: 100, epoch: 5 | loss: 0.5254525
[36m(_train_fn pid=833967)[0m 	speed: 0.0220s/iter; left time: 8.5666s
[36m(_train_fn pid=833967)[0m Updating learning rate to 0.0004819298468456188
[36m(_train_fn pid=833967)[0m saving checkpoint...
[36m(_train_fn pid=833967)[0m Validation loss decreased (1.5941 --> 1.5850).  Saving model state dict ...
[36m(_train_fn pid=833967)[0m Epoch: 5 cost time: 1.9069409370422363
[36m(_train_fn pid=833967)[0m Epoch: 5, Steps: 122 | Train Loss: 0.5234704 Vali Loss: 1.5849854 Best vali loss: 1.5849854
[36m(_train_fn pid=833967)[0m 	iters: 100, epoch: 6 | loss: 0.5356331
[36m(_train_fn pid=833967)[0m 	speed: 0.0221s/iter; left time: 5.9106s
[36m(_train_fn pid=833967)[0m Updating learning rate to 0.0002409649234228094
[36m(_train_fn pid=833967)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=833967)[0m saving checkpoint...
[36m(_train_fn pid=833967)[0m Epoch: 6 cost time: 1.9067347049713135
[36m(_train_fn pid=833967)[0m Epoch: 6, Steps: 122 | Train Loss: 0.5129634 Vali Loss: 1.6011251 Best vali loss: 1.5849854
[36m(_train_fn pid=833967)[0m 	iters: 100, epoch: 7 | loss: 0.5070934
[36m(_train_fn pid=833967)[0m 	speed: 0.0219s/iter; left time: 3.1799s
[36m(_train_fn pid=833967)[0m Updating learning rate to 0.0001204824617114047
[36m(_train_fn pid=833967)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=833967)[0m saving checkpoint...
[36m(_train_fn pid=833967)[0m Epoch: 7 cost time: 1.8950777053833008
[36m(_train_fn pid=833967)[0m Epoch: 7, Steps: 122 | Train Loss: 0.5063891 Vali Loss: 1.6177454 Best vali loss: 1.5849854
[36m(_train_fn pid=833967)[0m 	iters: 100, epoch: 8 | loss: 0.5065010
[36m(_train_fn pid=833967)[0m 	speed: 0.0219s/iter; left time: 0.5043s
[36m(_train_fn pid=833967)[0m Updating learning rate to 6.024123085570235e-05
[36m(_train_fn pid=833967)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=833967)[0m saving checkpoint...
[36m(_train_fn pid=833967)[0m Epoch: 8 cost time: 1.9021129608154297
[36m(_train_fn pid=833967)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-282fda45_145_alpha_d_ff=2,batch_size=64,d_model=32,decomp_method=moving_avg,moving_avg=15,down_sampling_method=avg,dropout=0_2024-08-24_09-18-41/checkpoint_000007)
2024-08-24 09:19:01,829	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=834676)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e2d060_146_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_09-19-01/checkpoint_000000)
2024-08-24 09:19:09,723	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=834676)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e2d060_146_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_09-19-01/checkpoint_000001)
2024-08-24 09:19:12,494	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=834676)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e2d060_146_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_09-19-01/checkpoint_000002)
2024-08-24 09:19:15,267	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=834676)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e2d060_146_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_09-19-01/checkpoint_000003)
[36m(_train_fn pid=834676)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e2d060_146_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_09-19-01/checkpoint_000004)
2024-08-24 09:19:18,037	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=834676)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e2d060_146_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_09-19-01/checkpoint_000005)
2024-08-24 09:19:20,814	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:19:23,596	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=834676)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e2d060_146_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_09-19-01/checkpoint_000006)
2024-08-24 09:19:26,358	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=833967)[0m Epoch: 8, Steps: 122 | Train Loss: 0.5019968 Vali Loss: 1.6260422 Best vali loss: 1.5849854
[36m(_train_fn pid=833967)[0m Early stopping

Trial trial-282fda45 completed after 8 iterations at 2024-08-24 09:19:01. Total running time: 1hr 57min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-282fda45 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          2.20009 â”‚
â”‚ time_total_s                             18.22175 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.58499 â”‚
â”‚ train_loss                                  0.502 â”‚
â”‚ valid_loss                                1.62604 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-d4e2d060 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d4e2d060 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.10664 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00699 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=834676)[0m configuration
[36m(_train_fn pid=834676)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'conv', 'dropout': 0.10664157831072274, 'e_layers': 2, 'learning_rate': 0.006991638677028083, 'd_ff': 128}
[36m(_train_fn pid=834676)[0m Use GPU: cuda:0
[36m(_train_fn pid=834676)[0m train 7825
[36m(_train_fn pid=834676)[0m val 2161
[36m(_train_fn pid=834676)[0m start_epoch 0
[36m(_train_fn pid=834676)[0m max_epoch 8
[36m(_train_fn pid=834676)[0m Validation loss decreased (inf --> 1.9325).  Saving model state dict ...
[36m(_train_fn pid=834676)[0m Updating learning rate to 0.006991638677028083
[36m(_train_fn pid=834676)[0m saving checkpoint...
[36m(_train_fn pid=834676)[0m Epoch: 1 cost time: 2.6221835613250732
[36m(_train_fn pid=834676)[0m Epoch: 1, Steps: 61 | Train Loss: 0.8776013 Vali Loss: 1.9325107 Best vali loss: 1.9325107
[36m(_train_fn pid=834676)[0m Updating learning rate to 0.0034958193385140413
[36m(_train_fn pid=834676)[0m saving checkpoint...
[36m(_train_fn pid=834676)[0m Validation loss decreased (1.9325 --> 1.6138).  Saving model state dict ...
[36m(_train_fn pid=834676)[0m Epoch: 2 cost time: 2.410604476928711
[36m(_train_fn pid=834676)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6391718 Vali Loss: 1.6138333 Best vali loss: 1.6138333
[36m(_train_fn pid=834676)[0m Updating learning rate to 0.0017479096692570206
[36m(_train_fn pid=834676)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=834676)[0m saving checkpoint...
[36m(_train_fn pid=834676)[0m Epoch: 3 cost time: 2.424323081970215
[36m(_train_fn pid=834676)[0m Epoch: 3, Steps: 61 | Train Loss: 0.5971307 Vali Loss: 1.6328645 Best vali loss: 1.6138333
[36m(_train_fn pid=834676)[0m Updating learning rate to 0.0008739548346285103
[36m(_train_fn pid=834676)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=834676)[0m saving checkpoint...
[36m(_train_fn pid=834676)[0m Epoch: 4 cost time: 2.421740770339966
[36m(_train_fn pid=834676)[0m Epoch: 4, Steps: 61 | Train Loss: 0.5775088 Vali Loss: 1.6326759 Best vali loss: 1.6138333
[36m(_train_fn pid=834676)[0m Updating learning rate to 0.00043697741731425516
[36m(_train_fn pid=834676)[0m saving checkpoint...
[36m(_train_fn pid=834676)[0m Validation loss decreased (1.6138 --> 1.5940).  Saving model state dict ...
[36m(_train_fn pid=834676)[0m Epoch: 5 cost time: 2.413540840148926
[36m(_train_fn pid=834676)[0m Epoch: 5, Steps: 61 | Train Loss: 0.5679473 Vali Loss: 1.5939524 Best vali loss: 1.5939524

Trial status: 145 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:19:20. Total running time: 1hr 58min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d4e2d060   RUNNING           5            14.4394       0.567947        1.59395             1.59395 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
140 more TERMINATED
[36m(_train_fn pid=834676)[0m Updating learning rate to 0.00021848870865712758
[36m(_train_fn pid=834676)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=834676)[0m saving checkpoint...
[36m(_train_fn pid=834676)[0m Epoch: 6 cost time: 2.4220144748687744
[36m(_train_fn pid=834676)[0m Epoch: 6, Steps: 61 | Train Loss: 0.5604267 Vali Loss: 1.6074869 Best vali loss: 1.5939524
[36m(_train_fn pid=834676)[0m Updating learning rate to 0.00010924435432856379
[36m(_train_fn pid=834676)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=834676)[0m saving checkpoint...
[36m(_train_fn pid=834676)[0m Epoch: 7 cost time: 2.4377694129943848
[36m(_train_fn pid=834676)[0m Epoch: 7, Steps: 61 | Train Loss: 0.5552058 Vali Loss: 1.6229596 Best vali loss: 1.5939524

Trial trial-d4e2d060 completed after 8 iterations at 2024-08-24 09:19:26. Total running time: 1hr 58min 17s
[36m(_train_fn pid=834676)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d4e2d060_146_alpha_d_ff=2,batch_size=128,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout_2024-08-24_09-19-01/checkpoint_000007)
[36m(_train_fn pid=835402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-32e12be8_147_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-19-26/checkpoint_000000)
2024-08-24 09:19:38,384	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=835402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-32e12be8_147_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-19-26/checkpoint_000001)
2024-08-24 09:19:42,969	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=835402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-32e12be8_147_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-19-26/checkpoint_000002)
2024-08-24 09:19:47,549	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=835402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-32e12be8_147_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-19-26/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d4e2d060 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          2.75881 â”‚
â”‚ time_total_s                             22.75428 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.59395 â”‚
â”‚ train_loss                                0.55138 â”‚
â”‚ valid_loss                                1.61252 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=834676)[0m Updating learning rate to 5.4622177164281895e-05
[36m(_train_fn pid=834676)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=834676)[0m saving checkpoint...
[36m(_train_fn pid=834676)[0m Epoch: 8 cost time: 2.4127771854400635
[36m(_train_fn pid=834676)[0m Epoch: 8, Steps: 61 | Train Loss: 0.5513757 Vali Loss: 1.6125239 Best vali loss: 1.5939524
[36m(_train_fn pid=834676)[0m Early stopping

Trial trial-32e12be8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-32e12be8 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     moving_avg â”‚
â”‚ decomp_method/moving_avg                15 â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.09773 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00109 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=835402)[0m configuration
[36m(_train_fn pid=835402)[0m {'batch_size': 32, 'd_model': 64, 'decomp_method': 'moving_avg', 'moving_avg': 15, 'down_sampling_method': 'conv', 'dropout': 0.09773354252483628, 'e_layers': 3, 'learning_rate': 0.0010934460752467993, 'd_ff': 192}
[36m(_train_fn pid=835402)[0m Use GPU: cuda:0
[36m(_train_fn pid=835402)[0m train 7825
[36m(_train_fn pid=835402)[0m val 2161
[36m(_train_fn pid=835402)[0m start_epoch 0
[36m(_train_fn pid=835402)[0m max_epoch 8
[36m(_train_fn pid=835402)[0m 	iters: 100, epoch: 1 | loss: 0.8108202
[36m(_train_fn pid=835402)[0m 	speed: 0.0216s/iter; left time: 40.0000s
[36m(_train_fn pid=835402)[0m 	iters: 200, epoch: 1 | loss: 0.7503448
[36m(_train_fn pid=835402)[0m 	speed: 0.0163s/iter; left time: 28.6448s
[36m(_train_fn pid=835402)[0m Updating learning rate to 0.0010934460752467993
[36m(_train_fn pid=835402)[0m saving checkpoint...
[36m(_train_fn pid=835402)[0m Validation loss decreased (inf --> 1.9282).  Saving model state dict ...
[36m(_train_fn pid=835402)[0m Epoch: 1 cost time: 4.251782178878784
[36m(_train_fn pid=835402)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7998986 Vali Loss: 1.9282029 Best vali loss: 1.9282029
[36m(_train_fn pid=835402)[0m 	iters: 100, epoch: 2 | loss: 0.5971217
[36m(_train_fn pid=835402)[0m 	speed: 0.0294s/iter; left time: 47.3211s
[36m(_train_fn pid=835402)[0m 	iters: 200, epoch: 2 | loss: 0.6000525
[36m(_train_fn pid=835402)[0m 	speed: 0.0163s/iter; left time: 24.6317s
[36m(_train_fn pid=835402)[0m Updating learning rate to 0.0005467230376233997
[36m(_train_fn pid=835402)[0m saving checkpoint...
[36m(_train_fn pid=835402)[0m Validation loss decreased (1.9282 --> 1.6376).  Saving model state dict ...
[36m(_train_fn pid=835402)[0m Epoch: 2 cost time: 4.022699356079102
[36m(_train_fn pid=835402)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6279274 Vali Loss: 1.6376169 Best vali loss: 1.6376169
[36m(_train_fn pid=835402)[0m 	iters: 100, epoch: 3 | loss: 0.6332104
[36m(_train_fn pid=835402)[0m 	speed: 0.0296s/iter; left time: 40.3975s
[36m(_train_fn pid=835402)[0m 	iters: 200, epoch: 3 | loss: 0.6112844
[36m(_train_fn pid=835402)[0m 	speed: 0.0164s/iter; left time: 20.7094s
[36m(_train_fn pid=835402)[0m Updating learning rate to 0.00027336151881169983
[36m(_train_fn pid=835402)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=835402)[0m saving checkpoint...
[36m(_train_fn pid=835402)[0m Epoch: 3 cost time: 4.034387111663818
[36m(_train_fn pid=835402)[0m Epoch: 3, Steps: 244 | Train Loss: 0.5798439 Vali Loss: 1.6473201 Best vali loss: 1.6376169
[36m(_train_fn pid=835402)[0m 	iters: 100, epoch: 4 | loss: 0.5492868
[36m(_train_fn pid=835402)[0m 	speed: 0.0295s/iter; left time: 33.0216s
[36m(_train_fn pid=835402)[0m 	iters: 200, epoch: 4 | loss: 0.5343046
[36m(_train_fn pid=835402)[0m 	speed: 0.0164s/iter; left time: 16.6956s
[36m(_train_fn pid=835402)[0m Updating learning rate to 0.00013668075940584992
[36m(_train_fn pid=835402)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=835402)[0m saving checkpoint...
[36m(_train_fn pid=835402)[0m Epoch: 4 cost time: 4.030134439468384
[36m(_train_fn pid=835402)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5583480 Vali Loss: 1.6616926 Best vali loss: 1.6376169
[36m(_train_fn pid=835402)[0m 	iters: 100, epoch: 5 | loss: 0.5837640
[36m(_train_fn pid=835402)[0m 	speed: 0.0294s/iter; left time: 25.7803s

Trial status: 146 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:19:50. Total running time: 1hr 58min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-32e12be8   RUNNING           4            18.947        0.558348        1.66169             1.63762 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
141 more TERMINATED
2024-08-24 09:19:52,120	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=835402)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-32e12be8_147_alpha_d_ff=3,batch_size=32,d_model=64,decomp_method=moving_avg,moving_avg=15,down_sampling_method=conv,dropout=_2024-08-24_09-19-26/checkpoint_000004)
2024-08-24 09:20:03,549	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=835918)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c60ba4aa_148_alpha_d_ff=3,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers_2024-08-24_09-19-52/checkpoint_000000)
[36m(_train_fn pid=835918)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c60ba4aa_148_alpha_d_ff=3,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers_2024-08-24_09-19-52/checkpoint_000001)
[36m(_train_fn pid=835918)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c60ba4aa_148_alpha_d_ff=3,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers_2024-08-24_09-19-52/checkpoint_000002)
[36m(_train_fn pid=835402)[0m 	iters: 200, epoch: 5 | loss: 0.5462996
[36m(_train_fn pid=835402)[0m 	speed: 0.0163s/iter; left time: 12.6616s

Trial trial-32e12be8 completed after 5 iterations at 2024-08-24 09:19:52. Total running time: 1hr 58min 43s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-32e12be8 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          4.57051 â”‚
â”‚ time_total_s                             23.51748 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.63762 â”‚
â”‚ train_loss                                0.54542 â”‚
â”‚ valid_loss                                1.65537 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=835402)[0m Updating learning rate to 6.834037970292496e-05
[36m(_train_fn pid=835402)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=835402)[0m saving checkpoint...
[36m(_train_fn pid=835402)[0m Epoch: 5 cost time: 4.020553827285767
[36m(_train_fn pid=835402)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5454229 Vali Loss: 1.6553722 Best vali loss: 1.6376169
[36m(_train_fn pid=835402)[0m Early stopping

Trial trial-c60ba4aa started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c60ba4aa config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09899 â”‚
â”‚ e_layers                                 4 â”‚
â”‚ learning_rate                      0.00054 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=835918)[0m configuration
[36m(_train_fn pid=835918)[0m {'batch_size': 16, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.09899489976816206, 'e_layers': 4, 'learning_rate': 0.0005371090236635101, 'd_ff': 192}
[36m(_train_fn pid=835918)[0m Use GPU: cuda:0
[36m(_train_fn pid=835918)[0m train 7825
[36m(_train_fn pid=835918)[0m val 2161
[36m(_train_fn pid=835918)[0m start_epoch 0
[36m(_train_fn pid=835918)[0m max_epoch 8
[36m(_train_fn pid=835918)[0m 	iters: 100, epoch: 1 | loss: 0.8605441
[36m(_train_fn pid=835918)[0m 	speed: 0.0217s/iter; left time: 82.5843s
[36m(_train_fn pid=835918)[0m 	iters: 200, epoch: 1 | loss: 0.7470015
[36m(_train_fn pid=835918)[0m 	speed: 0.0146s/iter; left time: 54.2008s
[36m(_train_fn pid=835918)[0m 	iters: 300, epoch: 1 | loss: 0.8453668
[36m(_train_fn pid=835918)[0m 	speed: 0.0146s/iter; left time: 52.7813s
[36m(_train_fn pid=835918)[0m 	iters: 400, epoch: 1 | loss: 0.8132646
[36m(_train_fn pid=835918)[0m 	speed: 0.0146s/iter; left time: 51.3310s
[36m(_train_fn pid=835918)[0m Updating learning rate to 0.0005371090236635101
[36m(_train_fn pid=835918)[0m saving checkpoint...
[36m(_train_fn pid=835918)[0m Validation loss decreased (inf --> 1.9256).  Saving model state dict ...
[36m(_train_fn pid=835918)[0m Epoch: 1 cost time: 7.5951831340789795
[36m(_train_fn pid=835918)[0m Epoch: 1, Steps: 489 | Train Loss: 0.8019355 Vali Loss: 1.9256479 Best vali loss: 1.9256479
[36m(_train_fn pid=835918)[0m 	iters: 100, epoch: 2 | loss: 0.7053666
[36m(_train_fn pid=835918)[0m 	speed: 0.0371s/iter; left time: 123.2524s
[36m(_train_fn pid=835918)[0m 	iters: 200, epoch: 2 | loss: 0.6320671
[36m(_train_fn pid=835918)[0m 	speed: 0.0139s/iter; left time: 44.6676s
[36m(_train_fn pid=835918)[0m 	iters: 300, epoch: 2 | loss: 0.6631219
[36m(_train_fn pid=835918)[0m 	speed: 0.0138s/iter; left time: 43.2560s
[36m(_train_fn pid=835918)[0m 	iters: 400, epoch: 2 | loss: 0.6156586
[36m(_train_fn pid=835918)[0m 	speed: 0.0139s/iter; left time: 42.0420s
[36m(_train_fn pid=835918)[0m Updating learning rate to 0.00026855451183175504
[36m(_train_fn pid=835918)[0m saving checkpoint...
[36m(_train_fn pid=835918)[0m Validation loss decreased (1.9256 --> 1.5680).  Saving model state dict ...
[36m(_train_fn pid=835918)[0m Epoch: 2 cost time: 6.830280303955078
[36m(_train_fn pid=835918)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6337150 Vali Loss: 1.5680469 Best vali loss: 1.5680469
[36m(_train_fn pid=835918)[0m 	iters: 100, epoch: 3 | loss: 0.6730104
[36m(_train_fn pid=835918)[0m 	speed: 0.0374s/iter; left time: 105.9273s
[36m(_train_fn pid=835918)[0m 	iters: 200, epoch: 3 | loss: 0.6110857
[36m(_train_fn pid=835918)[0m 	speed: 0.0147s/iter; left time: 40.2802s
[36m(_train_fn pid=835918)[0m 	iters: 300, epoch: 3 | loss: 0.5349591
[36m(_train_fn pid=835918)[0m 	speed: 0.0147s/iter; left time: 38.6894s
[36m(_train_fn pid=835918)[0m 	iters: 400, epoch: 3 | loss: 0.5388077
[36m(_train_fn pid=835918)[0m 	speed: 0.0147s/iter; left time: 37.1799s
[36m(_train_fn pid=835918)[0m Updating learning rate to 0.00013427725591587752
[36m(_train_fn pid=835918)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=835918)[0m saving checkpoint...
[36m(_train_fn pid=835918)[0m Epoch: 3 cost time: 7.235403537750244
[36m(_train_fn pid=835918)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6003429 Vali Loss: 1.5757354 Best vali loss: 1.5680469

Trial status: 147 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:20:20. Total running time: 1hr 59min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=835918)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c60ba4aa_148_alpha_d_ff=3,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers_2024-08-24_09-19-52/checkpoint_000003)
[36m(_train_fn pid=835918)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c60ba4aa_148_alpha_d_ff=3,batch_size=16,d_model=64,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0990,e_layers_2024-08-24_09-19-52/checkpoint_000004)
2024-08-24 09:20:40,674	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=836482)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0eb3a40_149_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0969,e_layer_2024-08-24_09-20-35/checkpoint_000000)
2024-08-24 09:20:42,959	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=836482)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0eb3a40_149_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0969,e_layer_2024-08-24_09-20-35/checkpoint_000001)
[36m(_train_fn pid=836482)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0eb3a40_149_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0969,e_layer_2024-08-24_09-20-35/checkpoint_000002)
2024-08-24 09:20:45,232	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:20:47,502	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=836482)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0eb3a40_149_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0969,e_layer_2024-08-24_09-20-35/checkpoint_000003)
2024-08-24 09:20:49,781	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=836482)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0eb3a40_149_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0969,e_layer_2024-08-24_09-20-35/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c60ba4aa   RUNNING           3            24.9649       0.600343        1.57574             1.56805 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
142 more TERMINATED
[36m(_train_fn pid=835918)[0m 	iters: 100, epoch: 4 | loss: 0.6838701
[36m(_train_fn pid=835918)[0m 	speed: 0.0377s/iter; left time: 88.5304s
[36m(_train_fn pid=835918)[0m 	iters: 200, epoch: 4 | loss: 0.5219195
[36m(_train_fn pid=835918)[0m 	speed: 0.0147s/iter; left time: 32.9352s
[36m(_train_fn pid=835918)[0m 	iters: 300, epoch: 4 | loss: 0.6243794
[36m(_train_fn pid=835918)[0m 	speed: 0.0147s/iter; left time: 31.5180s
[36m(_train_fn pid=835918)[0m 	iters: 400, epoch: 4 | loss: 0.6471193
[36m(_train_fn pid=835918)[0m 	speed: 0.0147s/iter; left time: 30.0306s
[36m(_train_fn pid=835918)[0m Updating learning rate to 6.713862795793876e-05
[36m(_train_fn pid=835918)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=835918)[0m saving checkpoint...
[36m(_train_fn pid=835918)[0m Epoch: 4 cost time: 7.216102838516235
[36m(_train_fn pid=835918)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5862381 Vali Loss: 1.5791236 Best vali loss: 1.5680469
[36m(_train_fn pid=835918)[0m 	iters: 100, epoch: 5 | loss: 0.6555876
[36m(_train_fn pid=835918)[0m 	speed: 0.0377s/iter; left time: 70.0017s
[36m(_train_fn pid=835918)[0m 	iters: 200, epoch: 5 | loss: 0.5140763
[36m(_train_fn pid=835918)[0m 	speed: 0.0147s/iter; left time: 25.8687s
[36m(_train_fn pid=835918)[0m 	iters: 300, epoch: 5 | loss: 0.6315679
[36m(_train_fn pid=835918)[0m 	speed: 0.0147s/iter; left time: 24.3000s
[36m(_train_fn pid=835918)[0m 	iters: 400, epoch: 5 | loss: 0.6077746
[36m(_train_fn pid=835918)[0m 	speed: 0.0146s/iter; left time: 22.7873s

Trial trial-c60ba4aa completed after 5 iterations at 2024-08-24 09:20:35. Total running time: 1hr 59min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c60ba4aa result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          8.16819 â”‚
â”‚ time_total_s                             41.30252 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56805 â”‚
â”‚ train_loss                                0.57694 â”‚
â”‚ valid_loss                                1.58868 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=835918)[0m Updating learning rate to 3.356931397896938e-05
[36m(_train_fn pid=835918)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=835918)[0m saving checkpoint...
[36m(_train_fn pid=835918)[0m Epoch: 5 cost time: 7.215749502182007
[36m(_train_fn pid=835918)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5769413 Vali Loss: 1.5886761 Best vali loss: 1.5680469
[36m(_train_fn pid=835918)[0m Early stopping

Trial trial-a0eb3a40 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a0eb3a40 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               2 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.09688 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00066 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=836482)[0m configuration
[36m(_train_fn pid=836482)[0m {'batch_size': 128, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.09687811935963532, 'e_layers': 3, 'learning_rate': 0.000657862691741497, 'd_ff': 64}
[36m(_train_fn pid=836482)[0m Use GPU: cuda:0
[36m(_train_fn pid=836482)[0m train 7825
[36m(_train_fn pid=836482)[0m val 2161
[36m(_train_fn pid=836482)[0m start_epoch 0
[36m(_train_fn pid=836482)[0m max_epoch 8
[36m(_train_fn pid=836482)[0m Validation loss decreased (inf --> 2.5748).  Saving model state dict ...
[36m(_train_fn pid=836482)[0m Validation loss decreased (2.5748 --> 1.9436).  Saving model state dict ...
[36m(_train_fn pid=836482)[0m Updating learning rate to 0.0003289313458707485[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=836482)[0m saving checkpoint...[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=836482)[0m Epoch: 2 cost time: 1.9124293327331543[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=836482)[0m Epoch: 2, Steps: 61 | Train Loss: 0.8638800 Vali Loss: 1.9435598 Best vali loss: 1.9435598[32m [repeated 2x across cluster][0m
[36m(_train_fn pid=836482)[0m Validation loss decreased (1.9436 --> 1.7951).  Saving model state dict ...
[36m(_train_fn pid=836482)[0m Validation loss decreased (1.7951 --> 1.7318).  Saving model state dict ...
[36m(_train_fn pid=836482)[0m Validation loss decreased (1.7318 --> 1.7079).  Saving model state dict ...
[36m(_train_fn pid=836482)[0m Updating learning rate to 4.1116418233843565e-05[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=836482)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=836482)[0m Epoch: 5 cost time: 1.921825885772705[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=836482)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6763215 Vali Loss: 1.7079029 Best vali loss: 1.7079029[32m [repeated 3x across cluster][0m

Trial status: 148 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:20:50. Total running time: 1hr 59min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 09:20:52,051	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=836482)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0eb3a40_149_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0969,e_layer_2024-08-24_09-20-35/checkpoint_000005)
[36m(_train_fn pid=836482)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0eb3a40_149_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0969,e_layer_2024-08-24_09-20-35/checkpoint_000006)
2024-08-24 09:20:54,324	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:20:56,603	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=836482)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0eb3a40_149_alpha_d_ff=2,batch_size=128,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0969,e_layer_2024-08-24_09-20-35/checkpoint_000007)
[36m(_train_fn pid=837195)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33052edc_150_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0695,e_laye_2024-08-24_09-20-56/checkpoint_000000)
2024-08-24 09:21:08,044	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=837195)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33052edc_150_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0695,e_laye_2024-08-24_09-20-56/checkpoint_000001)
[36m(_train_fn pid=837195)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33052edc_150_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0695,e_laye_2024-08-24_09-20-56/checkpoint_000002)
2024-08-24 09:21:12,381	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:21:16,715	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=837195)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33052edc_150_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0695,e_laye_2024-08-24_09-20-56/checkpoint_000003)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a0eb3a40   RUNNING           5            12.1592       0.676322        1.7079              1.7079  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
143 more TERMINATED
[36m(_train_fn pid=836482)[0m Validation loss decreased (1.7079 --> 1.6984).  Saving model state dict ...
[36m(_train_fn pid=836482)[0m Validation loss decreased (1.6984 --> 1.6941).  Saving model state dict ...

Trial trial-a0eb3a40 completed after 8 iterations at 2024-08-24 09:20:56. Total running time: 1hr 59min 47s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a0eb3a40 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          2.27779 â”‚
â”‚ time_total_s                             18.97437 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.69202 â”‚
â”‚ train_loss                                0.66529 â”‚
â”‚ valid_loss                                1.69202 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=836482)[0m Validation loss decreased (1.6941 --> 1.6920).  Saving model state dict ...
[36m(_train_fn pid=836482)[0m Updating learning rate to 5.139552279230446e-06[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=836482)[0m saving checkpoint...[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=836482)[0m Epoch: 8 cost time: 1.9240548610687256[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=836482)[0m Epoch: 8, Steps: 61 | Train Loss: 0.6652931 Vali Loss: 1.6920167 Best vali loss: 1.6920167[32m [repeated 3x across cluster][0m

Trial trial-33052edc started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-33052edc config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               4 â”‚
â”‚ batch_size                             128 â”‚
â”‚ d_model                                 64 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                  conv â”‚
â”‚ dropout                            0.06954 â”‚
â”‚ e_layers                                 3 â”‚
â”‚ learning_rate                      0.00206 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=837195)[0m configuration
[36m(_train_fn pid=837195)[0m {'batch_size': 128, 'd_model': 64, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'conv', 'dropout': 0.06954449211031205, 'e_layers': 3, 'learning_rate': 0.0020589687051676482, 'd_ff': 256}
[36m(_train_fn pid=837195)[0m Use GPU: cuda:0
[36m(_train_fn pid=837195)[0m train 7825
[36m(_train_fn pid=837195)[0m val 2161
[36m(_train_fn pid=837195)[0m start_epoch 0
[36m(_train_fn pid=837195)[0m max_epoch 8
[36m(_train_fn pid=837195)[0m Validation loss decreased (inf --> 2.1519).  Saving model state dict ...
[36m(_train_fn pid=837195)[0m Updating learning rate to 0.0020589687051676482
[36m(_train_fn pid=837195)[0m saving checkpoint...
[36m(_train_fn pid=837195)[0m Epoch: 1 cost time: 4.161784887313843
[36m(_train_fn pid=837195)[0m Epoch: 1, Steps: 61 | Train Loss: 0.9280554 Vali Loss: 2.1518579 Best vali loss: 2.1518579
[36m(_train_fn pid=837195)[0m Updating learning rate to 0.0010294843525838241
[36m(_train_fn pid=837195)[0m saving checkpoint...
[36m(_train_fn pid=837195)[0m Validation loss decreased (2.1519 --> 1.6210).  Saving model state dict ...
[36m(_train_fn pid=837195)[0m Epoch: 2 cost time: 3.7425217628479004
[36m(_train_fn pid=837195)[0m Epoch: 2, Steps: 61 | Train Loss: 0.6999643 Vali Loss: 1.6210035 Best vali loss: 1.6210035
[36m(_train_fn pid=837195)[0m Updating learning rate to 0.0005147421762919121
[36m(_train_fn pid=837195)[0m saving checkpoint...
[36m(_train_fn pid=837195)[0m Validation loss decreased (1.6210 --> 1.5939).  Saving model state dict ...
[36m(_train_fn pid=837195)[0m Epoch: 3 cost time: 3.752467393875122
[36m(_train_fn pid=837195)[0m Epoch: 3, Steps: 61 | Train Loss: 0.6168992 Vali Loss: 1.5938595 Best vali loss: 1.5938595
[36m(_train_fn pid=837195)[0m Updating learning rate to 0.00025737108814595603
[36m(_train_fn pid=837195)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=837195)[0m saving checkpoint...
[36m(_train_fn pid=837195)[0m Epoch: 4 cost time: 3.757526159286499
[36m(_train_fn pid=837195)[0m Epoch: 4, Steps: 61 | Train Loss: 0.6093364 Vali Loss: 1.5990520 Best vali loss: 1.5938595

Trial status: 149 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:21:20. Total running time: 2hr 0min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=837195)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33052edc_150_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0695,e_laye_2024-08-24_09-20-56/checkpoint_000004)
2024-08-24 09:21:21,034	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 09:21:25,345	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=837195)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33052edc_150_alpha_d_ff=4,batch_size=128,d_model=64,decomp_method=dft_decomp,down_sampling_method=conv,dropout=0.0695,e_laye_2024-08-24_09-20-56/checkpoint_000005)
2024-08-24 09:21:47,626	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=837789)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f44654_151_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1307,e_layer_2024-08-24_09-21-25/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-33052edc   RUNNING           4            18.1221       0.609336        1.59905             1.59386 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
144 more TERMINATED
[36m(_train_fn pid=837195)[0m Updating learning rate to 0.00012868554407297801
[36m(_train_fn pid=837195)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=837195)[0m saving checkpoint...
[36m(_train_fn pid=837195)[0m Epoch: 5 cost time: 3.7407009601593018
[36m(_train_fn pid=837195)[0m Epoch: 5, Steps: 61 | Train Loss: 0.6047234 Vali Loss: 1.5982495 Best vali loss: 1.5938595

Trial trial-33052edc completed after 6 iterations at 2024-08-24 09:21:25. Total running time: 2hr 0min 16s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-33052edc result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          4.30957 â”‚
â”‚ time_total_s                             26.74776 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.59386 â”‚
â”‚ train_loss                                0.60211 â”‚
â”‚ valid_loss                                1.59962 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=837195)[0m Updating learning rate to 6.434277203648901e-05
[36m(_train_fn pid=837195)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=837195)[0m saving checkpoint...
[36m(_train_fn pid=837195)[0m Epoch: 6 cost time: 3.7374649047851562
[36m(_train_fn pid=837195)[0m Epoch: 6, Steps: 61 | Train Loss: 0.6021117 Vali Loss: 1.5996242 Best vali loss: 1.5938595
[36m(_train_fn pid=837195)[0m Early stopping

Trial trial-76f44654 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-76f44654 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13065 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00114 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=837789)[0m configuration
[36m(_train_fn pid=837789)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1306546382188581, 'e_layers': 1, 'learning_rate': 0.0011432722545641554, 'd_ff': 1536}
[36m(_train_fn pid=837789)[0m Use GPU: cuda:0
[36m(_train_fn pid=837789)[0m train 7825
[36m(_train_fn pid=837789)[0m val 2161
[36m(_train_fn pid=837789)[0m start_epoch 0
[36m(_train_fn pid=837789)[0m max_epoch 8
[36m(_train_fn pid=837789)[0m 	iters: 100, epoch: 1 | loss: 0.8264223
[36m(_train_fn pid=837789)[0m 	speed: 0.0764s/iter; left time: 141.5830s
[36m(_train_fn pid=837789)[0m 	iters: 200, epoch: 1 | loss: 0.6497389
[36m(_train_fn pid=837789)[0m 	speed: 0.0700s/iter; left time: 122.6719s
[36m(_train_fn pid=837789)[0m Updating learning rate to 0.0011432722545641554
[36m(_train_fn pid=837789)[0m saving checkpoint...
[36m(_train_fn pid=837789)[0m Validation loss decreased (inf --> 1.8923).  Saving model state dict ...
[36m(_train_fn pid=837789)[0m Epoch: 1 cost time: 17.4667706489563
[36m(_train_fn pid=837789)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7850798 Vali Loss: 1.8923356 Best vali loss: 1.8923356

Trial status: 150 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:21:50. Total running time: 2hr 0min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-76f44654   RUNNING           1            20.0302       0.78508         1.89234             1.89234 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
145 more TERMINATED
[36m(_train_fn pid=837789)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f44654_151_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1307,e_layer_2024-08-24_09-21-25/checkpoint_000001)
[36m(_train_fn pid=837789)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f44654_151_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1307,e_layer_2024-08-24_09-21-25/checkpoint_000002)
[36m(_train_fn pid=837789)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f44654_151_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1307,e_layer_2024-08-24_09-21-25/checkpoint_000003)
[36m(_train_fn pid=837789)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f44654_151_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1307,e_layer_2024-08-24_09-21-25/checkpoint_000004)
[36m(_train_fn pid=837789)[0m 	iters: 100, epoch: 2 | loss: 0.6684304
[36m(_train_fn pid=837789)[0m 	speed: 0.1226s/iter; left time: 197.2737s
[36m(_train_fn pid=837789)[0m 	iters: 200, epoch: 2 | loss: 0.7062592
[36m(_train_fn pid=837789)[0m 	speed: 0.0700s/iter; left time: 105.5940s
[36m(_train_fn pid=837789)[0m Updating learning rate to 0.0005716361272820777
[36m(_train_fn pid=837789)[0m saving checkpoint...
[36m(_train_fn pid=837789)[0m Validation loss decreased (1.8923 --> 1.5802).  Saving model state dict ...
[36m(_train_fn pid=837789)[0m Epoch: 2 cost time: 17.089433670043945
[36m(_train_fn pid=837789)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7606129 Vali Loss: 1.5801644 Best vali loss: 1.5801644
[36m(_train_fn pid=837789)[0m 	iters: 100, epoch: 3 | loss: 0.6793560
[36m(_train_fn pid=837789)[0m 	speed: 0.1226s/iter; left time: 167.3003s
Trial status: 150 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:22:20. Total running time: 2hr 1min 11s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-76f44654   RUNNING           2            39.2766       0.760613        1.58016             1.58016 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
145 more TERMINATED
[36m(_train_fn pid=837789)[0m 	iters: 200, epoch: 3 | loss: 0.6355533
[36m(_train_fn pid=837789)[0m 	speed: 0.0701s/iter; left time: 88.6358s
[36m(_train_fn pid=837789)[0m Updating learning rate to 0.00028581806364103886
[36m(_train_fn pid=837789)[0m saving checkpoint...
[36m(_train_fn pid=837789)[0m Validation loss decreased (1.5802 --> 1.5727).  Saving model state dict ...
[36m(_train_fn pid=837789)[0m Epoch: 3 cost time: 17.11108660697937
[36m(_train_fn pid=837789)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6191100 Vali Loss: 1.5727208 Best vali loss: 1.5727208
[36m(_train_fn pid=837789)[0m 	iters: 100, epoch: 4 | loss: 0.6329926
[36m(_train_fn pid=837789)[0m 	speed: 0.1228s/iter; left time: 137.6358s
[36m(_train_fn pid=837789)[0m 	iters: 200, epoch: 4 | loss: 0.6391757
[36m(_train_fn pid=837789)[0m 	speed: 0.0701s/iter; left time: 71.5348s
[36m(_train_fn pid=837789)[0m Updating learning rate to 0.00014290903182051943
[36m(_train_fn pid=837789)[0m saving checkpoint...
[36m(_train_fn pid=837789)[0m Validation loss decreased (1.5727 --> 1.5659).  Saving model state dict ...
[36m(_train_fn pid=837789)[0m Epoch: 4 cost time: 17.1135151386261
[36m(_train_fn pid=837789)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6141882 Vali Loss: 1.5659356 Best vali loss: 1.5659356
Trial status: 150 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:22:50. Total running time: 2hr 1min 41s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-76f44654   RUNNING           4            77.8327       0.614188        1.56594             1.56594 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
145 more TERMINATED
[36m(_train_fn pid=837789)[0m 	iters: 100, epoch: 5 | loss: 0.6042968
[36m(_train_fn pid=837789)[0m 	speed: 0.1229s/iter; left time: 107.7617s
[36m(_train_fn pid=837789)[0m 	iters: 200, epoch: 5 | loss: 0.5470347
[36m(_train_fn pid=837789)[0m 	speed: 0.0703s/iter; left time: 54.5944s
[36m(_train_fn pid=837789)[0m Updating learning rate to 7.145451591025971e-05
[36m(_train_fn pid=837789)[0m saving checkpoint...
[36m(_train_fn pid=837789)[0m Validation loss decreased (1.5659 --> 1.5652).  Saving model state dict ...
[36m(_train_fn pid=837789)[0m Epoch: 5 cost time: 17.156336307525635
[36m(_train_fn pid=837789)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6122489 Vali Loss: 1.5651608 Best vali loss: 1.5651608
[36m(_train_fn pid=837789)[0m 	iters: 100, epoch: 6 | loss: 0.5882924
[36m(_train_fn pid=837789)[0m 	speed: 0.1231s/iter; left time: 77.9170s
[36m(_train_fn pid=837789)[0m 	iters: 200, epoch: 6 | loss: 0.5982536
[36m(_train_fn pid=837789)[0m 	speed: 0.0702s/iter; left time: 37.3934s
Trial status: 150 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:23:20. Total running time: 2hr 2min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=837789)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f44654_151_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1307,e_layer_2024-08-24_09-21-25/checkpoint_000005)
2024-08-24 09:23:46,609	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=838645)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-113d5626_152_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1428,e_layer_2024-08-24_09-23-24/checkpoint_000000)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-76f44654   RUNNING           5            97.1591       0.612249        1.56516             1.56516 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
145 more TERMINATED
[36m(_train_fn pid=837789)[0m Updating learning rate to 3.572725795512986e-05
[36m(_train_fn pid=837789)[0m saving checkpoint...
[36m(_train_fn pid=837789)[0m Validation loss decreased (1.5652 --> 1.5644).  Saving model state dict ...

Trial trial-76f44654 completed after 6 iterations at 2024-08-24 09:23:24. Total running time: 2hr 2min 15s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-76f44654 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.29197 â”‚
â”‚ time_total_s                            116.45105 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56437 â”‚
â”‚ train_loss                                0.61134 â”‚
â”‚ valid_loss                                1.56437 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-113d5626 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-113d5626 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.14282 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00088 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=838645)[0m configuration
[36m(_train_fn pid=838645)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.14282164770205308, 'e_layers': 1, 'learning_rate': 0.0008795984049775422, 'd_ff': 1536}
[36m(_train_fn pid=838645)[0m Use GPU: cuda:0
[36m(_train_fn pid=838645)[0m train 7825
[36m(_train_fn pid=838645)[0m val 2161
[36m(_train_fn pid=838645)[0m start_epoch 0
[36m(_train_fn pid=838645)[0m max_epoch 8
[36m(_train_fn pid=838645)[0m 	iters: 100, epoch: 1 | loss: 0.8339124
[36m(_train_fn pid=838645)[0m 	speed: 0.0764s/iter; left time: 141.5132s
[36m(_train_fn pid=838645)[0m 	iters: 200, epoch: 1 | loss: 0.6550617
[36m(_train_fn pid=838645)[0m 	speed: 0.0700s/iter; left time: 122.6675s
[36m(_train_fn pid=838645)[0m Updating learning rate to 0.0008795984049775422
[36m(_train_fn pid=838645)[0m saving checkpoint...
[36m(_train_fn pid=838645)[0m Validation loss decreased (inf --> 1.9134).  Saving model state dict ...
[36m(_train_fn pid=838645)[0m Epoch: 1 cost time: 17.459145545959473
[36m(_train_fn pid=838645)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7929661 Vali Loss: 1.9134064 Best vali loss: 1.9134064

Trial status: 151 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:23:50. Total running time: 2hr 2min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-113d5626   RUNNING           1            20.0261       0.792966        1.91341             1.91341 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
146 more TERMINATED
[36m(_train_fn pid=838645)[0m 	iters: 100, epoch: 2 | loss: 0.6419080
[36m(_train_fn pid=838645)[0m 	speed: 0.1226s/iter; left time: 197.1933s
[36m(_train_fn pid=838645)[0m 	iters: 200, epoch: 2 | loss: 0.6918505
[36m(_train_fn pid=838645)[0m 	speed: 0.0700s/iter; left time: 105.5916s
[36m(_train_fn pid=838645)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-113d5626_152_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1428,e_layer_2024-08-24_09-23-24/checkpoint_000001)
[36m(_train_fn pid=838645)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-113d5626_152_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1428,e_layer_2024-08-24_09-23-24/checkpoint_000002)
[36m(_train_fn pid=838645)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-113d5626_152_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1428,e_layer_2024-08-24_09-23-24/checkpoint_000003)
[36m(_train_fn pid=838645)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-113d5626_152_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1428,e_layer_2024-08-24_09-23-24/checkpoint_000004)
[36m(_train_fn pid=838645)[0m Updating learning rate to 0.0004397992024887711
[36m(_train_fn pid=838645)[0m saving checkpoint...
[36m(_train_fn pid=838645)[0m Validation loss decreased (1.9134 --> 1.5718).  Saving model state dict ...
[36m(_train_fn pid=838645)[0m Epoch: 2 cost time: 17.090576171875
[36m(_train_fn pid=838645)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6995525 Vali Loss: 1.5718160 Best vali loss: 1.5718160
[36m(_train_fn pid=838645)[0m 	iters: 100, epoch: 3 | loss: 0.6656240
[36m(_train_fn pid=838645)[0m 	speed: 0.1226s/iter; left time: 167.3171s
[36m(_train_fn pid=838645)[0m 	iters: 200, epoch: 3 | loss: 0.6299215
[36m(_train_fn pid=838645)[0m 	speed: 0.0700s/iter; left time: 88.5210s
Trial status: 151 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:24:20. Total running time: 2hr 3min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-113d5626   RUNNING           2            39.28         0.699552        1.57182             1.57182 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
146 more TERMINATED
[36m(_train_fn pid=838645)[0m Updating learning rate to 0.00021989960124438554
[36m(_train_fn pid=838645)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=838645)[0m saving checkpoint...
[36m(_train_fn pid=838645)[0m Epoch: 3 cost time: 17.085009336471558
[36m(_train_fn pid=838645)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6146652 Vali Loss: 1.5735011 Best vali loss: 1.5718160
[36m(_train_fn pid=838645)[0m 	iters: 100, epoch: 4 | loss: 0.6327586
[36m(_train_fn pid=838645)[0m 	speed: 0.1225s/iter; left time: 137.2803s
[36m(_train_fn pid=838645)[0m 	iters: 200, epoch: 4 | loss: 0.6369756
[36m(_train_fn pid=838645)[0m 	speed: 0.0700s/iter; left time: 71.4427s
[36m(_train_fn pid=838645)[0m Updating learning rate to 0.00010994980062219277
[36m(_train_fn pid=838645)[0m saving checkpoint...
[36m(_train_fn pid=838645)[0m Validation loss decreased (1.5718 --> 1.5661).  Saving model state dict ...
[36m(_train_fn pid=838645)[0m Epoch: 4 cost time: 17.096917152404785
[36m(_train_fn pid=838645)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6108325 Vali Loss: 1.5661280 Best vali loss: 1.5661280
Trial status: 151 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:24:50. Total running time: 2hr 3min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-113d5626   RUNNING           4            77.7655       0.610832        1.56613             1.56613 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
146 more TERMINATED
[36m(_train_fn pid=838645)[0m 	iters: 100, epoch: 5 | loss: 0.6048025
[36m(_train_fn pid=838645)[0m 	speed: 0.1226s/iter; left time: 107.5062s
[36m(_train_fn pid=838645)[0m 	iters: 200, epoch: 5 | loss: 0.5441299
[36m(_train_fn pid=838645)[0m 	speed: 0.0701s/iter; left time: 54.4316s
[36m(_train_fn pid=838645)[0m Updating learning rate to 5.4974900311096385e-05
[36m(_train_fn pid=838645)[0m saving checkpoint...
[36m(_train_fn pid=838645)[0m Validation loss decreased (1.5661 --> 1.5661).  Saving model state dict ...
[36m(_train_fn pid=838645)[0m Epoch: 5 cost time: 17.10104727745056
[36m(_train_fn pid=838645)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6092369 Vali Loss: 1.5660985 Best vali loss: 1.5660985
[36m(_train_fn pid=838645)[0m 	iters: 100, epoch: 6 | loss: 0.5811619
[36m(_train_fn pid=838645)[0m 	speed: 0.1227s/iter; left time: 77.6563s
[36m(_train_fn pid=838645)[0m 	iters: 200, epoch: 6 | loss: 0.5933089
[36m(_train_fn pid=838645)[0m 	speed: 0.0701s/iter; left time: 37.3530s
Trial status: 151 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:25:20. Total running time: 2hr 4min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 0a718da3 with best_valid_loss=1.5639687750074598 and params={'alpha_d_ff': 3, 'batch_size': 16, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.10005171002606002, 'e_layers': 1, 'learning_rate': 0.0008318929334924678}
[36m(_train_fn pid=838645)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-113d5626_152_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1428,e_layer_2024-08-24_09-23-24/checkpoint_000005)
2024-08-24 09:25:44,632	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=839503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33f85791_153_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1555,e_layer_2024-08-24_09-25-22/checkpoint_000000)
[36m(_train_fn pid=839503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33f85791_153_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1555,e_layer_2024-08-24_09-25-22/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-113d5626   RUNNING           5            97.036        0.609237        1.5661              1.5661  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
146 more TERMINATED
[36m(_train_fn pid=838645)[0m Updating learning rate to 2.7487450155548192e-05
[36m(_train_fn pid=838645)[0m saving checkpoint...
[36m(_train_fn pid=838645)[0m Validation loss decreased (1.5661 --> 1.5624).  Saving model state dict ...

Trial trial-113d5626 completed after 6 iterations at 2024-08-24 09:25:22. Total running time: 2hr 4min 14s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-113d5626 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.26151 â”‚
â”‚ time_total_s                            116.29753 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56236 â”‚
â”‚ train_loss                                0.60843 â”‚
â”‚ valid_loss                                1.56236 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-33f85791 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-33f85791 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.15554 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00113 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=839503)[0m configuration
[36m(_train_fn pid=839503)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.15554151945976283, 'e_layers': 1, 'learning_rate': 0.0011342022329016352, 'd_ff': 1536}
[36m(_train_fn pid=839503)[0m Use GPU: cuda:0
[36m(_train_fn pid=839503)[0m train 7825
[36m(_train_fn pid=839503)[0m val 2161
[36m(_train_fn pid=839503)[0m start_epoch 0
[36m(_train_fn pid=839503)[0m max_epoch 8
[36m(_train_fn pid=839503)[0m 	iters: 100, epoch: 1 | loss: 0.8295793
[36m(_train_fn pid=839503)[0m 	speed: 0.0765s/iter; left time: 141.8058s
[36m(_train_fn pid=839503)[0m 	iters: 200, epoch: 1 | loss: 0.6501412
[36m(_train_fn pid=839503)[0m 	speed: 0.0700s/iter; left time: 122.6730s
[36m(_train_fn pid=839503)[0m Updating learning rate to 0.0011342022329016352
[36m(_train_fn pid=839503)[0m saving checkpoint...
[36m(_train_fn pid=839503)[0m Validation loss decreased (inf --> 1.8965).  Saving model state dict ...
[36m(_train_fn pid=839503)[0m Epoch: 1 cost time: 17.471268892288208
[36m(_train_fn pid=839503)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7889250 Vali Loss: 1.8964826 Best vali loss: 1.8964826

Trial status: 152 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:25:51. Total running time: 2hr 4min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 113d5626 with best_valid_loss=1.5623615090526752 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.14282164770205308, 'e_layers': 1, 'learning_rate': 0.0008795984049775422}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-33f85791   RUNNING           1            20.0396       0.788925        1.89648             1.89648 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
147 more TERMINATED
[36m(_train_fn pid=839503)[0m 	iters: 100, epoch: 2 | loss: 0.6692345
[36m(_train_fn pid=839503)[0m 	speed: 0.1226s/iter; left time: 197.2109s
[36m(_train_fn pid=839503)[0m 	iters: 200, epoch: 2 | loss: 0.7055746
[36m(_train_fn pid=839503)[0m 	speed: 0.0700s/iter; left time: 105.6141s
[36m(_train_fn pid=839503)[0m Updating learning rate to 0.0005671011164508176
[36m(_train_fn pid=839503)[0m saving checkpoint...
[36m(_train_fn pid=839503)[0m Validation loss decreased (1.8965 --> 1.5868).  Saving model state dict ...
[36m(_train_fn pid=839503)[0m Epoch: 2 cost time: 17.091301441192627
[36m(_train_fn pid=839503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33f85791_153_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1555,e_layer_2024-08-24_09-25-22/checkpoint_000002)
[36m(_train_fn pid=839503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33f85791_153_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1555,e_layer_2024-08-24_09-25-22/checkpoint_000003)
[36m(_train_fn pid=839503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33f85791_153_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1555,e_layer_2024-08-24_09-25-22/checkpoint_000004)
[36m(_train_fn pid=839503)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-33f85791_153_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1555,e_layer_2024-08-24_09-25-22/checkpoint_000005)
[36m(_train_fn pid=839503)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7622926 Vali Loss: 1.5868294 Best vali loss: 1.5868294
[36m(_train_fn pid=839503)[0m 	iters: 100, epoch: 3 | loss: 0.6751072
[36m(_train_fn pid=839503)[0m 	speed: 0.1227s/iter; left time: 167.4352s
[36m(_train_fn pid=839503)[0m 	iters: 200, epoch: 3 | loss: 0.6463253
[36m(_train_fn pid=839503)[0m 	speed: 0.0701s/iter; left time: 88.6139s
Trial status: 152 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:26:21. Total running time: 2hr 5min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 113d5626 with best_valid_loss=1.5623615090526752 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.14282164770205308, 'e_layers': 1, 'learning_rate': 0.0008795984049775422}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-33f85791   RUNNING           2            39.2907       0.762293        1.58683             1.58683 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
147 more TERMINATED
[36m(_train_fn pid=839503)[0m Updating learning rate to 0.0002835505582254088
[36m(_train_fn pid=839503)[0m saving checkpoint...
[36m(_train_fn pid=839503)[0m Validation loss decreased (1.5868 --> 1.5785).  Saving model state dict ...
[36m(_train_fn pid=839503)[0m Epoch: 3 cost time: 17.109652519226074
[36m(_train_fn pid=839503)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6192856 Vali Loss: 1.5785475 Best vali loss: 1.5785475
[36m(_train_fn pid=839503)[0m 	iters: 100, epoch: 4 | loss: 0.6323276
[36m(_train_fn pid=839503)[0m 	speed: 0.1227s/iter; left time: 137.5077s
[36m(_train_fn pid=839503)[0m 	iters: 200, epoch: 4 | loss: 0.6413342
[36m(_train_fn pid=839503)[0m 	speed: 0.0701s/iter; left time: 71.5827s
[36m(_train_fn pid=839503)[0m Updating learning rate to 0.0001417752791127044
[36m(_train_fn pid=839503)[0m saving checkpoint...
[36m(_train_fn pid=839503)[0m Validation loss decreased (1.5785 --> 1.5662).  Saving model state dict ...
[36m(_train_fn pid=839503)[0m Epoch: 4 cost time: 17.127466440200806
[36m(_train_fn pid=839503)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6150648 Vali Loss: 1.5662361 Best vali loss: 1.5662361
[36m(_train_fn pid=839503)[0m 	iters: 100, epoch: 5 | loss: 0.6052803
[36m(_train_fn pid=839503)[0m 	speed: 0.1229s/iter; left time: 107.7511s
Trial status: 152 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:26:51. Total running time: 2hr 5min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 113d5626 with best_valid_loss=1.5623615090526752 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.14282164770205308, 'e_layers': 1, 'learning_rate': 0.0008795984049775422}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-33f85791   RUNNING           4            77.848        0.615065        1.56624             1.56624 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
147 more TERMINATED
[36m(_train_fn pid=839503)[0m 	iters: 200, epoch: 5 | loss: 0.5487429
[36m(_train_fn pid=839503)[0m 	speed: 0.0702s/iter; left time: 54.5353s
[36m(_train_fn pid=839503)[0m Updating learning rate to 7.08876395563522e-05
[36m(_train_fn pid=839503)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=839503)[0m saving checkpoint...
[36m(_train_fn pid=839503)[0m Epoch: 5 cost time: 17.131014823913574
[36m(_train_fn pid=839503)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6126474 Vali Loss: 1.5670933 Best vali loss: 1.5662361
[36m(_train_fn pid=839503)[0m 	iters: 100, epoch: 6 | loss: 0.5882606
[36m(_train_fn pid=839503)[0m 	speed: 0.1226s/iter; left time: 77.6104s
[36m(_train_fn pid=839503)[0m 	iters: 200, epoch: 6 | loss: 0.5981973
[36m(_train_fn pid=839503)[0m 	speed: 0.0702s/iter; left time: 37.4126s

Trial trial-33f85791 completed after 6 iterations at 2024-08-24 09:27:21. Total running time: 2hr 6min 12s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-33f85791 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.29291 â”‚
â”‚ time_total_s                            116.41622 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56569 â”‚
â”‚ train_loss                                0.61179 â”‚
â”‚ valid_loss                                1.56569 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
2024-08-24 09:27:43,620	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=840363)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5a3162da_154_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1312,e_layer_2024-08-24_09-27-21/checkpoint_000000)
[36m(_train_fn pid=840363)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5a3162da_154_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1312,e_layer_2024-08-24_09-27-21/checkpoint_000001)
[36m(_train_fn pid=839503)[0m Updating learning rate to 3.54438197781761e-05
[36m(_train_fn pid=839503)[0m saving checkpoint...
[36m(_train_fn pid=839503)[0m Validation loss decreased (1.5662 --> 1.5657).  Saving model state dict ...

Trial status: 153 TERMINATED | 1 PENDING
Current time: 2024-08-24 09:27:21. Total running time: 2hr 6min 12s
Logical resource usage: 0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 113d5626 with best_valid_loss=1.5623615090526752 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.14282164770205308, 'e_layers': 1, 'learning_rate': 0.0008795984049775422}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-5a3162da   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
148 more TERMINATED

Trial trial-5a3162da started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5a3162da config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.13123 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00089 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=840363)[0m configuration
[36m(_train_fn pid=840363)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.13122674367670495, 'e_layers': 1, 'learning_rate': 0.000891902957580305, 'd_ff': 1536}
[36m(_train_fn pid=840363)[0m Use GPU: cuda:0
[36m(_train_fn pid=840363)[0m train 7825
[36m(_train_fn pid=840363)[0m val 2161
[36m(_train_fn pid=840363)[0m start_epoch 0
[36m(_train_fn pid=840363)[0m max_epoch 8
[36m(_train_fn pid=840363)[0m 	iters: 100, epoch: 1 | loss: 0.8315042
[36m(_train_fn pid=840363)[0m 	speed: 0.0765s/iter; left time: 141.6874s
[36m(_train_fn pid=840363)[0m 	iters: 200, epoch: 1 | loss: 0.6545150
[36m(_train_fn pid=840363)[0m 	speed: 0.0700s/iter; left time: 122.6950s
[36m(_train_fn pid=840363)[0m Updating learning rate to 0.000891902957580305
[36m(_train_fn pid=840363)[0m saving checkpoint...
[36m(_train_fn pid=840363)[0m Validation loss decreased (inf --> 1.9117).  Saving model state dict ...
[36m(_train_fn pid=840363)[0m Epoch: 1 cost time: 17.464242219924927
[36m(_train_fn pid=840363)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7905911 Vali Loss: 1.9116810 Best vali loss: 1.9116810
[36m(_train_fn pid=840363)[0m 	iters: 100, epoch: 2 | loss: 0.6323014
[36m(_train_fn pid=840363)[0m 	speed: 0.1224s/iter; left time: 196.8901s

Trial status: 153 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:27:51. Total running time: 2hr 6min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 113d5626 with best_valid_loss=1.5623615090526752 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.14282164770205308, 'e_layers': 1, 'learning_rate': 0.0008795984049775422}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5a3162da   RUNNING           1            20.0247       0.790591        1.91168             1.91168 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
148 more TERMINATED
[36m(_train_fn pid=840363)[0m 	iters: 200, epoch: 2 | loss: 0.6928295
[36m(_train_fn pid=840363)[0m 	speed: 0.0700s/iter; left time: 105.6242s
[36m(_train_fn pid=840363)[0m Updating learning rate to 0.0004459514787901525
[36m(_train_fn pid=840363)[0m saving checkpoint...
[36m(_train_fn pid=840363)[0m Validation loss decreased (1.9117 --> 1.5676).  Saving model state dict ...
[36m(_train_fn pid=840363)[0m Epoch: 2 cost time: 17.083088636398315
[36m(_train_fn pid=840363)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6980526 Vali Loss: 1.5676325 Best vali loss: 1.5676325
[36m(_train_fn pid=840363)[0m 	iters: 100, epoch: 3 | loss: 0.6663581
[36m(_train_fn pid=840363)[0m 	speed: 0.1225s/iter; left time: 167.2631s
[36m(_train_fn pid=840363)[0m 	iters: 200, epoch: 3 | loss: 0.6271784
[36m(_train_fn pid=840363)[0m 	speed: 0.0701s/iter; left time: 88.6721s
Trial status: 153 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:28:21. Total running time: 2hr 7min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=840363)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5a3162da_154_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1312,e_layer_2024-08-24_09-27-21/checkpoint_000002)
[36m(_train_fn pid=840363)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5a3162da_154_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1312,e_layer_2024-08-24_09-27-21/checkpoint_000003)
[36m(_train_fn pid=840363)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5a3162da_154_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1312,e_layer_2024-08-24_09-27-21/checkpoint_000004)
[36m(_train_fn pid=840363)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5a3162da_154_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1312,e_layer_2024-08-24_09-27-21/checkpoint_000005)
Current best trial: 113d5626 with best_valid_loss=1.5623615090526752 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.14282164770205308, 'e_layers': 1, 'learning_rate': 0.0008795984049775422}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5a3162da   RUNNING           2            39.2718       0.698053        1.56763             1.56763 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
148 more TERMINATED
[36m(_train_fn pid=840363)[0m Updating learning rate to 0.00022297573939507624
[36m(_train_fn pid=840363)[0m saving checkpoint...
[36m(_train_fn pid=840363)[0m Validation loss decreased (1.5676 --> 1.5663).  Saving model state dict ...
[36m(_train_fn pid=840363)[0m Epoch: 3 cost time: 17.09744644165039
[36m(_train_fn pid=840363)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6152362 Vali Loss: 1.5663428 Best vali loss: 1.5663428
[36m(_train_fn pid=840363)[0m 	iters: 100, epoch: 4 | loss: 0.6337869
[36m(_train_fn pid=840363)[0m 	speed: 0.1226s/iter; left time: 137.4138s
[36m(_train_fn pid=840363)[0m 	iters: 200, epoch: 4 | loss: 0.6360671
[36m(_train_fn pid=840363)[0m 	speed: 0.0700s/iter; left time: 71.4689s
[36m(_train_fn pid=840363)[0m Updating learning rate to 0.00011148786969753812
[36m(_train_fn pid=840363)[0m saving checkpoint...
[36m(_train_fn pid=840363)[0m Validation loss decreased (1.5663 --> 1.5627).  Saving model state dict ...
[36m(_train_fn pid=840363)[0m Epoch: 4 cost time: 17.10715889930725
[36m(_train_fn pid=840363)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6106520 Vali Loss: 1.5627137 Best vali loss: 1.5627137
[36m(_train_fn pid=840363)[0m 	iters: 100, epoch: 5 | loss: 0.6045245
[36m(_train_fn pid=840363)[0m 	speed: 0.1227s/iter; left time: 107.6319s
Trial status: 153 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:28:51. Total running time: 2hr 7min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 113d5626 with best_valid_loss=1.5623615090526752 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.14282164770205308, 'e_layers': 1, 'learning_rate': 0.0008795984049775422}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5a3162da   RUNNING           4            77.7843       0.610652        1.56271             1.56271 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
148 more TERMINATED
[36m(_train_fn pid=840363)[0m 	iters: 200, epoch: 5 | loss: 0.5438626
[36m(_train_fn pid=840363)[0m 	speed: 0.0701s/iter; left time: 54.4600s
[36m(_train_fn pid=840363)[0m Updating learning rate to 5.574393484876906e-05
[36m(_train_fn pid=840363)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=840363)[0m saving checkpoint...
[36m(_train_fn pid=840363)[0m Epoch: 5 cost time: 17.11674165725708
[36m(_train_fn pid=840363)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6088663 Vali Loss: 1.5696028 Best vali loss: 1.5627137
[36m(_train_fn pid=840363)[0m 	iters: 100, epoch: 6 | loss: 0.5816223
[36m(_train_fn pid=840363)[0m 	speed: 0.1224s/iter; left time: 77.4919s
[36m(_train_fn pid=840363)[0m 	iters: 200, epoch: 6 | loss: 0.5934826
[36m(_train_fn pid=840363)[0m 	speed: 0.0701s/iter; left time: 37.3730s

Trial trial-5a3162da completed after 6 iterations at 2024-08-24 09:29:19. Total running time: 2hr 8min 11s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5a3162da result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.28082 â”‚
â”‚ time_total_s                            116.32017 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56185 â”‚
â”‚ train_loss                                 0.6081 â”‚
â”‚ valid_loss                                1.56185 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=840363)[0m Updating learning rate to 2.787196742438453e-05
[36m(_train_fn pid=840363)[0m saving checkpoint...
[36m(_train_fn pid=840363)[0m Validation loss decreased (1.5627 --> 1.5618).  Saving model state dict ...

Trial status: 154 TERMINATED | 1 PENDING
Current time: 2024-08-24 09:29:21. Total running time: 2hr 8min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 09:29:41,673	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=841218)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4d6541d2_155_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1730,e_layer_2024-08-24_09-29-19/checkpoint_000000)
[36m(_train_fn pid=841218)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4d6541d2_155_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1730,e_layer_2024-08-24_09-29-19/checkpoint_000001)
[36m(_train_fn pid=841218)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4d6541d2_155_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1730,e_layer_2024-08-24_09-29-19/checkpoint_000002)
Current best trial: 5a3162da with best_valid_loss=1.56184813157836 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.13122674367670495, 'e_layers': 1, 'learning_rate': 0.000891902957580305}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-4d6541d2   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
149 more TERMINATED

Trial trial-4d6541d2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4d6541d2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17302 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00088 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=841218)[0m configuration
[36m(_train_fn pid=841218)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457, 'd_ff': 1536}
[36m(_train_fn pid=841218)[0m Use GPU: cuda:0
[36m(_train_fn pid=841218)[0m train 7825
[36m(_train_fn pid=841218)[0m val 2161
[36m(_train_fn pid=841218)[0m start_epoch 0
[36m(_train_fn pid=841218)[0m max_epoch 8
[36m(_train_fn pid=841218)[0m 	iters: 100, epoch: 1 | loss: 0.8381280
[36m(_train_fn pid=841218)[0m 	speed: 0.0767s/iter; left time: 142.0352s
[36m(_train_fn pid=841218)[0m 	iters: 200, epoch: 1 | loss: 0.6549359
[36m(_train_fn pid=841218)[0m 	speed: 0.0700s/iter; left time: 122.6863s
[36m(_train_fn pid=841218)[0m Updating learning rate to 0.0008798898128670457
[36m(_train_fn pid=841218)[0m saving checkpoint...
[36m(_train_fn pid=841218)[0m Validation loss decreased (inf --> 1.9155).  Saving model state dict ...
[36m(_train_fn pid=841218)[0m Epoch: 1 cost time: 17.493162631988525
[36m(_train_fn pid=841218)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7979117 Vali Loss: 1.9154972 Best vali loss: 1.9154972
[36m(_train_fn pid=841218)[0m 	iters: 100, epoch: 2 | loss: 0.6365429
[36m(_train_fn pid=841218)[0m 	speed: 0.1227s/iter; left time: 197.4022s

Trial status: 154 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:29:51. Total running time: 2hr 8min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 5a3162da with best_valid_loss=1.56184813157836 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.13122674367670495, 'e_layers': 1, 'learning_rate': 0.000891902957580305}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4d6541d2   RUNNING           1            20.0632       0.797912        1.9155              1.9155  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
149 more TERMINATED
[36m(_train_fn pid=841218)[0m 	iters: 200, epoch: 2 | loss: 0.6918601
[36m(_train_fn pid=841218)[0m 	speed: 0.0700s/iter; left time: 105.5608s
[36m(_train_fn pid=841218)[0m Updating learning rate to 0.00043994490643352286
[36m(_train_fn pid=841218)[0m saving checkpoint...
[36m(_train_fn pid=841218)[0m Validation loss decreased (1.9155 --> 1.5704).  Saving model state dict ...
[36m(_train_fn pid=841218)[0m Epoch: 2 cost time: 17.099647521972656
[36m(_train_fn pid=841218)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6956031 Vali Loss: 1.5703787 Best vali loss: 1.5703787
[36m(_train_fn pid=841218)[0m 	iters: 100, epoch: 3 | loss: 0.6708198
[36m(_train_fn pid=841218)[0m 	speed: 0.1226s/iter; left time: 167.3816s
[36m(_train_fn pid=841218)[0m 	iters: 200, epoch: 3 | loss: 0.6296027
[36m(_train_fn pid=841218)[0m 	speed: 0.0700s/iter; left time: 88.6033s
[36m(_train_fn pid=841218)[0m Updating learning rate to 0.00021997245321676143
[36m(_train_fn pid=841218)[0m saving checkpoint...
[36m(_train_fn pid=841218)[0m Validation loss decreased (1.5704 --> 1.5681).  Saving model state dict ...
[36m(_train_fn pid=841218)[0m Epoch: 3 cost time: 17.108264684677124
[36m(_train_fn pid=841218)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6151278 Vali Loss: 1.5680886 Best vali loss: 1.5680886
Trial status: 154 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:30:21. Total running time: 2hr 9min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=841218)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4d6541d2_155_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1730,e_layer_2024-08-24_09-29-19/checkpoint_000003)
[36m(_train_fn pid=841218)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4d6541d2_155_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1730,e_layer_2024-08-24_09-29-19/checkpoint_000004)
[36m(_train_fn pid=841218)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4d6541d2_155_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1730,e_layer_2024-08-24_09-29-19/checkpoint_000005)
Current best trial: 5a3162da with best_valid_loss=1.56184813157836 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.13122674367670495, 'e_layers': 1, 'learning_rate': 0.000891902957580305}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4d6541d2   RUNNING           3            58.5812       0.615128        1.56809             1.56809 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
149 more TERMINATED
[36m(_train_fn pid=841218)[0m 	iters: 100, epoch: 4 | loss: 0.6303860
[36m(_train_fn pid=841218)[0m 	speed: 0.1226s/iter; left time: 137.4717s
[36m(_train_fn pid=841218)[0m 	iters: 200, epoch: 4 | loss: 0.6365632
[36m(_train_fn pid=841218)[0m 	speed: 0.0701s/iter; left time: 71.5679s
[36m(_train_fn pid=841218)[0m Updating learning rate to 0.00010998622660838071
[36m(_train_fn pid=841218)[0m saving checkpoint...
[36m(_train_fn pid=841218)[0m Validation loss decreased (1.5681 --> 1.5616).  Saving model state dict ...
[36m(_train_fn pid=841218)[0m Epoch: 4 cost time: 17.115564346313477
[36m(_train_fn pid=841218)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6110037 Vali Loss: 1.5615533 Best vali loss: 1.5615533
[36m(_train_fn pid=841218)[0m 	iters: 100, epoch: 5 | loss: 0.6053160
[36m(_train_fn pid=841218)[0m 	speed: 0.1229s/iter; left time: 107.7523s
Trial status: 154 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:30:51. Total running time: 2hr 9min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.561553270069521 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4d6541d2   RUNNING           4            77.8577       0.611004        1.56155             1.56155 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
149 more TERMINATED
[36m(_train_fn pid=841218)[0m 	iters: 200, epoch: 5 | loss: 0.5441235
[36m(_train_fn pid=841218)[0m 	speed: 0.0701s/iter; left time: 54.4876s
[36m(_train_fn pid=841218)[0m Updating learning rate to 5.499311330419036e-05
[36m(_train_fn pid=841218)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=841218)[0m saving checkpoint...
[36m(_train_fn pid=841218)[0m Epoch: 5 cost time: 17.1300265789032
[36m(_train_fn pid=841218)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6090529 Vali Loss: 1.5625992 Best vali loss: 1.5615533
[36m(_train_fn pid=841218)[0m 	iters: 100, epoch: 6 | loss: 0.5819889
[36m(_train_fn pid=841218)[0m 	speed: 0.1226s/iter; left time: 77.5877s
[36m(_train_fn pid=841218)[0m 	iters: 200, epoch: 6 | loss: 0.5934258
[36m(_train_fn pid=841218)[0m 	speed: 0.0702s/iter; left time: 37.3968s
[36m(_train_fn pid=841218)[0m Updating learning rate to 2.749655665209518e-05
[36m(_train_fn pid=841218)[0m saving checkpoint...
[36m(_train_fn pid=841218)[0m Validation loss decreased (1.5616 --> 1.5605).  Saving model state dict ...

Trial trial-4d6541d2 completed after 6 iterations at 2024-08-24 09:31:18. Total running time: 2hr 10min 9s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4d6541d2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.27962 â”‚
â”‚ time_total_s                            116.41211 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56048 â”‚
â”‚ train_loss                                0.60819 â”‚
â”‚ valid_loss                                1.56048 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-d9e723f0 started with configuration:
[36m(_train_fn pid=842082)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d9e723f0_156_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2172,e_layer_2024-08-24_09-31-18/checkpoint_000000)
2024-08-24 09:31:40,662	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=842082)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d9e723f0_156_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2172,e_layer_2024-08-24_09-31-18/checkpoint_000001)
[36m(_train_fn pid=842082)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d9e723f0_156_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2172,e_layer_2024-08-24_09-31-18/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d9e723f0 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.21716 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00086 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=842082)[0m configuration
[36m(_train_fn pid=842082)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.21715769635436494, 'e_layers': 1, 'learning_rate': 0.0008587221909287304, 'd_ff': 1536}
[36m(_train_fn pid=842082)[0m Use GPU: cuda:0
[36m(_train_fn pid=842082)[0m train 7825
[36m(_train_fn pid=842082)[0m val 2161
[36m(_train_fn pid=842082)[0m start_epoch 0
[36m(_train_fn pid=842082)[0m max_epoch 8

Trial status: 155 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:31:21. Total running time: 2hr 10min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d9e723f0   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
150 more TERMINATED
[36m(_train_fn pid=842082)[0m 	iters: 100, epoch: 1 | loss: 0.8465226
[36m(_train_fn pid=842082)[0m 	speed: 0.0766s/iter; left time: 141.9958s
[36m(_train_fn pid=842082)[0m 	iters: 200, epoch: 1 | loss: 0.6550445
[36m(_train_fn pid=842082)[0m 	speed: 0.0700s/iter; left time: 122.6733s
[36m(_train_fn pid=842082)[0m Updating learning rate to 0.0008587221909287304
[36m(_train_fn pid=842082)[0m saving checkpoint...
[36m(_train_fn pid=842082)[0m Validation loss decreased (inf --> 1.9191).  Saving model state dict ...
[36m(_train_fn pid=842082)[0m Epoch: 1 cost time: 17.482972860336304
[36m(_train_fn pid=842082)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8056159 Vali Loss: 1.9191473 Best vali loss: 1.9191473
[36m(_train_fn pid=842082)[0m 	iters: 100, epoch: 2 | loss: 0.6368515
[36m(_train_fn pid=842082)[0m 	speed: 0.1226s/iter; left time: 197.2128s
Trial status: 155 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:31:51. Total running time: 2hr 10min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d9e723f0   RUNNING           1            20.0506       0.805616        1.91915             1.91915 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
150 more TERMINATED
[36m(_train_fn pid=842082)[0m 	iters: 200, epoch: 2 | loss: 0.6967353
[36m(_train_fn pid=842082)[0m 	speed: 0.0700s/iter; left time: 105.6161s
[36m(_train_fn pid=842082)[0m Updating learning rate to 0.0004293610954643652
[36m(_train_fn pid=842082)[0m saving checkpoint...
[36m(_train_fn pid=842082)[0m Validation loss decreased (1.9191 --> 1.5722).  Saving model state dict ...
[36m(_train_fn pid=842082)[0m Epoch: 2 cost time: 17.089762210845947
[36m(_train_fn pid=842082)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6966806 Vali Loss: 1.5722266 Best vali loss: 1.5722266
[36m(_train_fn pid=842082)[0m 	iters: 100, epoch: 3 | loss: 0.6723650
[36m(_train_fn pid=842082)[0m 	speed: 0.1227s/iter; left time: 167.4301s
[36m(_train_fn pid=842082)[0m 	iters: 200, epoch: 3 | loss: 0.6284603
[36m(_train_fn pid=842082)[0m 	speed: 0.0701s/iter; left time: 88.6669s
[36m(_train_fn pid=842082)[0m Updating learning rate to 0.0002146805477321826
[36m(_train_fn pid=842082)[0m saving checkpoint...
[36m(_train_fn pid=842082)[0m Validation loss decreased (1.5722 --> 1.5682).  Saving model state dict ...
[36m(_train_fn pid=842082)[0m Epoch: 3 cost time: 17.12167263031006
[36m(_train_fn pid=842082)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6153812 Vali Loss: 1.5681811 Best vali loss: 1.5681811
Trial status: 155 TERMINATED | 1 RUNNING
[36m(_train_fn pid=842082)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d9e723f0_156_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2172,e_layer_2024-08-24_09-31-18/checkpoint_000003)
[36m(_train_fn pid=842082)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d9e723f0_156_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2172,e_layer_2024-08-24_09-31-18/checkpoint_000004)
[36m(_train_fn pid=842082)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d9e723f0_156_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2172,e_layer_2024-08-24_09-31-18/checkpoint_000005)
Current time: 2024-08-24 09:32:21. Total running time: 2hr 11min 12s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d9e723f0   RUNNING           3            58.5828       0.615381        1.56818             1.56818 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
150 more TERMINATED
[36m(_train_fn pid=842082)[0m 	iters: 100, epoch: 4 | loss: 0.6331668
[36m(_train_fn pid=842082)[0m 	speed: 0.1228s/iter; left time: 137.6950s
[36m(_train_fn pid=842082)[0m 	iters: 200, epoch: 4 | loss: 0.6344267
[36m(_train_fn pid=842082)[0m 	speed: 0.0702s/iter; left time: 71.6401s
[36m(_train_fn pid=842082)[0m Updating learning rate to 0.0001073402738660913
[36m(_train_fn pid=842082)[0m saving checkpoint...
[36m(_train_fn pid=842082)[0m Validation loss decreased (1.5682 --> 1.5641).  Saving model state dict ...
[36m(_train_fn pid=842082)[0m Epoch: 4 cost time: 17.131364107131958
[36m(_train_fn pid=842082)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6115063 Vali Loss: 1.5640895 Best vali loss: 1.5640895
[36m(_train_fn pid=842082)[0m 	iters: 100, epoch: 5 | loss: 0.6057125
[36m(_train_fn pid=842082)[0m 	speed: 0.1229s/iter; left time: 107.8114s
Trial status: 155 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:32:51. Total running time: 2hr 11min 42s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d9e723f0   RUNNING           4            77.8829       0.611506        1.56409             1.56409 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
150 more TERMINATED
[36m(_train_fn pid=842082)[0m 	iters: 200, epoch: 5 | loss: 0.5449637
[36m(_train_fn pid=842082)[0m 	speed: 0.0702s/iter; left time: 54.5700s
[36m(_train_fn pid=842082)[0m Updating learning rate to 5.367013693304565e-05
[36m(_train_fn pid=842082)[0m saving checkpoint...
[36m(_train_fn pid=842082)[0m Validation loss decreased (1.5641 --> 1.5629).  Saving model state dict ...
[36m(_train_fn pid=842082)[0m Epoch: 5 cost time: 17.15337562561035
[36m(_train_fn pid=842082)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6093966 Vali Loss: 1.5628618 Best vali loss: 1.5628618
[36m(_train_fn pid=842082)[0m 	iters: 100, epoch: 6 | loss: 0.5831827
[36m(_train_fn pid=842082)[0m 	speed: 0.1229s/iter; left time: 77.8053s
[36m(_train_fn pid=842082)[0m 	iters: 200, epoch: 6 | loss: 0.5937173
[36m(_train_fn pid=842082)[0m 	speed: 0.0701s/iter; left time: 37.3826s

Trial trial-d9e723f0 completed after 6 iterations at 2024-08-24 09:33:17. Total running time: 2hr 12min 8s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d9e723f0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.27964 â”‚
â”‚ time_total_s                            116.47587 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56156 â”‚
â”‚ train_loss                                 0.6086 â”‚
â”‚ valid_loss                                1.56156 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=842082)[0m Updating learning rate to 2.6835068466522826e-05
[36m(_train_fn pid=842082)[0m saving checkpoint...
[36m(_train_fn pid=842082)[0m Validation loss decreased (1.5629 --> 1.5616).  Saving model state dict ...

Trial trial-18e6cfa9 started with configuration:
2024-08-24 09:33:39,652	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=842946)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18e6cfa9_157_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2553,e_layer_2024-08-24_09-33-17/checkpoint_000000)
[36m(_train_fn pid=842946)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18e6cfa9_157_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2553,e_layer_2024-08-24_09-33-17/checkpoint_000001)
[36m(_train_fn pid=842946)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18e6cfa9_157_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2553,e_layer_2024-08-24_09-33-17/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-18e6cfa9 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.25526 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00087 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=842946)[0m configuration
[36m(_train_fn pid=842946)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.2552560109235833, 'e_layers': 1, 'learning_rate': 0.0008731059694251077, 'd_ff': 1536}
[36m(_train_fn pid=842946)[0m Use GPU: cuda:0
[36m(_train_fn pid=842946)[0m train 7825
[36m(_train_fn pid=842946)[0m val 2161
[36m(_train_fn pid=842946)[0m start_epoch 0
[36m(_train_fn pid=842946)[0m max_epoch 8

Trial status: 156 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:33:21. Total running time: 2hr 12min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-18e6cfa9   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
151 more TERMINATED
[36m(_train_fn pid=842946)[0m 	iters: 100, epoch: 1 | loss: 0.8494315
[36m(_train_fn pid=842946)[0m 	speed: 0.0766s/iter; left time: 141.8487s
[36m(_train_fn pid=842946)[0m 	iters: 200, epoch: 1 | loss: 0.6537794
[36m(_train_fn pid=842946)[0m 	speed: 0.0699s/iter; left time: 122.6056s
[36m(_train_fn pid=842946)[0m Updating learning rate to 0.0008731059694251077
[36m(_train_fn pid=842946)[0m saving checkpoint...
[36m(_train_fn pid=842946)[0m Validation loss decreased (inf --> 1.9208).  Saving model state dict ...
[36m(_train_fn pid=842946)[0m Epoch: 1 cost time: 17.46529459953308
[36m(_train_fn pid=842946)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8110120 Vali Loss: 1.9207821 Best vali loss: 1.9207821
[36m(_train_fn pid=842946)[0m 	iters: 100, epoch: 2 | loss: 0.6440805
[36m(_train_fn pid=842946)[0m 	speed: 0.1225s/iter; left time: 197.0811s
Trial status: 156 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:33:51. Total running time: 2hr 12min 43s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-18e6cfa9   RUNNING           1            20.0391       0.811012        1.92078             1.92078 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
151 more TERMINATED
[36m(_train_fn pid=842946)[0m 	iters: 200, epoch: 2 | loss: 0.6926048
[36m(_train_fn pid=842946)[0m 	speed: 0.0700s/iter; left time: 105.6103s
[36m(_train_fn pid=842946)[0m Updating learning rate to 0.00043655298471255384
[36m(_train_fn pid=842946)[0m saving checkpoint...
[36m(_train_fn pid=842946)[0m Validation loss decreased (1.9208 --> 1.5720).  Saving model state dict ...
[36m(_train_fn pid=842946)[0m Epoch: 2 cost time: 17.08082389831543
[36m(_train_fn pid=842946)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6948325 Vali Loss: 1.5719632 Best vali loss: 1.5719632
[36m(_train_fn pid=842946)[0m 	iters: 100, epoch: 3 | loss: 0.6666496
[36m(_train_fn pid=842946)[0m 	speed: 0.1224s/iter; left time: 167.1432s
[36m(_train_fn pid=842946)[0m 	iters: 200, epoch: 3 | loss: 0.6265902
[36m(_train_fn pid=842946)[0m 	speed: 0.0700s/iter; left time: 88.5235s
[36m(_train_fn pid=842946)[0m Updating learning rate to 0.00021827649235627692
[36m(_train_fn pid=842946)[0m saving checkpoint...
[36m(_train_fn pid=842946)[0m Validation loss decreased (1.5720 --> 1.5683).  Saving model state dict ...
[36m(_train_fn pid=842946)[0m Epoch: 3 cost time: 17.0910804271698
[36m(_train_fn pid=842946)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6145818 Vali Loss: 1.5682558 Best vali loss: 1.5682558
Trial status: 156 TERMINATED | 1 RUNNING
[36m(_train_fn pid=842946)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18e6cfa9_157_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2553,e_layer_2024-08-24_09-33-17/checkpoint_000003)
[36m(_train_fn pid=842946)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18e6cfa9_157_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2553,e_layer_2024-08-24_09-33-17/checkpoint_000004)
[36m(_train_fn pid=842946)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-18e6cfa9_157_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2553,e_layer_2024-08-24_09-33-17/checkpoint_000005)
Current time: 2024-08-24 09:34:21. Total running time: 2hr 13min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-18e6cfa9   RUNNING           3            58.5212       0.614582        1.56826             1.56826 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
151 more TERMINATED
[36m(_train_fn pid=842946)[0m 	iters: 100, epoch: 4 | loss: 0.6298919
[36m(_train_fn pid=842946)[0m 	speed: 0.1226s/iter; left time: 137.4238s
[36m(_train_fn pid=842946)[0m 	iters: 200, epoch: 4 | loss: 0.6339181
[36m(_train_fn pid=842946)[0m 	speed: 0.0701s/iter; left time: 71.5227s
[36m(_train_fn pid=842946)[0m Updating learning rate to 0.00010913824617813846
[36m(_train_fn pid=842946)[0m saving checkpoint...
[36m(_train_fn pid=842946)[0m Validation loss decreased (1.5683 --> 1.5664).  Saving model state dict ...
[36m(_train_fn pid=842946)[0m Epoch: 4 cost time: 17.097373247146606
[36m(_train_fn pid=842946)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6105362 Vali Loss: 1.5664372 Best vali loss: 1.5664372
[36m(_train_fn pid=842946)[0m 	iters: 100, epoch: 5 | loss: 0.6051289
[36m(_train_fn pid=842946)[0m 	speed: 0.1227s/iter; left time: 107.6019s
[36m(_train_fn pid=842946)[0m 	iters: 200, epoch: 5 | loss: 0.5444229
[36m(_train_fn pid=842946)[0m 	speed: 0.0701s/iter; left time: 54.5050s
Trial status: 156 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:34:51. Total running time: 2hr 13min 43s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-18e6cfa9   RUNNING           4            77.7738       0.610536        1.56644             1.56644 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
151 more TERMINATED
[36m(_train_fn pid=842946)[0m Updating learning rate to 5.456912308906923e-05
[36m(_train_fn pid=842946)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=842946)[0m saving checkpoint...
[36m(_train_fn pid=842946)[0m Epoch: 5 cost time: 17.133736610412598
[36m(_train_fn pid=842946)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6089926 Vali Loss: 1.5670919 Best vali loss: 1.5664372
[36m(_train_fn pid=842946)[0m 	iters: 100, epoch: 6 | loss: 0.5816302
[36m(_train_fn pid=842946)[0m 	speed: 0.1224s/iter; left time: 77.4821s
[36m(_train_fn pid=842946)[0m 	iters: 200, epoch: 6 | loss: 0.5934435
[36m(_train_fn pid=842946)[0m 	speed: 0.0701s/iter; left time: 37.3744s

Trial trial-18e6cfa9 completed after 6 iterations at 2024-08-24 09:35:15. Total running time: 2hr 14min 7s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-18e6cfa9 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          19.2675 â”‚
â”‚ time_total_s                            116.30804 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56359 â”‚
â”‚ train_loss                                0.60817 â”‚
â”‚ valid_loss                                1.56359 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=842946)[0m Updating learning rate to 2.7284561544534615e-05
[36m(_train_fn pid=842946)[0m saving checkpoint...
[36m(_train_fn pid=842946)[0m Validation loss decreased (1.5664 --> 1.5636).  Saving model state dict ...

Trial trial-fbb451de started with configuration:
2024-08-24 09:35:37,694	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=843802)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fbb451de_158_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1924,e_layer_2024-08-24_09-35-15/checkpoint_000000)
[36m(_train_fn pid=843802)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fbb451de_158_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1924,e_layer_2024-08-24_09-35-15/checkpoint_000001)
[36m(_train_fn pid=843802)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fbb451de_158_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1924,e_layer_2024-08-24_09-35-15/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fbb451de config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19237 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00085 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=843802)[0m configuration
[36m(_train_fn pid=843802)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993, 'd_ff': 1536}
[36m(_train_fn pid=843802)[0m Use GPU: cuda:0
[36m(_train_fn pid=843802)[0m train 7825
[36m(_train_fn pid=843802)[0m val 2161
[36m(_train_fn pid=843802)[0m start_epoch 0
[36m(_train_fn pid=843802)[0m max_epoch 8

Trial status: 157 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:35:22. Total running time: 2hr 14min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fbb451de   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
152 more TERMINATED
[36m(_train_fn pid=843802)[0m 	iters: 100, epoch: 1 | loss: 0.8431205
[36m(_train_fn pid=843802)[0m 	speed: 0.0766s/iter; left time: 142.0277s
[36m(_train_fn pid=843802)[0m 	iters: 200, epoch: 1 | loss: 0.6558899
[36m(_train_fn pid=843802)[0m 	speed: 0.0700s/iter; left time: 122.6569s
[36m(_train_fn pid=843802)[0m Updating learning rate to 0.0008450451542293993
[36m(_train_fn pid=843802)[0m saving checkpoint...
[36m(_train_fn pid=843802)[0m Validation loss decreased (inf --> 1.9183).  Saving model state dict ...
[36m(_train_fn pid=843802)[0m Epoch: 1 cost time: 17.4839026927948
[36m(_train_fn pid=843802)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8022116 Vali Loss: 1.9183235 Best vali loss: 1.9183235
[36m(_train_fn pid=843802)[0m 	iters: 100, epoch: 2 | loss: 0.6478056
[36m(_train_fn pid=843802)[0m 	speed: 0.1225s/iter; left time: 197.0677s
[36m(_train_fn pid=843802)[0m 	iters: 200, epoch: 2 | loss: 0.6909218
[36m(_train_fn pid=843802)[0m 	speed: 0.0700s/iter; left time: 105.5888s
Trial status: 157 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:35:52. Total running time: 2hr 14min 43s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fbb451de   RUNNING           1            20.0549       0.802212        1.91832             1.91832 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
152 more TERMINATED
[36m(_train_fn pid=843802)[0m Updating learning rate to 0.00042252257711469966
[36m(_train_fn pid=843802)[0m saving checkpoint...
[36m(_train_fn pid=843802)[0m Validation loss decreased (1.9183 --> 1.5695).  Saving model state dict ...
[36m(_train_fn pid=843802)[0m Epoch: 2 cost time: 17.086066484451294
[36m(_train_fn pid=843802)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6938299 Vali Loss: 1.5695166 Best vali loss: 1.5695166
[36m(_train_fn pid=843802)[0m 	iters: 100, epoch: 3 | loss: 0.6672041
[36m(_train_fn pid=843802)[0m 	speed: 0.1227s/iter; left time: 167.4228s
[36m(_train_fn pid=843802)[0m 	iters: 200, epoch: 3 | loss: 0.6278279
[36m(_train_fn pid=843802)[0m 	speed: 0.0701s/iter; left time: 88.6374s
[36m(_train_fn pid=843802)[0m Updating learning rate to 0.00021126128855734983
[36m(_train_fn pid=843802)[0m saving checkpoint...
[36m(_train_fn pid=843802)[0m Validation loss decreased (1.5695 --> 1.5658).  Saving model state dict ...
[36m(_train_fn pid=843802)[0m Epoch: 3 cost time: 17.11706781387329
[36m(_train_fn pid=843802)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6149548 Vali Loss: 1.5657930 Best vali loss: 1.5657930
Trial status: 157 TERMINATED | 1 RUNNING
[36m(_train_fn pid=843802)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fbb451de_158_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1924,e_layer_2024-08-24_09-35-15/checkpoint_000003)
[36m(_train_fn pid=843802)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fbb451de_158_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1924,e_layer_2024-08-24_09-35-15/checkpoint_000004)
[36m(_train_fn pid=843802)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fbb451de_158_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1924,e_layer_2024-08-24_09-35-15/checkpoint_000005)
Current time: 2024-08-24 09:36:22. Total running time: 2hr 15min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fbb451de   RUNNING           3            58.5789       0.614955        1.56579             1.56579 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
152 more TERMINATED
[36m(_train_fn pid=843802)[0m 	iters: 100, epoch: 4 | loss: 0.6316949
[36m(_train_fn pid=843802)[0m 	speed: 0.1227s/iter; left time: 137.5673s
[36m(_train_fn pid=843802)[0m 	iters: 200, epoch: 4 | loss: 0.6377921
[36m(_train_fn pid=843802)[0m 	speed: 0.0700s/iter; left time: 71.5085s
[36m(_train_fn pid=843802)[0m Updating learning rate to 0.00010563064427867492
[36m(_train_fn pid=843802)[0m saving checkpoint...
[36m(_train_fn pid=843802)[0m Validation loss decreased (1.5658 --> 1.5611).  Saving model state dict ...
[36m(_train_fn pid=843802)[0m Epoch: 4 cost time: 17.099815845489502
[36m(_train_fn pid=843802)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6107267 Vali Loss: 1.5611131 Best vali loss: 1.5611131
[36m(_train_fn pid=843802)[0m 	iters: 100, epoch: 5 | loss: 0.6051970
[36m(_train_fn pid=843802)[0m 	speed: 0.1226s/iter; left time: 107.4957s
[36m(_train_fn pid=843802)[0m 	iters: 200, epoch: 5 | loss: 0.5440409
[36m(_train_fn pid=843802)[0m 	speed: 0.0701s/iter; left time: 54.4512s
Trial status: 157 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:36:52. Total running time: 2hr 15min 43s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: 4d6541d2 with best_valid_loss=1.5604774791802933 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.17302382897119806, 'e_layers': 1, 'learning_rate': 0.0008798898128670457}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fbb451de   RUNNING           4            77.8344       0.610727        1.56111             1.56111 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
152 more TERMINATED
[36m(_train_fn pid=843802)[0m Updating learning rate to 5.281532213933746e-05
[36m(_train_fn pid=843802)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=843802)[0m saving checkpoint...
[36m(_train_fn pid=843802)[0m Epoch: 5 cost time: 17.112184762954712
[36m(_train_fn pid=843802)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6088643 Vali Loss: 1.5627595 Best vali loss: 1.5611131
[36m(_train_fn pid=843802)[0m 	iters: 100, epoch: 6 | loss: 0.5815430
[36m(_train_fn pid=843802)[0m 	speed: 0.1223s/iter; left time: 77.4437s
[36m(_train_fn pid=843802)[0m 	iters: 200, epoch: 6 | loss: 0.5930427
[36m(_train_fn pid=843802)[0m 	speed: 0.0701s/iter; left time: 37.3535s

Trial trial-fbb451de completed after 6 iterations at 2024-08-24 09:37:13. Total running time: 2hr 16min 5s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fbb451de result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.25351 â”‚
â”‚ time_total_s                            116.33811 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56013 â”‚
â”‚ train_loss                                0.60811 â”‚
â”‚ valid_loss                                1.56013 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=843802)[0m Updating learning rate to 2.640766106966873e-05
[36m(_train_fn pid=843802)[0m saving checkpoint...
[36m(_train_fn pid=843802)[0m Validation loss decreased (1.5611 --> 1.5601).  Saving model state dict ...

Trial trial-b58a1502 started with configuration:
2024-08-24 09:37:35,657	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=844656)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b58a1502_159_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1970,e_layer_2024-08-24_09-37-14/checkpoint_000000)
[36m(_train_fn pid=844656)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b58a1502_159_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1970,e_layer_2024-08-24_09-37-14/checkpoint_000001)
[36m(_train_fn pid=844656)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b58a1502_159_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1970,e_layer_2024-08-24_09-37-14/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b58a1502 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                              0.197 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00123 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=844656)[0m configuration
[36m(_train_fn pid=844656)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19700120471547936, 'e_layers': 1, 'learning_rate': 0.0012290778113164629, 'd_ff': 1536}
[36m(_train_fn pid=844656)[0m Use GPU: cuda:0
[36m(_train_fn pid=844656)[0m train 7825
[36m(_train_fn pid=844656)[0m val 2161
[36m(_train_fn pid=844656)[0m start_epoch 0
[36m(_train_fn pid=844656)[0m max_epoch 8

Trial status: 158 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:37:22. Total running time: 2hr 16min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b58a1502   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
153 more TERMINATED
[36m(_train_fn pid=844656)[0m 	iters: 100, epoch: 1 | loss: 0.8319979
[36m(_train_fn pid=844656)[0m 	speed: 0.0764s/iter; left time: 141.6398s
[36m(_train_fn pid=844656)[0m 	iters: 200, epoch: 1 | loss: 0.6491140
[36m(_train_fn pid=844656)[0m 	speed: 0.0700s/iter; left time: 122.6850s
[36m(_train_fn pid=844656)[0m Updating learning rate to 0.0012290778113164629
[36m(_train_fn pid=844656)[0m saving checkpoint...
[36m(_train_fn pid=844656)[0m Validation loss decreased (inf --> 1.8935).  Saving model state dict ...
[36m(_train_fn pid=844656)[0m Epoch: 1 cost time: 17.47098708152771
[36m(_train_fn pid=844656)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7927713 Vali Loss: 1.8935201 Best vali loss: 1.8935201
[36m(_train_fn pid=844656)[0m 	iters: 100, epoch: 2 | loss: 0.6764748
[36m(_train_fn pid=844656)[0m 	speed: 0.1225s/iter; left time: 197.1687s
[36m(_train_fn pid=844656)[0m 	iters: 200, epoch: 2 | loss: 0.7090786
[36m(_train_fn pid=844656)[0m 	speed: 0.0700s/iter; left time: 105.6331s
Trial status: 158 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:37:52. Total running time: 2hr 16min 43s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b58a1502   RUNNING           1            20.0449       0.792771        1.89352             1.89352 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
153 more TERMINATED
[36m(_train_fn pid=844656)[0m Updating learning rate to 0.0006145389056582314
[36m(_train_fn pid=844656)[0m saving checkpoint...
[36m(_train_fn pid=844656)[0m Validation loss decreased (1.8935 --> 1.5860).  Saving model state dict ...
[36m(_train_fn pid=844656)[0m Epoch: 2 cost time: 17.08531141281128
[36m(_train_fn pid=844656)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7890006 Vali Loss: 1.5859853 Best vali loss: 1.5859853
[36m(_train_fn pid=844656)[0m 	iters: 100, epoch: 3 | loss: 0.6819447
[36m(_train_fn pid=844656)[0m 	speed: 0.1226s/iter; left time: 167.3043s
[36m(_train_fn pid=844656)[0m 	iters: 200, epoch: 3 | loss: 0.6360748
[36m(_train_fn pid=844656)[0m 	speed: 0.0700s/iter; left time: 88.5293s
[36m(_train_fn pid=844656)[0m Updating learning rate to 0.0003072694528291157
[36m(_train_fn pid=844656)[0m saving checkpoint...
[36m(_train_fn pid=844656)[0m Validation loss decreased (1.5860 --> 1.5792).  Saving model state dict ...
[36m(_train_fn pid=844656)[0m Epoch: 3 cost time: 17.097666263580322
[36m(_train_fn pid=844656)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6204396 Vali Loss: 1.5792173 Best vali loss: 1.5792173
[36m(_train_fn pid=844656)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b58a1502_159_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1970,e_layer_2024-08-24_09-37-14/checkpoint_000003)
[36m(_train_fn pid=844656)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b58a1502_159_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1970,e_layer_2024-08-24_09-37-14/checkpoint_000004)
[36m(_train_fn pid=844656)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b58a1502_159_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1970,e_layer_2024-08-24_09-37-14/checkpoint_000005)
[36m(_train_fn pid=844656)[0m 	iters: 100, epoch: 4 | loss: 0.6322775
[36m(_train_fn pid=844656)[0m 	speed: 0.1226s/iter; left time: 137.4892s
Trial status: 158 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:38:22. Total running time: 2hr 17min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b58a1502   RUNNING           3            58.5454       0.62044         1.57922             1.57922 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
153 more TERMINATED
[36m(_train_fn pid=844656)[0m 	iters: 200, epoch: 4 | loss: 0.6408907
[36m(_train_fn pid=844656)[0m 	speed: 0.0701s/iter; left time: 71.5536s
[36m(_train_fn pid=844656)[0m Updating learning rate to 0.00015363472641455786
[36m(_train_fn pid=844656)[0m saving checkpoint...
[36m(_train_fn pid=844656)[0m Validation loss decreased (1.5792 --> 1.5681).  Saving model state dict ...
[36m(_train_fn pid=844656)[0m Epoch: 4 cost time: 17.10458207130432
[36m(_train_fn pid=844656)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6154380 Vali Loss: 1.5681075 Best vali loss: 1.5681075
[36m(_train_fn pid=844656)[0m 	iters: 100, epoch: 5 | loss: 0.6060801
[36m(_train_fn pid=844656)[0m 	speed: 0.1228s/iter; left time: 107.6884s
[36m(_train_fn pid=844656)[0m 	iters: 200, epoch: 5 | loss: 0.5480120
[36m(_train_fn pid=844656)[0m 	speed: 0.0701s/iter; left time: 54.4909s
Trial status: 158 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:38:52. Total running time: 2hr 17min 43s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b58a1502   RUNNING           4            77.8176       0.615438        1.56811             1.56811 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
153 more TERMINATED
[36m(_train_fn pid=844656)[0m Updating learning rate to 7.681736320727893e-05
[36m(_train_fn pid=844656)[0m saving checkpoint...
[36m(_train_fn pid=844656)[0m Validation loss decreased (1.5681 --> 1.5672).  Saving model state dict ...
[36m(_train_fn pid=844656)[0m Epoch: 5 cost time: 17.11745572090149
[36m(_train_fn pid=844656)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6135784 Vali Loss: 1.5672004 Best vali loss: 1.5672004
[36m(_train_fn pid=844656)[0m 	iters: 100, epoch: 6 | loss: 0.5889643
[36m(_train_fn pid=844656)[0m 	speed: 0.1229s/iter; left time: 77.7844s
[36m(_train_fn pid=844656)[0m 	iters: 200, epoch: 6 | loss: 0.5989718
[36m(_train_fn pid=844656)[0m 	speed: 0.0701s/iter; left time: 37.3606s

Trial trial-b58a1502 completed after 6 iterations at 2024-08-24 09:39:12. Total running time: 2hr 18min 3s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b58a1502 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.28566 â”‚
â”‚ time_total_s                            116.38997 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56614 â”‚
â”‚ train_loss                                0.61268 â”‚
â”‚ valid_loss                                1.56614 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=844656)[0m Updating learning rate to 3.8408681603639465e-05
[36m(_train_fn pid=844656)[0m saving checkpoint...
[36m(_train_fn pid=844656)[0m Validation loss decreased (1.5672 --> 1.5661).  Saving model state dict ...

Trial trial-4637ccbe started with configuration:
[36m(_train_fn pid=845516)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4637ccbe_160_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1824,e_layer_2024-08-24_09-39-12/checkpoint_000000)
2024-08-24 09:39:34,675	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=845516)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4637ccbe_160_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1824,e_layer_2024-08-24_09-39-12/checkpoint_000001)
[36m(_train_fn pid=845516)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4637ccbe_160_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1824,e_layer_2024-08-24_09-39-12/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4637ccbe config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18237 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00072 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=845516)[0m configuration
[36m(_train_fn pid=845516)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18237499349138167, 'e_layers': 1, 'learning_rate': 0.0007232343746031119, 'd_ff': 1536}
[36m(_train_fn pid=845516)[0m Use GPU: cuda:0
[36m(_train_fn pid=845516)[0m train 7825
[36m(_train_fn pid=845516)[0m val 2161
[36m(_train_fn pid=845516)[0m start_epoch 0
[36m(_train_fn pid=845516)[0m max_epoch 8

Trial status: 159 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:39:22. Total running time: 2hr 18min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4637ccbe   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
154 more TERMINATED
[36m(_train_fn pid=845516)[0m 	iters: 100, epoch: 1 | loss: 0.8460969
[36m(_train_fn pid=845516)[0m 	speed: 0.0764s/iter; left time: 141.5951s
[36m(_train_fn pid=845516)[0m 	iters: 200, epoch: 1 | loss: 0.6590315
[36m(_train_fn pid=845516)[0m 	speed: 0.0700s/iter; left time: 122.6611s
[36m(_train_fn pid=845516)[0m Updating learning rate to 0.0007232343746031119
[36m(_train_fn pid=845516)[0m saving checkpoint...
[36m(_train_fn pid=845516)[0m Validation loss decreased (inf --> 1.9231).  Saving model state dict ...
[36m(_train_fn pid=845516)[0m Epoch: 1 cost time: 17.46012282371521
[36m(_train_fn pid=845516)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8049126 Vali Loss: 1.9230615 Best vali loss: 1.9230615
[36m(_train_fn pid=845516)[0m 	iters: 100, epoch: 2 | loss: 0.6777803
[36m(_train_fn pid=845516)[0m 	speed: 0.1225s/iter; left time: 197.0599s
[36m(_train_fn pid=845516)[0m 	iters: 200, epoch: 2 | loss: 0.6925467
[36m(_train_fn pid=845516)[0m 	speed: 0.0700s/iter; left time: 105.5991s
Trial status: 159 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:39:52. Total running time: 2hr 18min 43s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4637ccbe   RUNNING           1            20.0219       0.804913        1.92306             1.92306 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
154 more TERMINATED
[36m(_train_fn pid=845516)[0m Updating learning rate to 0.00036161718730155594
[36m(_train_fn pid=845516)[0m saving checkpoint...
[36m(_train_fn pid=845516)[0m Validation loss decreased (1.9231 --> 1.5792).  Saving model state dict ...
[36m(_train_fn pid=845516)[0m Epoch: 2 cost time: 17.088606595993042
[36m(_train_fn pid=845516)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6805340 Vali Loss: 1.5792275 Best vali loss: 1.5792275
[36m(_train_fn pid=845516)[0m 	iters: 100, epoch: 3 | loss: 0.6662937
[36m(_train_fn pid=845516)[0m 	speed: 0.1225s/iter; left time: 167.1597s
[36m(_train_fn pid=845516)[0m 	iters: 200, epoch: 3 | loss: 0.6274863
[36m(_train_fn pid=845516)[0m 	speed: 0.0700s/iter; left time: 88.5342s
[36m(_train_fn pid=845516)[0m Updating learning rate to 0.00018080859365077797
[36m(_train_fn pid=845516)[0m saving checkpoint...
[36m(_train_fn pid=845516)[0m Validation loss decreased (1.5792 --> 1.5645).  Saving model state dict ...
[36m(_train_fn pid=845516)[0m Epoch: 3 cost time: 17.079399585723877
[36m(_train_fn pid=845516)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6148574 Vali Loss: 1.5644728 Best vali loss: 1.5644728
[36m(_train_fn pid=845516)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4637ccbe_160_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1824,e_layer_2024-08-24_09-39-12/checkpoint_000003)
[36m(_train_fn pid=845516)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4637ccbe_160_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1824,e_layer_2024-08-24_09-39-12/checkpoint_000004)
[36m(_train_fn pid=845516)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4637ccbe_160_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1824,e_layer_2024-08-24_09-39-12/checkpoint_000005)
[36m(_train_fn pid=845516)[0m 	iters: 100, epoch: 4 | loss: 0.6313539
[36m(_train_fn pid=845516)[0m 	speed: 0.1226s/iter; left time: 137.3888s
Trial status: 159 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:40:22. Total running time: 2hr 19min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4637ccbe   RUNNING           3            58.5031       0.614857        1.56447             1.56447 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
154 more TERMINATED
[36m(_train_fn pid=845516)[0m 	iters: 200, epoch: 4 | loss: 0.6345654
[36m(_train_fn pid=845516)[0m 	speed: 0.0700s/iter; left time: 71.4759s
[36m(_train_fn pid=845516)[0m Updating learning rate to 9.040429682538899e-05
[36m(_train_fn pid=845516)[0m saving checkpoint...
[36m(_train_fn pid=845516)[0m Validation loss decreased (1.5645 --> 1.5644).  Saving model state dict ...
[36m(_train_fn pid=845516)[0m Epoch: 4 cost time: 17.097208976745605
[36m(_train_fn pid=845516)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6111088 Vali Loss: 1.5644033 Best vali loss: 1.5644033
[36m(_train_fn pid=845516)[0m 	iters: 100, epoch: 5 | loss: 0.6056182
[36m(_train_fn pid=845516)[0m 	speed: 0.1225s/iter; left time: 107.4633s
[36m(_train_fn pid=845516)[0m 	iters: 200, epoch: 5 | loss: 0.5442903
[36m(_train_fn pid=845516)[0m 	speed: 0.0701s/iter; left time: 54.4588s
[36m(_train_fn pid=845516)[0m Updating learning rate to 4.520214841269449e-05
[36m(_train_fn pid=845516)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=845516)[0m saving checkpoint...
[36m(_train_fn pid=845516)[0m Epoch: 5 cost time: 17.100279092788696
[36m(_train_fn pid=845516)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6098162 Vali Loss: 1.5694095 Best vali loss: 1.5644033
Trial status: 159 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:40:52. Total running time: 2hr 19min 43s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4637ccbe   RUNNING           5            96.9893       0.609816        1.56941             1.5644  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
154 more TERMINATED
[36m(_train_fn pid=845516)[0m 	iters: 100, epoch: 6 | loss: 0.5818159
[36m(_train_fn pid=845516)[0m 	speed: 0.1224s/iter; left time: 77.4942s
[36m(_train_fn pid=845516)[0m 	iters: 200, epoch: 6 | loss: 0.5941785
[36m(_train_fn pid=845516)[0m 	speed: 0.0702s/iter; left time: 37.4036s

Trial trial-4637ccbe completed after 6 iterations at 2024-08-24 09:41:10. Total running time: 2hr 20min 2s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4637ccbe result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.29299 â”‚
â”‚ time_total_s                            116.28229 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56151 â”‚
â”‚ train_loss                                0.60903 â”‚
â”‚ valid_loss                                1.56151 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=845516)[0m Updating learning rate to 2.2601074206347246e-05
[36m(_train_fn pid=845516)[0m saving checkpoint...
[36m(_train_fn pid=845516)[0m Validation loss decreased (1.5644 --> 1.5615).  Saving model state dict ...

Trial trial-1de22ba4 started with configuration:
[36m(_train_fn pid=846373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1de22ba4_161_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1825,e_layer_2024-08-24_09-41-10/checkpoint_000000)
2024-08-24 09:41:32,672	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=846373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1de22ba4_161_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1825,e_layer_2024-08-24_09-41-10/checkpoint_000001)
[36m(_train_fn pid=846373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1de22ba4_161_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1825,e_layer_2024-08-24_09-41-10/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1de22ba4 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18246 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00071 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=846373)[0m configuration
[36m(_train_fn pid=846373)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.182464869482654, 'e_layers': 1, 'learning_rate': 0.0007131523084578383, 'd_ff': 1536}
[36m(_train_fn pid=846373)[0m Use GPU: cuda:0
[36m(_train_fn pid=846373)[0m train 7825
[36m(_train_fn pid=846373)[0m val 2161
[36m(_train_fn pid=846373)[0m start_epoch 0
[36m(_train_fn pid=846373)[0m max_epoch 8
[36m(_train_fn pid=846373)[0m 	iters: 100, epoch: 1 | loss: 0.8466613
[36m(_train_fn pid=846373)[0m 	speed: 0.0766s/iter; left time: 141.9917s

Trial status: 160 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:41:22. Total running time: 2hr 20min 13s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1de22ba4   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
155 more TERMINATED
[36m(_train_fn pid=846373)[0m 	iters: 200, epoch: 1 | loss: 0.6593657
[36m(_train_fn pid=846373)[0m 	speed: 0.0700s/iter; left time: 122.6968s
[36m(_train_fn pid=846373)[0m Updating learning rate to 0.0007131523084578383
[36m(_train_fn pid=846373)[0m saving checkpoint...
[36m(_train_fn pid=846373)[0m Validation loss decreased (inf --> 1.9235).  Saving model state dict ...
[36m(_train_fn pid=846373)[0m Epoch: 1 cost time: 17.484030723571777
[36m(_train_fn pid=846373)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8053348 Vali Loss: 1.9234609 Best vali loss: 1.9234609
[36m(_train_fn pid=846373)[0m 	iters: 100, epoch: 2 | loss: 0.6767739
[36m(_train_fn pid=846373)[0m 	speed: 0.1226s/iter; left time: 197.2210s
[36m(_train_fn pid=846373)[0m 	iters: 200, epoch: 2 | loss: 0.6915826
[36m(_train_fn pid=846373)[0m 	speed: 0.0700s/iter; left time: 105.5959s
[36m(_train_fn pid=846373)[0m Updating learning rate to 0.00035657615422891913
[36m(_train_fn pid=846373)[0m saving checkpoint...
[36m(_train_fn pid=846373)[0m Validation loss decreased (1.9235 --> 1.5695).  Saving model state dict ...
[36m(_train_fn pid=846373)[0m Epoch: 2 cost time: 17.082539081573486
[36m(_train_fn pid=846373)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6805714 Vali Loss: 1.5694578 Best vali loss: 1.5694578
Trial status: 160 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:41:52. Total running time: 2hr 20min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1de22ba4   RUNNING           2            39.3053       0.680571        1.56946             1.56946 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
155 more TERMINATED
[36m(_train_fn pid=846373)[0m 	iters: 100, epoch: 3 | loss: 0.6673998
[36m(_train_fn pid=846373)[0m 	speed: 0.1226s/iter; left time: 167.4067s
[36m(_train_fn pid=846373)[0m 	iters: 200, epoch: 3 | loss: 0.6276195
[36m(_train_fn pid=846373)[0m 	speed: 0.0700s/iter; left time: 88.5333s
[36m(_train_fn pid=846373)[0m Updating learning rate to 0.00017828807711445956
[36m(_train_fn pid=846373)[0m saving checkpoint...
[36m(_train_fn pid=846373)[0m Validation loss decreased (1.5695 --> 1.5652).  Saving model state dict ...
[36m(_train_fn pid=846373)[0m Epoch: 3 cost time: 17.08753275871277
[36m(_train_fn pid=846373)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6144373 Vali Loss: 1.5652213 Best vali loss: 1.5652213
[36m(_train_fn pid=846373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1de22ba4_161_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1825,e_layer_2024-08-24_09-41-10/checkpoint_000003)
[36m(_train_fn pid=846373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1de22ba4_161_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1825,e_layer_2024-08-24_09-41-10/checkpoint_000004)
[36m(_train_fn pid=846373)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1de22ba4_161_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1825,e_layer_2024-08-24_09-41-10/checkpoint_000005)
[36m(_train_fn pid=846373)[0m 	iters: 100, epoch: 4 | loss: 0.6315975
[36m(_train_fn pid=846373)[0m 	speed: 0.1225s/iter; left time: 137.2944s
Trial status: 160 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:42:22. Total running time: 2hr 21min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1de22ba4   RUNNING           3            58.5468       0.614437        1.56522             1.56522 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
155 more TERMINATED
[36m(_train_fn pid=846373)[0m 	iters: 200, epoch: 4 | loss: 0.6344668
[36m(_train_fn pid=846373)[0m 	speed: 0.0700s/iter; left time: 71.4384s
[36m(_train_fn pid=846373)[0m Updating learning rate to 8.914403855722978e-05
[36m(_train_fn pid=846373)[0m saving checkpoint...
[36m(_train_fn pid=846373)[0m Validation loss decreased (1.5652 --> 1.5626).  Saving model state dict ...
[36m(_train_fn pid=846373)[0m Epoch: 4 cost time: 17.083437204360962
[36m(_train_fn pid=846373)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6109703 Vali Loss: 1.5625908 Best vali loss: 1.5625908
[36m(_train_fn pid=846373)[0m 	iters: 100, epoch: 5 | loss: 0.6051769
[36m(_train_fn pid=846373)[0m 	speed: 0.1225s/iter; left time: 107.4085s
[36m(_train_fn pid=846373)[0m 	iters: 200, epoch: 5 | loss: 0.5443585
[36m(_train_fn pid=846373)[0m 	speed: 0.0700s/iter; left time: 54.3993s
[36m(_train_fn pid=846373)[0m Updating learning rate to 4.457201927861489e-05
[36m(_train_fn pid=846373)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=846373)[0m saving checkpoint...
[36m(_train_fn pid=846373)[0m Epoch: 5 cost time: 17.09899139404297
[36m(_train_fn pid=846373)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6096218 Vali Loss: 1.5631699 Best vali loss: 1.5625908
Trial status: 160 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:42:52. Total running time: 2hr 21min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1de22ba4   RUNNING           5            97.0162       0.609622        1.56317             1.56259 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
155 more TERMINATED
[36m(_train_fn pid=846373)[0m 	iters: 100, epoch: 6 | loss: 0.5822184
[36m(_train_fn pid=846373)[0m 	speed: 0.1225s/iter; left time: 77.5379s
[36m(_train_fn pid=846373)[0m 	iters: 200, epoch: 6 | loss: 0.5943043
[36m(_train_fn pid=846373)[0m 	speed: 0.0702s/iter; left time: 37.3962s

Trial trial-1de22ba4 completed after 6 iterations at 2024-08-24 09:43:08. Total running time: 2hr 22min 0s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1de22ba4 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.29029 â”‚
â”‚ time_total_s                            116.30649 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56179 â”‚
â”‚ train_loss                                0.60876 â”‚
â”‚ valid_loss                                1.56179 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=846373)[0m Updating learning rate to 2.2286009639307446e-05
[36m(_train_fn pid=846373)[0m saving checkpoint...
[36m(_train_fn pid=846373)[0m Validation loss decreased (1.5626 --> 1.5618).  Saving model state dict ...

Trial trial-c936880f started with configuration:
2024-08-24 09:43:30,697	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=847227)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c936880f_162_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_09-43-08/checkpoint_000000)
[36m(_train_fn pid=847227)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c936880f_162_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_09-43-08/checkpoint_000001)
[36m(_train_fn pid=847227)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c936880f_162_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_09-43-08/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c936880f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18362 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00135 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=847227)[0m configuration
[36m(_train_fn pid=847227)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1836243541516383, 'e_layers': 1, 'learning_rate': 0.0013539761028723458, 'd_ff': 1536}
[36m(_train_fn pid=847227)[0m Use GPU: cuda:0
[36m(_train_fn pid=847227)[0m train 7825
[36m(_train_fn pid=847227)[0m val 2161
[36m(_train_fn pid=847227)[0m start_epoch 0
[36m(_train_fn pid=847227)[0m max_epoch 8
[36m(_train_fn pid=847227)[0m 	iters: 100, epoch: 1 | loss: 0.8271707
[36m(_train_fn pid=847227)[0m 	speed: 0.0766s/iter; left time: 142.0174s

Trial status: 161 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:43:22. Total running time: 2hr 22min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c936880f   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
156 more TERMINATED
[36m(_train_fn pid=847227)[0m 	iters: 200, epoch: 1 | loss: 0.6472745
[36m(_train_fn pid=847227)[0m 	speed: 0.0700s/iter; left time: 122.6694s
[36m(_train_fn pid=847227)[0m Updating learning rate to 0.0013539761028723458
[36m(_train_fn pid=847227)[0m saving checkpoint...
[36m(_train_fn pid=847227)[0m Validation loss decreased (inf --> 1.8786).  Saving model state dict ...
[36m(_train_fn pid=847227)[0m Epoch: 1 cost time: 17.484965324401855
[36m(_train_fn pid=847227)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7883007 Vali Loss: 1.8786062 Best vali loss: 1.8786062
[36m(_train_fn pid=847227)[0m 	iters: 100, epoch: 2 | loss: 0.6853614
[36m(_train_fn pid=847227)[0m 	speed: 0.1226s/iter; left time: 197.2373s
[36m(_train_fn pid=847227)[0m 	iters: 200, epoch: 2 | loss: 0.7156880
[36m(_train_fn pid=847227)[0m 	speed: 0.0701s/iter; left time: 105.7296s
[36m(_train_fn pid=847227)[0m Updating learning rate to 0.0006769880514361729
[36m(_train_fn pid=847227)[0m saving checkpoint...
[36m(_train_fn pid=847227)[0m Validation loss decreased (1.8786 --> 1.6041).  Saving model state dict ...
[36m(_train_fn pid=847227)[0m Epoch: 2 cost time: 17.100923776626587
[36m(_train_fn pid=847227)[0m Epoch: 2, Steps: 244 | Train Loss: 0.8458468 Vali Loss: 1.6041428 Best vali loss: 1.6041428
Trial status: 161 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:43:52. Total running time: 2hr 22min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c936880f   RUNNING           2            39.308        0.845847        1.60414             1.60414 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
156 more TERMINATED
[36m(_train_fn pid=847227)[0m 	iters: 100, epoch: 3 | loss: 0.6846685
[36m(_train_fn pid=847227)[0m 	speed: 0.1226s/iter; left time: 167.2920s
[36m(_train_fn pid=847227)[0m 	iters: 200, epoch: 3 | loss: 0.6390341
[36m(_train_fn pid=847227)[0m 	speed: 0.0700s/iter; left time: 88.5516s
[36m(_train_fn pid=847227)[0m Updating learning rate to 0.00033849402571808646
[36m(_train_fn pid=847227)[0m saving checkpoint...
[36m(_train_fn pid=847227)[0m Validation loss decreased (1.6041 --> 1.5871).  Saving model state dict ...
[36m(_train_fn pid=847227)[0m Epoch: 3 cost time: 17.09593176841736
[36m(_train_fn pid=847227)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6255045 Vali Loss: 1.5870569 Best vali loss: 1.5870569
[36m(_train_fn pid=847227)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c936880f_162_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_09-43-08/checkpoint_000003)
[36m(_train_fn pid=847227)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c936880f_162_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_09-43-08/checkpoint_000004)
[36m(_train_fn pid=847227)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c936880f_162_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_09-43-08/checkpoint_000005)
[36m(_train_fn pid=847227)[0m 	iters: 100, epoch: 4 | loss: 0.6326339
[36m(_train_fn pid=847227)[0m 	speed: 0.1228s/iter; left time: 137.6865s
Trial status: 161 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:44:23. Total running time: 2hr 23min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c936880f   RUNNING           3            58.5659       0.625505        1.58706             1.58706 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
156 more TERMINATED
[36m(_train_fn pid=847227)[0m 	iters: 200, epoch: 4 | loss: 0.6427535
[36m(_train_fn pid=847227)[0m 	speed: 0.0702s/iter; left time: 71.6237s
[36m(_train_fn pid=847227)[0m Updating learning rate to 0.00016924701285904323
[36m(_train_fn pid=847227)[0m saving checkpoint...
[36m(_train_fn pid=847227)[0m Validation loss decreased (1.5871 --> 1.5723).  Saving model state dict ...
[36m(_train_fn pid=847227)[0m Epoch: 4 cost time: 17.13239860534668
[36m(_train_fn pid=847227)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6181234 Vali Loss: 1.5723481 Best vali loss: 1.5723481
[36m(_train_fn pid=847227)[0m 	iters: 100, epoch: 5 | loss: 0.6082948
[36m(_train_fn pid=847227)[0m 	speed: 0.1228s/iter; left time: 107.6684s
[36m(_train_fn pid=847227)[0m 	iters: 200, epoch: 5 | loss: 0.5493003
[36m(_train_fn pid=847227)[0m 	speed: 0.0702s/iter; left time: 54.5157s
[36m(_train_fn pid=847227)[0m Updating learning rate to 8.462350642952162e-05
[36m(_train_fn pid=847227)[0m saving checkpoint...
[36m(_train_fn pid=847227)[0m Validation loss decreased (1.5723 --> 1.5697).  Saving model state dict ...
[36m(_train_fn pid=847227)[0m Epoch: 5 cost time: 17.131299018859863
[36m(_train_fn pid=847227)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6158244 Vali Loss: 1.5697439 Best vali loss: 1.5697439
Trial status: 161 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:44:53. Total running time: 2hr 23min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c936880f   RUNNING           5            97.1453       0.615824        1.56974             1.56974 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
156 more TERMINATED
[36m(_train_fn pid=847227)[0m 	iters: 100, epoch: 6 | loss: 0.5928959
[36m(_train_fn pid=847227)[0m 	speed: 0.1226s/iter; left time: 77.6152s
[36m(_train_fn pid=847227)[0m 	iters: 200, epoch: 6 | loss: 0.5999143
[36m(_train_fn pid=847227)[0m 	speed: 0.0701s/iter; left time: 37.3818s

Trial trial-c936880f completed after 6 iterations at 2024-08-24 09:45:07. Total running time: 2hr 23min 58s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c936880f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.27253 â”‚
â”‚ time_total_s                            116.41781 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56809 â”‚
â”‚ train_loss                                0.61496 â”‚
â”‚ valid_loss                                1.56809 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=847227)[0m Updating learning rate to 4.231175321476081e-05
[36m(_train_fn pid=847227)[0m saving checkpoint...
[36m(_train_fn pid=847227)[0m Validation loss decreased (1.5697 --> 1.5681).  Saving model state dict ...

Trial trial-ce2f2357 started with configuration:
[36m(_train_fn pid=848087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce2f2357_163_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2238,e_layer_2024-08-24_09-45-07/checkpoint_000000)
2024-08-24 09:45:29,722	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=848087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce2f2357_163_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2238,e_layer_2024-08-24_09-45-07/checkpoint_000001)
[36m(_train_fn pid=848087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce2f2357_163_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2238,e_layer_2024-08-24_09-45-07/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ce2f2357 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.22379 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00075 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=848087)[0m configuration
[36m(_train_fn pid=848087)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.22379162605957476, 'e_layers': 1, 'learning_rate': 0.000754789873200504, 'd_ff': 1536}
[36m(_train_fn pid=848087)[0m Use GPU: cuda:0
[36m(_train_fn pid=848087)[0m train 7825
[36m(_train_fn pid=848087)[0m val 2161
[36m(_train_fn pid=848087)[0m start_epoch 0
[36m(_train_fn pid=848087)[0m max_epoch 8
[36m(_train_fn pid=848087)[0m 	iters: 100, epoch: 1 | loss: 0.8528385
[36m(_train_fn pid=848087)[0m 	speed: 0.0766s/iter; left time: 141.9880s

Trial status: 162 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:45:23. Total running time: 2hr 24min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ce2f2357   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
157 more TERMINATED
[36m(_train_fn pid=848087)[0m 	iters: 200, epoch: 1 | loss: 0.6574934
[36m(_train_fn pid=848087)[0m 	speed: 0.0700s/iter; left time: 122.6862s
[36m(_train_fn pid=848087)[0m Updating learning rate to 0.000754789873200504
[36m(_train_fn pid=848087)[0m saving checkpoint...
[36m(_train_fn pid=848087)[0m Validation loss decreased (inf --> 1.9231).  Saving model state dict ...
[36m(_train_fn pid=848087)[0m Epoch: 1 cost time: 17.470521926879883
[36m(_train_fn pid=848087)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8107204 Vali Loss: 1.9231476 Best vali loss: 1.9231476
[36m(_train_fn pid=848087)[0m 	iters: 100, epoch: 2 | loss: 0.6508550
[36m(_train_fn pid=848087)[0m 	speed: 0.1225s/iter; left time: 197.0492s
[36m(_train_fn pid=848087)[0m 	iters: 200, epoch: 2 | loss: 0.6915175
[36m(_train_fn pid=848087)[0m 	speed: 0.0700s/iter; left time: 105.6114s
[36m(_train_fn pid=848087)[0m Updating learning rate to 0.000377394936600252
[36m(_train_fn pid=848087)[0m saving checkpoint...
[36m(_train_fn pid=848087)[0m Validation loss decreased (1.9231 --> 1.5691).  Saving model state dict ...
[36m(_train_fn pid=848087)[0m Epoch: 2 cost time: 17.08828639984131
[36m(_train_fn pid=848087)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6900244 Vali Loss: 1.5690916 Best vali loss: 1.5690916
Trial status: 162 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:45:53. Total running time: 2hr 24min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ce2f2357   RUNNING           2            39.3218       0.690024        1.56909             1.56909 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
157 more TERMINATED
[36m(_train_fn pid=848087)[0m 	iters: 100, epoch: 3 | loss: 0.6688661
[36m(_train_fn pid=848087)[0m 	speed: 0.1226s/iter; left time: 167.2911s
[36m(_train_fn pid=848087)[0m 	iters: 200, epoch: 3 | loss: 0.6283296
[36m(_train_fn pid=848087)[0m 	speed: 0.0701s/iter; left time: 88.6747s
[36m(_train_fn pid=848087)[0m Updating learning rate to 0.000188697468300126
[36m(_train_fn pid=848087)[0m saving checkpoint...
[36m(_train_fn pid=848087)[0m Validation loss decreased (1.5691 --> 1.5675).  Saving model state dict ...
[36m(_train_fn pid=848087)[0m Epoch: 3 cost time: 17.114238262176514
[36m(_train_fn pid=848087)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6148242 Vali Loss: 1.5674606 Best vali loss: 1.5674606
[36m(_train_fn pid=848087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce2f2357_163_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2238,e_layer_2024-08-24_09-45-07/checkpoint_000003)
[36m(_train_fn pid=848087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce2f2357_163_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2238,e_layer_2024-08-24_09-45-07/checkpoint_000004)
[36m(_train_fn pid=848087)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce2f2357_163_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2238,e_layer_2024-08-24_09-45-07/checkpoint_000005)
[36m(_train_fn pid=848087)[0m 	iters: 100, epoch: 4 | loss: 0.6327752
[36m(_train_fn pid=848087)[0m 	speed: 0.1229s/iter; left time: 137.7452s
[36m(_train_fn pid=848087)[0m 	iters: 200, epoch: 4 | loss: 0.6357471
[36m(_train_fn pid=848087)[0m 	speed: 0.0702s/iter; left time: 71.7031s
Trial status: 162 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:46:23. Total running time: 2hr 25min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ce2f2357   RUNNING           3            58.6025       0.614824        1.56746             1.56746 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
157 more TERMINATED
[36m(_train_fn pid=848087)[0m Updating learning rate to 9.4348734150063e-05
[36m(_train_fn pid=848087)[0m saving checkpoint...
[36m(_train_fn pid=848087)[0m Validation loss decreased (1.5675 --> 1.5644).  Saving model state dict ...
[36m(_train_fn pid=848087)[0m Epoch: 4 cost time: 17.143887042999268
[36m(_train_fn pid=848087)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6114905 Vali Loss: 1.5644181 Best vali loss: 1.5644181
[36m(_train_fn pid=848087)[0m 	iters: 100, epoch: 5 | loss: 0.6063134
[36m(_train_fn pid=848087)[0m 	speed: 0.1229s/iter; left time: 107.7990s
[36m(_train_fn pid=848087)[0m 	iters: 200, epoch: 5 | loss: 0.5451117
[36m(_train_fn pid=848087)[0m 	speed: 0.0702s/iter; left time: 54.5451s
[36m(_train_fn pid=848087)[0m Updating learning rate to 4.71743670750315e-05
[36m(_train_fn pid=848087)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=848087)[0m saving checkpoint...
[36m(_train_fn pid=848087)[0m Epoch: 5 cost time: 17.140277862548828
[36m(_train_fn pid=848087)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6100641 Vali Loss: 1.5659078 Best vali loss: 1.5644181
Trial status: 162 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:46:53. Total running time: 2hr 25min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ce2f2357   RUNNING           5            97.1893       0.610064        1.56591             1.56442 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
157 more TERMINATED
[36m(_train_fn pid=848087)[0m 	iters: 100, epoch: 6 | loss: 0.5829358
[36m(_train_fn pid=848087)[0m 	speed: 0.1225s/iter; left time: 77.5584s
[36m(_train_fn pid=848087)[0m 	iters: 200, epoch: 6 | loss: 0.5946750
[36m(_train_fn pid=848087)[0m 	speed: 0.0702s/iter; left time: 37.4107s

Trial trial-ce2f2357 completed after 6 iterations at 2024-08-24 09:47:06. Total running time: 2hr 25min 57s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ce2f2357 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.29151 â”‚
â”‚ time_total_s                             116.4808 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56397 â”‚
â”‚ train_loss                                0.60926 â”‚
â”‚ valid_loss                                1.56397 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=848087)[0m Updating learning rate to 2.358718353751575e-05
[36m(_train_fn pid=848087)[0m saving checkpoint...
[36m(_train_fn pid=848087)[0m Validation loss decreased (1.5644 --> 1.5640).  Saving model state dict ...

Trial trial-76f4b60d started with configuration:
[36m(_train_fn pid=848947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f4b60d_164_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1823,e_layer_2024-08-24_09-47-06/checkpoint_000000)
2024-08-24 09:47:28,689	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=848947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f4b60d_164_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1823,e_layer_2024-08-24_09-47-06/checkpoint_000001)
[36m(_train_fn pid=848947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f4b60d_164_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1823,e_layer_2024-08-24_09-47-06/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-76f4b60d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18231 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00085 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=848947)[0m configuration
[36m(_train_fn pid=848947)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18231268737104747, 'e_layers': 1, 'learning_rate': 0.0008503812363519, 'd_ff': 1536}
[36m(_train_fn pid=848947)[0m Use GPU: cuda:0
[36m(_train_fn pid=848947)[0m train 7825
[36m(_train_fn pid=848947)[0m val 2161
[36m(_train_fn pid=848947)[0m start_epoch 0
[36m(_train_fn pid=848947)[0m max_epoch 8
[36m(_train_fn pid=848947)[0m 	iters: 100, epoch: 1 | loss: 0.8409526
[36m(_train_fn pid=848947)[0m 	speed: 0.0764s/iter; left time: 141.6290s
[36m(_train_fn pid=848947)[0m 	iters: 200, epoch: 1 | loss: 0.6554508
[36m(_train_fn pid=848947)[0m 	speed: 0.0700s/iter; left time: 122.6261s

Trial status: 163 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:47:23. Total running time: 2hr 26min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-76f4b60d   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
158 more TERMINATED
[36m(_train_fn pid=848947)[0m Updating learning rate to 0.0008503812363519
[36m(_train_fn pid=848947)[0m saving checkpoint...
[36m(_train_fn pid=848947)[0m Validation loss decreased (inf --> 1.9174).  Saving model state dict ...
[36m(_train_fn pid=848947)[0m Epoch: 1 cost time: 17.46333599090576
[36m(_train_fn pid=848947)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8003203 Vali Loss: 1.9174443 Best vali loss: 1.9174443
[36m(_train_fn pid=848947)[0m 	iters: 100, epoch: 2 | loss: 0.6387315
[36m(_train_fn pid=848947)[0m 	speed: 0.1225s/iter; left time: 197.0798s
[36m(_train_fn pid=848947)[0m 	iters: 200, epoch: 2 | loss: 0.6916614
[36m(_train_fn pid=848947)[0m 	speed: 0.0700s/iter; left time: 105.6077s
[36m(_train_fn pid=848947)[0m Updating learning rate to 0.00042519061817595
[36m(_train_fn pid=848947)[0m saving checkpoint...
[36m(_train_fn pid=848947)[0m Validation loss decreased (1.9174 --> 1.5691).  Saving model state dict ...
[36m(_train_fn pid=848947)[0m Epoch: 2 cost time: 17.08633828163147
[36m(_train_fn pid=848947)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6935196 Vali Loss: 1.5691026 Best vali loss: 1.5691026
Trial status: 163 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:47:53. Total running time: 2hr 26min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-76f4b60d   RUNNING           2            39.308        0.69352         1.5691              1.5691  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
158 more TERMINATED
[36m(_train_fn pid=848947)[0m 	iters: 100, epoch: 3 | loss: 0.6668619
[36m(_train_fn pid=848947)[0m 	speed: 0.1224s/iter; left time: 167.1436s
[36m(_train_fn pid=848947)[0m 	iters: 200, epoch: 3 | loss: 0.6278855
[36m(_train_fn pid=848947)[0m 	speed: 0.0700s/iter; left time: 88.5372s
[36m(_train_fn pid=848947)[0m Updating learning rate to 0.000212595309087975
[36m(_train_fn pid=848947)[0m saving checkpoint...
[36m(_train_fn pid=848947)[0m Validation loss decreased (1.5691 --> 1.5660).  Saving model state dict ...
[36m(_train_fn pid=848947)[0m Epoch: 3 cost time: 17.085574626922607
[36m(_train_fn pid=848947)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6152726 Vali Loss: 1.5660375 Best vali loss: 1.5660375
[36m(_train_fn pid=848947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f4b60d_164_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1823,e_layer_2024-08-24_09-47-06/checkpoint_000003)
[36m(_train_fn pid=848947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f4b60d_164_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1823,e_layer_2024-08-24_09-47-06/checkpoint_000004)
[36m(_train_fn pid=848947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-76f4b60d_164_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1823,e_layer_2024-08-24_09-47-06/checkpoint_000005)
[36m(_train_fn pid=848947)[0m 	iters: 100, epoch: 4 | loss: 0.6313658
[36m(_train_fn pid=848947)[0m 	speed: 0.1226s/iter; left time: 137.4136s
[36m(_train_fn pid=848947)[0m 	iters: 200, epoch: 4 | loss: 0.6380331
[36m(_train_fn pid=848947)[0m 	speed: 0.0701s/iter; left time: 71.6219s
Trial status: 163 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:48:23. Total running time: 2hr 27min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-76f4b60d   RUNNING           3            58.5483       0.615273        1.56604             1.56604 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
158 more TERMINATED
[36m(_train_fn pid=848947)[0m Updating learning rate to 0.0001062976545439875
[36m(_train_fn pid=848947)[0m saving checkpoint...
[36m(_train_fn pid=848947)[0m Validation loss decreased (1.5660 --> 1.5613).  Saving model state dict ...
[36m(_train_fn pid=848947)[0m Epoch: 4 cost time: 17.118231773376465
[36m(_train_fn pid=848947)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6108461 Vali Loss: 1.5612714 Best vali loss: 1.5612714
[36m(_train_fn pid=848947)[0m 	iters: 100, epoch: 5 | loss: 0.6053107
[36m(_train_fn pid=848947)[0m 	speed: 0.1228s/iter; left time: 107.6680s
[36m(_train_fn pid=848947)[0m 	iters: 200, epoch: 5 | loss: 0.5439536
[36m(_train_fn pid=848947)[0m 	speed: 0.0702s/iter; left time: 54.5327s
[36m(_train_fn pid=848947)[0m Updating learning rate to 5.314882727199375e-05
[36m(_train_fn pid=848947)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=848947)[0m saving checkpoint...
[36m(_train_fn pid=848947)[0m Epoch: 5 cost time: 17.129202127456665
[36m(_train_fn pid=848947)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6089088 Vali Loss: 1.5626336 Best vali loss: 1.5612714
[36m(_train_fn pid=848947)[0m 	iters: 100, epoch: 6 | loss: 0.5817772
[36m(_train_fn pid=848947)[0m 	speed: 0.1226s/iter; left time: 77.5984s
Trial status: 163 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:48:53. Total running time: 2hr 27min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-76f4b60d   RUNNING           5            97.1008       0.608909        1.56263             1.56127 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
158 more TERMINATED
[36m(_train_fn pid=848947)[0m 	iters: 200, epoch: 6 | loss: 0.5930701
[36m(_train_fn pid=848947)[0m 	speed: 0.0702s/iter; left time: 37.3940s

Trial trial-76f4b60d completed after 6 iterations at 2024-08-24 09:49:05. Total running time: 2hr 27min 56s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-76f4b60d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.28558 â”‚
â”‚ time_total_s                            116.38635 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56025 â”‚
â”‚ train_loss                                0.60813 â”‚
â”‚ valid_loss                                1.56025 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=848947)[0m Updating learning rate to 2.6574413635996874e-05
[36m(_train_fn pid=848947)[0m saving checkpoint...
[36m(_train_fn pid=848947)[0m Validation loss decreased (1.5613 --> 1.5602).  Saving model state dict ...

Trial trial-10b98384 started with configuration:
2024-08-24 09:49:26,659	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=849804)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-10b98384_165_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1822,e_layer_2024-08-24_09-49-05/checkpoint_000000)
[36m(_train_fn pid=849804)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-10b98384_165_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1822,e_layer_2024-08-24_09-49-05/checkpoint_000001)
[36m(_train_fn pid=849804)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-10b98384_165_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1822,e_layer_2024-08-24_09-49-05/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-10b98384 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18223 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00062 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=849804)[0m configuration
[36m(_train_fn pid=849804)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18223054305373515, 'e_layers': 1, 'learning_rate': 0.0006183384502234162, 'd_ff': 1536}
[36m(_train_fn pid=849804)[0m Use GPU: cuda:0
[36m(_train_fn pid=849804)[0m train 7825
[36m(_train_fn pid=849804)[0m val 2161
[36m(_train_fn pid=849804)[0m start_epoch 0
[36m(_train_fn pid=849804)[0m max_epoch 8
[36m(_train_fn pid=849804)[0m 	iters: 100, epoch: 1 | loss: 0.8514048
[36m(_train_fn pid=849804)[0m 	speed: 0.0764s/iter; left time: 141.5254s
[36m(_train_fn pid=849804)[0m 	iters: 200, epoch: 1 | loss: 0.6633192
[36m(_train_fn pid=849804)[0m 	speed: 0.0700s/iter; left time: 122.7124s

Trial status: 164 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:49:23. Total running time: 2hr 28min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-10b98384   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
159 more TERMINATED
[36m(_train_fn pid=849804)[0m Updating learning rate to 0.0006183384502234162
[36m(_train_fn pid=849804)[0m saving checkpoint...
[36m(_train_fn pid=849804)[0m Validation loss decreased (inf --> 1.9275).  Saving model state dict ...
[36m(_train_fn pid=849804)[0m Epoch: 1 cost time: 17.465929746627808
[36m(_train_fn pid=849804)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8095834 Vali Loss: 1.9275295 Best vali loss: 1.9275295
[36m(_train_fn pid=849804)[0m 	iters: 100, epoch: 2 | loss: 0.6416260
[36m(_train_fn pid=849804)[0m 	speed: 0.1226s/iter; left time: 197.2164s
[36m(_train_fn pid=849804)[0m 	iters: 200, epoch: 2 | loss: 0.6936587
[36m(_train_fn pid=849804)[0m 	speed: 0.0700s/iter; left time: 105.5762s
[36m(_train_fn pid=849804)[0m Updating learning rate to 0.0003091692251117081
[36m(_train_fn pid=849804)[0m saving checkpoint...
[36m(_train_fn pid=849804)[0m Validation loss decreased (1.9275 --> 1.5711).  Saving model state dict ...
[36m(_train_fn pid=849804)[0m Epoch: 2 cost time: 17.08918023109436
[36m(_train_fn pid=849804)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6648849 Vali Loss: 1.5711326 Best vali loss: 1.5711326
[36m(_train_fn pid=849804)[0m 	iters: 100, epoch: 3 | loss: 0.6679054
[36m(_train_fn pid=849804)[0m 	speed: 0.1226s/iter; left time: 167.4152s
Trial status: 164 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:49:53. Total running time: 2hr 28min 44s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-10b98384   RUNNING           2            39.272        0.664885        1.57113             1.57113 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
159 more TERMINATED
[36m(_train_fn pid=849804)[0m 	iters: 200, epoch: 3 | loss: 0.6298080
[36m(_train_fn pid=849804)[0m 	speed: 0.0701s/iter; left time: 88.6456s
[36m(_train_fn pid=849804)[0m Updating learning rate to 0.00015458461255585406
[36m(_train_fn pid=849804)[0m saving checkpoint...
[36m(_train_fn pid=849804)[0m Validation loss decreased (1.5711 --> 1.5647).  Saving model state dict ...
[36m(_train_fn pid=849804)[0m Epoch: 3 cost time: 17.11900758743286
[36m(_train_fn pid=849804)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6160126 Vali Loss: 1.5646712 Best vali loss: 1.5646712
[36m(_train_fn pid=849804)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-10b98384_165_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1822,e_layer_2024-08-24_09-49-05/checkpoint_000003)
[36m(_train_fn pid=849804)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-10b98384_165_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1822,e_layer_2024-08-24_09-49-05/checkpoint_000004)
[36m(_train_fn pid=849804)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-10b98384_165_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1822,e_layer_2024-08-24_09-49-05/checkpoint_000005)
[36m(_train_fn pid=849804)[0m 	iters: 100, epoch: 4 | loss: 0.6313861
[36m(_train_fn pid=849804)[0m 	speed: 0.1227s/iter; left time: 137.5356s
[36m(_train_fn pid=849804)[0m 	iters: 200, epoch: 4 | loss: 0.6348075
[36m(_train_fn pid=849804)[0m 	speed: 0.0700s/iter; left time: 71.4413s
Trial status: 164 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:50:23. Total running time: 2hr 29min 14s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-10b98384   RUNNING           3            58.5506       0.616013        1.56467             1.56467 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
159 more TERMINATED
[36m(_train_fn pid=849804)[0m Updating learning rate to 7.729230627792703e-05
[36m(_train_fn pid=849804)[0m saving checkpoint...
[36m(_train_fn pid=849804)[0m Validation loss decreased (1.5647 --> 1.5637).  Saving model state dict ...
[36m(_train_fn pid=849804)[0m Epoch: 4 cost time: 17.094353675842285
[36m(_train_fn pid=849804)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6117694 Vali Loss: 1.5636933 Best vali loss: 1.5636933
[36m(_train_fn pid=849804)[0m 	iters: 100, epoch: 5 | loss: 0.6054351
[36m(_train_fn pid=849804)[0m 	speed: 0.1226s/iter; left time: 107.4882s
[36m(_train_fn pid=849804)[0m 	iters: 200, epoch: 5 | loss: 0.5448508
[36m(_train_fn pid=849804)[0m 	speed: 0.0700s/iter; left time: 54.3748s
[36m(_train_fn pid=849804)[0m Updating learning rate to 3.8646153138963515e-05
[36m(_train_fn pid=849804)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=849804)[0m saving checkpoint...
[36m(_train_fn pid=849804)[0m Epoch: 5 cost time: 17.096025943756104
[36m(_train_fn pid=849804)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6101875 Vali Loss: 1.5693421 Best vali loss: 1.5636933
[36m(_train_fn pid=849804)[0m 	iters: 100, epoch: 6 | loss: 0.5826029
[36m(_train_fn pid=849804)[0m 	speed: 0.1224s/iter; left time: 77.5085s
Trial status: 164 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:50:53. Total running time: 2hr 29min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-10b98384   RUNNING           5            97.043        0.610188        1.56934             1.56369 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
159 more TERMINATED
[36m(_train_fn pid=849804)[0m 	iters: 200, epoch: 6 | loss: 0.5946817
[36m(_train_fn pid=849804)[0m 	speed: 0.0700s/iter; left time: 37.2973s
[36m(_train_fn pid=849804)[0m Updating learning rate to 1.9323076569481757e-05
[36m(_train_fn pid=849804)[0m saving checkpoint...
[36m(_train_fn pid=849804)[0m Validation loss decreased (1.5637 --> 1.5607).  Saving model state dict ...

Trial trial-10b98384 completed after 6 iterations at 2024-08-24 09:51:02. Total running time: 2hr 29min 54s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-10b98384 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.25468 â”‚
â”‚ time_total_s                            116.29766 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56074 â”‚
â”‚ train_loss                                0.60953 â”‚
â”‚ valid_loss                                1.56074 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-c26f3ddf started with configuration:
2024-08-24 09:51:24,711	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=850659)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c26f3ddf_166_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1866,e_layer_2024-08-24_09-51-02/checkpoint_000000)
[36m(_train_fn pid=850659)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c26f3ddf_166_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1866,e_layer_2024-08-24_09-51-02/checkpoint_000001)
[36m(_train_fn pid=850659)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c26f3ddf_166_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1866,e_layer_2024-08-24_09-51-02/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c26f3ddf config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.1866 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00061 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=850659)[0m configuration
[36m(_train_fn pid=850659)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.186595115611924, 'e_layers': 1, 'learning_rate': 0.0006136559876026847, 'd_ff': 1536}
[36m(_train_fn pid=850659)[0m Use GPU: cuda:0
[36m(_train_fn pid=850659)[0m train 7825
[36m(_train_fn pid=850659)[0m val 2161
[36m(_train_fn pid=850659)[0m start_epoch 0
[36m(_train_fn pid=850659)[0m max_epoch 8
[36m(_train_fn pid=850659)[0m 	iters: 100, epoch: 1 | loss: 0.8529152
[36m(_train_fn pid=850659)[0m 	speed: 0.0768s/iter; left time: 142.2714s
[36m(_train_fn pid=850659)[0m 	iters: 200, epoch: 1 | loss: 0.6637737
[36m(_train_fn pid=850659)[0m 	speed: 0.0700s/iter; left time: 122.6605s

Trial status: 165 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:51:23. Total running time: 2hr 30min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c26f3ddf   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
160 more TERMINATED
[36m(_train_fn pid=850659)[0m Updating learning rate to 0.0006136559876026847
[36m(_train_fn pid=850659)[0m saving checkpoint...
[36m(_train_fn pid=850659)[0m Validation loss decreased (inf --> 1.9279).  Saving model state dict ...
[36m(_train_fn pid=850659)[0m Epoch: 1 cost time: 17.495004177093506
[36m(_train_fn pid=850659)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8107699 Vali Loss: 1.9278601 Best vali loss: 1.9278601
[36m(_train_fn pid=850659)[0m 	iters: 100, epoch: 2 | loss: 0.6388469
[36m(_train_fn pid=850659)[0m 	speed: 0.1226s/iter; left time: 197.1998s
[36m(_train_fn pid=850659)[0m 	iters: 200, epoch: 2 | loss: 0.6973199
[36m(_train_fn pid=850659)[0m 	speed: 0.0700s/iter; left time: 105.6124s
[36m(_train_fn pid=850659)[0m Updating learning rate to 0.00030682799380134235
[36m(_train_fn pid=850659)[0m saving checkpoint...
[36m(_train_fn pid=850659)[0m Validation loss decreased (1.9279 --> 1.5818).  Saving model state dict ...
[36m(_train_fn pid=850659)[0m Epoch: 2 cost time: 17.08911919593811
[36m(_train_fn pid=850659)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6637807 Vali Loss: 1.5817778 Best vali loss: 1.5817778
[36m(_train_fn pid=850659)[0m 	iters: 100, epoch: 3 | loss: 0.6676905
[36m(_train_fn pid=850659)[0m 	speed: 0.1226s/iter; left time: 167.3305s
Trial status: 165 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:51:54. Total running time: 2hr 30min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c26f3ddf   RUNNING           2            39.3133       0.663781        1.58178             1.58178 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
160 more TERMINATED
[36m(_train_fn pid=850659)[0m 	iters: 200, epoch: 3 | loss: 0.6300085
[36m(_train_fn pid=850659)[0m 	speed: 0.0701s/iter; left time: 88.6367s
[36m(_train_fn pid=850659)[0m Updating learning rate to 0.00015341399690067117
[36m(_train_fn pid=850659)[0m saving checkpoint...
[36m(_train_fn pid=850659)[0m Validation loss decreased (1.5818 --> 1.5650).  Saving model state dict ...
[36m(_train_fn pid=850659)[0m Epoch: 3 cost time: 17.100505590438843
[36m(_train_fn pid=850659)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6159525 Vali Loss: 1.5649727 Best vali loss: 1.5649727
[36m(_train_fn pid=850659)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c26f3ddf_166_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1866,e_layer_2024-08-24_09-51-02/checkpoint_000003)
[36m(_train_fn pid=850659)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c26f3ddf_166_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1866,e_layer_2024-08-24_09-51-02/checkpoint_000004)
[36m(_train_fn pid=850659)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c26f3ddf_166_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1866,e_layer_2024-08-24_09-51-02/checkpoint_000005)
[36m(_train_fn pid=850659)[0m 	iters: 100, epoch: 4 | loss: 0.6311991
[36m(_train_fn pid=850659)[0m 	speed: 0.1227s/iter; left time: 137.5051s
[36m(_train_fn pid=850659)[0m 	iters: 200, epoch: 4 | loss: 0.6346959
[36m(_train_fn pid=850659)[0m 	speed: 0.0700s/iter; left time: 71.5175s
[36m(_train_fn pid=850659)[0m Updating learning rate to 7.670699845033559e-05
[36m(_train_fn pid=850659)[0m saving checkpoint...
[36m(_train_fn pid=850659)[0m Validation loss decreased (1.5650 --> 1.5635).  Saving model state dict ...
[36m(_train_fn pid=850659)[0m Epoch: 4 cost time: 17.099137783050537
[36m(_train_fn pid=850659)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6118037 Vali Loss: 1.5635383 Best vali loss: 1.5635383
Trial status: 165 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:52:24. Total running time: 2hr 31min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c26f3ddf   RUNNING           4            77.8496       0.611804        1.56354             1.56354 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
160 more TERMINATED
[36m(_train_fn pid=850659)[0m 	iters: 100, epoch: 5 | loss: 0.6053787
[36m(_train_fn pid=850659)[0m 	speed: 0.1227s/iter; left time: 107.6142s
[36m(_train_fn pid=850659)[0m 	iters: 200, epoch: 5 | loss: 0.5449593
[36m(_train_fn pid=850659)[0m 	speed: 0.0701s/iter; left time: 54.4870s
[36m(_train_fn pid=850659)[0m Updating learning rate to 3.8353499225167794e-05
[36m(_train_fn pid=850659)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=850659)[0m saving checkpoint...
[36m(_train_fn pid=850659)[0m Epoch: 5 cost time: 17.122158527374268
[36m(_train_fn pid=850659)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6102325 Vali Loss: 1.5689989 Best vali loss: 1.5635383
[36m(_train_fn pid=850659)[0m 	iters: 100, epoch: 6 | loss: 0.5826354
[36m(_train_fn pid=850659)[0m 	speed: 0.1225s/iter; left time: 77.5250s
Trial status: 165 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:52:54. Total running time: 2hr 31min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c26f3ddf   RUNNING           5            97.1019       0.610232        1.569               1.56354 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
160 more TERMINATED
[36m(_train_fn pid=850659)[0m 	iters: 200, epoch: 6 | loss: 0.5947286
[36m(_train_fn pid=850659)[0m 	speed: 0.0701s/iter; left time: 37.3388s

Trial trial-c26f3ddf completed after 6 iterations at 2024-08-24 09:53:01. Total running time: 2hr 31min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c26f3ddf result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                            19.27 â”‚
â”‚ time_total_s                            116.37191 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                            1.5607 â”‚
â”‚ train_loss                                0.60956 â”‚
â”‚ valid_loss                                 1.5607 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=850659)[0m Updating learning rate to 1.9176749612583897e-05
[36m(_train_fn pid=850659)[0m saving checkpoint...
[36m(_train_fn pid=850659)[0m Validation loss decreased (1.5635 --> 1.5607).  Saving model state dict ...

Trial trial-7292344b started with configuration:
[36m(_train_fn pid=851517)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7292344b_167_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-53-01/checkpoint_000000)
2024-08-24 09:53:22,729	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=851517)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7292344b_167_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-53-01/checkpoint_000001)
[36m(_train_fn pid=851517)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7292344b_167_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-53-01/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7292344b config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18997 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00121 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=851517)[0m configuration
[36m(_train_fn pid=851517)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1899680319255472, 'e_layers': 1, 'learning_rate': 0.0012056612439896456, 'd_ff': 1536}
[36m(_train_fn pid=851517)[0m Use GPU: cuda:0
[36m(_train_fn pid=851517)[0m train 7825
[36m(_train_fn pid=851517)[0m val 2161
[36m(_train_fn pid=851517)[0m start_epoch 0
[36m(_train_fn pid=851517)[0m max_epoch 8
[36m(_train_fn pid=851517)[0m 	iters: 100, epoch: 1 | loss: 0.8322067
[36m(_train_fn pid=851517)[0m 	speed: 0.0767s/iter; left time: 142.1036s
[36m(_train_fn pid=851517)[0m 	iters: 200, epoch: 1 | loss: 0.6494669
[36m(_train_fn pid=851517)[0m 	speed: 0.0700s/iter; left time: 122.6996s
[36m(_train_fn pid=851517)[0m Updating learning rate to 0.0012056612439896456
[36m(_train_fn pid=851517)[0m saving checkpoint...
[36m(_train_fn pid=851517)[0m Validation loss decreased (inf --> 1.8950).  Saving model state dict ...
[36m(_train_fn pid=851517)[0m Epoch: 1 cost time: 17.488781452178955
[36m(_train_fn pid=851517)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7924440 Vali Loss: 1.8950059 Best vali loss: 1.8950059

Trial status: 166 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:53:24. Total running time: 2hr 32min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7292344b   RUNNING           1            20.0619       0.792444        1.89501             1.89501 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
161 more TERMINATED
[36m(_train_fn pid=851517)[0m 	iters: 100, epoch: 2 | loss: 0.6724325
[36m(_train_fn pid=851517)[0m 	speed: 0.1225s/iter; left time: 197.0352s
[36m(_train_fn pid=851517)[0m 	iters: 200, epoch: 2 | loss: 0.7078137
[36m(_train_fn pid=851517)[0m 	speed: 0.0700s/iter; left time: 105.5821s
[36m(_train_fn pid=851517)[0m Updating learning rate to 0.0006028306219948228
[36m(_train_fn pid=851517)[0m saving checkpoint...
[36m(_train_fn pid=851517)[0m Validation loss decreased (1.8950 --> 1.5851).  Saving model state dict ...
[36m(_train_fn pid=851517)[0m Epoch: 2 cost time: 17.092555284500122
[36m(_train_fn pid=851517)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7800207 Vali Loss: 1.5851314 Best vali loss: 1.5851314
[36m(_train_fn pid=851517)[0m 	iters: 100, epoch: 3 | loss: 0.6734900
[36m(_train_fn pid=851517)[0m 	speed: 0.1226s/iter; left time: 167.3132s
Trial status: 166 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:53:54. Total running time: 2hr 32min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7292344b   RUNNING           2            39.3082       0.780021        1.58513             1.58513 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
161 more TERMINATED
[36m(_train_fn pid=851517)[0m 	iters: 200, epoch: 3 | loss: 0.6378680
[36m(_train_fn pid=851517)[0m 	speed: 0.0700s/iter; left time: 88.5937s
[36m(_train_fn pid=851517)[0m Updating learning rate to 0.0003014153109974114
[36m(_train_fn pid=851517)[0m saving checkpoint...
[36m(_train_fn pid=851517)[0m Validation loss decreased (1.5851 --> 1.5779).  Saving model state dict ...
[36m(_train_fn pid=851517)[0m Epoch: 3 cost time: 17.0956974029541
[36m(_train_fn pid=851517)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6204987 Vali Loss: 1.5779261 Best vali loss: 1.5779261
[36m(_train_fn pid=851517)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7292344b_167_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-53-01/checkpoint_000003)
[36m(_train_fn pid=851517)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7292344b_167_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-53-01/checkpoint_000004)
[36m(_train_fn pid=851517)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7292344b_167_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-53-01/checkpoint_000005)
[36m(_train_fn pid=851517)[0m 	iters: 100, epoch: 4 | loss: 0.6322615
[36m(_train_fn pid=851517)[0m 	speed: 0.1226s/iter; left time: 137.4342s
[36m(_train_fn pid=851517)[0m 	iters: 200, epoch: 4 | loss: 0.6405265
[36m(_train_fn pid=851517)[0m 	speed: 0.0701s/iter; left time: 71.5621s
[36m(_train_fn pid=851517)[0m Updating learning rate to 0.0001507076554987057
[36m(_train_fn pid=851517)[0m saving checkpoint...
[36m(_train_fn pid=851517)[0m Validation loss decreased (1.5779 --> 1.5676).  Saving model state dict ...
[36m(_train_fn pid=851517)[0m Epoch: 4 cost time: 17.102377891540527
[36m(_train_fn pid=851517)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6155992 Vali Loss: 1.5675611 Best vali loss: 1.5675611
Trial status: 166 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:54:24. Total running time: 2hr 33min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7292344b   RUNNING           4            77.8251       0.615599        1.56756             1.56756 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
161 more TERMINATED
[36m(_train_fn pid=851517)[0m 	iters: 100, epoch: 5 | loss: 0.6061283
[36m(_train_fn pid=851517)[0m 	speed: 0.1226s/iter; left time: 107.5581s
[36m(_train_fn pid=851517)[0m 	iters: 200, epoch: 5 | loss: 0.5489315
[36m(_train_fn pid=851517)[0m 	speed: 0.0701s/iter; left time: 54.4657s
[36m(_train_fn pid=851517)[0m Updating learning rate to 7.535382774935285e-05
[36m(_train_fn pid=851517)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=851517)[0m saving checkpoint...
[36m(_train_fn pid=851517)[0m Epoch: 5 cost time: 17.117241859436035
[36m(_train_fn pid=851517)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6134791 Vali Loss: 1.5683522 Best vali loss: 1.5675611
[36m(_train_fn pid=851517)[0m 	iters: 100, epoch: 6 | loss: 0.5886669
[36m(_train_fn pid=851517)[0m 	speed: 0.1226s/iter; left time: 77.5958s
[36m(_train_fn pid=851517)[0m 	iters: 200, epoch: 6 | loss: 0.5985453
[36m(_train_fn pid=851517)[0m 	speed: 0.0701s/iter; left time: 37.3692s
Trial status: 166 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:54:54. Total running time: 2hr 33min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7292344b   RUNNING           5            97.0883       0.613479        1.56835             1.56756 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
161 more TERMINATED

Trial trial-7292344b completed after 6 iterations at 2024-08-24 09:54:59. Total running time: 2hr 33min 50s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7292344b result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.28031 â”‚
â”‚ time_total_s                            116.36865 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56643 â”‚
â”‚ train_loss                                0.61266 â”‚
â”‚ valid_loss                                1.56643 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=851517)[0m Updating learning rate to 3.7676913874676424e-05
[36m(_train_fn pid=851517)[0m saving checkpoint...
[36m(_train_fn pid=851517)[0m Validation loss decreased (1.5676 --> 1.5664).  Saving model state dict ...

Trial trial-be5f29e9 started with configuration:
2024-08-24 09:55:20,710	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=852375)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-be5f29e9_168_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-54-59/checkpoint_000000)
[36m(_train_fn pid=852375)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-be5f29e9_168_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-54-59/checkpoint_000001)
[36m(_train_fn pid=852375)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-be5f29e9_168_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-54-59/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-be5f29e9 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                               0.19 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0017 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=852375)[0m configuration
[36m(_train_fn pid=852375)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1900030190622361, 'e_layers': 1, 'learning_rate': 0.0016968833427116535, 'd_ff': 1536}
[36m(_train_fn pid=852375)[0m Use GPU: cuda:0
[36m(_train_fn pid=852375)[0m train 7825
[36m(_train_fn pid=852375)[0m val 2161
[36m(_train_fn pid=852375)[0m start_epoch 0
[36m(_train_fn pid=852375)[0m max_epoch 8
[36m(_train_fn pid=852375)[0m 	iters: 100, epoch: 1 | loss: 0.8204869
[36m(_train_fn pid=852375)[0m 	speed: 0.0767s/iter; left time: 142.2093s
[36m(_train_fn pid=852375)[0m 	iters: 200, epoch: 1 | loss: 0.6421591
[36m(_train_fn pid=852375)[0m 	speed: 0.0700s/iter; left time: 122.7084s
[36m(_train_fn pid=852375)[0m Updating learning rate to 0.0016968833427116535
[36m(_train_fn pid=852375)[0m saving checkpoint...
[36m(_train_fn pid=852375)[0m Validation loss decreased (inf --> 1.8352).  Saving model state dict ...
[36m(_train_fn pid=852375)[0m Epoch: 1 cost time: 17.488964557647705
[36m(_train_fn pid=852375)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7821982 Vali Loss: 1.8351740 Best vali loss: 1.8351740

Trial status: 167 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:55:24. Total running time: 2hr 34min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-be5f29e9   RUNNING           1            20.07         0.782198        1.83517             1.83517 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
162 more TERMINATED
[36m(_train_fn pid=852375)[0m 	iters: 100, epoch: 2 | loss: 0.7251980
[36m(_train_fn pid=852375)[0m 	speed: 0.1225s/iter; left time: 197.1656s
[36m(_train_fn pid=852375)[0m 	iters: 200, epoch: 2 | loss: 0.7285740
[36m(_train_fn pid=852375)[0m 	speed: 0.0700s/iter; left time: 105.6135s
[36m(_train_fn pid=852375)[0m Updating learning rate to 0.0008484416713558267
[36m(_train_fn pid=852375)[0m saving checkpoint...
[36m(_train_fn pid=852375)[0m Validation loss decreased (1.8352 --> 1.6426).  Saving model state dict ...
[36m(_train_fn pid=852375)[0m Epoch: 2 cost time: 17.085405826568604
[36m(_train_fn pid=852375)[0m Epoch: 2, Steps: 244 | Train Loss: 1.1513433 Vali Loss: 1.6426239 Best vali loss: 1.6426239
[36m(_train_fn pid=852375)[0m 	iters: 100, epoch: 3 | loss: 0.6969309
[36m(_train_fn pid=852375)[0m 	speed: 0.1224s/iter; left time: 167.1431s
[36m(_train_fn pid=852375)[0m 	iters: 200, epoch: 3 | loss: 0.6540289
[36m(_train_fn pid=852375)[0m 	speed: 0.0700s/iter; left time: 88.5292s
Trial status: 167 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:55:54. Total running time: 2hr 34min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-be5f29e9   RUNNING           2            39.3095       1.15134         1.64262             1.64262 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
162 more TERMINATED
[36m(_train_fn pid=852375)[0m Updating learning rate to 0.00042422083567791337
[36m(_train_fn pid=852375)[0m saving checkpoint...
[36m(_train_fn pid=852375)[0m Validation loss decreased (1.6426 --> 1.6184).  Saving model state dict ...
[36m(_train_fn pid=852375)[0m Epoch: 3 cost time: 17.083596229553223
[36m(_train_fn pid=852375)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6431736 Vali Loss: 1.6184175 Best vali loss: 1.6184175
[36m(_train_fn pid=852375)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-be5f29e9_168_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-54-59/checkpoint_000003)
[36m(_train_fn pid=852375)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-be5f29e9_168_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-54-59/checkpoint_000004)
[36m(_train_fn pid=852375)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-be5f29e9_168_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1900,e_layer_2024-08-24_09-54-59/checkpoint_000005)
[36m(_train_fn pid=852375)[0m 	iters: 100, epoch: 4 | loss: 0.6385309
[36m(_train_fn pid=852375)[0m 	speed: 0.1226s/iter; left time: 137.3878s
[36m(_train_fn pid=852375)[0m 	iters: 200, epoch: 4 | loss: 0.6575013
[36m(_train_fn pid=852375)[0m 	speed: 0.0700s/iter; left time: 71.4420s
[36m(_train_fn pid=852375)[0m Updating learning rate to 0.00021211041783895669
[36m(_train_fn pid=852375)[0m saving checkpoint...
[36m(_train_fn pid=852375)[0m Validation loss decreased (1.6184 --> 1.6060).  Saving model state dict ...
[36m(_train_fn pid=852375)[0m Epoch: 4 cost time: 17.090941190719604
[36m(_train_fn pid=852375)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6343594 Vali Loss: 1.6060327 Best vali loss: 1.6060327
Trial status: 167 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:56:24. Total running time: 2hr 35min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-be5f29e9   RUNNING           4            77.802        0.634359        1.60603             1.60603 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
162 more TERMINATED
[36m(_train_fn pid=852375)[0m 	iters: 100, epoch: 5 | loss: 0.6201253
[36m(_train_fn pid=852375)[0m 	speed: 0.1226s/iter; left time: 107.4948s
[36m(_train_fn pid=852375)[0m 	iters: 200, epoch: 5 | loss: 0.5586369
[36m(_train_fn pid=852375)[0m 	speed: 0.0700s/iter; left time: 54.3719s
[36m(_train_fn pid=852375)[0m Updating learning rate to 0.00010605520891947834
[36m(_train_fn pid=852375)[0m saving checkpoint...
[36m(_train_fn pid=852375)[0m Validation loss decreased (1.6060 --> 1.6000).  Saving model state dict ...
[36m(_train_fn pid=852375)[0m Epoch: 5 cost time: 17.09024715423584
[36m(_train_fn pid=852375)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6297675 Vali Loss: 1.5999790 Best vali loss: 1.5999790
[36m(_train_fn pid=852375)[0m 	iters: 100, epoch: 6 | loss: 0.6038730
[36m(_train_fn pid=852375)[0m 	speed: 0.1226s/iter; left time: 77.5818s
[36m(_train_fn pid=852375)[0m 	iters: 200, epoch: 6 | loss: 0.6100069
[36m(_train_fn pid=852375)[0m 	speed: 0.0700s/iter; left time: 37.3077s
Trial status: 167 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:56:54. Total running time: 2hr 35min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-be5f29e9   RUNNING           5            97.0523       0.629767        1.59998             1.59998 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
162 more TERMINATED

Trial trial-be5f29e9 completed after 6 iterations at 2024-08-24 09:56:56. Total running time: 2hr 35min 48s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-be5f29e9 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.25229 â”‚
â”‚ time_total_s                            116.30461 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.59556 â”‚
â”‚ train_loss                                0.62734 â”‚
â”‚ valid_loss                                1.59556 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=852375)[0m Updating learning rate to 5.302760445973917e-05
[36m(_train_fn pid=852375)[0m saving checkpoint...
[36m(_train_fn pid=852375)[0m Validation loss decreased (1.6000 --> 1.5956).  Saving model state dict ...

Trial trial-16aa2a55 started with configuration:
2024-08-24 09:57:18,682	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=853228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-16aa2a55_169_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1901,e_layer_2024-08-24_09-56-56/checkpoint_000000)
[36m(_train_fn pid=853228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-16aa2a55_169_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1901,e_layer_2024-08-24_09-56-56/checkpoint_000001)
[36m(_train_fn pid=853228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-16aa2a55_169_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1901,e_layer_2024-08-24_09-56-56/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-16aa2a55 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19009 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0005 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=853228)[0m configuration
[36m(_train_fn pid=853228)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19008981536703115, 'e_layers': 1, 'learning_rate': 0.0005033440625285477, 'd_ff': 1536}
[36m(_train_fn pid=853228)[0m Use GPU: cuda:0
[36m(_train_fn pid=853228)[0m train 7825
[36m(_train_fn pid=853228)[0m val 2161
[36m(_train_fn pid=853228)[0m start_epoch 0
[36m(_train_fn pid=853228)[0m max_epoch 8
[36m(_train_fn pid=853228)[0m 	iters: 100, epoch: 1 | loss: 0.8596230
[36m(_train_fn pid=853228)[0m 	speed: 0.0765s/iter; left time: 141.8174s
[36m(_train_fn pid=853228)[0m 	iters: 200, epoch: 1 | loss: 0.6698069
[36m(_train_fn pid=853228)[0m 	speed: 0.0700s/iter; left time: 122.7034s
[36m(_train_fn pid=853228)[0m Updating learning rate to 0.0005033440625285477
[36m(_train_fn pid=853228)[0m saving checkpoint...
[36m(_train_fn pid=853228)[0m Validation loss decreased (inf --> 1.9317).  Saving model state dict ...
[36m(_train_fn pid=853228)[0m Epoch: 1 cost time: 17.472498416900635
[36m(_train_fn pid=853228)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8176429 Vali Loss: 1.9316899 Best vali loss: 1.9316899

Trial status: 168 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:57:24. Total running time: 2hr 36min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-16aa2a55   RUNNING           1            20.0418       0.817643        1.93169             1.93169 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
163 more TERMINATED
[36m(_train_fn pid=853228)[0m 	iters: 100, epoch: 2 | loss: 0.6419625
[36m(_train_fn pid=853228)[0m 	speed: 0.1225s/iter; left time: 197.0516s
[36m(_train_fn pid=853228)[0m 	iters: 200, epoch: 2 | loss: 0.6985600
[36m(_train_fn pid=853228)[0m 	speed: 0.0700s/iter; left time: 105.5671s
[36m(_train_fn pid=853228)[0m Updating learning rate to 0.00025167203126427387
[36m(_train_fn pid=853228)[0m saving checkpoint...
[36m(_train_fn pid=853228)[0m Validation loss decreased (1.9317 --> 1.5718).  Saving model state dict ...
[36m(_train_fn pid=853228)[0m Epoch: 2 cost time: 17.084126710891724
[36m(_train_fn pid=853228)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6618816 Vali Loss: 1.5718481 Best vali loss: 1.5718481
[36m(_train_fn pid=853228)[0m 	iters: 100, epoch: 3 | loss: 0.6683244
[36m(_train_fn pid=853228)[0m 	speed: 0.1226s/iter; left time: 167.3293s
[36m(_train_fn pid=853228)[0m 	iters: 200, epoch: 3 | loss: 0.6295847
[36m(_train_fn pid=853228)[0m 	speed: 0.0700s/iter; left time: 88.5504s
Trial status: 168 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:57:54. Total running time: 2hr 36min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-16aa2a55   RUNNING           2            39.2831       0.661882        1.57185             1.57185 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
163 more TERMINATED
[36m(_train_fn pid=853228)[0m Updating learning rate to 0.00012583601563213693
[36m(_train_fn pid=853228)[0m saving checkpoint...
[36m(_train_fn pid=853228)[0m Validation loss decreased (1.5718 --> 1.5651).  Saving model state dict ...
[36m(_train_fn pid=853228)[0m Epoch: 3 cost time: 17.097320318222046
[36m(_train_fn pid=853228)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6173684 Vali Loss: 1.5650963 Best vali loss: 1.5650963
[36m(_train_fn pid=853228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-16aa2a55_169_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1901,e_layer_2024-08-24_09-56-56/checkpoint_000003)
[36m(_train_fn pid=853228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-16aa2a55_169_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1901,e_layer_2024-08-24_09-56-56/checkpoint_000004)
[36m(_train_fn pid=853228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-16aa2a55_169_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1901,e_layer_2024-08-24_09-56-56/checkpoint_000005)
[36m(_train_fn pid=853228)[0m 	iters: 100, epoch: 4 | loss: 0.6336170
[36m(_train_fn pid=853228)[0m 	speed: 0.1225s/iter; left time: 137.3555s
[36m(_train_fn pid=853228)[0m 	iters: 200, epoch: 4 | loss: 0.6361358
[36m(_train_fn pid=853228)[0m 	speed: 0.0700s/iter; left time: 71.4625s
[36m(_train_fn pid=853228)[0m Updating learning rate to 6.291800781606847e-05
[36m(_train_fn pid=853228)[0m saving checkpoint...
[36m(_train_fn pid=853228)[0m Validation loss decreased (1.5651 --> 1.5644).  Saving model state dict ...
[36m(_train_fn pid=853228)[0m Epoch: 4 cost time: 17.085245370864868
[36m(_train_fn pid=853228)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6128377 Vali Loss: 1.5644134 Best vali loss: 1.5644134
[36m(_train_fn pid=853228)[0m 	iters: 100, epoch: 5 | loss: 0.6069865
[36m(_train_fn pid=853228)[0m 	speed: 0.1226s/iter; left time: 107.4957s
Trial status: 168 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:58:24. Total running time: 2hr 37min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-16aa2a55   RUNNING           4            77.7842       0.612838        1.56441             1.56441 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
163 more TERMINATED
[36m(_train_fn pid=853228)[0m 	iters: 200, epoch: 5 | loss: 0.5456749
[36m(_train_fn pid=853228)[0m 	speed: 0.0701s/iter; left time: 54.4461s
[36m(_train_fn pid=853228)[0m Updating learning rate to 3.1459003908034234e-05
[36m(_train_fn pid=853228)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=853228)[0m saving checkpoint...
[36m(_train_fn pid=853228)[0m Epoch: 5 cost time: 17.100396871566772
[36m(_train_fn pid=853228)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6112693 Vali Loss: 1.5712074 Best vali loss: 1.5644134
[36m(_train_fn pid=853228)[0m 	iters: 100, epoch: 6 | loss: 0.5832320
[36m(_train_fn pid=853228)[0m 	speed: 0.1223s/iter; left time: 77.3938s
[36m(_train_fn pid=853228)[0m 	iters: 200, epoch: 6 | loss: 0.5956959
[36m(_train_fn pid=853228)[0m 	speed: 0.0700s/iter; left time: 37.3093s
Trial status: 168 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:58:54. Total running time: 2hr 37min 45s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-16aa2a55   RUNNING           5            97.0225       0.611269        1.57121             1.56441 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
163 more TERMINATED

Trial trial-16aa2a55 completed after 6 iterations at 2024-08-24 09:58:54. Total running time: 2hr 37min 46s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-16aa2a55 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.24915 â”‚
â”‚ time_total_s                             116.2716 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56149 â”‚
â”‚ train_loss                                 0.6107 â”‚
â”‚ valid_loss                                1.56149 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=853228)[0m Updating learning rate to 1.5729501954017117e-05
[36m(_train_fn pid=853228)[0m saving checkpoint...
[36m(_train_fn pid=853228)[0m Validation loss decreased (1.5644 --> 1.5615).  Saving model state dict ...

Trial trial-994d84e0 started with configuration:
2024-08-24 09:59:16,802	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=854086)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-994d84e0_170_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1882,e_layer_2024-08-24_09-58-54/checkpoint_000000)
[36m(_train_fn pid=854086)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-994d84e0_170_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1882,e_layer_2024-08-24_09-58-54/checkpoint_000001)
[36m(_train_fn pid=854086)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-994d84e0_170_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1882,e_layer_2024-08-24_09-58-54/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-994d84e0 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18824 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0008 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=854086)[0m configuration
[36m(_train_fn pid=854086)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18824143189357143, 'e_layers': 1, 'learning_rate': 0.0007994153225088394, 'd_ff': 1536}
[36m(_train_fn pid=854086)[0m Use GPU: cuda:0
[36m(_train_fn pid=854086)[0m train 7825
[36m(_train_fn pid=854086)[0m val 2161
[36m(_train_fn pid=854086)[0m start_epoch 0
[36m(_train_fn pid=854086)[0m max_epoch 8
[36m(_train_fn pid=854086)[0m 	iters: 100, epoch: 1 | loss: 0.8440498
[36m(_train_fn pid=854086)[0m 	speed: 0.0769s/iter; left time: 142.5127s
[36m(_train_fn pid=854086)[0m 	iters: 200, epoch: 1 | loss: 0.6569545
[36m(_train_fn pid=854086)[0m 	speed: 0.0704s/iter; left time: 123.3636s
[36m(_train_fn pid=854086)[0m Updating learning rate to 0.0007994153225088394
[36m(_train_fn pid=854086)[0m saving checkpoint...
[36m(_train_fn pid=854086)[0m Validation loss decreased (inf --> 1.9201).  Saving model state dict ...
[36m(_train_fn pid=854086)[0m Epoch: 1 cost time: 17.566152095794678
[36m(_train_fn pid=854086)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8031358 Vali Loss: 1.9200831 Best vali loss: 1.9200831
[36m(_train_fn pid=854086)[0m 	iters: 100, epoch: 2 | loss: 0.6417145
[36m(_train_fn pid=854086)[0m 	speed: 0.1230s/iter; left time: 197.9297s

Trial status: 169 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:59:24. Total running time: 2hr 38min 15s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-994d84e0   RUNNING           1            20.1293       0.803136        1.92008             1.92008 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
164 more TERMINATED
[36m(_train_fn pid=854086)[0m 	iters: 200, epoch: 2 | loss: 0.6948966
[36m(_train_fn pid=854086)[0m 	speed: 0.0703s/iter; left time: 106.1002s
[36m(_train_fn pid=854086)[0m Updating learning rate to 0.0003997076612544197
[36m(_train_fn pid=854086)[0m saving checkpoint...
[36m(_train_fn pid=854086)[0m Validation loss decreased (1.9201 --> 1.5706).  Saving model state dict ...
[36m(_train_fn pid=854086)[0m Epoch: 2 cost time: 17.159889459609985
[36m(_train_fn pid=854086)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6894438 Vali Loss: 1.5706198 Best vali loss: 1.5706198
[36m(_train_fn pid=854086)[0m 	iters: 100, epoch: 3 | loss: 0.6663844
[36m(_train_fn pid=854086)[0m 	speed: 0.1226s/iter; left time: 167.4128s
[36m(_train_fn pid=854086)[0m 	iters: 200, epoch: 3 | loss: 0.6278463
[36m(_train_fn pid=854086)[0m 	speed: 0.0700s/iter; left time: 88.5486s
Trial status: 169 TERMINATED | 1 RUNNING
Current time: 2024-08-24 09:59:54. Total running time: 2hr 38min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-994d84e0   RUNNING           2            39.4517       0.689444        1.57062             1.57062 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
164 more TERMINATED
[36m(_train_fn pid=854086)[0m Updating learning rate to 0.00019985383062720986
[36m(_train_fn pid=854086)[0m saving checkpoint...
[36m(_train_fn pid=854086)[0m Validation loss decreased (1.5706 --> 1.5671).  Saving model state dict ...
[36m(_train_fn pid=854086)[0m Epoch: 3 cost time: 17.08648133277893
[36m(_train_fn pid=854086)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6156954 Vali Loss: 1.5671078 Best vali loss: 1.5671078
[36m(_train_fn pid=854086)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-994d84e0_170_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1882,e_layer_2024-08-24_09-58-54/checkpoint_000003)
[36m(_train_fn pid=854086)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-994d84e0_170_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1882,e_layer_2024-08-24_09-58-54/checkpoint_000004)
[36m(_train_fn pid=854086)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-994d84e0_170_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1882,e_layer_2024-08-24_09-58-54/checkpoint_000005)
[36m(_train_fn pid=854086)[0m 	iters: 100, epoch: 4 | loss: 0.6322616
[36m(_train_fn pid=854086)[0m 	speed: 0.1224s/iter; left time: 137.2522s
[36m(_train_fn pid=854086)[0m 	iters: 200, epoch: 4 | loss: 0.6355600
[36m(_train_fn pid=854086)[0m 	speed: 0.0700s/iter; left time: 71.4664s
[36m(_train_fn pid=854086)[0m Updating learning rate to 9.992691531360493e-05
[36m(_train_fn pid=854086)[0m saving checkpoint...
[36m(_train_fn pid=854086)[0m Validation loss decreased (1.5671 --> 1.5642).  Saving model state dict ...
[36m(_train_fn pid=854086)[0m Epoch: 4 cost time: 17.081154584884644
[36m(_train_fn pid=854086)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6112111 Vali Loss: 1.5641921 Best vali loss: 1.5641921
[36m(_train_fn pid=854086)[0m 	iters: 100, epoch: 5 | loss: 0.6051543
[36m(_train_fn pid=854086)[0m 	speed: 0.1225s/iter; left time: 107.3919s
Trial status: 169 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:00:24. Total running time: 2hr 39min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-994d84e0   RUNNING           4            77.9289       0.611211        1.56419             1.56419 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
164 more TERMINATED
[36m(_train_fn pid=854086)[0m 	iters: 200, epoch: 5 | loss: 0.5443763
[36m(_train_fn pid=854086)[0m 	speed: 0.0700s/iter; left time: 54.3768s
[36m(_train_fn pid=854086)[0m Updating learning rate to 4.9963457656802465e-05
[36m(_train_fn pid=854086)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=854086)[0m saving checkpoint...
[36m(_train_fn pid=854086)[0m Epoch: 5 cost time: 17.090405702590942
[36m(_train_fn pid=854086)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6094214 Vali Loss: 1.5706961 Best vali loss: 1.5641921
[36m(_train_fn pid=854086)[0m 	iters: 100, epoch: 6 | loss: 0.5825124
[36m(_train_fn pid=854086)[0m 	speed: 0.1223s/iter; left time: 77.3974s
[36m(_train_fn pid=854086)[0m 	iters: 200, epoch: 6 | loss: 0.5938179
[36m(_train_fn pid=854086)[0m 	speed: 0.0700s/iter; left time: 37.2964s
[36m(_train_fn pid=854086)[0m Updating learning rate to 2.4981728828401233e-05
[36m(_train_fn pid=854086)[0m saving checkpoint...
[36m(_train_fn pid=854086)[0m Validation loss decreased (1.5642 --> 1.5609).  Saving model state dict ...

Trial trial-994d84e0 completed after 6 iterations at 2024-08-24 10:00:53. Total running time: 2hr 39min 44s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-994d84e0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.23292 â”‚
â”‚ time_total_s                            116.38821 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56089 â”‚
â”‚ train_loss                                0.60864 â”‚
â”‚ valid_loss                                1.56089 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 170 TERMINATED | 1 PENDING
Current time: 2024-08-24 10:00:54. Total running time: 2hr 39min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-dcf07010   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
165 more TERMINATED

Trial trial-dcf07010 started with configuration:
2024-08-24 10:01:15,716	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=854947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcf07010_171_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1721,e_layer_2024-08-24_10-00-53/checkpoint_000000)
[36m(_train_fn pid=854947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcf07010_171_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1721,e_layer_2024-08-24_10-00-53/checkpoint_000001)
[36m(_train_fn pid=854947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcf07010_171_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1721,e_layer_2024-08-24_10-00-53/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-dcf07010 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17208 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00057 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=854947)[0m configuration
[36m(_train_fn pid=854947)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1720753751220818, 'e_layers': 1, 'learning_rate': 0.0005744346804237223, 'd_ff': 1536}
[36m(_train_fn pid=854947)[0m Use GPU: cuda:0
[36m(_train_fn pid=854947)[0m train 7825
[36m(_train_fn pid=854947)[0m val 2161
[36m(_train_fn pid=854947)[0m start_epoch 0
[36m(_train_fn pid=854947)[0m max_epoch 8
[36m(_train_fn pid=854947)[0m 	iters: 100, epoch: 1 | loss: 0.8503635
[36m(_train_fn pid=854947)[0m 	speed: 0.0767s/iter; left time: 142.0997s
[36m(_train_fn pid=854947)[0m 	iters: 200, epoch: 1 | loss: 0.6653845
[36m(_train_fn pid=854947)[0m 	speed: 0.0700s/iter; left time: 122.6830s
[36m(_train_fn pid=854947)[0m Updating learning rate to 0.0005744346804237223
[36m(_train_fn pid=854947)[0m saving checkpoint...
[36m(_train_fn pid=854947)[0m Validation loss decreased (inf --> 1.9289).  Saving model state dict ...
[36m(_train_fn pid=854947)[0m Epoch: 1 cost time: 17.49612522125244
[36m(_train_fn pid=854947)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8095173 Vali Loss: 1.9288837 Best vali loss: 1.9288837
[36m(_train_fn pid=854947)[0m 	iters: 100, epoch: 2 | loss: 0.6439926
[36m(_train_fn pid=854947)[0m 	speed: 0.1227s/iter; left time: 197.3900s

Trial status: 170 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:01:24. Total running time: 2hr 40min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-dcf07010   RUNNING           1            20.0677       0.809517        1.92888             1.92888 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
165 more TERMINATED
[36m(_train_fn pid=854947)[0m 	iters: 200, epoch: 2 | loss: 0.6941445
[36m(_train_fn pid=854947)[0m 	speed: 0.0701s/iter; left time: 105.7632s
[36m(_train_fn pid=854947)[0m Updating learning rate to 0.00028721734021186116
[36m(_train_fn pid=854947)[0m saving checkpoint...
[36m(_train_fn pid=854947)[0m Validation loss decreased (1.9289 --> 1.5691).  Saving model state dict ...
[36m(_train_fn pid=854947)[0m Epoch: 2 cost time: 17.100350618362427
[36m(_train_fn pid=854947)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6753152 Vali Loss: 1.5690688 Best vali loss: 1.5690688
[36m(_train_fn pid=854947)[0m 	iters: 100, epoch: 3 | loss: 0.6707572
[36m(_train_fn pid=854947)[0m 	speed: 0.1227s/iter; left time: 167.5382s
[36m(_train_fn pid=854947)[0m 	iters: 200, epoch: 3 | loss: 0.6287095
[36m(_train_fn pid=854947)[0m 	speed: 0.0701s/iter; left time: 88.6594s
[36m(_train_fn pid=854947)[0m Updating learning rate to 0.00014360867010593058
[36m(_train_fn pid=854947)[0m saving checkpoint...
[36m(_train_fn pid=854947)[0m Validation loss decreased (1.5691 --> 1.5666).  Saving model state dict ...
[36m(_train_fn pid=854947)[0m Epoch: 3 cost time: 17.1105535030365
[36m(_train_fn pid=854947)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6173153 Vali Loss: 1.5666071 Best vali loss: 1.5666071
Trial status: 170 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:01:54. Total running time: 2hr 40min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-dcf07010   RUNNING           3            58.6152       0.617315        1.56661             1.56661 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
165 more TERMINATED
[36m(_train_fn pid=854947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcf07010_171_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1721,e_layer_2024-08-24_10-00-53/checkpoint_000003)
[36m(_train_fn pid=854947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcf07010_171_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1721,e_layer_2024-08-24_10-00-53/checkpoint_000004)
[36m(_train_fn pid=854947)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-dcf07010_171_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1721,e_layer_2024-08-24_10-00-53/checkpoint_000005)
[36m(_train_fn pid=854947)[0m 	iters: 100, epoch: 4 | loss: 0.6322867
[36m(_train_fn pid=854947)[0m 	speed: 0.1228s/iter; left time: 137.6768s
[36m(_train_fn pid=854947)[0m 	iters: 200, epoch: 4 | loss: 0.6361406
[36m(_train_fn pid=854947)[0m 	speed: 0.0701s/iter; left time: 71.6129s
[36m(_train_fn pid=854947)[0m Updating learning rate to 7.180433505296529e-05
[36m(_train_fn pid=854947)[0m saving checkpoint...
[36m(_train_fn pid=854947)[0m Validation loss decreased (1.5666 --> 1.5630).  Saving model state dict ...
[36m(_train_fn pid=854947)[0m Epoch: 4 cost time: 17.12387180328369
[36m(_train_fn pid=854947)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6125675 Vali Loss: 1.5630089 Best vali loss: 1.5630089
[36m(_train_fn pid=854947)[0m 	iters: 100, epoch: 5 | loss: 0.6061023
[36m(_train_fn pid=854947)[0m 	speed: 0.1230s/iter; left time: 107.8301s
Trial status: 170 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:02:25. Total running time: 2hr 41min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-dcf07010   RUNNING           4            77.9097       0.612567        1.56301             1.56301 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
165 more TERMINATED
[36m(_train_fn pid=854947)[0m 	iters: 200, epoch: 5 | loss: 0.5452777
[36m(_train_fn pid=854947)[0m 	speed: 0.0703s/iter; left time: 54.5871s
[36m(_train_fn pid=854947)[0m Updating learning rate to 3.5902167526482645e-05
[36m(_train_fn pid=854947)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=854947)[0m saving checkpoint...
[36m(_train_fn pid=854947)[0m Epoch: 5 cost time: 17.151325464248657
[36m(_train_fn pid=854947)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6108494 Vali Loss: 1.5689673 Best vali loss: 1.5630089
[36m(_train_fn pid=854947)[0m 	iters: 100, epoch: 6 | loss: 0.5835672
[36m(_train_fn pid=854947)[0m 	speed: 0.1226s/iter; left time: 77.6093s
[36m(_train_fn pid=854947)[0m 	iters: 200, epoch: 6 | loss: 0.5956746
[36m(_train_fn pid=854947)[0m 	speed: 0.0702s/iter; left time: 37.4038s

Trial trial-dcf07010 completed after 6 iterations at 2024-08-24 10:02:52. Total running time: 2hr 41min 43s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-dcf07010 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.29658 â”‚
â”‚ time_total_s                            116.49809 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56216 â”‚
â”‚ train_loss                                0.61006 â”‚
â”‚ valid_loss                                1.56216 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=854947)[0m Updating learning rate to 1.7951083763241323e-05
[36m(_train_fn pid=854947)[0m saving checkpoint...
[36m(_train_fn pid=854947)[0m Validation loss decreased (1.5630 --> 1.5622).  Saving model state dict ...

Trial trial-19caa7f2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-19caa7f2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19728 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00105 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=855806)[0m configuration
[36m(_train_fn pid=855806)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19728020529707174, 'e_layers': 1, 'learning_rate': 0.0010477992586258957, 'd_ff': 1536}
[36m(_train_fn pid=855806)[0m Use GPU: cuda:0
[36m(_train_fn pid=855806)[0m train 7825
[36m(_train_fn pid=855806)[0m val 2161

Trial status: 171 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:02:55. Total running time: 2hr 41min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
2024-08-24 10:03:14,680	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=855806)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-19caa7f2_172_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1973,e_layer_2024-08-24_10-02-52/checkpoint_000000)
[36m(_train_fn pid=855806)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-19caa7f2_172_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1973,e_layer_2024-08-24_10-02-52/checkpoint_000001)
[36m(_train_fn pid=855806)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-19caa7f2_172_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1973,e_layer_2024-08-24_10-02-52/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-19caa7f2   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
166 more TERMINATED
[36m(_train_fn pid=855806)[0m start_epoch 0
[36m(_train_fn pid=855806)[0m max_epoch 8
[36m(_train_fn pid=855806)[0m 	iters: 100, epoch: 1 | loss: 0.8362524
[36m(_train_fn pid=855806)[0m 	speed: 0.0765s/iter; left time: 141.7333s
[36m(_train_fn pid=855806)[0m 	iters: 200, epoch: 1 | loss: 0.6517819
[36m(_train_fn pid=855806)[0m 	speed: 0.0700s/iter; left time: 122.6890s
[36m(_train_fn pid=855806)[0m Updating learning rate to 0.0010477992586258957
[36m(_train_fn pid=855806)[0m saving checkpoint...
[36m(_train_fn pid=855806)[0m Validation loss decreased (inf --> 1.9078).  Saving model state dict ...
[36m(_train_fn pid=855806)[0m Epoch: 1 cost time: 17.472877025604248
[36m(_train_fn pid=855806)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7970579 Vali Loss: 1.9077941 Best vali loss: 1.9077941
[36m(_train_fn pid=855806)[0m 	iters: 100, epoch: 2 | loss: 0.6725196
[36m(_train_fn pid=855806)[0m 	speed: 0.1227s/iter; left time: 197.4535s
Trial status: 171 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:03:25. Total running time: 2hr 42min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-19caa7f2   RUNNING           1            20.0347       0.797058        1.90779             1.90779 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
166 more TERMINATED
[36m(_train_fn pid=855806)[0m 	iters: 200, epoch: 2 | loss: 0.7097676
[36m(_train_fn pid=855806)[0m 	speed: 0.0702s/iter; left time: 105.9438s
[36m(_train_fn pid=855806)[0m Updating learning rate to 0.0005238996293129479
[36m(_train_fn pid=855806)[0m saving checkpoint...
[36m(_train_fn pid=855806)[0m Validation loss decreased (1.9078 --> 1.5910).  Saving model state dict ...
[36m(_train_fn pid=855806)[0m Epoch: 2 cost time: 17.144965171813965
[36m(_train_fn pid=855806)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7511697 Vali Loss: 1.5909634 Best vali loss: 1.5909634
[36m(_train_fn pid=855806)[0m 	iters: 100, epoch: 3 | loss: 0.6783941
[36m(_train_fn pid=855806)[0m 	speed: 0.1230s/iter; left time: 167.8865s
[36m(_train_fn pid=855806)[0m 	iters: 200, epoch: 3 | loss: 0.6455191
[36m(_train_fn pid=855806)[0m 	speed: 0.0704s/iter; left time: 89.0156s
[36m(_train_fn pid=855806)[0m Updating learning rate to 0.00026194981465647393
[36m(_train_fn pid=855806)[0m saving checkpoint...
[36m(_train_fn pid=855806)[0m Validation loss decreased (1.5910 --> 1.5732).  Saving model state dict ...
[36m(_train_fn pid=855806)[0m Epoch: 3 cost time: 17.169764280319214
[36m(_train_fn pid=855806)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6214188 Vali Loss: 1.5732214 Best vali loss: 1.5732214
Trial status: 171 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:03:55. Total running time: 2hr 42min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=855806)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-19caa7f2_172_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1973,e_layer_2024-08-24_10-02-52/checkpoint_000003)
[36m(_train_fn pid=855806)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-19caa7f2_172_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1973,e_layer_2024-08-24_10-02-52/checkpoint_000004)
[36m(_train_fn pid=855806)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-19caa7f2_172_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1973,e_layer_2024-08-24_10-02-52/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-19caa7f2   RUNNING           3            58.6798       0.621419        1.57322             1.57322 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
166 more TERMINATED
[36m(_train_fn pid=855806)[0m 	iters: 100, epoch: 4 | loss: 0.6363251
[36m(_train_fn pid=855806)[0m 	speed: 0.1231s/iter; left time: 138.0017s
[36m(_train_fn pid=855806)[0m 	iters: 200, epoch: 4 | loss: 0.6387333
[36m(_train_fn pid=855806)[0m 	speed: 0.0704s/iter; left time: 71.8548s
[36m(_train_fn pid=855806)[0m Updating learning rate to 0.00013097490732823697
[36m(_train_fn pid=855806)[0m saving checkpoint...
[36m(_train_fn pid=855806)[0m Validation loss decreased (1.5732 --> 1.5708).  Saving model state dict ...
[36m(_train_fn pid=855806)[0m Epoch: 4 cost time: 17.18049669265747
[36m(_train_fn pid=855806)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6155745 Vali Loss: 1.5707568 Best vali loss: 1.5707568
[36m(_train_fn pid=855806)[0m 	iters: 100, epoch: 5 | loss: 0.6075121
[36m(_train_fn pid=855806)[0m 	speed: 0.1233s/iter; left time: 108.0983s
Trial status: 171 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:04:25. Total running time: 2hr 43min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-19caa7f2   RUNNING           4            78.0289       0.615575        1.57076             1.57076 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
166 more TERMINATED
[36m(_train_fn pid=855806)[0m 	iters: 200, epoch: 5 | loss: 0.5482432
[36m(_train_fn pid=855806)[0m 	speed: 0.0704s/iter; left time: 54.7058s
[36m(_train_fn pid=855806)[0m Updating learning rate to 6.548745366411848e-05
[36m(_train_fn pid=855806)[0m saving checkpoint...
[36m(_train_fn pid=855806)[0m Validation loss decreased (1.5708 --> 1.5677).  Saving model state dict ...
[36m(_train_fn pid=855806)[0m Epoch: 5 cost time: 17.194933891296387
[36m(_train_fn pid=855806)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6139646 Vali Loss: 1.5676965 Best vali loss: 1.5676965
[36m(_train_fn pid=855806)[0m 	iters: 100, epoch: 6 | loss: 0.5929014
[36m(_train_fn pid=855806)[0m 	speed: 0.1230s/iter; left time: 77.8836s
[36m(_train_fn pid=855806)[0m 	iters: 200, epoch: 6 | loss: 0.6003680
[36m(_train_fn pid=855806)[0m 	speed: 0.0701s/iter; left time: 37.3384s

Trial trial-19caa7f2 completed after 6 iterations at 2024-08-24 10:04:51. Total running time: 2hr 43min 42s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-19caa7f2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.27012 â”‚
â”‚ time_total_s                            116.67258 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56608 â”‚
â”‚ train_loss                                 0.6129 â”‚
â”‚ valid_loss                                1.56608 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=855806)[0m Updating learning rate to 3.274372683205924e-05
[36m(_train_fn pid=855806)[0m saving checkpoint...
[36m(_train_fn pid=855806)[0m Validation loss decreased (1.5677 --> 1.5661).  Saving model state dict ...

Trial trial-86cfced8 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-86cfced8 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19543 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00079 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=856665)[0m configuration
2024-08-24 10:05:13,718	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=856665)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-86cfced8_173_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1954,e_layer_2024-08-24_10-04-51/checkpoint_000000)
[36m(_train_fn pid=856665)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-86cfced8_173_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1954,e_layer_2024-08-24_10-04-51/checkpoint_000001)
[36m(_train_fn pid=856665)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-86cfced8_173_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1954,e_layer_2024-08-24_10-04-51/checkpoint_000002)
[36m(_train_fn pid=856665)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19542833430060907, 'e_layers': 1, 'learning_rate': 0.0007909164347950213, 'd_ff': 1536}
[36m(_train_fn pid=856665)[0m Use GPU: cuda:0
[36m(_train_fn pid=856665)[0m train 7825
[36m(_train_fn pid=856665)[0m val 2161
[36m(_train_fn pid=856665)[0m start_epoch 0
[36m(_train_fn pid=856665)[0m max_epoch 8

Trial status: 172 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:04:55. Total running time: 2hr 43min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-86cfced8   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
167 more TERMINATED
[36m(_train_fn pid=856665)[0m 	iters: 100, epoch: 1 | loss: 0.8456817
[36m(_train_fn pid=856665)[0m 	speed: 0.0765s/iter; left time: 141.6805s
[36m(_train_fn pid=856665)[0m 	iters: 200, epoch: 1 | loss: 0.6571026
[36m(_train_fn pid=856665)[0m 	speed: 0.0700s/iter; left time: 122.6891s
[36m(_train_fn pid=856665)[0m Updating learning rate to 0.0007909164347950213
[36m(_train_fn pid=856665)[0m saving checkpoint...
[36m(_train_fn pid=856665)[0m Validation loss decreased (inf --> 1.9207).  Saving model state dict ...
[36m(_train_fn pid=856665)[0m Epoch: 1 cost time: 17.468836307525635
[36m(_train_fn pid=856665)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8045567 Vali Loss: 1.9207143 Best vali loss: 1.9207143
[36m(_train_fn pid=856665)[0m 	iters: 100, epoch: 2 | loss: 0.6419420
[36m(_train_fn pid=856665)[0m 	speed: 0.1226s/iter; left time: 197.2911s
Trial status: 172 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:05:25. Total running time: 2hr 44min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-86cfced8   RUNNING           1            20.0465       0.804557        1.92071             1.92071 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
167 more TERMINATED
[36m(_train_fn pid=856665)[0m 	iters: 200, epoch: 2 | loss: 0.6920869
[36m(_train_fn pid=856665)[0m 	speed: 0.0701s/iter; left time: 105.7949s
[36m(_train_fn pid=856665)[0m Updating learning rate to 0.00039545821739751065
[36m(_train_fn pid=856665)[0m saving checkpoint...
[36m(_train_fn pid=856665)[0m Validation loss decreased (1.9207 --> 1.5716).  Saving model state dict ...
[36m(_train_fn pid=856665)[0m Epoch: 2 cost time: 17.112568616867065
[36m(_train_fn pid=856665)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6883937 Vali Loss: 1.5715845 Best vali loss: 1.5715845
[36m(_train_fn pid=856665)[0m 	iters: 100, epoch: 3 | loss: 0.6673567
[36m(_train_fn pid=856665)[0m 	speed: 0.1226s/iter; left time: 167.3540s
[36m(_train_fn pid=856665)[0m 	iters: 200, epoch: 3 | loss: 0.6276524
[36m(_train_fn pid=856665)[0m 	speed: 0.0701s/iter; left time: 88.6594s
[36m(_train_fn pid=856665)[0m Updating learning rate to 0.00019772910869875532
[36m(_train_fn pid=856665)[0m saving checkpoint...
[36m(_train_fn pid=856665)[0m Validation loss decreased (1.5716 --> 1.5663).  Saving model state dict ...
[36m(_train_fn pid=856665)[0m Epoch: 3 cost time: 17.10916304588318
[36m(_train_fn pid=856665)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6159507 Vali Loss: 1.5662836 Best vali loss: 1.5662836
Trial status: 172 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:05:55. Total running time: 2hr 44min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=856665)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-86cfced8_173_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1954,e_layer_2024-08-24_10-04-51/checkpoint_000003)
[36m(_train_fn pid=856665)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-86cfced8_173_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1954,e_layer_2024-08-24_10-04-51/checkpoint_000004)
[36m(_train_fn pid=856665)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-86cfced8_173_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1954,e_layer_2024-08-24_10-04-51/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-86cfced8   RUNNING           3            58.5835       0.615951        1.56628             1.56628 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
167 more TERMINATED
[36m(_train_fn pid=856665)[0m 	iters: 100, epoch: 4 | loss: 0.6325611
[36m(_train_fn pid=856665)[0m 	speed: 0.1227s/iter; left time: 137.5379s
[36m(_train_fn pid=856665)[0m 	iters: 200, epoch: 4 | loss: 0.6362625
[36m(_train_fn pid=856665)[0m 	speed: 0.0701s/iter; left time: 71.5828s
[36m(_train_fn pid=856665)[0m Updating learning rate to 9.886455434937766e-05
[36m(_train_fn pid=856665)[0m saving checkpoint...
[36m(_train_fn pid=856665)[0m Validation loss decreased (1.5663 --> 1.5651).  Saving model state dict ...
[36m(_train_fn pid=856665)[0m Epoch: 4 cost time: 17.11447763442993
[36m(_train_fn pid=856665)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6111564 Vali Loss: 1.5651464 Best vali loss: 1.5651464
[36m(_train_fn pid=856665)[0m 	iters: 100, epoch: 5 | loss: 0.6052042
[36m(_train_fn pid=856665)[0m 	speed: 0.1232s/iter; left time: 108.0562s
Trial status: 172 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:06:25. Total running time: 2hr 45min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-86cfced8   RUNNING           4            77.8758       0.611156        1.56515             1.56515 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
167 more TERMINATED
[36m(_train_fn pid=856665)[0m 	iters: 200, epoch: 5 | loss: 0.5445675
[36m(_train_fn pid=856665)[0m 	speed: 0.0704s/iter; left time: 54.7297s
[36m(_train_fn pid=856665)[0m Updating learning rate to 4.943227717468883e-05
[36m(_train_fn pid=856665)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=856665)[0m saving checkpoint...
[36m(_train_fn pid=856665)[0m Epoch: 5 cost time: 17.199431657791138
[36m(_train_fn pid=856665)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6093848 Vali Loss: 1.5724753 Best vali loss: 1.5651464
[36m(_train_fn pid=856665)[0m 	iters: 100, epoch: 6 | loss: 0.5824329
[36m(_train_fn pid=856665)[0m 	speed: 0.1229s/iter; left time: 77.7965s
[36m(_train_fn pid=856665)[0m 	iters: 200, epoch: 6 | loss: 0.5939048
[36m(_train_fn pid=856665)[0m 	speed: 0.0704s/iter; left time: 37.5073s
[36m(_train_fn pid=856665)[0m Updating learning rate to 2.4716138587344415e-05
[36m(_train_fn pid=856665)[0m saving checkpoint...
[36m(_train_fn pid=856665)[0m Validation loss decreased (1.5651 --> 1.5608).  Saving model state dict ...

Trial trial-86cfced8 completed after 6 iterations at 2024-08-24 10:06:50. Total running time: 2hr 45min 41s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-86cfced8 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.35233 â”‚
â”‚ time_total_s                            116.56719 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56077 â”‚
â”‚ train_loss                                0.60862 â”‚
â”‚ valid_loss                                1.56077 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-f641d2d1 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f641d2d1 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17591 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00062 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=857525)[0m configuration
2024-08-24 10:07:12,703	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=857525)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f641d2d1_174_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1759,e_layer_2024-08-24_10-06-50/checkpoint_000000)
[36m(_train_fn pid=857525)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f641d2d1_174_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1759,e_layer_2024-08-24_10-06-50/checkpoint_000001)
[36m(_train_fn pid=857525)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f641d2d1_174_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1759,e_layer_2024-08-24_10-06-50/checkpoint_000002)
[36m(_train_fn pid=857525)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.17590662224404055, 'e_layers': 1, 'learning_rate': 0.0006240467322178126, 'd_ff': 1536}
[36m(_train_fn pid=857525)[0m Use GPU: cuda:0
[36m(_train_fn pid=857525)[0m train 7825
[36m(_train_fn pid=857525)[0m val 2161
[36m(_train_fn pid=857525)[0m start_epoch 0
[36m(_train_fn pid=857525)[0m max_epoch 8

Trial status: 173 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:06:55. Total running time: 2hr 45min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f641d2d1   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
168 more TERMINATED
[36m(_train_fn pid=857525)[0m 	iters: 100, epoch: 1 | loss: 0.8492441
[36m(_train_fn pid=857525)[0m 	speed: 0.0764s/iter; left time: 141.6176s
[36m(_train_fn pid=857525)[0m 	iters: 200, epoch: 1 | loss: 0.6629503
[36m(_train_fn pid=857525)[0m 	speed: 0.0700s/iter; left time: 122.6428s
[36m(_train_fn pid=857525)[0m Updating learning rate to 0.0006240467322178126
[36m(_train_fn pid=857525)[0m saving checkpoint...
[36m(_train_fn pid=857525)[0m Validation loss decreased (inf --> 1.9271).  Saving model state dict ...
[36m(_train_fn pid=857525)[0m Epoch: 1 cost time: 17.45763635635376
[36m(_train_fn pid=857525)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8079419 Vali Loss: 1.9271267 Best vali loss: 1.9271267
[36m(_train_fn pid=857525)[0m 	iters: 100, epoch: 2 | loss: 0.6359066
[36m(_train_fn pid=857525)[0m 	speed: 0.1224s/iter; left time: 196.9500s
Trial status: 173 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:07:25. Total running time: 2hr 46min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f641d2d1   RUNNING           1            20.0222       0.807942        1.92713             1.92713 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
168 more TERMINATED
[36m(_train_fn pid=857525)[0m 	iters: 200, epoch: 2 | loss: 0.6936188
[36m(_train_fn pid=857525)[0m 	speed: 0.0700s/iter; left time: 105.5869s
[36m(_train_fn pid=857525)[0m Updating learning rate to 0.0003120233661089063
[36m(_train_fn pid=857525)[0m saving checkpoint...
[36m(_train_fn pid=857525)[0m Validation loss decreased (1.9271 --> 1.5699).  Saving model state dict ...
[36m(_train_fn pid=857525)[0m Epoch: 2 cost time: 17.080915451049805
[36m(_train_fn pid=857525)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6665866 Vali Loss: 1.5699359 Best vali loss: 1.5699359
[36m(_train_fn pid=857525)[0m 	iters: 100, epoch: 3 | loss: 0.6681940
[36m(_train_fn pid=857525)[0m 	speed: 0.1225s/iter; left time: 167.2202s
[36m(_train_fn pid=857525)[0m 	iters: 200, epoch: 3 | loss: 0.6278768
[36m(_train_fn pid=857525)[0m 	speed: 0.0701s/iter; left time: 88.6855s
[36m(_train_fn pid=857525)[0m Updating learning rate to 0.00015601168305445315
[36m(_train_fn pid=857525)[0m saving checkpoint...
[36m(_train_fn pid=857525)[0m Validation loss decreased (1.5699 --> 1.5663).  Saving model state dict ...
[36m(_train_fn pid=857525)[0m Epoch: 3 cost time: 17.111963748931885
[36m(_train_fn pid=857525)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6161459 Vali Loss: 1.5663035 Best vali loss: 1.5663035
Trial status: 173 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:07:55. Total running time: 2hr 46min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=857525)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f641d2d1_174_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1759,e_layer_2024-08-24_10-06-50/checkpoint_000003)
[36m(_train_fn pid=857525)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f641d2d1_174_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1759,e_layer_2024-08-24_10-06-50/checkpoint_000004)
[36m(_train_fn pid=857525)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f641d2d1_174_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1759,e_layer_2024-08-24_10-06-50/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f641d2d1   RUNNING           3            58.5292       0.616146        1.5663              1.5663  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
168 more TERMINATED
[36m(_train_fn pid=857525)[0m 	iters: 100, epoch: 4 | loss: 0.6346440
[36m(_train_fn pid=857525)[0m 	speed: 0.1228s/iter; left time: 137.6551s
[36m(_train_fn pid=857525)[0m 	iters: 200, epoch: 4 | loss: 0.6351279
[36m(_train_fn pid=857525)[0m 	speed: 0.0702s/iter; left time: 71.6362s
[36m(_train_fn pid=857525)[0m Updating learning rate to 7.800584152722657e-05
[36m(_train_fn pid=857525)[0m saving checkpoint...
[36m(_train_fn pid=857525)[0m Validation loss decreased (1.5663 --> 1.5642).  Saving model state dict ...
[36m(_train_fn pid=857525)[0m Epoch: 4 cost time: 17.128227710723877
[36m(_train_fn pid=857525)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6118389 Vali Loss: 1.5642445 Best vali loss: 1.5642445
[36m(_train_fn pid=857525)[0m 	iters: 100, epoch: 5 | loss: 0.6054464
[36m(_train_fn pid=857525)[0m 	speed: 0.1230s/iter; left time: 107.9130s
[36m(_train_fn pid=857525)[0m 	iters: 200, epoch: 5 | loss: 0.5446498
[36m(_train_fn pid=857525)[0m 	speed: 0.0703s/iter; left time: 54.6605s
Trial status: 173 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:08:25. Total running time: 2hr 47min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f641d2d1   RUNNING           4            77.821        0.611839        1.56424             1.56424 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
168 more TERMINATED
[36m(_train_fn pid=857525)[0m Updating learning rate to 3.900292076361329e-05
[36m(_train_fn pid=857525)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=857525)[0m saving checkpoint...
[36m(_train_fn pid=857525)[0m Epoch: 5 cost time: 17.18295431137085
[36m(_train_fn pid=857525)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6099554 Vali Loss: 1.5701640 Best vali loss: 1.5642445
[36m(_train_fn pid=857525)[0m 	iters: 100, epoch: 6 | loss: 0.5826278
[36m(_train_fn pid=857525)[0m 	speed: 0.1231s/iter; left time: 77.9206s
[36m(_train_fn pid=857525)[0m 	iters: 200, epoch: 6 | loss: 0.5947869
[36m(_train_fn pid=857525)[0m 	speed: 0.0703s/iter; left time: 37.4930s

Trial trial-f641d2d1 completed after 6 iterations at 2024-08-24 10:08:49. Total running time: 2hr 47min 40s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f641d2d1 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.34651 â”‚
â”‚ time_total_s                            116.50401 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56164 â”‚
â”‚ train_loss                                0.60927 â”‚
â”‚ valid_loss                                1.56164 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=857525)[0m Updating learning rate to 1.9501460381806644e-05
[36m(_train_fn pid=857525)[0m saving checkpoint...
[36m(_train_fn pid=857525)[0m Validation loss decreased (1.5642 --> 1.5616).  Saving model state dict ...

Trial trial-e90c3939 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e90c3939 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19366 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00084 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=858384)[0m configuration
2024-08-24 10:09:11,689	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=858384)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e90c3939_175_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1937,e_layer_2024-08-24_10-08-49/checkpoint_000000)
[36m(_train_fn pid=858384)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e90c3939_175_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1937,e_layer_2024-08-24_10-08-49/checkpoint_000001)
[36m(_train_fn pid=858384)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e90c3939_175_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1937,e_layer_2024-08-24_10-08-49/checkpoint_000002)
[36m(_train_fn pid=858384)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19366173708635612, 'e_layers': 1, 'learning_rate': 0.0008439277989600191, 'd_ff': 1536}
[36m(_train_fn pid=858384)[0m Use GPU: cuda:0
[36m(_train_fn pid=858384)[0m train 7825
[36m(_train_fn pid=858384)[0m val 2161
[36m(_train_fn pid=858384)[0m start_epoch 0
[36m(_train_fn pid=858384)[0m max_epoch 8

Trial status: 174 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:08:55. Total running time: 2hr 47min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e90c3939   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
169 more TERMINATED
[36m(_train_fn pid=858384)[0m 	iters: 100, epoch: 1 | loss: 0.8434766
[36m(_train_fn pid=858384)[0m 	speed: 0.0764s/iter; left time: 141.6434s
[36m(_train_fn pid=858384)[0m 	iters: 200, epoch: 1 | loss: 0.6558154
[36m(_train_fn pid=858384)[0m 	speed: 0.0700s/iter; left time: 122.7546s
[36m(_train_fn pid=858384)[0m Updating learning rate to 0.0008439277989600191
[36m(_train_fn pid=858384)[0m saving checkpoint...
[36m(_train_fn pid=858384)[0m Validation loss decreased (inf --> 1.9184).  Saving model state dict ...
[36m(_train_fn pid=858384)[0m Epoch: 1 cost time: 17.468319416046143
[36m(_train_fn pid=858384)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8023867 Vali Loss: 1.9184192 Best vali loss: 1.9184192
[36m(_train_fn pid=858384)[0m 	iters: 100, epoch: 2 | loss: 0.6339118
[36m(_train_fn pid=858384)[0m 	speed: 0.1224s/iter; left time: 197.0022s
Trial status: 174 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:09:25. Total running time: 2hr 48min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e90c3939   RUNNING           1            20.0321       0.802387        1.91842             1.91842 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
169 more TERMINATED
[36m(_train_fn pid=858384)[0m 	iters: 200, epoch: 2 | loss: 0.6930844
[36m(_train_fn pid=858384)[0m 	speed: 0.0700s/iter; left time: 105.6133s
[36m(_train_fn pid=858384)[0m Updating learning rate to 0.00042196389948000954
[36m(_train_fn pid=858384)[0m saving checkpoint...
[36m(_train_fn pid=858384)[0m Validation loss decreased (1.9184 --> 1.5773).  Saving model state dict ...
[36m(_train_fn pid=858384)[0m Epoch: 2 cost time: 17.087801218032837
[36m(_train_fn pid=858384)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7002299 Vali Loss: 1.5773130 Best vali loss: 1.5773130
[36m(_train_fn pid=858384)[0m 	iters: 100, epoch: 3 | loss: 0.6662148
[36m(_train_fn pid=858384)[0m 	speed: 0.1225s/iter; left time: 167.2576s
[36m(_train_fn pid=858384)[0m 	iters: 200, epoch: 3 | loss: 0.6267314
[36m(_train_fn pid=858384)[0m 	speed: 0.0700s/iter; left time: 88.5941s
[36m(_train_fn pid=858384)[0m Updating learning rate to 0.00021098194974000477
[36m(_train_fn pid=858384)[0m saving checkpoint...
[36m(_train_fn pid=858384)[0m Validation loss decreased (1.5773 --> 1.5656).  Saving model state dict ...
[36m(_train_fn pid=858384)[0m Epoch: 3 cost time: 17.096913814544678
[36m(_train_fn pid=858384)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6145390 Vali Loss: 1.5655645 Best vali loss: 1.5655645
Trial status: 174 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:09:55. Total running time: 2hr 48min 46s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=858384)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e90c3939_175_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1937,e_layer_2024-08-24_10-08-49/checkpoint_000003)
[36m(_train_fn pid=858384)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e90c3939_175_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1937,e_layer_2024-08-24_10-08-49/checkpoint_000004)
[36m(_train_fn pid=858384)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e90c3939_175_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1937,e_layer_2024-08-24_10-08-49/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e90c3939   RUNNING           3            58.5439       0.614539        1.56556             1.56556 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
169 more TERMINATED
[36m(_train_fn pid=858384)[0m 	iters: 100, epoch: 4 | loss: 0.6330692
[36m(_train_fn pid=858384)[0m 	speed: 0.1228s/iter; left time: 137.7036s
[36m(_train_fn pid=858384)[0m 	iters: 200, epoch: 4 | loss: 0.6372095
[36m(_train_fn pid=858384)[0m 	speed: 0.0702s/iter; left time: 71.6365s
[36m(_train_fn pid=858384)[0m Updating learning rate to 0.00010549097487000239
[36m(_train_fn pid=858384)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=858384)[0m saving checkpoint...
[36m(_train_fn pid=858384)[0m Epoch: 4 cost time: 17.130211114883423
[36m(_train_fn pid=858384)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6110484 Vali Loss: 1.5664906 Best vali loss: 1.5655645
[36m(_train_fn pid=858384)[0m 	iters: 100, epoch: 5 | loss: 0.6056733
[36m(_train_fn pid=858384)[0m 	speed: 0.1225s/iter; left time: 107.4206s
[36m(_train_fn pid=858384)[0m 	iters: 200, epoch: 5 | loss: 0.5445924
[36m(_train_fn pid=858384)[0m 	speed: 0.0701s/iter; left time: 54.5031s
Trial status: 174 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:10:25. Total running time: 2hr 49min 16s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e90c3939   RUNNING           4            77.8132       0.611048        1.56649             1.56556 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
169 more TERMINATED
[36m(_train_fn pid=858384)[0m Updating learning rate to 5.274548743500119e-05
[36m(_train_fn pid=858384)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=858384)[0m saving checkpoint...
[36m(_train_fn pid=858384)[0m Epoch: 5 cost time: 17.116408109664917
[36m(_train_fn pid=858384)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6093187 Vali Loss: 1.5683028 Best vali loss: 1.5655645
[36m(_train_fn pid=858384)[0m 	iters: 100, epoch: 6 | loss: 0.5822655
[36m(_train_fn pid=858384)[0m 	speed: 0.1224s/iter; left time: 77.4831s
[36m(_train_fn pid=858384)[0m 	iters: 200, epoch: 6 | loss: 0.5939282
[36m(_train_fn pid=858384)[0m 	speed: 0.0701s/iter; left time: 37.3393s

Trial trial-e90c3939 completed after 6 iterations at 2024-08-24 10:10:47. Total running time: 2hr 49min 39s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e90c3939 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.27366 â”‚
â”‚ time_total_s                            116.33666 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56271 â”‚
â”‚ train_loss                                 0.6085 â”‚
â”‚ valid_loss                                1.56271 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=858384)[0m Updating learning rate to 2.6372743717500596e-05
[36m(_train_fn pid=858384)[0m saving checkpoint...
[36m(_train_fn pid=858384)[0m Validation loss decreased (1.5656 --> 1.5627).  Saving model state dict ...

Trial trial-26da4402 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-26da4402 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.1856 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0005 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=859251)[0m configuration
2024-08-24 10:11:09,684	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=859251)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-26da4402_176_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1856,e_layer_2024-08-24_10-10-48/checkpoint_000000)
[36m(_train_fn pid=859251)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-26da4402_176_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1856,e_layer_2024-08-24_10-10-48/checkpoint_000001)
[36m(_train_fn pid=859251)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-26da4402_176_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1856,e_layer_2024-08-24_10-10-48/checkpoint_000002)
[36m(_train_fn pid=859251)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1855988143416285, 'e_layers': 1, 'learning_rate': 0.0005017709619401364, 'd_ff': 1536}
[36m(_train_fn pid=859251)[0m Use GPU: cuda:0
[36m(_train_fn pid=859251)[0m train 7825
[36m(_train_fn pid=859251)[0m val 2161
[36m(_train_fn pid=859251)[0m start_epoch 0
[36m(_train_fn pid=859251)[0m max_epoch 8

Trial status: 175 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:10:55. Total running time: 2hr 49min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-26da4402   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
170 more TERMINATED
[36m(_train_fn pid=859251)[0m 	iters: 100, epoch: 1 | loss: 0.8585742
[36m(_train_fn pid=859251)[0m 	speed: 0.0765s/iter; left time: 141.7530s
[36m(_train_fn pid=859251)[0m 	iters: 200, epoch: 1 | loss: 0.6693755
[36m(_train_fn pid=859251)[0m 	speed: 0.0700s/iter; left time: 122.6954s
[36m(_train_fn pid=859251)[0m Updating learning rate to 0.0005017709619401364
[36m(_train_fn pid=859251)[0m saving checkpoint...
[36m(_train_fn pid=859251)[0m Validation loss decreased (inf --> 1.9316).  Saving model state dict ...
[36m(_train_fn pid=859251)[0m Epoch: 1 cost time: 17.469266176223755
[36m(_train_fn pid=859251)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8166308 Vali Loss: 1.9316208 Best vali loss: 1.9316208
[36m(_train_fn pid=859251)[0m 	iters: 100, epoch: 2 | loss: 0.6417416
[36m(_train_fn pid=859251)[0m 	speed: 0.1225s/iter; left time: 197.1049s
[36m(_train_fn pid=859251)[0m 	iters: 200, epoch: 2 | loss: 0.6969135
[36m(_train_fn pid=859251)[0m 	speed: 0.0700s/iter; left time: 105.7036s
Trial status: 175 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:11:25. Total running time: 2hr 50min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-26da4402   RUNNING           1            20.029        0.816631        1.93162             1.93162 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
170 more TERMINATED
[36m(_train_fn pid=859251)[0m Updating learning rate to 0.0002508854809700682
[36m(_train_fn pid=859251)[0m saving checkpoint...
[36m(_train_fn pid=859251)[0m Validation loss decreased (1.9316 --> 1.5720).  Saving model state dict ...
[36m(_train_fn pid=859251)[0m Epoch: 2 cost time: 17.10062289237976
[36m(_train_fn pid=859251)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6604076 Vali Loss: 1.5720173 Best vali loss: 1.5720173
[36m(_train_fn pid=859251)[0m 	iters: 100, epoch: 3 | loss: 0.6685441
[36m(_train_fn pid=859251)[0m 	speed: 0.1229s/iter; left time: 167.7018s
[36m(_train_fn pid=859251)[0m 	iters: 200, epoch: 3 | loss: 0.6297511
[36m(_train_fn pid=859251)[0m 	speed: 0.0702s/iter; left time: 88.7592s
[36m(_train_fn pid=859251)[0m Updating learning rate to 0.0001254427404850341
[36m(_train_fn pid=859251)[0m saving checkpoint...
[36m(_train_fn pid=859251)[0m Validation loss decreased (1.5720 --> 1.5656).  Saving model state dict ...
[36m(_train_fn pid=859251)[0m Epoch: 3 cost time: 17.14118719100952
[36m(_train_fn pid=859251)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6174957 Vali Loss: 1.5655864 Best vali loss: 1.5655864
[36m(_train_fn pid=859251)[0m 	iters: 100, epoch: 4 | loss: 0.6340005
[36m(_train_fn pid=859251)[0m 	speed: 0.1228s/iter; left time: 137.6260s
Trial status: 175 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:11:55. Total running time: 2hr 50min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=859251)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-26da4402_176_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1856,e_layer_2024-08-24_10-10-48/checkpoint_000003)
[36m(_train_fn pid=859251)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-26da4402_176_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1856,e_layer_2024-08-24_10-10-48/checkpoint_000004)
[36m(_train_fn pid=859251)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-26da4402_176_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1856,e_layer_2024-08-24_10-10-48/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-26da4402   RUNNING           3            58.5906       0.617496        1.56559             1.56559 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
170 more TERMINATED
[36m(_train_fn pid=859251)[0m 	iters: 200, epoch: 4 | loss: 0.6361505
[36m(_train_fn pid=859251)[0m 	speed: 0.0702s/iter; left time: 71.7236s
[36m(_train_fn pid=859251)[0m Updating learning rate to 6.272137024251705e-05
[36m(_train_fn pid=859251)[0m saving checkpoint...
[36m(_train_fn pid=859251)[0m Validation loss decreased (1.5656 --> 1.5641).  Saving model state dict ...
[36m(_train_fn pid=859251)[0m Epoch: 4 cost time: 17.137964725494385
[36m(_train_fn pid=859251)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6128386 Vali Loss: 1.5641022 Best vali loss: 1.5641022
[36m(_train_fn pid=859251)[0m 	iters: 100, epoch: 5 | loss: 0.6069149
[36m(_train_fn pid=859251)[0m 	speed: 0.1229s/iter; left time: 107.7696s
[36m(_train_fn pid=859251)[0m 	iters: 200, epoch: 5 | loss: 0.5454437
[36m(_train_fn pid=859251)[0m 	speed: 0.0702s/iter; left time: 54.5201s
Trial status: 175 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:12:26. Total running time: 2hr 51min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-26da4402   RUNNING           4            77.8934       0.612839        1.5641              1.5641  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
170 more TERMINATED
[36m(_train_fn pid=859251)[0m Updating learning rate to 3.1360685121258525e-05
[36m(_train_fn pid=859251)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=859251)[0m saving checkpoint...
[36m(_train_fn pid=859251)[0m Epoch: 5 cost time: 17.135986804962158
[36m(_train_fn pid=859251)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6111914 Vali Loss: 1.5707150 Best vali loss: 1.5641022
[36m(_train_fn pid=859251)[0m 	iters: 100, epoch: 6 | loss: 0.5832400
[36m(_train_fn pid=859251)[0m 	speed: 0.1227s/iter; left time: 77.6417s
[36m(_train_fn pid=859251)[0m 	iters: 200, epoch: 6 | loss: 0.5954619
[36m(_train_fn pid=859251)[0m 	speed: 0.0702s/iter; left time: 37.4216s
[36m(_train_fn pid=859251)[0m Updating learning rate to 1.5680342560629262e-05
[36m(_train_fn pid=859251)[0m saving checkpoint...
[36m(_train_fn pid=859251)[0m Validation loss decreased (1.5641 --> 1.5615).  Saving model state dict ...

Trial trial-26da4402 completed after 6 iterations at 2024-08-24 10:12:46. Total running time: 2hr 51min 37s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-26da4402 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.30103 â”‚
â”‚ time_total_s                             116.4683 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56153 â”‚
â”‚ train_loss                                0.61062 â”‚
â”‚ valid_loss                                1.56153 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-991da5f6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-991da5f6 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.2036 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00428 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=860110)[0m configuration
[36m(_train_fn pid=860110)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.2036038852580143, 'e_layers': 1, 'learning_rate': 0.004278823536202294, 'd_ff': 1536}
[36m(_train_fn pid=860110)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-991da5f6_177_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2036,e_layer_2024-08-24_10-12-46/checkpoint_000000)
2024-08-24 10:13:08,660	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=860110)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-991da5f6_177_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2036,e_layer_2024-08-24_10-12-46/checkpoint_000001)
[36m(_train_fn pid=860110)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-991da5f6_177_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2036,e_layer_2024-08-24_10-12-46/checkpoint_000002)
[36m(_train_fn pid=860110)[0m Use GPU: cuda:0
[36m(_train_fn pid=860110)[0m train 7825
[36m(_train_fn pid=860110)[0m val 2161
[36m(_train_fn pid=860110)[0m start_epoch 0
[36m(_train_fn pid=860110)[0m max_epoch 8

Trial status: 176 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:12:56. Total running time: 2hr 51min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-991da5f6   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
171 more TERMINATED
[36m(_train_fn pid=860110)[0m 	iters: 100, epoch: 1 | loss: 0.7962765
[36m(_train_fn pid=860110)[0m 	speed: 0.0764s/iter; left time: 141.5858s
[36m(_train_fn pid=860110)[0m 	iters: 200, epoch: 1 | loss: 0.5988179
[36m(_train_fn pid=860110)[0m 	speed: 0.0699s/iter; left time: 122.5975s
[36m(_train_fn pid=860110)[0m Updating learning rate to 0.004278823536202294
[36m(_train_fn pid=860110)[0m saving checkpoint...
[36m(_train_fn pid=860110)[0m Validation loss decreased (inf --> 1.6494).  Saving model state dict ...
[36m(_train_fn pid=860110)[0m Epoch: 1 cost time: 17.44805669784546
[36m(_train_fn pid=860110)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7474916 Vali Loss: 1.6493705 Best vali loss: 1.6493705
[36m(_train_fn pid=860110)[0m 	iters: 100, epoch: 2 | loss: 0.8005651
[36m(_train_fn pid=860110)[0m 	speed: 0.1220s/iter; left time: 196.3495s
[36m(_train_fn pid=860110)[0m 	iters: 200, epoch: 2 | loss: 0.7981437
[36m(_train_fn pid=860110)[0m 	speed: 0.0694s/iter; left time: 104.6755s
Trial status: 176 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:13:26. Total running time: 2hr 52min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-991da5f6   RUNNING           1            20.0083       0.747492        1.64937             1.64937 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
171 more TERMINATED
[36m(_train_fn pid=860110)[0m Updating learning rate to 0.002139411768101147
[36m(_train_fn pid=860110)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=860110)[0m saving checkpoint...
[36m(_train_fn pid=860110)[0m Epoch: 2 cost time: 16.96000099182129
[36m(_train_fn pid=860110)[0m Epoch: 2, Steps: 244 | Train Loss: 12.4989562 Vali Loss: 1.8548988 Best vali loss: 1.6493705
[36m(_train_fn pid=860110)[0m 	iters: 100, epoch: 3 | loss: 0.7882617
[36m(_train_fn pid=860110)[0m 	speed: 0.1213s/iter; left time: 165.5754s
[36m(_train_fn pid=860110)[0m 	iters: 200, epoch: 3 | loss: 0.7452127
[36m(_train_fn pid=860110)[0m 	speed: 0.0695s/iter; left time: 87.8630s
[36m(_train_fn pid=860110)[0m Updating learning rate to 0.0010697058840505734
[36m(_train_fn pid=860110)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=860110)[0m saving checkpoint...
[36m(_train_fn pid=860110)[0m Epoch: 3 cost time: 16.968605995178223
[36m(_train_fn pid=860110)[0m Epoch: 3, Steps: 244 | Train Loss: 0.7349854 Vali Loss: 1.8413321 Best vali loss: 1.6493705
[36m(_train_fn pid=860110)[0m 	iters: 100, epoch: 4 | loss: 0.7256985
[36m(_train_fn pid=860110)[0m 	speed: 0.1213s/iter; left time: 136.0177s
Trial status: 176 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:13:56. Total running time: 2hr 52min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=860110)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-991da5f6_177_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2036,e_layer_2024-08-24_10-12-46/checkpoint_000003)
2024-08-24 10:14:27,715	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=860712)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-807ab17f_178_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1788,e_layer_2024-08-24_10-14-05/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-991da5f6   RUNNING           3            58.1643       0.734985        1.84133             1.64937 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
171 more TERMINATED
[36m(_train_fn pid=860110)[0m 	iters: 200, epoch: 4 | loss: 0.7372115
[36m(_train_fn pid=860110)[0m 	speed: 0.0695s/iter; left time: 70.9378s

Trial trial-991da5f6 completed after 4 iterations at 2024-08-24 10:14:05. Total running time: 2hr 52min 57s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-991da5f6 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000003 â”‚
â”‚ time_this_iter_s                         19.07234 â”‚
â”‚ time_total_s                             77.23664 â”‚
â”‚ training_iteration                              4 â”‚
â”‚ best_valid_loss                           1.64937 â”‚
â”‚ train_loss                                0.72874 â”‚
â”‚ valid_loss                                1.82518 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=860110)[0m Updating learning rate to 0.0005348529420252867
[36m(_train_fn pid=860110)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=860110)[0m saving checkpoint...
[36m(_train_fn pid=860110)[0m Epoch: 4 cost time: 16.959702730178833
[36m(_train_fn pid=860110)[0m Epoch: 4, Steps: 244 | Train Loss: 0.7287399 Vali Loss: 1.8251764 Best vali loss: 1.6493705
[36m(_train_fn pid=860110)[0m Early stopping

Trial trial-807ab17f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-807ab17f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17877 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0007 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=860712)[0m configuration
[36m(_train_fn pid=860712)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.17877445587936366, 'e_layers': 1, 'learning_rate': 0.0006990632996231341, 'd_ff': 1536}
[36m(_train_fn pid=860712)[0m Use GPU: cuda:0
[36m(_train_fn pid=860712)[0m train 7825
[36m(_train_fn pid=860712)[0m val 2161
[36m(_train_fn pid=860712)[0m start_epoch 0
[36m(_train_fn pid=860712)[0m max_epoch 8
[36m(_train_fn pid=860712)[0m 	iters: 100, epoch: 1 | loss: 0.8460279
[36m(_train_fn pid=860712)[0m 	speed: 0.0766s/iter; left time: 142.0136s
[36m(_train_fn pid=860712)[0m 	iters: 200, epoch: 1 | loss: 0.6598151
[36m(_train_fn pid=860712)[0m 	speed: 0.0700s/iter; left time: 122.6571s

Trial status: 177 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:14:26. Total running time: 2hr 53min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-807ab17f   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
172 more TERMINATED
[36m(_train_fn pid=860712)[0m Updating learning rate to 0.0006990632996231341
[36m(_train_fn pid=860712)[0m saving checkpoint...
[36m(_train_fn pid=860712)[0m Validation loss decreased (inf --> 1.9239).  Saving model state dict ...
[36m(_train_fn pid=860712)[0m Epoch: 1 cost time: 17.477508306503296
[36m(_train_fn pid=860712)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8052061 Vali Loss: 1.9238606 Best vali loss: 1.9238606
[36m(_train_fn pid=860712)[0m 	iters: 100, epoch: 2 | loss: 0.6467041
[36m(_train_fn pid=860712)[0m 	speed: 0.1231s/iter; left time: 198.0004s
[36m(_train_fn pid=860712)[0m 	iters: 200, epoch: 2 | loss: 0.6944290
[36m(_train_fn pid=860712)[0m 	speed: 0.0704s/iter; left time: 106.2425s
[36m(_train_fn pid=860712)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-807ab17f_178_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1788,e_layer_2024-08-24_10-14-05/checkpoint_000001)
[36m(_train_fn pid=860712)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-807ab17f_178_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1788,e_layer_2024-08-24_10-14-05/checkpoint_000002)
[36m(_train_fn pid=860712)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-807ab17f_178_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1788,e_layer_2024-08-24_10-14-05/checkpoint_000003)
[36m(_train_fn pid=860712)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-807ab17f_178_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1788,e_layer_2024-08-24_10-14-05/checkpoint_000004)
[36m(_train_fn pid=860712)[0m Updating learning rate to 0.00034953164981156706
[36m(_train_fn pid=860712)[0m saving checkpoint...
[36m(_train_fn pid=860712)[0m Validation loss decreased (1.9239 --> 1.5795).  Saving model state dict ...
[36m(_train_fn pid=860712)[0m Epoch: 2 cost time: 17.195056200027466
[36m(_train_fn pid=860712)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6811500 Vali Loss: 1.5795287 Best vali loss: 1.5795287
[36m(_train_fn pid=860712)[0m 	iters: 100, epoch: 3 | loss: 0.6685774
[36m(_train_fn pid=860712)[0m 	speed: 0.1231s/iter; left time: 167.9694s
Trial status: 177 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:14:56. Total running time: 2hr 53min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-807ab17f   RUNNING           2            39.4036       0.68115         1.57953             1.57953 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
172 more TERMINATED
[36m(_train_fn pid=860712)[0m 	iters: 200, epoch: 3 | loss: 0.6288340
[36m(_train_fn pid=860712)[0m 	speed: 0.0704s/iter; left time: 89.0744s
[36m(_train_fn pid=860712)[0m Updating learning rate to 0.00017476582490578353
[36m(_train_fn pid=860712)[0m saving checkpoint...
[36m(_train_fn pid=860712)[0m Validation loss decreased (1.5795 --> 1.5645).  Saving model state dict ...
[36m(_train_fn pid=860712)[0m Epoch: 3 cost time: 17.18764638900757
[36m(_train_fn pid=860712)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6154900 Vali Loss: 1.5644922 Best vali loss: 1.5644922
[36m(_train_fn pid=860712)[0m 	iters: 100, epoch: 4 | loss: 0.6308908
[36m(_train_fn pid=860712)[0m 	speed: 0.1232s/iter; left time: 138.1505s
[36m(_train_fn pid=860712)[0m 	iters: 200, epoch: 4 | loss: 0.6350774
[36m(_train_fn pid=860712)[0m 	speed: 0.0704s/iter; left time: 71.8857s
[36m(_train_fn pid=860712)[0m Updating learning rate to 8.738291245289177e-05
[36m(_train_fn pid=860712)[0m saving checkpoint...
[36m(_train_fn pid=860712)[0m Validation loss decreased (1.5645 --> 1.5639).  Saving model state dict ...
[36m(_train_fn pid=860712)[0m Epoch: 4 cost time: 17.194143295288086
[36m(_train_fn pid=860712)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6115006 Vali Loss: 1.5638900 Best vali loss: 1.5638900
Trial status: 177 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:15:26. Total running time: 2hr 54min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-807ab17f   RUNNING           4            78.1222       0.611501        1.56389             1.56389 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
172 more TERMINATED
[36m(_train_fn pid=860712)[0m 	iters: 100, epoch: 5 | loss: 0.6057664
[36m(_train_fn pid=860712)[0m 	speed: 0.1232s/iter; left time: 108.0648s
[36m(_train_fn pid=860712)[0m 	iters: 200, epoch: 5 | loss: 0.5447532
[36m(_train_fn pid=860712)[0m 	speed: 0.0704s/iter; left time: 54.6839s
[36m(_train_fn pid=860712)[0m Updating learning rate to 4.369145622644588e-05
[36m(_train_fn pid=860712)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=860712)[0m saving checkpoint...
[36m(_train_fn pid=860712)[0m Epoch: 5 cost time: 17.17816424369812
[36m(_train_fn pid=860712)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6096200 Vali Loss: 1.5666799 Best vali loss: 1.5638900
[36m(_train_fn pid=860712)[0m 	iters: 100, epoch: 6 | loss: 0.5827490
[36m(_train_fn pid=860712)[0m 	speed: 0.1229s/iter; left time: 77.8014s
Trial status: 177 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:15:56. Total running time: 2hr 54min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=860712)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-807ab17f_178_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1788,e_layer_2024-08-24_10-14-05/checkpoint_000005)
2024-08-24 10:16:26,697	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=861570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fba640ce_179_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1684,e_layer_2024-08-24_10-16-04/checkpoint_000000)
[36m(_train_fn pid=861570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fba640ce_179_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1684,e_layer_2024-08-24_10-16-04/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-807ab17f   RUNNING           5            97.4474       0.60962         1.56668             1.56389 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
172 more TERMINATED
[36m(_train_fn pid=860712)[0m 	iters: 200, epoch: 6 | loss: 0.5943953
[36m(_train_fn pid=860712)[0m 	speed: 0.0704s/iter; left time: 37.5042s

Trial trial-807ab17f completed after 6 iterations at 2024-08-24 10:16:04. Total running time: 2hr 54min 55s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-807ab17f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.33577 â”‚
â”‚ time_total_s                            116.78316 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56097 â”‚
â”‚ train_loss                                0.60891 â”‚
â”‚ valid_loss                                1.56097 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=860712)[0m Updating learning rate to 2.184572811322294e-05
[36m(_train_fn pid=860712)[0m saving checkpoint...
[36m(_train_fn pid=860712)[0m Validation loss decreased (1.5639 --> 1.5610).  Saving model state dict ...

Trial trial-fba640ce started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fba640ce config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.16838 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00128 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=861570)[0m configuration
[36m(_train_fn pid=861570)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.16838204068033455, 'e_layers': 1, 'learning_rate': 0.0012815000014081387, 'd_ff': 1536}
[36m(_train_fn pid=861570)[0m Use GPU: cuda:0
[36m(_train_fn pid=861570)[0m train 7825
[36m(_train_fn pid=861570)[0m val 2161
[36m(_train_fn pid=861570)[0m start_epoch 0
[36m(_train_fn pid=861570)[0m max_epoch 8
[36m(_train_fn pid=861570)[0m 	iters: 100, epoch: 1 | loss: 0.8279915
[36m(_train_fn pid=861570)[0m 	speed: 0.0766s/iter; left time: 141.8631s
[36m(_train_fn pid=861570)[0m 	iters: 200, epoch: 1 | loss: 0.6480815
[36m(_train_fn pid=861570)[0m 	speed: 0.0700s/iter; left time: 122.6297s

Trial status: 178 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:16:26. Total running time: 2hr 55min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fba640ce   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
173 more TERMINATED
[36m(_train_fn pid=861570)[0m Updating learning rate to 0.0012815000014081387
[36m(_train_fn pid=861570)[0m saving checkpoint...
[36m(_train_fn pid=861570)[0m Validation loss decreased (inf --> 1.8839).  Saving model state dict ...
[36m(_train_fn pid=861570)[0m Epoch: 1 cost time: 17.47222876548767
[36m(_train_fn pid=861570)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7876871 Vali Loss: 1.8838575 Best vali loss: 1.8838575
[36m(_train_fn pid=861570)[0m 	iters: 100, epoch: 2 | loss: 0.6749434
[36m(_train_fn pid=861570)[0m 	speed: 0.1228s/iter; left time: 197.6224s
[36m(_train_fn pid=861570)[0m 	iters: 200, epoch: 2 | loss: 0.7081515
[36m(_train_fn pid=861570)[0m 	speed: 0.0703s/iter; left time: 106.1023s
[36m(_train_fn pid=861570)[0m Updating learning rate to 0.0006407500007040693
[36m(_train_fn pid=861570)[0m saving checkpoint...
[36m(_train_fn pid=861570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fba640ce_179_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1684,e_layer_2024-08-24_10-16-04/checkpoint_000002)
[36m(_train_fn pid=861570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fba640ce_179_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1684,e_layer_2024-08-24_10-16-04/checkpoint_000003)
[36m(_train_fn pid=861570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fba640ce_179_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1684,e_layer_2024-08-24_10-16-04/checkpoint_000004)
[36m(_train_fn pid=861570)[0m Validation loss decreased (1.8839 --> 1.5868).  Saving model state dict ...
[36m(_train_fn pid=861570)[0m Epoch: 2 cost time: 17.17536735534668
[36m(_train_fn pid=861570)[0m Epoch: 2, Steps: 244 | Train Loss: 0.8205285 Vali Loss: 1.5867694 Best vali loss: 1.5867694
[36m(_train_fn pid=861570)[0m 	iters: 100, epoch: 3 | loss: 0.6791681
[36m(_train_fn pid=861570)[0m 	speed: 0.1232s/iter; left time: 168.1096s
Trial status: 178 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:16:56. Total running time: 2hr 55min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fba640ce   RUNNING           2            39.3665       0.820528        1.58677             1.58677 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
173 more TERMINATED
[36m(_train_fn pid=861570)[0m 	iters: 200, epoch: 3 | loss: 0.6353862
[36m(_train_fn pid=861570)[0m 	speed: 0.0705s/iter; left time: 89.1268s
[36m(_train_fn pid=861570)[0m Updating learning rate to 0.00032037500035203467
[36m(_train_fn pid=861570)[0m saving checkpoint...
[36m(_train_fn pid=861570)[0m Validation loss decreased (1.5868 --> 1.5711).  Saving model state dict ...
[36m(_train_fn pid=861570)[0m Epoch: 3 cost time: 17.19434952735901
[36m(_train_fn pid=861570)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6210803 Vali Loss: 1.5710829 Best vali loss: 1.5710829
[36m(_train_fn pid=861570)[0m 	iters: 100, epoch: 4 | loss: 0.6341357
[36m(_train_fn pid=861570)[0m 	speed: 0.1233s/iter; left time: 138.2198s
[36m(_train_fn pid=861570)[0m 	iters: 200, epoch: 4 | loss: 0.6415402
[36m(_train_fn pid=861570)[0m 	speed: 0.0705s/iter; left time: 72.0260s
[36m(_train_fn pid=861570)[0m Updating learning rate to 0.00016018750017601733
[36m(_train_fn pid=861570)[0m saving checkpoint...
[36m(_train_fn pid=861570)[0m Validation loss decreased (1.5711 --> 1.5679).  Saving model state dict ...
[36m(_train_fn pid=861570)[0m Epoch: 4 cost time: 17.215116024017334
[36m(_train_fn pid=861570)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6155447 Vali Loss: 1.5679124 Best vali loss: 1.5679124
Trial status: 178 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:17:26. Total running time: 2hr 56min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fba640ce   RUNNING           4            78.1057       0.615545        1.56791             1.56791 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
173 more TERMINATED
[36m(_train_fn pid=861570)[0m 	iters: 100, epoch: 5 | loss: 0.6063155
[36m(_train_fn pid=861570)[0m 	speed: 0.1233s/iter; left time: 108.1040s
[36m(_train_fn pid=861570)[0m 	iters: 200, epoch: 5 | loss: 0.5473211
[36m(_train_fn pid=861570)[0m 	speed: 0.0705s/iter; left time: 54.7818s
[36m(_train_fn pid=861570)[0m Updating learning rate to 8.009375008800867e-05
[36m(_train_fn pid=861570)[0m saving checkpoint...
[36m(_train_fn pid=861570)[0m Validation loss decreased (1.5679 --> 1.5656).  Saving model state dict ...
[36m(_train_fn pid=861570)[0m Epoch: 5 cost time: 17.20931386947632
[36m(_train_fn pid=861570)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6136361 Vali Loss: 1.5655942 Best vali loss: 1.5655942
[36m(_train_fn pid=861570)[0m 	iters: 100, epoch: 6 | loss: 0.5891244
[36m(_train_fn pid=861570)[0m 	speed: 0.1234s/iter; left time: 78.0886s
Trial status: 178 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:17:56. Total running time: 2hr 56min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=861570)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-fba640ce_179_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1684,e_layer_2024-08-24_10-16-04/checkpoint_000005)
[36m(_train_fn pid=862432)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b4e9ba3a_180_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-18-03/checkpoint_000000)
2024-08-24 10:18:25,750	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-fba640ce   RUNNING           5            97.4819       0.613636        1.56559             1.56559 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
173 more TERMINATED
[36m(_train_fn pid=861570)[0m 	iters: 200, epoch: 6 | loss: 0.5992026
[36m(_train_fn pid=861570)[0m 	speed: 0.0705s/iter; left time: 37.5773s

Trial trial-fba640ce completed after 6 iterations at 2024-08-24 10:18:03. Total running time: 2hr 56min 54s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-fba640ce result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.38472 â”‚
â”‚ time_total_s                            116.86665 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56541 â”‚
â”‚ train_loss                                0.61273 â”‚
â”‚ valid_loss                                1.56541 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=861570)[0m Updating learning rate to 4.004687504400433e-05
[36m(_train_fn pid=861570)[0m saving checkpoint...
[36m(_train_fn pid=861570)[0m Validation loss decreased (1.5656 --> 1.5654).  Saving model state dict ...

Trial trial-b4e9ba3a started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b4e9ba3a config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19159 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0014 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=862432)[0m configuration
[36m(_train_fn pid=862432)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19159443875960805, 'e_layers': 1, 'learning_rate': 0.0013967249511529494, 'd_ff': 1536}
[36m(_train_fn pid=862432)[0m Use GPU: cuda:0
[36m(_train_fn pid=862432)[0m train 7825
[36m(_train_fn pid=862432)[0m val 2161
[36m(_train_fn pid=862432)[0m start_epoch 0
[36m(_train_fn pid=862432)[0m max_epoch 8
[36m(_train_fn pid=862432)[0m 	iters: 100, epoch: 1 | loss: 0.8266783
[36m(_train_fn pid=862432)[0m 	speed: 0.0769s/iter; left time: 142.4445s
[36m(_train_fn pid=862432)[0m 	iters: 200, epoch: 1 | loss: 0.6469238
[36m(_train_fn pid=862432)[0m 	speed: 0.0700s/iter; left time: 122.6880s
[36m(_train_fn pid=862432)[0m Updating learning rate to 0.0013967249511529494
[36m(_train_fn pid=862432)[0m saving checkpoint...
[36m(_train_fn pid=862432)[0m Validation loss decreased (inf --> 1.8755).  Saving model state dict ...
[36m(_train_fn pid=862432)[0m Epoch: 1 cost time: 17.497172594070435
[36m(_train_fn pid=862432)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7885864 Vali Loss: 1.8755330 Best vali loss: 1.8755330

Trial status: 179 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:18:26. Total running time: 2hr 57min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b4e9ba3a   RUNNING           1            20.0872       0.788586        1.87553             1.87553 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
174 more TERMINATED
[36m(_train_fn pid=862432)[0m 	iters: 100, epoch: 2 | loss: 0.6798701
[36m(_train_fn pid=862432)[0m 	speed: 0.1228s/iter; left time: 197.6141s
[36m(_train_fn pid=862432)[0m 	iters: 200, epoch: 2 | loss: 0.7136264
[36m(_train_fn pid=862432)[0m 	speed: 0.0703s/iter; left time: 106.0158s
[36m(_train_fn pid=862432)[0m Updating learning rate to 0.0006983624755764747
[36m(_train_fn pid=862432)[0m saving checkpoint...
[36m(_train_fn pid=862432)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b4e9ba3a_180_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-18-03/checkpoint_000001)
[36m(_train_fn pid=862432)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b4e9ba3a_180_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-18-03/checkpoint_000002)
[36m(_train_fn pid=862432)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b4e9ba3a_180_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-18-03/checkpoint_000003)
[36m(_train_fn pid=862432)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b4e9ba3a_180_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-18-03/checkpoint_000004)
[36m(_train_fn pid=862432)[0m Validation loss decreased (1.8755 --> 1.6044).  Saving model state dict ...
[36m(_train_fn pid=862432)[0m Epoch: 2 cost time: 17.158510208129883
[36m(_train_fn pid=862432)[0m Epoch: 2, Steps: 244 | Train Loss: 0.8696465 Vali Loss: 1.6043850 Best vali loss: 1.6043850
[36m(_train_fn pid=862432)[0m 	iters: 100, epoch: 3 | loss: 0.6820939
[36m(_train_fn pid=862432)[0m 	speed: 0.1231s/iter; left time: 167.9983s
Trial status: 179 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:18:56. Total running time: 2hr 57min 47s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b4e9ba3a   RUNNING           2            39.4225       0.869647        1.60439             1.60439 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
174 more TERMINATED
[36m(_train_fn pid=862432)[0m 	iters: 200, epoch: 3 | loss: 0.6391515
[36m(_train_fn pid=862432)[0m 	speed: 0.0703s/iter; left time: 88.9505s
[36m(_train_fn pid=862432)[0m Updating learning rate to 0.00034918123778823735
[36m(_train_fn pid=862432)[0m saving checkpoint...
[36m(_train_fn pid=862432)[0m Validation loss decreased (1.6044 --> 1.5796).  Saving model state dict ...
[36m(_train_fn pid=862432)[0m Epoch: 3 cost time: 17.158096313476562
[36m(_train_fn pid=862432)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6264557 Vali Loss: 1.5796216 Best vali loss: 1.5796216
[36m(_train_fn pid=862432)[0m 	iters: 100, epoch: 4 | loss: 0.6330900
[36m(_train_fn pid=862432)[0m 	speed: 0.1231s/iter; left time: 137.9790s
[36m(_train_fn pid=862432)[0m 	iters: 200, epoch: 4 | loss: 0.6439474
[36m(_train_fn pid=862432)[0m 	speed: 0.0703s/iter; left time: 71.7962s
[36m(_train_fn pid=862432)[0m Updating learning rate to 0.00017459061889411867
[36m(_train_fn pid=862432)[0m saving checkpoint...
[36m(_train_fn pid=862432)[0m Validation loss decreased (1.5796 --> 1.5735).  Saving model state dict ...
[36m(_train_fn pid=862432)[0m Epoch: 4 cost time: 17.16726326942444
[36m(_train_fn pid=862432)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6187056 Vali Loss: 1.5734915 Best vali loss: 1.5734915
Trial status: 179 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:19:26. Total running time: 2hr 58min 17s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b4e9ba3a   RUNNING           4            78.0795       0.618706        1.57349             1.57349 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
174 more TERMINATED
[36m(_train_fn pid=862432)[0m 	iters: 100, epoch: 5 | loss: 0.6084155
[36m(_train_fn pid=862432)[0m 	speed: 0.1231s/iter; left time: 107.9232s
[36m(_train_fn pid=862432)[0m 	iters: 200, epoch: 5 | loss: 0.5496777
[36m(_train_fn pid=862432)[0m 	speed: 0.0703s/iter; left time: 54.6326s
[36m(_train_fn pid=862432)[0m Updating learning rate to 8.729530944705934e-05
[36m(_train_fn pid=862432)[0m saving checkpoint...
[36m(_train_fn pid=862432)[0m Validation loss decreased (1.5735 --> 1.5701).  Saving model state dict ...
[36m(_train_fn pid=862432)[0m Epoch: 5 cost time: 17.1700541973114
[36m(_train_fn pid=862432)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6161815 Vali Loss: 1.5701243 Best vali loss: 1.5701243
[36m(_train_fn pid=862432)[0m 	iters: 100, epoch: 6 | loss: 0.5927224
[36m(_train_fn pid=862432)[0m 	speed: 0.1231s/iter; left time: 77.9329s
Trial status: 179 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:19:56. Total running time: 2hr 58min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=862432)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b4e9ba3a_180_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-18-03/checkpoint_000005)
2024-08-24 10:20:24,755	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=863292)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d704276_181_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1868,e_layer_2024-08-24_10-20-02/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-b4e9ba3a   RUNNING           5            97.4177       0.616181        1.57012             1.57012 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
174 more TERMINATED
[36m(_train_fn pid=862432)[0m 	iters: 200, epoch: 6 | loss: 0.6005734
[36m(_train_fn pid=862432)[0m 	speed: 0.0705s/iter; left time: 37.5716s

Trial trial-b4e9ba3a completed after 6 iterations at 2024-08-24 10:20:02. Total running time: 2hr 58min 53s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b4e9ba3a result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.35642 â”‚
â”‚ time_total_s                            116.77412 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56923 â”‚
â”‚ train_loss                                0.61514 â”‚
â”‚ valid_loss                                1.56923 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=862432)[0m Updating learning rate to 4.364765472352967e-05
[36m(_train_fn pid=862432)[0m saving checkpoint...
[36m(_train_fn pid=862432)[0m Validation loss decreased (1.5701 --> 1.5692).  Saving model state dict ...

Trial trial-1d704276 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1d704276 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.1868 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00094 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=863292)[0m configuration
[36m(_train_fn pid=863292)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18679625473150846, 'e_layers': 1, 'learning_rate': 0.0009378771046190314, 'd_ff': 1536}
[36m(_train_fn pid=863292)[0m Use GPU: cuda:0
[36m(_train_fn pid=863292)[0m train 7825
[36m(_train_fn pid=863292)[0m val 2161
[36m(_train_fn pid=863292)[0m start_epoch 0
[36m(_train_fn pid=863292)[0m max_epoch 8
[36m(_train_fn pid=863292)[0m 	iters: 100, epoch: 1 | loss: 0.8388944
[36m(_train_fn pid=863292)[0m 	speed: 0.0766s/iter; left time: 142.0209s
[36m(_train_fn pid=863292)[0m 	iters: 200, epoch: 1 | loss: 0.6536621
[36m(_train_fn pid=863292)[0m 	speed: 0.0700s/iter; left time: 122.7757s
[36m(_train_fn pid=863292)[0m Updating learning rate to 0.0009378771046190314
[36m(_train_fn pid=863292)[0m saving checkpoint...
[36m(_train_fn pid=863292)[0m Validation loss decreased (inf --> 1.9137).  Saving model state dict ...
[36m(_train_fn pid=863292)[0m Epoch: 1 cost time: 17.494122743606567
[36m(_train_fn pid=863292)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7985084 Vali Loss: 1.9137098 Best vali loss: 1.9137098

Trial status: 180 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:20:26. Total running time: 2hr 59min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1d704276   RUNNING           1            20.0596       0.798508        1.91371             1.91371 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
175 more TERMINATED
[36m(_train_fn pid=863292)[0m 	iters: 100, epoch: 2 | loss: 0.6389799
[36m(_train_fn pid=863292)[0m 	speed: 0.1230s/iter; left time: 197.9190s
[36m(_train_fn pid=863292)[0m 	iters: 200, epoch: 2 | loss: 0.6936704
[36m(_train_fn pid=863292)[0m 	speed: 0.0705s/iter; left time: 106.3153s
[36m(_train_fn pid=863292)[0m Updating learning rate to 0.0004689385523095157
[36m(_train_fn pid=863292)[0m saving checkpoint...
[36m(_train_fn pid=863292)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d704276_181_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1868,e_layer_2024-08-24_10-20-02/checkpoint_000001)
[36m(_train_fn pid=863292)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d704276_181_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1868,e_layer_2024-08-24_10-20-02/checkpoint_000002)
[36m(_train_fn pid=863292)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d704276_181_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1868,e_layer_2024-08-24_10-20-02/checkpoint_000003)
[36m(_train_fn pid=863292)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d704276_181_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1868,e_layer_2024-08-24_10-20-02/checkpoint_000004)
[36m(_train_fn pid=863292)[0m Validation loss decreased (1.9137 --> 1.5702).  Saving model state dict ...
[36m(_train_fn pid=863292)[0m Epoch: 2 cost time: 17.200751066207886
[36m(_train_fn pid=863292)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7016585 Vali Loss: 1.5701789 Best vali loss: 1.5701789
[36m(_train_fn pid=863292)[0m 	iters: 100, epoch: 3 | loss: 0.6695502
[36m(_train_fn pid=863292)[0m 	speed: 0.1233s/iter; left time: 168.2394s
Trial status: 180 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:20:56. Total running time: 2hr 59min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1d704276   RUNNING           2            39.4291       0.701659        1.57018             1.57018 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
175 more TERMINATED
[36m(_train_fn pid=863292)[0m 	iters: 200, epoch: 3 | loss: 0.6326225
[36m(_train_fn pid=863292)[0m 	speed: 0.0704s/iter; left time: 89.0204s
[36m(_train_fn pid=863292)[0m Updating learning rate to 0.00023446927615475784
[36m(_train_fn pid=863292)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=863292)[0m saving checkpoint...
[36m(_train_fn pid=863292)[0m Epoch: 3 cost time: 17.181476593017578
[36m(_train_fn pid=863292)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6164691 Vali Loss: 1.5712649 Best vali loss: 1.5701789
[36m(_train_fn pid=863292)[0m 	iters: 100, epoch: 4 | loss: 0.6330342
[36m(_train_fn pid=863292)[0m 	speed: 0.1239s/iter; left time: 138.9353s
[36m(_train_fn pid=863292)[0m 	iters: 200, epoch: 4 | loss: 0.6359971
[36m(_train_fn pid=863292)[0m 	speed: 0.0705s/iter; left time: 71.9396s
[36m(_train_fn pid=863292)[0m Updating learning rate to 0.00011723463807737892
[36m(_train_fn pid=863292)[0m saving checkpoint...
[36m(_train_fn pid=863292)[0m Validation loss decreased (1.5702 --> 1.5661).  Saving model state dict ...
[36m(_train_fn pid=863292)[0m Epoch: 4 cost time: 17.307136297225952
[36m(_train_fn pid=863292)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6127349 Vali Loss: 1.5660847 Best vali loss: 1.5660847
Trial status: 180 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:21:26. Total running time: 3hr 0min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1d704276   RUNNING           4            78.221        0.612735        1.56608             1.56608 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
175 more TERMINATED
[36m(_train_fn pid=863292)[0m 	iters: 100, epoch: 5 | loss: 0.6071886
[36m(_train_fn pid=863292)[0m 	speed: 0.1233s/iter; left time: 108.1467s
[36m(_train_fn pid=863292)[0m 	iters: 200, epoch: 5 | loss: 0.5451203
[36m(_train_fn pid=863292)[0m 	speed: 0.0705s/iter; left time: 54.7897s
[36m(_train_fn pid=863292)[0m Updating learning rate to 5.861731903868946e-05
[36m(_train_fn pid=863292)[0m saving checkpoint...
[36m(_train_fn pid=863292)[0m Validation loss decreased (1.5661 --> 1.5658).  Saving model state dict ...
[36m(_train_fn pid=863292)[0m Epoch: 5 cost time: 17.22623109817505
[36m(_train_fn pid=863292)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6104206 Vali Loss: 1.5658500 Best vali loss: 1.5658500
[36m(_train_fn pid=863292)[0m 	iters: 100, epoch: 6 | loss: 0.5838655
[36m(_train_fn pid=863292)[0m 	speed: 0.1234s/iter; left time: 78.0828s
[36m(_train_fn pid=863292)[0m 	iters: 200, epoch: 6 | loss: 0.5936859
[36m(_train_fn pid=863292)[0m 	speed: 0.0704s/iter; left time: 37.5106s
Trial status: 180 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:21:56. Total running time: 3hr 0min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=863292)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1d704276_181_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1868,e_layer_2024-08-24_10-20-02/checkpoint_000005)
2024-08-24 10:22:23,733	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=864154)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e36d9f5_182_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1783,e_layer_2024-08-24_10-22-01/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1d704276   RUNNING           5            97.6147       0.610421        1.56585             1.56585 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
175 more TERMINATED
[36m(_train_fn pid=863292)[0m Updating learning rate to 2.930865951934473e-05
[36m(_train_fn pid=863292)[0m saving checkpoint...
[36m(_train_fn pid=863292)[0m Validation loss decreased (1.5658 --> 1.5622).  Saving model state dict ...

Trial trial-1d704276 completed after 6 iterations at 2024-08-24 10:22:01. Total running time: 3hr 0min 52s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1d704276 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.34445 â”‚
â”‚ time_total_s                            116.95917 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56224 â”‚
â”‚ train_loss                                0.60952 â”‚
â”‚ valid_loss                                1.56224 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-3e36d9f5 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3e36d9f5 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17828 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00056 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=864154)[0m configuration
[36m(_train_fn pid=864154)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.17828166344889634, 'e_layers': 1, 'learning_rate': 0.0005601514328336088, 'd_ff': 1536}
[36m(_train_fn pid=864154)[0m Use GPU: cuda:0
[36m(_train_fn pid=864154)[0m train 7825
[36m(_train_fn pid=864154)[0m val 2161
[36m(_train_fn pid=864154)[0m start_epoch 0
[36m(_train_fn pid=864154)[0m max_epoch 8
[36m(_train_fn pid=864154)[0m 	iters: 100, epoch: 1 | loss: 0.8526197
[36m(_train_fn pid=864154)[0m 	speed: 0.0764s/iter; left time: 141.6098s
[36m(_train_fn pid=864154)[0m 	iters: 200, epoch: 1 | loss: 0.6659099
[36m(_train_fn pid=864154)[0m 	speed: 0.0700s/iter; left time: 122.7336s
[36m(_train_fn pid=864154)[0m Updating learning rate to 0.0005601514328336088
[36m(_train_fn pid=864154)[0m saving checkpoint...
[36m(_train_fn pid=864154)[0m Validation loss decreased (inf --> 1.9296).  Saving model state dict ...
[36m(_train_fn pid=864154)[0m Epoch: 1 cost time: 17.46502709388733
[36m(_train_fn pid=864154)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8116467 Vali Loss: 1.9296196 Best vali loss: 1.9296196

Trial status: 181 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:22:27. Total running time: 3hr 1min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e36d9f5   RUNNING           1            20.0417       0.811647        1.92962             1.92962 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
176 more TERMINATED
[36m(_train_fn pid=864154)[0m 	iters: 100, epoch: 2 | loss: 0.6399448
[36m(_train_fn pid=864154)[0m 	speed: 0.1229s/iter; left time: 197.7047s
[36m(_train_fn pid=864154)[0m 	iters: 200, epoch: 2 | loss: 0.6972657
[36m(_train_fn pid=864154)[0m 	speed: 0.0702s/iter; left time: 105.9532s
[36m(_train_fn pid=864154)[0m Updating learning rate to 0.0002800757164168044
[36m(_train_fn pid=864154)[0m saving checkpoint...
[36m(_train_fn pid=864154)[0m Validation loss decreased (1.9296 --> 1.5813).  Saving model state dict ...
[36m(_train_fn pid=864154)[0m Epoch: 2 cost time: 17.155925989151
[36m(_train_fn pid=864154)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e36d9f5_182_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1783,e_layer_2024-08-24_10-22-01/checkpoint_000001)
[36m(_train_fn pid=864154)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e36d9f5_182_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1783,e_layer_2024-08-24_10-22-01/checkpoint_000002)
[36m(_train_fn pid=864154)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e36d9f5_182_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1783,e_layer_2024-08-24_10-22-01/checkpoint_000003)
[36m(_train_fn pid=864154)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e36d9f5_182_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1783,e_layer_2024-08-24_10-22-01/checkpoint_000004)
[36m(_train_fn pid=864154)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6719071 Vali Loss: 1.5812515 Best vali loss: 1.5812515
[36m(_train_fn pid=864154)[0m 	iters: 100, epoch: 3 | loss: 0.6686344
[36m(_train_fn pid=864154)[0m 	speed: 0.1230s/iter; left time: 167.9220s
[36m(_train_fn pid=864154)[0m 	iters: 200, epoch: 3 | loss: 0.6289455
[36m(_train_fn pid=864154)[0m 	speed: 0.0704s/iter; left time: 89.0256s
Trial status: 181 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:22:57. Total running time: 3hr 1min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e36d9f5   RUNNING           2            39.3558       0.671907        1.58125             1.58125 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
176 more TERMINATED
[36m(_train_fn pid=864154)[0m Updating learning rate to 0.0001400378582084022
[36m(_train_fn pid=864154)[0m saving checkpoint...
[36m(_train_fn pid=864154)[0m Validation loss decreased (1.5813 --> 1.5690).  Saving model state dict ...
[36m(_train_fn pid=864154)[0m Epoch: 3 cost time: 17.177760362625122
[36m(_train_fn pid=864154)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6165035 Vali Loss: 1.5689577 Best vali loss: 1.5689577
[36m(_train_fn pid=864154)[0m 	iters: 100, epoch: 4 | loss: 0.6351946
[36m(_train_fn pid=864154)[0m 	speed: 0.1232s/iter; left time: 138.0762s
[36m(_train_fn pid=864154)[0m 	iters: 200, epoch: 4 | loss: 0.6357226
[36m(_train_fn pid=864154)[0m 	speed: 0.0704s/iter; left time: 71.9011s
[36m(_train_fn pid=864154)[0m Updating learning rate to 7.00189291042011e-05
[36m(_train_fn pid=864154)[0m saving checkpoint...
[36m(_train_fn pid=864154)[0m Validation loss decreased (1.5690 --> 1.5626).  Saving model state dict ...
[36m(_train_fn pid=864154)[0m Epoch: 4 cost time: 17.191975116729736
[36m(_train_fn pid=864154)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6126768 Vali Loss: 1.5625756 Best vali loss: 1.5625756
Trial status: 181 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:23:27. Total running time: 3hr 2min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e36d9f5   RUNNING           4            78.0627       0.612677        1.56258             1.56258 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
176 more TERMINATED
[36m(_train_fn pid=864154)[0m 	iters: 100, epoch: 5 | loss: 0.6061178
[36m(_train_fn pid=864154)[0m 	speed: 0.1232s/iter; left time: 108.0391s
[36m(_train_fn pid=864154)[0m 	iters: 200, epoch: 5 | loss: 0.5451760
[36m(_train_fn pid=864154)[0m 	speed: 0.0705s/iter; left time: 54.7633s
[36m(_train_fn pid=864154)[0m Updating learning rate to 3.500946455210055e-05
[36m(_train_fn pid=864154)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=864154)[0m saving checkpoint...
[36m(_train_fn pid=864154)[0m Epoch: 5 cost time: 17.19248604774475
[36m(_train_fn pid=864154)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6110074 Vali Loss: 1.5706455 Best vali loss: 1.5625756
[36m(_train_fn pid=864154)[0m 	iters: 100, epoch: 6 | loss: 0.5835294
[36m(_train_fn pid=864154)[0m 	speed: 0.1230s/iter; left time: 77.8696s
[36m(_train_fn pid=864154)[0m 	iters: 200, epoch: 6 | loss: 0.5957967
[36m(_train_fn pid=864154)[0m 	speed: 0.0705s/iter; left time: 37.5852s
Trial status: 181 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:23:57. Total running time: 3hr 2min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=864154)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e36d9f5_182_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1783,e_layer_2024-08-24_10-22-01/checkpoint_000005)
2024-08-24 10:24:22,782	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=865013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0ac7b70_183_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2017,e_layer_2024-08-24_10-24-00/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e36d9f5   RUNNING           5            97.3955       0.611007        1.57065             1.56258 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
176 more TERMINATED

Trial trial-3e36d9f5 completed after 6 iterations at 2024-08-24 10:24:00. Total running time: 3hr 2min 51s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3e36d9f5 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          19.3716 â”‚
â”‚ time_total_s                            116.76706 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56225 â”‚
â”‚ train_loss                                 0.6103 â”‚
â”‚ valid_loss                                1.56225 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=864154)[0m Updating learning rate to 1.7504732276050277e-05
[36m(_train_fn pid=864154)[0m saving checkpoint...
[36m(_train_fn pid=864154)[0m Validation loss decreased (1.5626 --> 1.5622).  Saving model state dict ...

Trial trial-a0ac7b70 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a0ac7b70 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.20166 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00118 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=865013)[0m configuration
[36m(_train_fn pid=865013)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.20165645221129802, 'e_layers': 1, 'learning_rate': 0.0011795372912605097, 'd_ff': 1536}
[36m(_train_fn pid=865013)[0m Use GPU: cuda:0
[36m(_train_fn pid=865013)[0m train 7825
[36m(_train_fn pid=865013)[0m val 2161
[36m(_train_fn pid=865013)[0m start_epoch 0
[36m(_train_fn pid=865013)[0m max_epoch 8
[36m(_train_fn pid=865013)[0m 	iters: 100, epoch: 1 | loss: 0.8337094
[36m(_train_fn pid=865013)[0m 	speed: 0.0769s/iter; left time: 142.5300s
[36m(_train_fn pid=865013)[0m 	iters: 200, epoch: 1 | loss: 0.6496345
[36m(_train_fn pid=865013)[0m 	speed: 0.0701s/iter; left time: 122.8078s
[36m(_train_fn pid=865013)[0m Updating learning rate to 0.0011795372912605097
[36m(_train_fn pid=865013)[0m saving checkpoint...
[36m(_train_fn pid=865013)[0m Validation loss decreased (inf --> 1.8987).  Saving model state dict ...
[36m(_train_fn pid=865013)[0m Epoch: 1 cost time: 17.50481605529785
[36m(_train_fn pid=865013)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7946422 Vali Loss: 1.8986550 Best vali loss: 1.8986550

Trial status: 182 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:24:27. Total running time: 3hr 3min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a0ac7b70   RUNNING           1            20.0858       0.794642        1.89865             1.89865 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
177 more TERMINATED
[36m(_train_fn pid=865013)[0m 	iters: 100, epoch: 2 | loss: 0.6790367
[36m(_train_fn pid=865013)[0m 	speed: 0.1228s/iter; left time: 197.5916s
[36m(_train_fn pid=865013)[0m 	iters: 200, epoch: 2 | loss: 0.7070040
[36m(_train_fn pid=865013)[0m 	speed: 0.0704s/iter; left time: 106.2583s
[36m(_train_fn pid=865013)[0m Updating learning rate to 0.0005897686456302548
[36m(_train_fn pid=865013)[0m saving checkpoint...
[36m(_train_fn pid=865013)[0m Validation loss decreased (1.8987 --> 1.5836).  Saving model state dict ...
[36m(_train_fn pid=865013)[0m Epoch: 2 cost time: 17.19080924987793
[36m(_train_fn pid=865013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0ac7b70_183_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2017,e_layer_2024-08-24_10-24-00/checkpoint_000001)
[36m(_train_fn pid=865013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0ac7b70_183_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2017,e_layer_2024-08-24_10-24-00/checkpoint_000002)
[36m(_train_fn pid=865013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0ac7b70_183_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2017,e_layer_2024-08-24_10-24-00/checkpoint_000003)
[36m(_train_fn pid=865013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0ac7b70_183_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2017,e_layer_2024-08-24_10-24-00/checkpoint_000004)
[36m(_train_fn pid=865013)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7702129 Vali Loss: 1.5836268 Best vali loss: 1.5836268
[36m(_train_fn pid=865013)[0m 	iters: 100, epoch: 3 | loss: 0.6754563
[36m(_train_fn pid=865013)[0m 	speed: 0.1233s/iter; left time: 168.2677s
[36m(_train_fn pid=865013)[0m 	iters: 200, epoch: 3 | loss: 0.6352955
[36m(_train_fn pid=865013)[0m 	speed: 0.0704s/iter; left time: 89.0289s
Trial status: 182 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:24:57. Total running time: 3hr 3min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a0ac7b70   RUNNING           2            39.4434       0.770213        1.58363             1.58363 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
177 more TERMINATED
[36m(_train_fn pid=865013)[0m Updating learning rate to 0.0002948843228151274
[36m(_train_fn pid=865013)[0m saving checkpoint...
[36m(_train_fn pid=865013)[0m Validation loss decreased (1.5836 --> 1.5826).  Saving model state dict ...
[36m(_train_fn pid=865013)[0m Epoch: 3 cost time: 17.186045169830322
[36m(_train_fn pid=865013)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6195864 Vali Loss: 1.5826459 Best vali loss: 1.5826459
[36m(_train_fn pid=865013)[0m 	iters: 100, epoch: 4 | loss: 0.6322637
[36m(_train_fn pid=865013)[0m 	speed: 0.1233s/iter; left time: 138.1782s
[36m(_train_fn pid=865013)[0m 	iters: 200, epoch: 4 | loss: 0.6397967
[36m(_train_fn pid=865013)[0m 	speed: 0.0705s/iter; left time: 71.9719s
[36m(_train_fn pid=865013)[0m Updating learning rate to 0.0001474421614075637
[36m(_train_fn pid=865013)[0m saving checkpoint...
[36m(_train_fn pid=865013)[0m Validation loss decreased (1.5826 --> 1.5671).  Saving model state dict ...
[36m(_train_fn pid=865013)[0m Epoch: 4 cost time: 17.212892055511475
[36m(_train_fn pid=865013)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6149771 Vali Loss: 1.5671429 Best vali loss: 1.5671429
Trial status: 182 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:25:27. Total running time: 3hr 4min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a0ac7b70   RUNNING           4            78.1757       0.614977        1.56714             1.56714 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
177 more TERMINATED
[36m(_train_fn pid=865013)[0m 	iters: 100, epoch: 5 | loss: 0.6059164
[36m(_train_fn pid=865013)[0m 	speed: 0.1232s/iter; left time: 108.0834s
[36m(_train_fn pid=865013)[0m 	iters: 200, epoch: 5 | loss: 0.5481814
[36m(_train_fn pid=865013)[0m 	speed: 0.0704s/iter; left time: 54.6848s
[36m(_train_fn pid=865013)[0m Updating learning rate to 7.372108070378185e-05
[36m(_train_fn pid=865013)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=865013)[0m saving checkpoint...
[36m(_train_fn pid=865013)[0m Epoch: 5 cost time: 17.180871963500977
[36m(_train_fn pid=865013)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6129430 Vali Loss: 1.5681265 Best vali loss: 1.5671429
[36m(_train_fn pid=865013)[0m 	iters: 100, epoch: 6 | loss: 0.5878512
[36m(_train_fn pid=865013)[0m 	speed: 0.1229s/iter; left time: 77.7913s
[36m(_train_fn pid=865013)[0m 	iters: 200, epoch: 6 | loss: 0.5985635
[36m(_train_fn pid=865013)[0m 	speed: 0.0704s/iter; left time: 37.5226s
Trial status: 182 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:25:57. Total running time: 3hr 4min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=865013)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a0ac7b70_183_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2017,e_layer_2024-08-24_10-24-00/checkpoint_000005)
2024-08-24 10:26:21,737	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=865872)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d20c25bb_184_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1930,e_layer_2024-08-24_10-25-59/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a0ac7b70   RUNNING           5            97.5017       0.612943        1.56813             1.56714 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
177 more TERMINATED

Trial trial-a0ac7b70 completed after 6 iterations at 2024-08-24 10:25:59. Total running time: 3hr 4min 50s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a0ac7b70 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          19.3447 â”‚
â”‚ time_total_s                            116.84639 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56607 â”‚
â”‚ train_loss                                 0.6121 â”‚
â”‚ valid_loss                                1.56607 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=865013)[0m Updating learning rate to 3.686054035189093e-05
[36m(_train_fn pid=865013)[0m saving checkpoint...
[36m(_train_fn pid=865013)[0m Validation loss decreased (1.5671 --> 1.5661).  Saving model state dict ...

Trial trial-d20c25bb started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d20c25bb config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19301 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00102 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=865872)[0m configuration
[36m(_train_fn pid=865872)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19300611131139792, 'e_layers': 1, 'learning_rate': 0.0010242905266401236, 'd_ff': 1536}
[36m(_train_fn pid=865872)[0m Use GPU: cuda:0
[36m(_train_fn pid=865872)[0m train 7825
[36m(_train_fn pid=865872)[0m val 2161
[36m(_train_fn pid=865872)[0m start_epoch 0
[36m(_train_fn pid=865872)[0m max_epoch 8
[36m(_train_fn pid=865872)[0m 	iters: 100, epoch: 1 | loss: 0.8368250
[36m(_train_fn pid=865872)[0m 	speed: 0.0765s/iter; left time: 141.8172s
[36m(_train_fn pid=865872)[0m 	iters: 200, epoch: 1 | loss: 0.6522757
[36m(_train_fn pid=865872)[0m 	speed: 0.0700s/iter; left time: 122.6534s
[36m(_train_fn pid=865872)[0m Updating learning rate to 0.0010242905266401236
[36m(_train_fn pid=865872)[0m saving checkpoint...
[36m(_train_fn pid=865872)[0m Validation loss decreased (inf --> 1.9092).  Saving model state dict ...
[36m(_train_fn pid=865872)[0m Epoch: 1 cost time: 17.469207763671875
[36m(_train_fn pid=865872)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7970745 Vali Loss: 1.9091968 Best vali loss: 1.9091968

Trial status: 183 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:26:27. Total running time: 3hr 5min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d20c25bb   RUNNING           1            20.0332       0.797075        1.9092              1.9092  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
178 more TERMINATED
[36m(_train_fn pid=865872)[0m 	iters: 100, epoch: 2 | loss: 0.6722232
[36m(_train_fn pid=865872)[0m 	speed: 0.1225s/iter; left time: 197.0634s
[36m(_train_fn pid=865872)[0m 	iters: 200, epoch: 2 | loss: 0.7083007
[36m(_train_fn pid=865872)[0m 	speed: 0.0700s/iter; left time: 105.5996s
[36m(_train_fn pid=865872)[0m Updating learning rate to 0.0005121452633200618
[36m(_train_fn pid=865872)[0m saving checkpoint...
[36m(_train_fn pid=865872)[0m Validation loss decreased (1.9092 --> 1.5890).  Saving model state dict ...
[36m(_train_fn pid=865872)[0m Epoch: 2 cost time: 17.085679531097412
[36m(_train_fn pid=865872)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d20c25bb_184_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1930,e_layer_2024-08-24_10-25-59/checkpoint_000001)
[36m(_train_fn pid=865872)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d20c25bb_184_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1930,e_layer_2024-08-24_10-25-59/checkpoint_000002)
[36m(_train_fn pid=865872)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d20c25bb_184_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1930,e_layer_2024-08-24_10-25-59/checkpoint_000003)
[36m(_train_fn pid=865872)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d20c25bb_184_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1930,e_layer_2024-08-24_10-25-59/checkpoint_000004)
[36m(_train_fn pid=865872)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7476389 Vali Loss: 1.5890301 Best vali loss: 1.5890301
[36m(_train_fn pid=865872)[0m 	iters: 100, epoch: 3 | loss: 0.6752591
[36m(_train_fn pid=865872)[0m 	speed: 0.1231s/iter; left time: 168.0069s
[36m(_train_fn pid=865872)[0m 	iters: 200, epoch: 3 | loss: 0.6353498
[36m(_train_fn pid=865872)[0m 	speed: 0.0706s/iter; left time: 89.2734s
Trial status: 183 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:26:57. Total running time: 3hr 5min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d20c25bb   RUNNING           2            39.2797       0.747639        1.58903             1.58903 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
178 more TERMINATED
[36m(_train_fn pid=865872)[0m Updating learning rate to 0.0002560726316600309
[36m(_train_fn pid=865872)[0m saving checkpoint...
[36m(_train_fn pid=865872)[0m Validation loss decreased (1.5890 --> 1.5793).  Saving model state dict ...
[36m(_train_fn pid=865872)[0m Epoch: 3 cost time: 17.226440906524658
[36m(_train_fn pid=865872)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6219924 Vali Loss: 1.5793349 Best vali loss: 1.5793349
[36m(_train_fn pid=865872)[0m 	iters: 100, epoch: 4 | loss: 0.6389617
[36m(_train_fn pid=865872)[0m 	speed: 0.1233s/iter; left time: 138.2236s
[36m(_train_fn pid=865872)[0m 	iters: 200, epoch: 4 | loss: 0.6390323
[36m(_train_fn pid=865872)[0m 	speed: 0.0704s/iter; left time: 71.9255s
[36m(_train_fn pid=865872)[0m Updating learning rate to 0.00012803631583001545
[36m(_train_fn pid=865872)[0m saving checkpoint...
[36m(_train_fn pid=865872)[0m Validation loss decreased (1.5793 --> 1.5697).  Saving model state dict ...
[36m(_train_fn pid=865872)[0m Epoch: 4 cost time: 17.203121662139893
[36m(_train_fn pid=865872)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6159663 Vali Loss: 1.5696667 Best vali loss: 1.5696667
[36m(_train_fn pid=865872)[0m 	iters: 100, epoch: 5 | loss: 0.6095684
[36m(_train_fn pid=865872)[0m 	speed: 0.1235s/iter; left time: 108.2775s
Trial status: 183 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:27:27. Total running time: 3hr 6min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d20c25bb   RUNNING           4            78.0515       0.615966        1.56967             1.56967 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
178 more TERMINATED
[36m(_train_fn pid=865872)[0m 	iters: 200, epoch: 5 | loss: 0.5479592
[36m(_train_fn pid=865872)[0m 	speed: 0.0704s/iter; left time: 54.7394s
[36m(_train_fn pid=865872)[0m Updating learning rate to 6.401815791500773e-05
[36m(_train_fn pid=865872)[0m saving checkpoint...
[36m(_train_fn pid=865872)[0m Validation loss decreased (1.5697 --> 1.5679).  Saving model state dict ...
[36m(_train_fn pid=865872)[0m Epoch: 5 cost time: 17.20243263244629
[36m(_train_fn pid=865872)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6140022 Vali Loss: 1.5678513 Best vali loss: 1.5678513
[36m(_train_fn pid=865872)[0m 	iters: 100, epoch: 6 | loss: 0.5904235
[36m(_train_fn pid=865872)[0m 	speed: 0.1233s/iter; left time: 78.0504s
[36m(_train_fn pid=865872)[0m 	iters: 200, epoch: 6 | loss: 0.6000873
[36m(_train_fn pid=865872)[0m 	speed: 0.0704s/iter; left time: 37.5349s
Trial status: 183 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:27:57. Total running time: 3hr 6min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=865872)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d20c25bb_184_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1930,e_layer_2024-08-24_10-25-59/checkpoint_000005)
2024-08-24 10:28:20,776	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=866730)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51ad3077_185_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1846,e_layer_2024-08-24_10-27-58/checkpoint_000000)
[36m(_train_fn pid=866730)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51ad3077_185_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1846,e_layer_2024-08-24_10-27-58/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d20c25bb   RUNNING           5            97.4245       0.614002        1.56785             1.56785 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
178 more TERMINATED

Trial trial-d20c25bb completed after 6 iterations at 2024-08-24 10:27:58. Total running time: 3hr 6min 49s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d20c25bb result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.35638 â”‚
â”‚ time_total_s                            116.78085 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56596 â”‚
â”‚ train_loss                                 0.6131 â”‚
â”‚ valid_loss                                1.56596 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=865872)[0m Updating learning rate to 3.200907895750386e-05
[36m(_train_fn pid=865872)[0m saving checkpoint...
[36m(_train_fn pid=865872)[0m Validation loss decreased (1.5679 --> 1.5660).  Saving model state dict ...

Trial trial-51ad3077 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-51ad3077 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18462 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00092 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=866730)[0m configuration
[36m(_train_fn pid=866730)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1846193916446428, 'e_layers': 1, 'learning_rate': 0.0009150134459807923, 'd_ff': 1536}
[36m(_train_fn pid=866730)[0m Use GPU: cuda:0
[36m(_train_fn pid=866730)[0m train 7825
[36m(_train_fn pid=866730)[0m val 2161
[36m(_train_fn pid=866730)[0m start_epoch 0
[36m(_train_fn pid=866730)[0m max_epoch 8
[36m(_train_fn pid=866730)[0m 	iters: 100, epoch: 1 | loss: 0.8393127
[36m(_train_fn pid=866730)[0m 	speed: 0.0769s/iter; left time: 142.5498s
[36m(_train_fn pid=866730)[0m 	iters: 200, epoch: 1 | loss: 0.6540335
[36m(_train_fn pid=866730)[0m 	speed: 0.0700s/iter; left time: 122.6508s
[36m(_train_fn pid=866730)[0m Updating learning rate to 0.0009150134459807923
[36m(_train_fn pid=866730)[0m saving checkpoint...
[36m(_train_fn pid=866730)[0m Validation loss decreased (inf --> 1.9148).  Saving model state dict ...
[36m(_train_fn pid=866730)[0m Epoch: 1 cost time: 17.50231647491455
[36m(_train_fn pid=866730)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7987790 Vali Loss: 1.9147685 Best vali loss: 1.9147685

Trial status: 184 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:28:27. Total running time: 3hr 7min 18s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-51ad3077   RUNNING           1            20.097        0.798779        1.91477             1.91477 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
179 more TERMINATED
[36m(_train_fn pid=866730)[0m 	iters: 100, epoch: 2 | loss: 0.6373983
[36m(_train_fn pid=866730)[0m 	speed: 0.1228s/iter; left time: 197.5736s
[36m(_train_fn pid=866730)[0m 	iters: 200, epoch: 2 | loss: 0.6935022
[36m(_train_fn pid=866730)[0m 	speed: 0.0703s/iter; left time: 106.0295s
[36m(_train_fn pid=866730)[0m Updating learning rate to 0.00045750672299039617
[36m(_train_fn pid=866730)[0m saving checkpoint...
[36m(_train_fn pid=866730)[0m Validation loss decreased (1.9148 --> 1.5701).  Saving model state dict ...
[36m(_train_fn pid=866730)[0m Epoch: 2 cost time: 17.152464866638184
[36m(_train_fn pid=866730)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51ad3077_185_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1846,e_layer_2024-08-24_10-27-58/checkpoint_000002)
[36m(_train_fn pid=866730)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51ad3077_185_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1846,e_layer_2024-08-24_10-27-58/checkpoint_000003)
[36m(_train_fn pid=866730)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51ad3077_185_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1846,e_layer_2024-08-24_10-27-58/checkpoint_000004)
[36m(_train_fn pid=866730)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-51ad3077_185_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1846,e_layer_2024-08-24_10-27-58/checkpoint_000005)
[36m(_train_fn pid=866730)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6946862 Vali Loss: 1.5701046 Best vali loss: 1.5701046
[36m(_train_fn pid=866730)[0m 	iters: 100, epoch: 3 | loss: 0.6667109
[36m(_train_fn pid=866730)[0m 	speed: 0.1230s/iter; left time: 167.8413s
[36m(_train_fn pid=866730)[0m 	iters: 200, epoch: 3 | loss: 0.6283137
[36m(_train_fn pid=866730)[0m 	speed: 0.0704s/iter; left time: 89.0106s
Trial status: 184 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:28:57. Total running time: 3hr 7min 48s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-51ad3077   RUNNING           2            39.4075       0.694686        1.5701              1.5701  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
179 more TERMINATED
[36m(_train_fn pid=866730)[0m Updating learning rate to 0.00022875336149519808
[36m(_train_fn pid=866730)[0m saving checkpoint...
[36m(_train_fn pid=866730)[0m Validation loss decreased (1.5701 --> 1.5663).  Saving model state dict ...
[36m(_train_fn pid=866730)[0m Epoch: 3 cost time: 17.174859046936035
[36m(_train_fn pid=866730)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6152075 Vali Loss: 1.5663253 Best vali loss: 1.5663253
[36m(_train_fn pid=866730)[0m 	iters: 100, epoch: 4 | loss: 0.6292917
[36m(_train_fn pid=866730)[0m 	speed: 0.1232s/iter; left time: 138.1037s
[36m(_train_fn pid=866730)[0m 	iters: 200, epoch: 4 | loss: 0.6340204
[36m(_train_fn pid=866730)[0m 	speed: 0.0704s/iter; left time: 71.8780s
[36m(_train_fn pid=866730)[0m Updating learning rate to 0.00011437668074759904
[36m(_train_fn pid=866730)[0m saving checkpoint...
[36m(_train_fn pid=866730)[0m Validation loss decreased (1.5663 --> 1.5659).  Saving model state dict ...
[36m(_train_fn pid=866730)[0m Epoch: 4 cost time: 17.18351125717163
[36m(_train_fn pid=866730)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6110816 Vali Loss: 1.5659285 Best vali loss: 1.5659285
[36m(_train_fn pid=866730)[0m 	iters: 100, epoch: 5 | loss: 0.6059389
[36m(_train_fn pid=866730)[0m 	speed: 0.1233s/iter; left time: 108.1393s
Trial status: 184 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:29:27. Total running time: 3hr 8min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-51ad3077   RUNNING           4            78.1077       0.611082        1.56593             1.56593 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
179 more TERMINATED
[36m(_train_fn pid=866730)[0m 	iters: 200, epoch: 5 | loss: 0.5437765
[36m(_train_fn pid=866730)[0m 	speed: 0.0704s/iter; left time: 54.6961s
[36m(_train_fn pid=866730)[0m Updating learning rate to 5.718834037379952e-05
[36m(_train_fn pid=866730)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=866730)[0m saving checkpoint...
[36m(_train_fn pid=866730)[0m Epoch: 5 cost time: 17.18905735015869
[36m(_train_fn pid=866730)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6092735 Vali Loss: 1.5687702 Best vali loss: 1.5659285
[36m(_train_fn pid=866730)[0m 	iters: 100, epoch: 6 | loss: 0.5817032
[36m(_train_fn pid=866730)[0m 	speed: 0.1229s/iter; left time: 77.7828s
[36m(_train_fn pid=866730)[0m 	iters: 200, epoch: 6 | loss: 0.5927588
[36m(_train_fn pid=866730)[0m 	speed: 0.0704s/iter; left time: 37.5417s
[36m(_train_fn pid=866730)[0m Updating learning rate to 2.859417018689976e-05
[36m(_train_fn pid=866730)[0m saving checkpoint...
[36m(_train_fn pid=866730)[0m Validation loss decreased (1.5659 --> 1.5620).  Saving model state dict ...

Trial trial-51ad3077 completed after 6 iterations at 2024-08-24 10:29:57. Total running time: 3hr 8min 48s
2024-08-24 10:30:19,778	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=867590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-95c70997_186_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1886,e_layer_2024-08-24_10-29-57/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-51ad3077 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.34452 â”‚
â”‚ time_total_s                            116.78681 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56199 â”‚
â”‚ train_loss                                0.60837 â”‚
â”‚ valid_loss                                1.56199 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 185 TERMINATED | 1 PENDING
Current time: 2024-08-24 10:29:57. Total running time: 3hr 8min 49s
Logical resource usage: 0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-95c70997   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
180 more TERMINATED

Trial trial-95c70997 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-95c70997 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18859 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00077 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=867590)[0m configuration
[36m(_train_fn pid=867590)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18858525220902453, 'e_layers': 1, 'learning_rate': 0.0007655065791587929, 'd_ff': 1536}
[36m(_train_fn pid=867590)[0m Use GPU: cuda:0
[36m(_train_fn pid=867590)[0m train 7825
[36m(_train_fn pid=867590)[0m val 2161
[36m(_train_fn pid=867590)[0m start_epoch 0
[36m(_train_fn pid=867590)[0m max_epoch 8
[36m(_train_fn pid=867590)[0m 	iters: 100, epoch: 1 | loss: 0.8456083
[36m(_train_fn pid=867590)[0m 	speed: 0.0769s/iter; left time: 142.5024s
[36m(_train_fn pid=867590)[0m 	iters: 200, epoch: 1 | loss: 0.6580008
[36m(_train_fn pid=867590)[0m 	speed: 0.0700s/iter; left time: 122.7003s
[36m(_train_fn pid=867590)[0m Updating learning rate to 0.0007655065791587929
[36m(_train_fn pid=867590)[0m saving checkpoint...
[36m(_train_fn pid=867590)[0m Validation loss decreased (inf --> 1.9216).  Saving model state dict ...
[36m(_train_fn pid=867590)[0m Epoch: 1 cost time: 17.499345779418945
[36m(_train_fn pid=867590)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8044723 Vali Loss: 1.9216056 Best vali loss: 1.9216056
[36m(_train_fn pid=867590)[0m 	iters: 100, epoch: 2 | loss: 0.6497173
[36m(_train_fn pid=867590)[0m 	speed: 0.1231s/iter; left time: 198.0096s

Trial status: 185 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:30:27. Total running time: 3hr 9min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-95c70997   RUNNING           1            20.0872       0.804472        1.92161             1.92161 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
180 more TERMINATED
[36m(_train_fn pid=867590)[0m 	iters: 200, epoch: 2 | loss: 0.6917998
[36m(_train_fn pid=867590)[0m 	speed: 0.0705s/iter; left time: 106.3232s
[36m(_train_fn pid=867590)[0m Updating learning rate to 0.00038275328957939643
[36m(_train_fn pid=867590)[0m saving checkpoint...
[36m(_train_fn pid=867590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-95c70997_186_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1886,e_layer_2024-08-24_10-29-57/checkpoint_000001)
[36m(_train_fn pid=867590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-95c70997_186_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1886,e_layer_2024-08-24_10-29-57/checkpoint_000002)
[36m(_train_fn pid=867590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-95c70997_186_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1886,e_layer_2024-08-24_10-29-57/checkpoint_000003)
[36m(_train_fn pid=867590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-95c70997_186_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1886,e_layer_2024-08-24_10-29-57/checkpoint_000004)
[36m(_train_fn pid=867590)[0m Validation loss decreased (1.9216 --> 1.5699).  Saving model state dict ...
[36m(_train_fn pid=867590)[0m Epoch: 2 cost time: 17.20132303237915
[36m(_train_fn pid=867590)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6955774 Vali Loss: 1.5699308 Best vali loss: 1.5699308
[36m(_train_fn pid=867590)[0m 	iters: 100, epoch: 3 | loss: 0.6676998
[36m(_train_fn pid=867590)[0m 	speed: 0.1233s/iter; left time: 168.2617s
[36m(_train_fn pid=867590)[0m 	iters: 200, epoch: 3 | loss: 0.6281331
[36m(_train_fn pid=867590)[0m 	speed: 0.0704s/iter; left time: 89.1191s
Trial status: 185 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:30:58. Total running time: 3hr 9min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-95c70997   RUNNING           2            39.4561       0.695577        1.56993             1.56993 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
180 more TERMINATED
[36m(_train_fn pid=867590)[0m Updating learning rate to 0.00019137664478969822
[36m(_train_fn pid=867590)[0m saving checkpoint...
[36m(_train_fn pid=867590)[0m Validation loss decreased (1.5699 --> 1.5668).  Saving model state dict ...
[36m(_train_fn pid=867590)[0m Epoch: 3 cost time: 17.207165718078613
[36m(_train_fn pid=867590)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6152768 Vali Loss: 1.5668087 Best vali loss: 1.5668087
[36m(_train_fn pid=867590)[0m 	iters: 100, epoch: 4 | loss: 0.6323424
[36m(_train_fn pid=867590)[0m 	speed: 0.1233s/iter; left time: 138.2577s
[36m(_train_fn pid=867590)[0m 	iters: 200, epoch: 4 | loss: 0.6350203
[36m(_train_fn pid=867590)[0m 	speed: 0.0705s/iter; left time: 71.9726s
[36m(_train_fn pid=867590)[0m Updating learning rate to 9.568832239484911e-05
[36m(_train_fn pid=867590)[0m saving checkpoint...
[36m(_train_fn pid=867590)[0m Validation loss decreased (1.5668 --> 1.5644).  Saving model state dict ...
[36m(_train_fn pid=867590)[0m Epoch: 4 cost time: 17.209384202957153
[36m(_train_fn pid=867590)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6118633 Vali Loss: 1.5644469 Best vali loss: 1.5644469
[36m(_train_fn pid=867590)[0m 	iters: 100, epoch: 5 | loss: 0.6063933
[36m(_train_fn pid=867590)[0m 	speed: 0.1233s/iter; left time: 108.1021s
Trial status: 185 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:31:28. Total running time: 3hr 10min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-95c70997   RUNNING           4            78.2008       0.611863        1.56445             1.56445 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
180 more TERMINATED
[36m(_train_fn pid=867590)[0m 	iters: 200, epoch: 5 | loss: 0.5453267
[36m(_train_fn pid=867590)[0m 	speed: 0.0705s/iter; left time: 54.7467s
[36m(_train_fn pid=867590)[0m Updating learning rate to 4.7844161197424554e-05
[36m(_train_fn pid=867590)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=867590)[0m saving checkpoint...
[36m(_train_fn pid=867590)[0m Epoch: 5 cost time: 17.19834303855896
[36m(_train_fn pid=867590)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6106330 Vali Loss: 1.5663735 Best vali loss: 1.5644469
[36m(_train_fn pid=867590)[0m 	iters: 100, epoch: 6 | loss: 0.5828171
[36m(_train_fn pid=867590)[0m 	speed: 0.1230s/iter; left time: 77.8608s
[36m(_train_fn pid=867590)[0m 	iters: 200, epoch: 6 | loss: 0.5951481
[36m(_train_fn pid=867590)[0m 	speed: 0.0704s/iter; left time: 37.5401s

Trial trial-95c70997 completed after 6 iterations at 2024-08-24 10:31:56. Total running time: 3hr 10min 47s
[36m(_train_fn pid=867590)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-95c70997_186_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1886,e_layer_2024-08-24_10-29-57/checkpoint_000005)
2024-08-24 10:32:18,754	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=868451)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-db830771_187_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1795,e_layer_2024-08-24_10-31-56/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-95c70997 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.35271 â”‚
â”‚ time_total_s                            116.90086 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                            1.5638 â”‚
â”‚ train_loss                                0.60975 â”‚
â”‚ valid_loss                                 1.5638 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=867590)[0m Updating learning rate to 2.3922080598712277e-05
[36m(_train_fn pid=867590)[0m saving checkpoint...
[36m(_train_fn pid=867590)[0m Validation loss decreased (1.5644 --> 1.5638).  Saving model state dict ...

Trial status: 186 TERMINATED | 1 PENDING
Current time: 2024-08-24 10:31:58. Total running time: 3hr 10min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-db830771   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
181 more TERMINATED

Trial trial-db830771 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-db830771 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17954 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00066 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=868451)[0m configuration
[36m(_train_fn pid=868451)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.17953836225431236, 'e_layers': 1, 'learning_rate': 0.0006557289395676398, 'd_ff': 1536}
[36m(_train_fn pid=868451)[0m Use GPU: cuda:0
[36m(_train_fn pid=868451)[0m train 7825
[36m(_train_fn pid=868451)[0m val 2161
[36m(_train_fn pid=868451)[0m start_epoch 0
[36m(_train_fn pid=868451)[0m max_epoch 8
[36m(_train_fn pid=868451)[0m 	iters: 100, epoch: 1 | loss: 0.8483278
[36m(_train_fn pid=868451)[0m 	speed: 0.0765s/iter; left time: 141.6878s
[36m(_train_fn pid=868451)[0m 	iters: 200, epoch: 1 | loss: 0.6615736
[36m(_train_fn pid=868451)[0m 	speed: 0.0700s/iter; left time: 122.6727s
[36m(_train_fn pid=868451)[0m Updating learning rate to 0.0006557289395676398
[36m(_train_fn pid=868451)[0m saving checkpoint...
[36m(_train_fn pid=868451)[0m Validation loss decreased (inf --> 1.9257).  Saving model state dict ...
[36m(_train_fn pid=868451)[0m Epoch: 1 cost time: 17.46200728416443
[36m(_train_fn pid=868451)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8072546 Vali Loss: 1.9256712 Best vali loss: 1.9256712
[36m(_train_fn pid=868451)[0m 	iters: 100, epoch: 2 | loss: 0.6408291
[36m(_train_fn pid=868451)[0m 	speed: 0.1227s/iter; left time: 197.4081s

Trial status: 186 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:32:28. Total running time: 3hr 11min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-db830771   RUNNING           1            20.024        0.807255        1.92567             1.92567 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
181 more TERMINATED
[36m(_train_fn pid=868451)[0m 	iters: 200, epoch: 2 | loss: 0.6950332
[36m(_train_fn pid=868451)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-db830771_187_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1795,e_layer_2024-08-24_10-31-56/checkpoint_000001)
[36m(_train_fn pid=868451)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-db830771_187_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1795,e_layer_2024-08-24_10-31-56/checkpoint_000002)
[36m(_train_fn pid=868451)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-db830771_187_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1795,e_layer_2024-08-24_10-31-56/checkpoint_000003)
[36m(_train_fn pid=868451)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-db830771_187_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1795,e_layer_2024-08-24_10-31-56/checkpoint_000004)
[36m(_train_fn pid=868451)[0m 	speed: 0.0703s/iter; left time: 106.1268s
[36m(_train_fn pid=868451)[0m Updating learning rate to 0.0003278644697838199
[36m(_train_fn pid=868451)[0m saving checkpoint...
[36m(_train_fn pid=868451)[0m Validation loss decreased (1.9257 --> 1.5691).  Saving model state dict ...
[36m(_train_fn pid=868451)[0m Epoch: 2 cost time: 17.167718648910522
[36m(_train_fn pid=868451)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6749995 Vali Loss: 1.5690539 Best vali loss: 1.5690539
[36m(_train_fn pid=868451)[0m 	iters: 100, epoch: 3 | loss: 0.6667597
[36m(_train_fn pid=868451)[0m 	speed: 0.1232s/iter; left time: 168.1900s
[36m(_train_fn pid=868451)[0m 	iters: 200, epoch: 3 | loss: 0.6276720
[36m(_train_fn pid=868451)[0m 	speed: 0.0704s/iter; left time: 89.0435s
[36m(_train_fn pid=868451)[0m Updating learning rate to 0.00016393223489190995
[36m(_train_fn pid=868451)[0m saving checkpoint...
[36m(_train_fn pid=868451)[0m Validation loss decreased (1.5691 --> 1.5650).  Saving model state dict ...
[36m(_train_fn pid=868451)[0m Epoch: 3 cost time: 17.184791803359985
[36m(_train_fn pid=868451)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6154480 Vali Loss: 1.5650311 Best vali loss: 1.5650311
Trial status: 186 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:32:58. Total running time: 3hr 11min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-db830771   RUNNING           3            58.7108       0.615448        1.56503             1.56503 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
181 more TERMINATED
[36m(_train_fn pid=868451)[0m 	iters: 100, epoch: 4 | loss: 0.6332945
[36m(_train_fn pid=868451)[0m 	speed: 0.1232s/iter; left time: 138.0548s
[36m(_train_fn pid=868451)[0m 	iters: 200, epoch: 4 | loss: 0.6353737
[36m(_train_fn pid=868451)[0m 	speed: 0.0704s/iter; left time: 71.9095s
[36m(_train_fn pid=868451)[0m Updating learning rate to 8.196611744595497e-05
[36m(_train_fn pid=868451)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=868451)[0m saving checkpoint...
[36m(_train_fn pid=868451)[0m Epoch: 4 cost time: 17.191351413726807
[36m(_train_fn pid=868451)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6113563 Vali Loss: 1.5657273 Best vali loss: 1.5650311
[36m(_train_fn pid=868451)[0m 	iters: 100, epoch: 5 | loss: 0.6052667
[36m(_train_fn pid=868451)[0m 	speed: 0.1229s/iter; left time: 107.7744s
Trial status: 186 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:33:28. Total running time: 3hr 12min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-db830771   RUNNING           4            78.0454       0.611356        1.56573             1.56503 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
181 more TERMINATED
[36m(_train_fn pid=868451)[0m 	iters: 200, epoch: 5 | loss: 0.5442074
[36m(_train_fn pid=868451)[0m 	speed: 0.0704s/iter; left time: 54.7046s
[36m(_train_fn pid=868451)[0m Updating learning rate to 4.098305872297749e-05
[36m(_train_fn pid=868451)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=868451)[0m saving checkpoint...
[36m(_train_fn pid=868451)[0m Epoch: 5 cost time: 17.186217308044434
[36m(_train_fn pid=868451)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6096060 Vali Loss: 1.5720742 Best vali loss: 1.5650311
[36m(_train_fn pid=868451)[0m 	iters: 100, epoch: 6 | loss: 0.5823097
[36m(_train_fn pid=868451)[0m 	speed: 0.1229s/iter; left time: 77.8123s
[36m(_train_fn pid=868451)[0m 	iters: 200, epoch: 6 | loss: 0.5942054
[36m(_train_fn pid=868451)[0m 	speed: 0.0704s/iter; left time: 37.5036s
[36m(_train_fn pid=868451)[0m Updating learning rate to 2.0491529361488743e-05
[36m(_train_fn pid=868451)[0m saving checkpoint...
[36m(_train_fn pid=868451)[0m Validation loss decreased (1.5650 --> 1.5614).  Saving model state dict ...

Trial trial-db830771 completed after 6 iterations at 2024-08-24 10:33:55. Total running time: 3hr 12min 46s
[36m(_train_fn pid=868451)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-db830771_187_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1795,e_layer_2024-08-24_10-31-56/checkpoint_000005)
2024-08-24 10:34:17,748	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=869315)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-09541a32_188_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2006,e_layer_2024-08-24_10-33-55/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-db830771 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.35326 â”‚
â”‚ time_total_s                            116.72741 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56139 â”‚
â”‚ train_loss                                0.60889 â”‚
â”‚ valid_loss                                1.56139 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-09541a32 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-09541a32 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.20059 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00112 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=869315)[0m configuration
[36m(_train_fn pid=869315)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.20058826587958747, 'e_layers': 1, 'learning_rate': 0.0011210963361666993, 'd_ff': 1536}
[36m(_train_fn pid=869315)[0m Use GPU: cuda:0
[36m(_train_fn pid=869315)[0m train 7825
[36m(_train_fn pid=869315)[0m val 2161
[36m(_train_fn pid=869315)[0m start_epoch 0
[36m(_train_fn pid=869315)[0m max_epoch 8

Trial status: 187 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:33:58. Total running time: 3hr 12min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-09541a32   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
182 more TERMINATED
[36m(_train_fn pid=869315)[0m 	iters: 100, epoch: 1 | loss: 0.8349231
[36m(_train_fn pid=869315)[0m 	speed: 0.0765s/iter; left time: 141.7393s
[36m(_train_fn pid=869315)[0m 	iters: 200, epoch: 1 | loss: 0.6504909
[36m(_train_fn pid=869315)[0m 	speed: 0.0700s/iter; left time: 122.6889s
[36m(_train_fn pid=869315)[0m Updating learning rate to 0.0011210963361666993
[36m(_train_fn pid=869315)[0m saving checkpoint...
[36m(_train_fn pid=869315)[0m Validation loss decreased (inf --> 1.9031).  Saving model state dict ...
[36m(_train_fn pid=869315)[0m Epoch: 1 cost time: 17.457958459854126
[36m(_train_fn pid=869315)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7958197 Vali Loss: 1.9030502 Best vali loss: 1.9030502
[36m(_train_fn pid=869315)[0m 	iters: 100, epoch: 2 | loss: 0.6681213
[36m(_train_fn pid=869315)[0m 	speed: 0.1226s/iter; left time: 197.2614s
Trial status: 187 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:34:28. Total running time: 3hr 13min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-09541a32   RUNNING           1            20.0416       0.79582         1.90305             1.90305 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
182 more TERMINATED
[36m(_train_fn pid=869315)[0m 	iters: 200, epoch: 2 | loss: 0.7105557
[36m(_train_fn pid=869315)[0m 	speed: 0.0700s/iter; left time: 105.5934s
[36m(_train_fn pid=869315)[0m Updating learning rate to 0.0005605481680833497
[36m(_train_fn pid=869315)[0m saving checkpoint...
[36m(_train_fn pid=869315)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-09541a32_188_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2006,e_layer_2024-08-24_10-33-55/checkpoint_000001)
[36m(_train_fn pid=869315)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-09541a32_188_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2006,e_layer_2024-08-24_10-33-55/checkpoint_000002)
[36m(_train_fn pid=869315)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-09541a32_188_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2006,e_layer_2024-08-24_10-33-55/checkpoint_000003)
[36m(_train_fn pid=869315)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-09541a32_188_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2006,e_layer_2024-08-24_10-33-55/checkpoint_000004)
[36m(_train_fn pid=869315)[0m Validation loss decreased (1.9031 --> 1.5876).  Saving model state dict ...
[36m(_train_fn pid=869315)[0m Epoch: 2 cost time: 17.091373920440674
[36m(_train_fn pid=869315)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7613512 Vali Loss: 1.5875659 Best vali loss: 1.5875659
[36m(_train_fn pid=869315)[0m 	iters: 100, epoch: 3 | loss: 0.6770309
[36m(_train_fn pid=869315)[0m 	speed: 0.1226s/iter; left time: 167.4101s
[36m(_train_fn pid=869315)[0m 	iters: 200, epoch: 3 | loss: 0.6432474
[36m(_train_fn pid=869315)[0m 	speed: 0.0701s/iter; left time: 88.6876s
[36m(_train_fn pid=869315)[0m Updating learning rate to 0.00028027408404167483
[36m(_train_fn pid=869315)[0m saving checkpoint...
[36m(_train_fn pid=869315)[0m Validation loss decreased (1.5876 --> 1.5762).  Saving model state dict ...
[36m(_train_fn pid=869315)[0m Epoch: 3 cost time: 17.120882272720337
[36m(_train_fn pid=869315)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6205735 Vali Loss: 1.5762262 Best vali loss: 1.5762262
Trial status: 187 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:34:58. Total running time: 3hr 13min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-09541a32   RUNNING           3            58.5774       0.620574        1.57623             1.57623 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
182 more TERMINATED
[36m(_train_fn pid=869315)[0m 	iters: 100, epoch: 4 | loss: 0.6343739
[36m(_train_fn pid=869315)[0m 	speed: 0.1229s/iter; left time: 137.7387s
[36m(_train_fn pid=869315)[0m 	iters: 200, epoch: 4 | loss: 0.6410837
[36m(_train_fn pid=869315)[0m 	speed: 0.0702s/iter; left time: 71.7102s
[36m(_train_fn pid=869315)[0m Updating learning rate to 0.00014013704202083742
[36m(_train_fn pid=869315)[0m saving checkpoint...
[36m(_train_fn pid=869315)[0m Validation loss decreased (1.5762 --> 1.5682).  Saving model state dict ...
[36m(_train_fn pid=869315)[0m Epoch: 4 cost time: 17.14025592803955
[36m(_train_fn pid=869315)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6159136 Vali Loss: 1.5682293 Best vali loss: 1.5682293
[36m(_train_fn pid=869315)[0m 	iters: 100, epoch: 5 | loss: 0.6070972
[36m(_train_fn pid=869315)[0m 	speed: 0.1229s/iter; left time: 107.7418s
Trial status: 187 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:35:28. Total running time: 3hr 14min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-09541a32   RUNNING           4            77.8788       0.615914        1.56823             1.56823 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
182 more TERMINATED
[36m(_train_fn pid=869315)[0m 	iters: 200, epoch: 5 | loss: 0.5495443
[36m(_train_fn pid=869315)[0m 	speed: 0.0702s/iter; left time: 54.5505s
[36m(_train_fn pid=869315)[0m Updating learning rate to 7.006852101041871e-05
[36m(_train_fn pid=869315)[0m saving checkpoint...
[36m(_train_fn pid=869315)[0m Validation loss decreased (1.5682 --> 1.5680).  Saving model state dict ...
[36m(_train_fn pid=869315)[0m Epoch: 5 cost time: 17.140814781188965
[36m(_train_fn pid=869315)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6138866 Vali Loss: 1.5680039 Best vali loss: 1.5680039
[36m(_train_fn pid=869315)[0m 	iters: 100, epoch: 6 | loss: 0.5923786
[36m(_train_fn pid=869315)[0m 	speed: 0.1228s/iter; left time: 77.7327s
[36m(_train_fn pid=869315)[0m 	iters: 200, epoch: 6 | loss: 0.5990016
[36m(_train_fn pid=869315)[0m 	speed: 0.0701s/iter; left time: 37.3863s

Trial trial-09541a32 completed after 6 iterations at 2024-08-24 10:35:54. Total running time: 3hr 14min 45s
[36m(_train_fn pid=869315)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-09541a32_188_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2006,e_layer_2024-08-24_10-33-55/checkpoint_000005)
2024-08-24 10:36:16,765	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=870173)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f33279dc_189_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1810,e_layer_2024-08-24_10-35-54/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-09541a32 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.29886 â”‚
â”‚ time_total_s                            116.47595 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56639 â”‚
â”‚ train_loss                                  0.613 â”‚
â”‚ valid_loss                                1.56639 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=869315)[0m Updating learning rate to 3.5034260505209354e-05
[36m(_train_fn pid=869315)[0m saving checkpoint...
[36m(_train_fn pid=869315)[0m Validation loss decreased (1.5680 --> 1.5664).  Saving model state dict ...

Trial trial-f33279dc started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f33279dc config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18104 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00058 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=870173)[0m configuration
[36m(_train_fn pid=870173)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18104145725276435, 'e_layers': 1, 'learning_rate': 0.0005844734029454537, 'd_ff': 1536}
[36m(_train_fn pid=870173)[0m Use GPU: cuda:0
[36m(_train_fn pid=870173)[0m train 7825
[36m(_train_fn pid=870173)[0m val 2161
[36m(_train_fn pid=870173)[0m start_epoch 0
[36m(_train_fn pid=870173)[0m max_epoch 8

Trial status: 188 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:35:58. Total running time: 3hr 14min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f33279dc   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
183 more TERMINATED
[36m(_train_fn pid=870173)[0m 	iters: 100, epoch: 1 | loss: 0.8524715
[36m(_train_fn pid=870173)[0m 	speed: 0.0765s/iter; left time: 141.7690s
[36m(_train_fn pid=870173)[0m 	iters: 200, epoch: 1 | loss: 0.6649052
[36m(_train_fn pid=870173)[0m 	speed: 0.0700s/iter; left time: 122.7242s
[36m(_train_fn pid=870173)[0m Updating learning rate to 0.0005844734029454537
[36m(_train_fn pid=870173)[0m saving checkpoint...
[36m(_train_fn pid=870173)[0m Validation loss decreased (inf --> 1.9288).  Saving model state dict ...
[36m(_train_fn pid=870173)[0m Epoch: 1 cost time: 17.469406127929688
[36m(_train_fn pid=870173)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8110001 Vali Loss: 1.9287852 Best vali loss: 1.9287852
[36m(_train_fn pid=870173)[0m 	iters: 100, epoch: 2 | loss: 0.6501024
[36m(_train_fn pid=870173)[0m 	speed: 0.1228s/iter; left time: 197.6352s
Trial status: 188 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:36:28. Total running time: 3hr 15min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f33279dc   RUNNING           1            20.0433       0.811           1.92879             1.92879 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
183 more TERMINATED
[36m(_train_fn pid=870173)[0m 	iters: 200, epoch: 2 | loss: 0.6946422
[36m(_train_fn pid=870173)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f33279dc_189_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1810,e_layer_2024-08-24_10-35-54/checkpoint_000001)
[36m(_train_fn pid=870173)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f33279dc_189_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1810,e_layer_2024-08-24_10-35-54/checkpoint_000002)
[36m(_train_fn pid=870173)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f33279dc_189_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1810,e_layer_2024-08-24_10-35-54/checkpoint_000003)
[36m(_train_fn pid=870173)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f33279dc_189_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1810,e_layer_2024-08-24_10-35-54/checkpoint_000004)
[36m(_train_fn pid=870173)[0m 	speed: 0.0703s/iter; left time: 106.1186s
[36m(_train_fn pid=870173)[0m Updating learning rate to 0.00029223670147272683
[36m(_train_fn pid=870173)[0m saving checkpoint...
[36m(_train_fn pid=870173)[0m Validation loss decreased (1.9288 --> 1.5713).  Saving model state dict ...
[36m(_train_fn pid=870173)[0m Epoch: 2 cost time: 17.1675226688385
[36m(_train_fn pid=870173)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6776254 Vali Loss: 1.5712713 Best vali loss: 1.5712713
[36m(_train_fn pid=870173)[0m 	iters: 100, epoch: 3 | loss: 0.6708693
[36m(_train_fn pid=870173)[0m 	speed: 0.1231s/iter; left time: 168.0341s
[36m(_train_fn pid=870173)[0m 	iters: 200, epoch: 3 | loss: 0.6282937
[36m(_train_fn pid=870173)[0m 	speed: 0.0703s/iter; left time: 88.9211s
[36m(_train_fn pid=870173)[0m Updating learning rate to 0.00014611835073636341
[36m(_train_fn pid=870173)[0m saving checkpoint...
[36m(_train_fn pid=870173)[0m Validation loss decreased (1.5713 --> 1.5655).  Saving model state dict ...
[36m(_train_fn pid=870173)[0m Epoch: 3 cost time: 17.170403242111206
[36m(_train_fn pid=870173)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6169708 Vali Loss: 1.5654681 Best vali loss: 1.5654681
Trial status: 188 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:36:58. Total running time: 3hr 15min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f33279dc   RUNNING           3            58.7043       0.616971        1.56547             1.56547 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
183 more TERMINATED
[36m(_train_fn pid=870173)[0m 	iters: 100, epoch: 4 | loss: 0.6321468
[36m(_train_fn pid=870173)[0m 	speed: 0.1231s/iter; left time: 137.9907s
[36m(_train_fn pid=870173)[0m 	iters: 200, epoch: 4 | loss: 0.6372997
[36m(_train_fn pid=870173)[0m 	speed: 0.0704s/iter; left time: 71.8853s
[36m(_train_fn pid=870173)[0m Updating learning rate to 7.305917536818171e-05
[36m(_train_fn pid=870173)[0m saving checkpoint...
[36m(_train_fn pid=870173)[0m Validation loss decreased (1.5655 --> 1.5633).  Saving model state dict ...
[36m(_train_fn pid=870173)[0m Epoch: 4 cost time: 17.189841985702515
[36m(_train_fn pid=870173)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6127627 Vali Loss: 1.5633431 Best vali loss: 1.5633431
[36m(_train_fn pid=870173)[0m 	iters: 100, epoch: 5 | loss: 0.6064484
[36m(_train_fn pid=870173)[0m 	speed: 0.1232s/iter; left time: 108.0759s
Trial status: 188 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:37:28. Total running time: 3hr 16min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-f33279dc   RUNNING           4            78.0614       0.612763        1.56334             1.56334 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
183 more TERMINATED
[36m(_train_fn pid=870173)[0m 	iters: 200, epoch: 5 | loss: 0.5454044
[36m(_train_fn pid=870173)[0m 	speed: 0.0705s/iter; left time: 54.7486s
[36m(_train_fn pid=870173)[0m Updating learning rate to 3.6529587684090853e-05
[36m(_train_fn pid=870173)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=870173)[0m saving checkpoint...
[36m(_train_fn pid=870173)[0m Epoch: 5 cost time: 17.20032048225403
[36m(_train_fn pid=870173)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6109226 Vali Loss: 1.5684299 Best vali loss: 1.5633431
[36m(_train_fn pid=870173)[0m 	iters: 100, epoch: 6 | loss: 0.5836810
[36m(_train_fn pid=870173)[0m 	speed: 0.1229s/iter; left time: 77.8028s
[36m(_train_fn pid=870173)[0m 	iters: 200, epoch: 6 | loss: 0.5958002
[36m(_train_fn pid=870173)[0m 	speed: 0.0704s/iter; left time: 37.5449s

Trial trial-f33279dc completed after 6 iterations at 2024-08-24 10:37:53. Total running time: 3hr 16min 44s
[36m(_train_fn pid=870173)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-f33279dc_189_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1810,e_layer_2024-08-24_10-35-54/checkpoint_000005)
[36m(_train_fn pid=871033)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1cd0aa88_190_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1864,e_layer_2024-08-24_10-37-53/checkpoint_000000)
2024-08-24 10:38:15,780	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-f33279dc result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.35933 â”‚
â”‚ time_total_s                            116.76315 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56232 â”‚
â”‚ train_loss                                0.61013 â”‚
â”‚ valid_loss                                1.56232 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=870173)[0m Updating learning rate to 1.8264793842045427e-05
[36m(_train_fn pid=870173)[0m saving checkpoint...
[36m(_train_fn pid=870173)[0m Validation loss decreased (1.5633 --> 1.5623).  Saving model state dict ...

Trial trial-1cd0aa88 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1cd0aa88 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18637 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00083 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=871033)[0m configuration
[36m(_train_fn pid=871033)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18636895796845052, 'e_layers': 1, 'learning_rate': 0.0008281860531502722, 'd_ff': 1536}
[36m(_train_fn pid=871033)[0m Use GPU: cuda:0
[36m(_train_fn pid=871033)[0m train 7825
[36m(_train_fn pid=871033)[0m val 2161
[36m(_train_fn pid=871033)[0m start_epoch 0
[36m(_train_fn pid=871033)[0m max_epoch 8

Trial status: 189 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:37:58. Total running time: 3hr 16min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1cd0aa88   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
184 more TERMINATED
[36m(_train_fn pid=871033)[0m 	iters: 100, epoch: 1 | loss: 0.8426648
[36m(_train_fn pid=871033)[0m 	speed: 0.0768s/iter; left time: 142.3492s
[36m(_train_fn pid=871033)[0m 	iters: 200, epoch: 1 | loss: 0.6560643
[36m(_train_fn pid=871033)[0m 	speed: 0.0700s/iter; left time: 122.6314s
[36m(_train_fn pid=871033)[0m Updating learning rate to 0.0008281860531502722
[36m(_train_fn pid=871033)[0m saving checkpoint...
[36m(_train_fn pid=871033)[0m Validation loss decreased (inf --> 1.9187).  Saving model state dict ...
[36m(_train_fn pid=871033)[0m Epoch: 1 cost time: 17.496222734451294
[36m(_train_fn pid=871033)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8017694 Vali Loss: 1.9186763 Best vali loss: 1.9186763
[36m(_train_fn pid=871033)[0m 	iters: 100, epoch: 2 | loss: 0.6428034
[36m(_train_fn pid=871033)[0m 	speed: 0.1228s/iter; left time: 197.6321s
Trial status: 189 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:38:28. Total running time: 3hr 17min 19s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1cd0aa88   RUNNING           1            20.0711       0.801769        1.91868             1.91868 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
184 more TERMINATED
[36m(_train_fn pid=871033)[0m 	iters: 200, epoch: 2 | loss: 0.6926853
[36m(_train_fn pid=871033)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1cd0aa88_190_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1864,e_layer_2024-08-24_10-37-53/checkpoint_000001)
[36m(_train_fn pid=871033)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1cd0aa88_190_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1864,e_layer_2024-08-24_10-37-53/checkpoint_000002)
[36m(_train_fn pid=871033)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1cd0aa88_190_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1864,e_layer_2024-08-24_10-37-53/checkpoint_000003)
[36m(_train_fn pid=871033)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1cd0aa88_190_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1864,e_layer_2024-08-24_10-37-53/checkpoint_000004)
[36m(_train_fn pid=871033)[0m 	speed: 0.0703s/iter; left time: 106.0344s
[36m(_train_fn pid=871033)[0m Updating learning rate to 0.0004140930265751361
[36m(_train_fn pid=871033)[0m saving checkpoint...
[36m(_train_fn pid=871033)[0m Validation loss decreased (1.9187 --> 1.5880).  Saving model state dict ...
[36m(_train_fn pid=871033)[0m Epoch: 2 cost time: 17.157915353775024
[36m(_train_fn pid=871033)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6918408 Vali Loss: 1.5880352 Best vali loss: 1.5880352
[36m(_train_fn pid=871033)[0m 	iters: 100, epoch: 3 | loss: 0.6674030
[36m(_train_fn pid=871033)[0m 	speed: 0.1231s/iter; left time: 167.9635s
[36m(_train_fn pid=871033)[0m 	iters: 200, epoch: 3 | loss: 0.6316847
[36m(_train_fn pid=871033)[0m 	speed: 0.0703s/iter; left time: 88.9873s
[36m(_train_fn pid=871033)[0m Updating learning rate to 0.00020704651328756806
[36m(_train_fn pid=871033)[0m saving checkpoint...
[36m(_train_fn pid=871033)[0m Validation loss decreased (1.5880 --> 1.5756).  Saving model state dict ...
[36m(_train_fn pid=871033)[0m Epoch: 3 cost time: 17.176170587539673
[36m(_train_fn pid=871033)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6159332 Vali Loss: 1.5756321 Best vali loss: 1.5756321
Trial status: 189 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:38:58. Total running time: 3hr 17min 49s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1cd0aa88   RUNNING           3            58.7277       0.615933        1.57563             1.57563 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
184 more TERMINATED
[36m(_train_fn pid=871033)[0m 	iters: 100, epoch: 4 | loss: 0.6336499
[36m(_train_fn pid=871033)[0m 	speed: 0.1231s/iter; left time: 137.9875s
[36m(_train_fn pid=871033)[0m 	iters: 200, epoch: 4 | loss: 0.6379040
[36m(_train_fn pid=871033)[0m 	speed: 0.0704s/iter; left time: 71.8656s
[36m(_train_fn pid=871033)[0m Updating learning rate to 0.00010352325664378403
[36m(_train_fn pid=871033)[0m saving checkpoint...
[36m(_train_fn pid=871033)[0m Validation loss decreased (1.5756 --> 1.5631).  Saving model state dict ...
[36m(_train_fn pid=871033)[0m Epoch: 4 cost time: 17.18573760986328
[36m(_train_fn pid=871033)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6111874 Vali Loss: 1.5631207 Best vali loss: 1.5631207
[36m(_train_fn pid=871033)[0m 	iters: 100, epoch: 5 | loss: 0.6055455
[36m(_train_fn pid=871033)[0m 	speed: 0.1232s/iter; left time: 108.0194s
[36m(_train_fn pid=871033)[0m 	iters: 200, epoch: 5 | loss: 0.5444108
[36m(_train_fn pid=871033)[0m 	speed: 0.0704s/iter; left time: 54.7274s
Trial status: 189 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:39:28. Total running time: 3hr 18min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1cd0aa88   RUNNING           4            78.0772       0.611187        1.56312             1.56312 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
184 more TERMINATED
[36m(_train_fn pid=871033)[0m Updating learning rate to 5.1761628321892014e-05
[36m(_train_fn pid=871033)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=871033)[0m saving checkpoint...
[36m(_train_fn pid=871033)[0m Epoch: 5 cost time: 17.193016290664673
[36m(_train_fn pid=871033)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6092350 Vali Loss: 1.5656648 Best vali loss: 1.5631207
[36m(_train_fn pid=871033)[0m 	iters: 100, epoch: 6 | loss: 0.5817477
[36m(_train_fn pid=871033)[0m 	speed: 0.1229s/iter; left time: 77.7995s
[36m(_train_fn pid=871033)[0m 	iters: 200, epoch: 6 | loss: 0.5935965
[36m(_train_fn pid=871033)[0m 	speed: 0.0704s/iter; left time: 37.5376s

Trial trial-1cd0aa88 completed after 6 iterations at 2024-08-24 10:39:52. Total running time: 3hr 18min 43s
[36m(_train_fn pid=871033)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1cd0aa88_190_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1864,e_layer_2024-08-24_10-37-53/checkpoint_000005)
[36m(_train_fn pid=871895)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5329edda_191_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1764,e_layer_2024-08-24_10-39-52/checkpoint_000000)
2024-08-24 10:40:14,827	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1cd0aa88 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.36556 â”‚
â”‚ time_total_s                             116.7745 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56094 â”‚
â”‚ train_loss                                0.60844 â”‚
â”‚ valid_loss                                1.56094 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=871033)[0m Updating learning rate to 2.5880814160946007e-05
[36m(_train_fn pid=871033)[0m saving checkpoint...
[36m(_train_fn pid=871033)[0m Validation loss decreased (1.5631 --> 1.5609).  Saving model state dict ...

Trial trial-5329edda started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5329edda config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17643 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00161 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=871895)[0m configuration
[36m(_train_fn pid=871895)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.17642767733305462, 'e_layers': 1, 'learning_rate': 0.0016084273485011801, 'd_ff': 1536}
[36m(_train_fn pid=871895)[0m Use GPU: cuda:0
[36m(_train_fn pid=871895)[0m train 7825
[36m(_train_fn pid=871895)[0m val 2161
[36m(_train_fn pid=871895)[0m start_epoch 0
[36m(_train_fn pid=871895)[0m max_epoch 8

Trial status: 190 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:39:58. Total running time: 3hr 18min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5329edda   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
185 more TERMINATED
[36m(_train_fn pid=871895)[0m 	iters: 100, epoch: 1 | loss: 0.8209986
[36m(_train_fn pid=871895)[0m 	speed: 0.0769s/iter; left time: 142.4710s
[36m(_train_fn pid=871895)[0m 	iters: 200, epoch: 1 | loss: 0.6434827
[36m(_train_fn pid=871895)[0m 	speed: 0.0700s/iter; left time: 122.6581s
[36m(_train_fn pid=871895)[0m Updating learning rate to 0.0016084273485011801
[36m(_train_fn pid=871895)[0m saving checkpoint...
[36m(_train_fn pid=871895)[0m Validation loss decreased (inf --> 1.8440).  Saving model state dict ...
[36m(_train_fn pid=871895)[0m Epoch: 1 cost time: 17.4980890750885
[36m(_train_fn pid=871895)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7821817 Vali Loss: 1.8440130 Best vali loss: 1.8440130
[36m(_train_fn pid=871895)[0m 	iters: 100, epoch: 2 | loss: 0.6923890
[36m(_train_fn pid=871895)[0m 	speed: 0.1228s/iter; left time: 197.6613s
[36m(_train_fn pid=871895)[0m 	iters: 200, epoch: 2 | loss: 0.7176556
[36m(_train_fn pid=871895)[0m 	speed: 0.0704s/iter; left time: 106.1672s
Trial status: 190 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:40:28. Total running time: 3hr 19min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5329edda   RUNNING           1            20.1155       0.782182        1.84401             1.84401 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=871895)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5329edda_191_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1764,e_layer_2024-08-24_10-39-52/checkpoint_000001)
[36m(_train_fn pid=871895)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5329edda_191_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1764,e_layer_2024-08-24_10-39-52/checkpoint_000002)
[36m(_train_fn pid=871895)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5329edda_191_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1764,e_layer_2024-08-24_10-39-52/checkpoint_000003)
[36m(_train_fn pid=871895)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5329edda_191_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1764,e_layer_2024-08-24_10-39-52/checkpoint_000004)
185 more TERMINATED
[36m(_train_fn pid=871895)[0m Updating learning rate to 0.0008042136742505901
[36m(_train_fn pid=871895)[0m saving checkpoint...
[36m(_train_fn pid=871895)[0m Validation loss decreased (1.8440 --> 1.6140).  Saving model state dict ...
[36m(_train_fn pid=871895)[0m Epoch: 2 cost time: 17.177897453308105
[36m(_train_fn pid=871895)[0m Epoch: 2, Steps: 244 | Train Loss: 0.9844139 Vali Loss: 1.6140456 Best vali loss: 1.6140456
[36m(_train_fn pid=871895)[0m 	iters: 100, epoch: 3 | loss: 0.6851904
[36m(_train_fn pid=871895)[0m 	speed: 0.1231s/iter; left time: 168.0667s
[36m(_train_fn pid=871895)[0m 	iters: 200, epoch: 3 | loss: 0.6432706
[36m(_train_fn pid=871895)[0m 	speed: 0.0703s/iter; left time: 88.9736s
[36m(_train_fn pid=871895)[0m Updating learning rate to 0.00040210683712529503
[36m(_train_fn pid=871895)[0m saving checkpoint...
[36m(_train_fn pid=871895)[0m Validation loss decreased (1.6140 --> 1.5884).  Saving model state dict ...
[36m(_train_fn pid=871895)[0m Epoch: 3 cost time: 17.165584564208984
[36m(_train_fn pid=871895)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6303521 Vali Loss: 1.5884287 Best vali loss: 1.5884287
Trial status: 190 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:40:59. Total running time: 3hr 19min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5329edda   RUNNING           3            58.792        0.630352        1.58843             1.58843 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
185 more TERMINATED
[36m(_train_fn pid=871895)[0m 	iters: 100, epoch: 4 | loss: 0.6368527
[36m(_train_fn pid=871895)[0m 	speed: 0.1230s/iter; left time: 137.9387s
[36m(_train_fn pid=871895)[0m 	iters: 200, epoch: 4 | loss: 0.6465164
[36m(_train_fn pid=871895)[0m 	speed: 0.0704s/iter; left time: 71.9251s
[36m(_train_fn pid=871895)[0m Updating learning rate to 0.00020105341856264751
[36m(_train_fn pid=871895)[0m saving checkpoint...
[36m(_train_fn pid=871895)[0m Validation loss decreased (1.5884 --> 1.5785).  Saving model state dict ...
[36m(_train_fn pid=871895)[0m Epoch: 4 cost time: 17.191831350326538
[36m(_train_fn pid=871895)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6217646 Vali Loss: 1.5784555 Best vali loss: 1.5784555
[36m(_train_fn pid=871895)[0m 	iters: 100, epoch: 5 | loss: 0.6105527
[36m(_train_fn pid=871895)[0m 	speed: 0.1233s/iter; left time: 108.1086s
[36m(_train_fn pid=871895)[0m 	iters: 200, epoch: 5 | loss: 0.5515097
[36m(_train_fn pid=871895)[0m 	speed: 0.0704s/iter; left time: 54.7027s
Trial status: 190 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:41:29. Total running time: 3hr 20min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-5329edda   RUNNING           4            78.1494       0.621765        1.57846             1.57846 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
185 more TERMINATED
[36m(_train_fn pid=871895)[0m Updating learning rate to 0.00010052670928132376
[36m(_train_fn pid=871895)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=871895)[0m saving checkpoint...
[36m(_train_fn pid=871895)[0m Epoch: 5 cost time: 17.190888166427612
[36m(_train_fn pid=871895)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6187418 Vali Loss: 1.5784883 Best vali loss: 1.5784555
[36m(_train_fn pid=871895)[0m 	iters: 100, epoch: 6 | loss: 0.5937334
[36m(_train_fn pid=871895)[0m 	speed: 0.1229s/iter; left time: 77.7821s
[36m(_train_fn pid=871895)[0m 	iters: 200, epoch: 6 | loss: 0.6024672
[36m(_train_fn pid=871895)[0m 	speed: 0.0704s/iter; left time: 37.5220s

Trial trial-5329edda completed after 6 iterations at 2024-08-24 10:41:51. Total running time: 3hr 20min 42s
[36m(_train_fn pid=871895)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-5329edda_191_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1764,e_layer_2024-08-24_10-39-52/checkpoint_000005)
2024-08-24 10:42:13,734	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=872754)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-67e82c1c_192_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1689,e_layer_2024-08-24_10-41-51/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-5329edda result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.34623 â”‚
â”‚ time_total_s                            116.82547 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.57335 â”‚
â”‚ train_loss                                0.61711 â”‚
â”‚ valid_loss                                1.57335 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=871895)[0m Updating learning rate to 5.026335464066188e-05
[36m(_train_fn pid=871895)[0m saving checkpoint...
[36m(_train_fn pid=871895)[0m Validation loss decreased (1.5785 --> 1.5733).  Saving model state dict ...

Trial trial-67e82c1c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-67e82c1c config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.16888 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00063 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=872754)[0m configuration
[36m(_train_fn pid=872754)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.16887755470526553, 'e_layers': 1, 'learning_rate': 0.0006298429225856741, 'd_ff': 1536}
[36m(_train_fn pid=872754)[0m Use GPU: cuda:0
[36m(_train_fn pid=872754)[0m train 7825
[36m(_train_fn pid=872754)[0m val 2161
[36m(_train_fn pid=872754)[0m start_epoch 0
[36m(_train_fn pid=872754)[0m max_epoch 8

Trial status: 191 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:41:59. Total running time: 3hr 20min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-67e82c1c   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
186 more TERMINATED
[36m(_train_fn pid=872754)[0m 	iters: 100, epoch: 1 | loss: 0.8477409
[36m(_train_fn pid=872754)[0m 	speed: 0.0766s/iter; left time: 141.9049s
[36m(_train_fn pid=872754)[0m 	iters: 200, epoch: 1 | loss: 0.6628455
[36m(_train_fn pid=872754)[0m 	speed: 0.0700s/iter; left time: 122.6911s
[36m(_train_fn pid=872754)[0m Updating learning rate to 0.0006298429225856741
[36m(_train_fn pid=872754)[0m saving checkpoint...
[36m(_train_fn pid=872754)[0m Validation loss decreased (inf --> 1.9267).  Saving model state dict ...
[36m(_train_fn pid=872754)[0m Epoch: 1 cost time: 17.464718103408813
[36m(_train_fn pid=872754)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8062827 Vali Loss: 1.9266579 Best vali loss: 1.9266579
[36m(_train_fn pid=872754)[0m 	iters: 100, epoch: 2 | loss: 0.6394606
[36m(_train_fn pid=872754)[0m 	speed: 0.1227s/iter; left time: 197.4231s
[36m(_train_fn pid=872754)[0m 	iters: 200, epoch: 2 | loss: 0.6935447
[36m(_train_fn pid=872754)[0m 	speed: 0.0702s/iter; left time: 106.0052s
Trial status: 191 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:42:29. Total running time: 3hr 21min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-67e82c1c   RUNNING           1            20.0465       0.806283        1.92666             1.92666 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=872754)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-67e82c1c_192_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1689,e_layer_2024-08-24_10-41-51/checkpoint_000001)
[36m(_train_fn pid=872754)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-67e82c1c_192_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1689,e_layer_2024-08-24_10-41-51/checkpoint_000002)
[36m(_train_fn pid=872754)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-67e82c1c_192_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1689,e_layer_2024-08-24_10-41-51/checkpoint_000003)
[36m(_train_fn pid=872754)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-67e82c1c_192_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1689,e_layer_2024-08-24_10-41-51/checkpoint_000004)
186 more TERMINATED
[36m(_train_fn pid=872754)[0m Updating learning rate to 0.00031492146129283706
[36m(_train_fn pid=872754)[0m saving checkpoint...
[36m(_train_fn pid=872754)[0m Validation loss decreased (1.9267 --> 1.5847).  Saving model state dict ...
[36m(_train_fn pid=872754)[0m Epoch: 2 cost time: 17.152668476104736
[36m(_train_fn pid=872754)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6672268 Vali Loss: 1.5847205 Best vali loss: 1.5847205
[36m(_train_fn pid=872754)[0m 	iters: 100, epoch: 3 | loss: 0.6678252
[36m(_train_fn pid=872754)[0m 	speed: 0.1230s/iter; left time: 167.9067s
[36m(_train_fn pid=872754)[0m 	iters: 200, epoch: 3 | loss: 0.6297466
[36m(_train_fn pid=872754)[0m 	speed: 0.0703s/iter; left time: 88.9641s
[36m(_train_fn pid=872754)[0m Updating learning rate to 0.00015746073064641853
[36m(_train_fn pid=872754)[0m saving checkpoint...
[36m(_train_fn pid=872754)[0m Validation loss decreased (1.5847 --> 1.5666).  Saving model state dict ...
[36m(_train_fn pid=872754)[0m Epoch: 3 cost time: 17.178688526153564
[36m(_train_fn pid=872754)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6155084 Vali Loss: 1.5665862 Best vali loss: 1.5665862
Trial status: 191 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:42:59. Total running time: 3hr 21min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-67e82c1c   RUNNING           3            58.6996       0.615508        1.56659             1.56659 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
186 more TERMINATED
[36m(_train_fn pid=872754)[0m 	iters: 100, epoch: 4 | loss: 0.6313393
[36m(_train_fn pid=872754)[0m 	speed: 0.1231s/iter; left time: 138.0079s
[36m(_train_fn pid=872754)[0m 	iters: 200, epoch: 4 | loss: 0.6349153
[36m(_train_fn pid=872754)[0m 	speed: 0.0703s/iter; left time: 71.8216s
[36m(_train_fn pid=872754)[0m Updating learning rate to 7.873036532320927e-05
[36m(_train_fn pid=872754)[0m saving checkpoint...
[36m(_train_fn pid=872754)[0m Validation loss decreased (1.5666 --> 1.5636).  Saving model state dict ...
[36m(_train_fn pid=872754)[0m Epoch: 4 cost time: 17.173128128051758
[36m(_train_fn pid=872754)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6115406 Vali Loss: 1.5635974 Best vali loss: 1.5635974
[36m(_train_fn pid=872754)[0m 	iters: 100, epoch: 5 | loss: 0.6051914
[36m(_train_fn pid=872754)[0m 	speed: 0.1231s/iter; left time: 108.0013s
[36m(_train_fn pid=872754)[0m 	iters: 200, epoch: 5 | loss: 0.5447372
[36m(_train_fn pid=872754)[0m 	speed: 0.0704s/iter; left time: 54.6668s
Trial status: 191 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:43:29. Total running time: 3hr 22min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-67e82c1c   RUNNING           4            78.0386       0.611541        1.5636              1.5636  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
186 more TERMINATED
[36m(_train_fn pid=872754)[0m Updating learning rate to 3.936518266160463e-05
[36m(_train_fn pid=872754)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=872754)[0m saving checkpoint...
[36m(_train_fn pid=872754)[0m Epoch: 5 cost time: 17.181052684783936
[36m(_train_fn pid=872754)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6098436 Vali Loss: 1.5687020 Best vali loss: 1.5635974
[36m(_train_fn pid=872754)[0m 	iters: 100, epoch: 6 | loss: 0.5822734
[36m(_train_fn pid=872754)[0m 	speed: 0.1227s/iter; left time: 77.6696s
[36m(_train_fn pid=872754)[0m 	iters: 200, epoch: 6 | loss: 0.5942882
[36m(_train_fn pid=872754)[0m 	speed: 0.0703s/iter; left time: 37.4648s

Trial trial-67e82c1c completed after 6 iterations at 2024-08-24 10:43:50. Total running time: 3hr 22min 41s
[36m(_train_fn pid=872754)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-67e82c1c_192_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1689,e_layer_2024-08-24_10-41-51/checkpoint_000005)
2024-08-24 10:44:12,757	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=873614)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-39ca9fa6_193_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1877,e_layer_2024-08-24_10-43-50/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-67e82c1c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.32883 â”‚
â”‚ time_total_s                            116.68319 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56149 â”‚
â”‚ train_loss                                 0.6091 â”‚
â”‚ valid_loss                                1.56149 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=872754)[0m Updating learning rate to 1.9682591330802316e-05
[36m(_train_fn pid=872754)[0m saving checkpoint...
[36m(_train_fn pid=872754)[0m Validation loss decreased (1.5636 --> 1.5615).  Saving model state dict ...

Trial trial-39ca9fa6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-39ca9fa6 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18773 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00205 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=873614)[0m configuration
[36m(_train_fn pid=873614)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18772511043987333, 'e_layers': 1, 'learning_rate': 0.002051200075545681, 'd_ff': 1536}
[36m(_train_fn pid=873614)[0m Use GPU: cuda:0
[36m(_train_fn pid=873614)[0m train 7825
[36m(_train_fn pid=873614)[0m val 2161
[36m(_train_fn pid=873614)[0m start_epoch 0
[36m(_train_fn pid=873614)[0m max_epoch 8

Trial status: 192 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:43:59. Total running time: 3hr 22min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-39ca9fa6   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
187 more TERMINATED
[36m(_train_fn pid=873614)[0m 	iters: 100, epoch: 1 | loss: 0.8150225
[36m(_train_fn pid=873614)[0m 	speed: 0.0765s/iter; left time: 141.7837s
[36m(_train_fn pid=873614)[0m 	iters: 200, epoch: 1 | loss: 0.6347241
[36m(_train_fn pid=873614)[0m 	speed: 0.0700s/iter; left time: 122.6894s
[36m(_train_fn pid=873614)[0m Updating learning rate to 0.002051200075545681
[36m(_train_fn pid=873614)[0m saving checkpoint...
[36m(_train_fn pid=873614)[0m Validation loss decreased (inf --> 1.7850).  Saving model state dict ...
[36m(_train_fn pid=873614)[0m Epoch: 1 cost time: 17.467822313308716
[36m(_train_fn pid=873614)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7751811 Vali Loss: 1.7850208 Best vali loss: 1.7850208
[36m(_train_fn pid=873614)[0m 	iters: 100, epoch: 2 | loss: 0.6657018
[36m(_train_fn pid=873614)[0m 	speed: 0.1227s/iter; left time: 197.4396s
[36m(_train_fn pid=873614)[0m 	iters: 200, epoch: 2 | loss: 0.7134277
[36m(_train_fn pid=873614)[0m 	speed: 0.0703s/iter; left time: 106.1008s
Trial status: 192 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:44:29. Total running time: 3hr 23min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-39ca9fa6   RUNNING           1            20.0444       0.775181        1.78502             1.78502 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=873614)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-39ca9fa6_193_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1877,e_layer_2024-08-24_10-43-50/checkpoint_000001)
[36m(_train_fn pid=873614)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-39ca9fa6_193_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1877,e_layer_2024-08-24_10-43-50/checkpoint_000002)
[36m(_train_fn pid=873614)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-39ca9fa6_193_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1877,e_layer_2024-08-24_10-43-50/checkpoint_000003)
[36m(_train_fn pid=873614)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-39ca9fa6_193_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1877,e_layer_2024-08-24_10-43-50/checkpoint_000004)
187 more TERMINATED
[36m(_train_fn pid=873614)[0m Updating learning rate to 0.0010256000377728404
[36m(_train_fn pid=873614)[0m saving checkpoint...
[36m(_train_fn pid=873614)[0m Validation loss decreased (1.7850 --> 1.6100).  Saving model state dict ...
[36m(_train_fn pid=873614)[0m Epoch: 2 cost time: 17.161852836608887
[36m(_train_fn pid=873614)[0m Epoch: 2, Steps: 244 | Train Loss: 0.9598566 Vali Loss: 1.6099874 Best vali loss: 1.6099874
[36m(_train_fn pid=873614)[0m 	iters: 100, epoch: 3 | loss: 0.6829360
[36m(_train_fn pid=873614)[0m 	speed: 0.1231s/iter; left time: 168.0830s
[36m(_train_fn pid=873614)[0m 	iters: 200, epoch: 3 | loss: 0.6404824
[36m(_train_fn pid=873614)[0m 	speed: 0.0704s/iter; left time: 89.0517s
[36m(_train_fn pid=873614)[0m Updating learning rate to 0.0005128000188864202
[36m(_train_fn pid=873614)[0m saving checkpoint...
[36m(_train_fn pid=873614)[0m Validation loss decreased (1.6100 --> 1.5822).  Saving model state dict ...
[36m(_train_fn pid=873614)[0m Epoch: 3 cost time: 17.184746503829956
[36m(_train_fn pid=873614)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6275732 Vali Loss: 1.5822449 Best vali loss: 1.5822449
[36m(_train_fn pid=873614)[0m 	iters: 100, epoch: 4 | loss: 0.6332721
[36m(_train_fn pid=873614)[0m 	speed: 0.1233s/iter; left time: 138.1936s
Trial status: 192 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:44:59. Total running time: 3hr 23min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-39ca9fa6   RUNNING           3            58.7298       0.627573        1.58224             1.58224 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
187 more TERMINATED
[36m(_train_fn pid=873614)[0m 	iters: 200, epoch: 4 | loss: 0.6435061
[36m(_train_fn pid=873614)[0m 	speed: 0.0705s/iter; left time: 71.9697s
[36m(_train_fn pid=873614)[0m Updating learning rate to 0.0002564000094432101
[36m(_train_fn pid=873614)[0m saving checkpoint...
[36m(_train_fn pid=873614)[0m Validation loss decreased (1.5822 --> 1.5755).  Saving model state dict ...
[36m(_train_fn pid=873614)[0m Epoch: 4 cost time: 17.20333957672119
[36m(_train_fn pid=873614)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6192115 Vali Loss: 1.5754703 Best vali loss: 1.5754703
[36m(_train_fn pid=873614)[0m 	iters: 100, epoch: 5 | loss: 0.6085634
[36m(_train_fn pid=873614)[0m 	speed: 0.1234s/iter; left time: 108.1920s
[36m(_train_fn pid=873614)[0m 	iters: 200, epoch: 5 | loss: 0.5481982
[36m(_train_fn pid=873614)[0m 	speed: 0.0705s/iter; left time: 54.7616s
Trial status: 192 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:45:29. Total running time: 3hr 24min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-39ca9fa6   RUNNING           4            78.0989       0.619212        1.57547             1.57547 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
187 more TERMINATED
[36m(_train_fn pid=873614)[0m Updating learning rate to 0.00012820000472160505
[36m(_train_fn pid=873614)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=873614)[0m saving checkpoint...
[36m(_train_fn pid=873614)[0m Epoch: 5 cost time: 17.212629318237305
[36m(_train_fn pid=873614)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6166805 Vali Loss: 1.5755291 Best vali loss: 1.5754703
[36m(_train_fn pid=873614)[0m 	iters: 100, epoch: 6 | loss: 0.5936478
[36m(_train_fn pid=873614)[0m 	speed: 0.1231s/iter; left time: 77.9212s
[36m(_train_fn pid=873614)[0m 	iters: 200, epoch: 6 | loss: 0.5989841
[36m(_train_fn pid=873614)[0m 	speed: 0.0705s/iter; left time: 37.5605s

Trial trial-39ca9fa6 completed after 6 iterations at 2024-08-24 10:45:49. Total running time: 3hr 24min 40s
[36m(_train_fn pid=873614)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-39ca9fa6_193_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1877,e_layer_2024-08-24_10-43-50/checkpoint_000005)
2024-08-24 10:46:11,769	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=874474)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e89bf2d_194_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-45-49/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-39ca9fa6 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                          19.3635 â”‚
â”‚ time_total_s                             116.8272 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.57002 â”‚
â”‚ train_loss                                0.61537 â”‚
â”‚ valid_loss                                1.57002 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=873614)[0m Updating learning rate to 6.410000236080253e-05
[36m(_train_fn pid=873614)[0m saving checkpoint...
[36m(_train_fn pid=873614)[0m Validation loss decreased (1.5755 --> 1.5700).  Saving model state dict ...

Trial trial-3e89bf2d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3e89bf2d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.1916 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0014 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=874474)[0m configuration
[36m(_train_fn pid=874474)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19159858883335246, 'e_layers': 1, 'learning_rate': 0.0014015877056577336, 'd_ff': 1536}
[36m(_train_fn pid=874474)[0m Use GPU: cuda:0
[36m(_train_fn pid=874474)[0m train 7825
[36m(_train_fn pid=874474)[0m val 2161
[36m(_train_fn pid=874474)[0m start_epoch 0
[36m(_train_fn pid=874474)[0m max_epoch 8

Trial status: 193 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:45:59. Total running time: 3hr 24min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e89bf2d   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
188 more TERMINATED
[36m(_train_fn pid=874474)[0m 	iters: 100, epoch: 1 | loss: 0.8265495
[36m(_train_fn pid=874474)[0m 	speed: 0.0766s/iter; left time: 141.9044s
[36m(_train_fn pid=874474)[0m 	iters: 200, epoch: 1 | loss: 0.6468529
[36m(_train_fn pid=874474)[0m 	speed: 0.0700s/iter; left time: 122.6232s
[36m(_train_fn pid=874474)[0m Updating learning rate to 0.0014015877056577336
[36m(_train_fn pid=874474)[0m saving checkpoint...
[36m(_train_fn pid=874474)[0m Validation loss decreased (inf --> 1.8750).  Saving model state dict ...
[36m(_train_fn pid=874474)[0m Epoch: 1 cost time: 17.475605964660645
[36m(_train_fn pid=874474)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7884836 Vali Loss: 1.8749672 Best vali loss: 1.8749672
[36m(_train_fn pid=874474)[0m 	iters: 100, epoch: 2 | loss: 0.6772401
[36m(_train_fn pid=874474)[0m 	speed: 0.1226s/iter; left time: 197.2108s
[36m(_train_fn pid=874474)[0m 	iters: 200, epoch: 2 | loss: 0.7042133
[36m(_train_fn pid=874474)[0m 	speed: 0.0700s/iter; left time: 105.6375s
Trial status: 193 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:46:29. Total running time: 3hr 25min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e89bf2d   RUNNING           1            20.0503       0.788484        1.87497             1.87497 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=874474)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e89bf2d_194_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-45-49/checkpoint_000001)
[36m(_train_fn pid=874474)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e89bf2d_194_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-45-49/checkpoint_000002)
[36m(_train_fn pid=874474)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e89bf2d_194_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-45-49/checkpoint_000003)
[36m(_train_fn pid=874474)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e89bf2d_194_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-45-49/checkpoint_000004)
188 more TERMINATED
[36m(_train_fn pid=874474)[0m Updating learning rate to 0.0007007938528288668
[36m(_train_fn pid=874474)[0m saving checkpoint...
[36m(_train_fn pid=874474)[0m Validation loss decreased (1.8750 --> 1.5855).  Saving model state dict ...
[36m(_train_fn pid=874474)[0m Epoch: 2 cost time: 17.10457134246826
[36m(_train_fn pid=874474)[0m Epoch: 2, Steps: 244 | Train Loss: 0.8925289 Vali Loss: 1.5854790 Best vali loss: 1.5854790
[36m(_train_fn pid=874474)[0m 	iters: 100, epoch: 3 | loss: 0.6749013
[36m(_train_fn pid=874474)[0m 	speed: 0.1230s/iter; left time: 167.9574s
[36m(_train_fn pid=874474)[0m 	iters: 200, epoch: 3 | loss: 0.6345811
[36m(_train_fn pid=874474)[0m 	speed: 0.0704s/iter; left time: 89.0798s
[36m(_train_fn pid=874474)[0m Updating learning rate to 0.0003503969264144334
[36m(_train_fn pid=874474)[0m saving checkpoint...
[36m(_train_fn pid=874474)[0m Validation loss decreased (1.5855 --> 1.5740).  Saving model state dict ...
[36m(_train_fn pid=874474)[0m Epoch: 3 cost time: 17.191765546798706
[36m(_train_fn pid=874474)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6207389 Vali Loss: 1.5740215 Best vali loss: 1.5740215
[36m(_train_fn pid=874474)[0m 	iters: 100, epoch: 4 | loss: 0.6350002
[36m(_train_fn pid=874474)[0m 	speed: 0.1233s/iter; left time: 138.1995s
Trial status: 193 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:46:59. Total running time: 3hr 25min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e89bf2d   RUNNING           3            58.688        0.620739        1.57402             1.57402 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
188 more TERMINATED
[36m(_train_fn pid=874474)[0m 	iters: 200, epoch: 4 | loss: 0.6415816
[36m(_train_fn pid=874474)[0m 	speed: 0.0704s/iter; left time: 71.9029s
[36m(_train_fn pid=874474)[0m Updating learning rate to 0.0001751984632072167
[36m(_train_fn pid=874474)[0m saving checkpoint...
[36m(_train_fn pid=874474)[0m Validation loss decreased (1.5740 --> 1.5710).  Saving model state dict ...
[36m(_train_fn pid=874474)[0m Epoch: 4 cost time: 17.192436456680298
[36m(_train_fn pid=874474)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6160637 Vali Loss: 1.5709532 Best vali loss: 1.5709532
[36m(_train_fn pid=874474)[0m 	iters: 100, epoch: 5 | loss: 0.6074121
[36m(_train_fn pid=874474)[0m 	speed: 0.1232s/iter; left time: 108.0419s
[36m(_train_fn pid=874474)[0m 	iters: 200, epoch: 5 | loss: 0.5495695
[36m(_train_fn pid=874474)[0m 	speed: 0.0704s/iter; left time: 54.7324s
[36m(_train_fn pid=874474)[0m Updating learning rate to 8.759923160360835e-05
[36m(_train_fn pid=874474)[0m saving checkpoint...
[36m(_train_fn pid=874474)[0m Validation loss decreased (1.5710 --> 1.5694).  Saving model state dict ...
[36m(_train_fn pid=874474)[0m Epoch: 5 cost time: 17.19498634338379
[36m(_train_fn pid=874474)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6143981 Vali Loss: 1.5693622 Best vali loss: 1.5693622
Trial status: 193 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:47:29. Total running time: 3hr 26min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3e89bf2d   RUNNING           5            97.404        0.614398        1.56936             1.56936 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
188 more TERMINATED
[36m(_train_fn pid=874474)[0m 	iters: 100, epoch: 6 | loss: 0.5884156
[36m(_train_fn pid=874474)[0m 	speed: 0.1233s/iter; left time: 78.0341s
[36m(_train_fn pid=874474)[0m 	iters: 200, epoch: 6 | loss: 0.5996981
[36m(_train_fn pid=874474)[0m 	speed: 0.0704s/iter; left time: 37.5446s

Trial trial-3e89bf2d completed after 6 iterations at 2024-08-24 10:47:48. Total running time: 3hr 26min 39s
[36m(_train_fn pid=874474)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3e89bf2d_194_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1916,e_layer_2024-08-24_10-45-49/checkpoint_000005)
[36m(_train_fn pid=875331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c67079c3_195_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1952,e_layer_2024-08-24_10-47-48/checkpoint_000000)
2024-08-24 10:48:00,776	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=875331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c67079c3_195_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1952,e_layer_2024-08-24_10-47-48/checkpoint_000001)
2024-08-24 10:48:05,396	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=875331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c67079c3_195_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1952,e_layer_2024-08-24_10-47-48/checkpoint_000002)
2024-08-24 10:48:09,993	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=875331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c67079c3_195_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1952,e_layer_2024-08-24_10-47-48/checkpoint_000003)
[36m(_train_fn pid=875331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c67079c3_195_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1952,e_layer_2024-08-24_10-47-48/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3e89bf2d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.36337 â”‚
â”‚ time_total_s                            116.76739 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56882 â”‚
â”‚ train_loss                                 0.6136 â”‚
â”‚ valid_loss                                1.56882 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=874474)[0m Updating learning rate to 4.3799615801804174e-05
[36m(_train_fn pid=874474)[0m saving checkpoint...
[36m(_train_fn pid=874474)[0m Validation loss decreased (1.5694 --> 1.5688).  Saving model state dict ...

Trial trial-c67079c3 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c67079c3 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19519 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00074 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=875331)[0m configuration
[36m(_train_fn pid=875331)[0m {'batch_size': 32, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19519173235757464, 'e_layers': 1, 'learning_rate': 0.0007373618174381304, 'd_ff': 384}
[36m(_train_fn pid=875331)[0m Use GPU: cuda:0
[36m(_train_fn pid=875331)[0m train 7825
[36m(_train_fn pid=875331)[0m val 2161
[36m(_train_fn pid=875331)[0m start_epoch 0
[36m(_train_fn pid=875331)[0m max_epoch 8
[36m(_train_fn pid=875331)[0m 	iters: 100, epoch: 1 | loss: 0.8505458
[36m(_train_fn pid=875331)[0m 	speed: 0.0233s/iter; left time: 43.2322s
[36m(_train_fn pid=875331)[0m 	iters: 200, epoch: 1 | loss: 0.8639046
[36m(_train_fn pid=875331)[0m 	speed: 0.0162s/iter; left time: 28.4463s
[36m(_train_fn pid=875331)[0m Updating learning rate to 0.0007373618174381304
[36m(_train_fn pid=875331)[0m saving checkpoint...
[36m(_train_fn pid=875331)[0m Validation loss decreased (inf --> 1.9354).  Saving model state dict ...
[36m(_train_fn pid=875331)[0m Epoch: 1 cost time: 4.416146516799927
[36m(_train_fn pid=875331)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8390636 Vali Loss: 1.9353901 Best vali loss: 1.9353901
[36m(_train_fn pid=875331)[0m 	iters: 100, epoch: 2 | loss: 0.6668588
[36m(_train_fn pid=875331)[0m 	speed: 0.0299s/iter; left time: 48.1300s
[36m(_train_fn pid=875331)[0m 	iters: 200, epoch: 2 | loss: 0.6923973
[36m(_train_fn pid=875331)[0m 	speed: 0.0163s/iter; left time: 24.6443s

Trial status: 194 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:47:59. Total running time: 3hr 26min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c67079c3   RUNNING           1            5.44026       0.839064        1.93539             1.93539 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
189 more TERMINATED
[36m(_train_fn pid=875331)[0m Updating learning rate to 0.0003686809087190652
[36m(_train_fn pid=875331)[0m saving checkpoint...
[36m(_train_fn pid=875331)[0m Validation loss decreased (1.9354 --> 1.5733).  Saving model state dict ...
[36m(_train_fn pid=875331)[0m Epoch: 2 cost time: 4.020251750946045
[36m(_train_fn pid=875331)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6495411 Vali Loss: 1.5732598 Best vali loss: 1.5732598
[36m(_train_fn pid=875331)[0m 	iters: 100, epoch: 3 | loss: 0.5815147
[36m(_train_fn pid=875331)[0m 	speed: 0.0300s/iter; left time: 41.0155s
[36m(_train_fn pid=875331)[0m 	iters: 200, epoch: 3 | loss: 0.5349380
[36m(_train_fn pid=875331)[0m 	speed: 0.0163s/iter; left time: 20.6110s
[36m(_train_fn pid=875331)[0m Updating learning rate to 0.0001843404543595326
[36m(_train_fn pid=875331)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=875331)[0m saving checkpoint...
[36m(_train_fn pid=875331)[0m Epoch: 3 cost time: 4.018294811248779
[36m(_train_fn pid=875331)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6147780 Vali Loss: 1.5748397 Best vali loss: 1.5732598
[36m(_train_fn pid=875331)[0m 	iters: 100, epoch: 4 | loss: 0.6756998
[36m(_train_fn pid=875331)[0m 	speed: 0.0297s/iter; left time: 33.2915s
[36m(_train_fn pid=875331)[0m 	iters: 200, epoch: 4 | loss: 0.5460581
[36m(_train_fn pid=875331)[0m 	speed: 0.0162s/iter; left time: 16.5875s
[36m(_train_fn pid=875331)[0m Updating learning rate to 9.21702271797663e-05
[36m(_train_fn pid=875331)[0m saving checkpoint...
[36m(_train_fn pid=875331)[0m Validation loss decreased (1.5733 --> 1.5726).  Saving model state dict ...
[36m(_train_fn pid=875331)[0m Epoch: 4 cost time: 3.998539447784424
[36m(_train_fn pid=875331)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6108177 Vali Loss: 1.5725969 Best vali loss: 1.5725969
[36m(_train_fn pid=875331)[0m 	iters: 100, epoch: 5 | loss: 0.5462546
[36m(_train_fn pid=875331)[0m 	speed: 0.0297s/iter; left time: 26.0797s
[36m(_train_fn pid=875331)[0m 	iters: 200, epoch: 5 | loss: 0.6665048
[36m(_train_fn pid=875331)[0m 	speed: 0.0162s/iter; left time: 12.5879s
[36m(_train_fn pid=875331)[0m Updating learning rate to 4.608511358988315e-05
2024-08-24 10:48:14,580	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 10:48:19,164	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=875331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c67079c3_195_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1952,e_layer_2024-08-24_10-47-48/checkpoint_000005)
2024-08-24 10:48:23,801	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=875331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c67079c3_195_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1952,e_layer_2024-08-24_10-47-48/checkpoint_000006)
2024-08-24 10:48:28,400	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=875331)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c67079c3_195_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1952,e_layer_2024-08-24_10-47-48/checkpoint_000007)
2024-08-24 10:48:50,800	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=876101)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce472cf0_196_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1624,e_layer_2024-08-24_10-48-28/checkpoint_000000)
[36m(_train_fn pid=875331)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=875331)[0m saving checkpoint...
[36m(_train_fn pid=875331)[0m Epoch: 5 cost time: 3.992929697036743
[36m(_train_fn pid=875331)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6085684 Vali Loss: 1.5735254 Best vali loss: 1.5725969
[36m(_train_fn pid=875331)[0m 	iters: 100, epoch: 6 | loss: 0.6004729
[36m(_train_fn pid=875331)[0m 	speed: 0.0296s/iter; left time: 18.7650s
[36m(_train_fn pid=875331)[0m 	iters: 200, epoch: 6 | loss: 0.5678970
[36m(_train_fn pid=875331)[0m 	speed: 0.0162s/iter; left time: 8.6506s
[36m(_train_fn pid=875331)[0m Updating learning rate to 2.3042556794941575e-05
[36m(_train_fn pid=875331)[0m saving checkpoint...
[36m(_train_fn pid=875331)[0m Validation loss decreased (1.5726 --> 1.5719).  Saving model state dict ...
[36m(_train_fn pid=875331)[0m Epoch: 6 cost time: 3.994206428527832
[36m(_train_fn pid=875331)[0m Epoch: 6, Steps: 244 | Train Loss: 0.6071853 Vali Loss: 1.5718603 Best vali loss: 1.5718603
[36m(_train_fn pid=875331)[0m 	iters: 100, epoch: 7 | loss: 0.6913573
[36m(_train_fn pid=875331)[0m 	speed: 0.0298s/iter; left time: 11.5901s
[36m(_train_fn pid=875331)[0m 	iters: 200, epoch: 7 | loss: 0.6211216
[36m(_train_fn pid=875331)[0m 	speed: 0.0163s/iter; left time: 4.7182s
[36m(_train_fn pid=875331)[0m Updating learning rate to 1.1521278397470787e-05
[36m(_train_fn pid=875331)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=875331)[0m saving checkpoint...
[36m(_train_fn pid=875331)[0m Epoch: 7 cost time: 4.030208587646484
[36m(_train_fn pid=875331)[0m Epoch: 7, Steps: 244 | Train Loss: 0.6064967 Vali Loss: 1.5728890 Best vali loss: 1.5718603
[36m(_train_fn pid=875331)[0m 	iters: 100, epoch: 8 | loss: 0.6521958
[36m(_train_fn pid=875331)[0m 	speed: 0.0299s/iter; left time: 4.3330s
[36m(_train_fn pid=875331)[0m 	iters: 200, epoch: 8 | loss: 0.5901003
[36m(_train_fn pid=875331)[0m 	speed: 0.0163s/iter; left time: 0.7322s

Trial trial-c67079c3 completed after 8 iterations at 2024-08-24 10:48:28. Total running time: 3hr 27min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c67079c3 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          4.60495 â”‚
â”‚ time_total_s                             37.67707 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.57186 â”‚
â”‚ train_loss                                0.60586 â”‚
â”‚ valid_loss                                1.57423 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=875331)[0m Updating learning rate to 5.760639198735394e-06
[36m(_train_fn pid=875331)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=875331)[0m saving checkpoint...
[36m(_train_fn pid=875331)[0m Epoch: 8 cost time: 4.001800060272217
[36m(_train_fn pid=875331)[0m Epoch: 8, Steps: 244 | Train Loss: 0.6058554 Vali Loss: 1.5742296 Best vali loss: 1.5718603

Trial status: 195 TERMINATED | 1 PENDING
Current time: 2024-08-24 10:48:29. Total running time: 3hr 27min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-ce472cf0   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
190 more TERMINATED

Trial trial-ce472cf0 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ce472cf0 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.16238 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00069 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=876101)[0m configuration
[36m(_train_fn pid=876101)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.16238191883401693, 'e_layers': 1, 'learning_rate': 0.0006868362229201992, 'd_ff': 1536}
[36m(_train_fn pid=876101)[0m Use GPU: cuda:0
[36m(_train_fn pid=876101)[0m train 7825
[36m(_train_fn pid=876101)[0m val 2161
[36m(_train_fn pid=876101)[0m start_epoch 0
[36m(_train_fn pid=876101)[0m max_epoch 8
[36m(_train_fn pid=876101)[0m 	iters: 100, epoch: 1 | loss: 0.8441642
[36m(_train_fn pid=876101)[0m 	speed: 0.0767s/iter; left time: 142.1816s
[36m(_train_fn pid=876101)[0m 	iters: 200, epoch: 1 | loss: 0.6605528
[36m(_train_fn pid=876101)[0m 	speed: 0.0701s/iter; left time: 122.8406s
[36m(_train_fn pid=876101)[0m Updating learning rate to 0.0006868362229201992
[36m(_train_fn pid=876101)[0m saving checkpoint...
[36m(_train_fn pid=876101)[0m Validation loss decreased (inf --> 1.9237).  Saving model state dict ...
[36m(_train_fn pid=876101)[0m Epoch: 1 cost time: 17.50588369369507
[36m(_train_fn pid=876101)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8025883 Vali Loss: 1.9237396 Best vali loss: 1.9237396
[36m(_train_fn pid=876101)[0m 	iters: 100, epoch: 2 | loss: 0.6419533
[36m(_train_fn pid=876101)[0m 	speed: 0.1230s/iter; left time: 197.9648s

Trial status: 195 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:48:59. Total running time: 3hr 27min 50s
[36m(_train_fn pid=876101)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce472cf0_196_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1624,e_layer_2024-08-24_10-48-28/checkpoint_000001)
[36m(_train_fn pid=876101)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce472cf0_196_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1624,e_layer_2024-08-24_10-48-28/checkpoint_000002)
[36m(_train_fn pid=876101)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce472cf0_196_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1624,e_layer_2024-08-24_10-48-28/checkpoint_000003)
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ce472cf0   RUNNING           1            20.0852       0.802588        1.92374             1.92374 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
190 more TERMINATED
[36m(_train_fn pid=876101)[0m 	iters: 200, epoch: 2 | loss: 0.6947618
[36m(_train_fn pid=876101)[0m 	speed: 0.0704s/iter; left time: 106.2976s
[36m(_train_fn pid=876101)[0m Updating learning rate to 0.0003434181114600996
[36m(_train_fn pid=876101)[0m saving checkpoint...
[36m(_train_fn pid=876101)[0m Validation loss decreased (1.9237 --> 1.5701).  Saving model state dict ...
[36m(_train_fn pid=876101)[0m Epoch: 2 cost time: 17.195047616958618
[36m(_train_fn pid=876101)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6769580 Vali Loss: 1.5701138 Best vali loss: 1.5701138
[36m(_train_fn pid=876101)[0m 	iters: 100, epoch: 3 | loss: 0.6666141
[36m(_train_fn pid=876101)[0m 	speed: 0.1234s/iter; left time: 168.3887s
[36m(_train_fn pid=876101)[0m 	iters: 200, epoch: 3 | loss: 0.6287688
[36m(_train_fn pid=876101)[0m 	speed: 0.0706s/iter; left time: 89.2583s
[36m(_train_fn pid=876101)[0m Updating learning rate to 0.0001717090557300498
[36m(_train_fn pid=876101)[0m saving checkpoint...
[36m(_train_fn pid=876101)[0m Validation loss decreased (1.5701 --> 1.5664).  Saving model state dict ...
[36m(_train_fn pid=876101)[0m Epoch: 3 cost time: 17.21862769126892
[36m(_train_fn pid=876101)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6157724 Vali Loss: 1.5663902 Best vali loss: 1.5663902
Trial status: 195 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:49:29. Total running time: 3hr 28min 20s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ce472cf0   RUNNING           3            58.8372       0.615772        1.56639             1.56639 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
190 more TERMINATED
[36m(_train_fn pid=876101)[0m 	iters: 100, epoch: 4 | loss: 0.6318966
[36m(_train_fn pid=876101)[0m 	speed: 0.1235s/iter; left time: 138.3980s
[36m(_train_fn pid=876101)[0m 	iters: 200, epoch: 4 | loss: 0.6352960
[36m(_train_fn pid=876101)[0m 	speed: 0.0706s/iter; left time: 72.0514s
[36m(_train_fn pid=876101)[0m Updating learning rate to 8.58545278650249e-05
[36m(_train_fn pid=876101)[0m saving checkpoint...
[36m(_train_fn pid=876101)[0m Validation loss decreased (1.5664 --> 1.5644).  Saving model state dict ...
[36m(_train_fn pid=876101)[0m Epoch: 4 cost time: 17.23027729988098
[36m(_train_fn pid=876101)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6112256 Vali Loss: 1.5643845 Best vali loss: 1.5643845
[36m(_train_fn pid=876101)[0m 	iters: 100, epoch: 5 | loss: 0.6047807
[36m(_train_fn pid=876101)[0m 	speed: 0.1235s/iter; left time: 108.2877s
Trial status: 195 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:49:59. Total running time: 3hr 28min 50s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=876101)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce472cf0_196_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1624,e_layer_2024-08-24_10-48-28/checkpoint_000004)
[36m(_train_fn pid=876101)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ce472cf0_196_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1624,e_layer_2024-08-24_10-48-28/checkpoint_000005)
2024-08-24 10:50:49,766	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ce472cf0   RUNNING           4            78.2342       0.611226        1.56438             1.56438 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
190 more TERMINATED
[36m(_train_fn pid=876101)[0m 	iters: 200, epoch: 5 | loss: 0.5440872
[36m(_train_fn pid=876101)[0m 	speed: 0.0706s/iter; left time: 54.8349s
[36m(_train_fn pid=876101)[0m Updating learning rate to 4.292726393251245e-05
[36m(_train_fn pid=876101)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=876101)[0m saving checkpoint...
[36m(_train_fn pid=876101)[0m Epoch: 5 cost time: 17.23711133003235
[36m(_train_fn pid=876101)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6094104 Vali Loss: 1.5706471 Best vali loss: 1.5643845
[36m(_train_fn pid=876101)[0m 	iters: 100, epoch: 6 | loss: 0.5824024
[36m(_train_fn pid=876101)[0m 	speed: 0.1231s/iter; left time: 77.9032s
[36m(_train_fn pid=876101)[0m 	iters: 200, epoch: 6 | loss: 0.5934148
[36m(_train_fn pid=876101)[0m 	speed: 0.0704s/iter; left time: 37.5410s

Trial trial-ce472cf0 completed after 6 iterations at 2024-08-24 10:50:27. Total running time: 3hr 29min 18s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ce472cf0 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.35448 â”‚
â”‚ time_total_s                            116.97478 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56084 â”‚
â”‚ train_loss                                0.60869 â”‚
â”‚ valid_loss                                1.56084 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=876101)[0m Updating learning rate to 2.1463631966256227e-05
[36m(_train_fn pid=876101)[0m saving checkpoint...
[36m(_train_fn pid=876101)[0m Validation loss decreased (1.5644 --> 1.5608).  Saving model state dict ...

Trial trial-e89050e2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e89050e2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18449 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00127 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 196 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:50:29. Total running time: 3hr 29min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e89050e2   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
191 more TERMINATED
[36m(_train_fn pid=876958)[0m configuration
[36m(_train_fn pid=876958)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1844854466165716, 'e_layers': 1, 'learning_rate': 0.0012741039448970943, 'd_ff': 1536}
[36m(_train_fn pid=876958)[0m Use GPU: cuda:0
[36m(_train_fn pid=876958)[0m train 7825
[36m(_train_fn pid=876958)[0m val 2161
[36m(_train_fn pid=876958)[0m start_epoch 0
[36m(_train_fn pid=876958)[0m max_epoch 8
[36m(_train_fn pid=876958)[0m 	iters: 100, epoch: 1 | loss: 0.8297359
[36m(_train_fn pid=876958)[0m 	speed: 0.0766s/iter; left time: 142.0253s
[36m(_train_fn pid=876958)[0m 	iters: 200, epoch: 1 | loss: 0.6483860
[36m(_train_fn pid=876958)[0m 	speed: 0.0699s/iter; left time: 122.5296s
[36m(_train_fn pid=876958)[0m Updating learning rate to 0.0012741039448970943
[36m(_train_fn pid=876958)[0m saving checkpoint...
[36m(_train_fn pid=876958)[0m Validation loss decreased (inf --> 1.8876).  Saving model state dict ...
[36m(_train_fn pid=876958)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e89050e2_197_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1845,e_layer_2024-08-24_10-50-27/checkpoint_000000)
[36m(_train_fn pid=876958)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e89050e2_197_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1845,e_layer_2024-08-24_10-50-27/checkpoint_000001)
[36m(_train_fn pid=876958)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e89050e2_197_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1845,e_layer_2024-08-24_10-50-27/checkpoint_000002)
[36m(_train_fn pid=876958)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e89050e2_197_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1845,e_layer_2024-08-24_10-50-27/checkpoint_000003)
[36m(_train_fn pid=876958)[0m Epoch: 1 cost time: 17.4720139503479
[36m(_train_fn pid=876958)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7901218 Vali Loss: 1.8876125 Best vali loss: 1.8876125
[36m(_train_fn pid=876958)[0m 	iters: 100, epoch: 2 | loss: 0.6793504
[36m(_train_fn pid=876958)[0m 	speed: 0.1225s/iter; left time: 197.0846s
Trial status: 196 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:50:59. Total running time: 3hr 29min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e89050e2   RUNNING           1            20.0431       0.790122        1.88761             1.88761 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
191 more TERMINATED
[36m(_train_fn pid=876958)[0m 	iters: 200, epoch: 2 | loss: 0.7083928
[36m(_train_fn pid=876958)[0m 	speed: 0.0700s/iter; left time: 105.5758s
[36m(_train_fn pid=876958)[0m Updating learning rate to 0.0006370519724485472
[36m(_train_fn pid=876958)[0m saving checkpoint...
[36m(_train_fn pid=876958)[0m Validation loss decreased (1.8876 --> 1.5868).  Saving model state dict ...
[36m(_train_fn pid=876958)[0m Epoch: 2 cost time: 17.087199687957764
[36m(_train_fn pid=876958)[0m Epoch: 2, Steps: 244 | Train Loss: 0.8095583 Vali Loss: 1.5867551 Best vali loss: 1.5867551
[36m(_train_fn pid=876958)[0m 	iters: 100, epoch: 3 | loss: 0.6739934
[36m(_train_fn pid=876958)[0m 	speed: 0.1227s/iter; left time: 167.5187s
[36m(_train_fn pid=876958)[0m 	iters: 200, epoch: 3 | loss: 0.6365482
[36m(_train_fn pid=876958)[0m 	speed: 0.0702s/iter; left time: 88.7454s
[36m(_train_fn pid=876958)[0m Updating learning rate to 0.0003185259862242736
[36m(_train_fn pid=876958)[0m saving checkpoint...
[36m(_train_fn pid=876958)[0m Validation loss decreased (1.5868 --> 1.5716).  Saving model state dict ...
[36m(_train_fn pid=876958)[0m Epoch: 3 cost time: 17.131921529769897
[36m(_train_fn pid=876958)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6207169 Vali Loss: 1.5715524 Best vali loss: 1.5715524
Trial status: 196 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:51:29. Total running time: 3hr 30min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e89050e2   RUNNING           3            58.586        0.620717        1.57155             1.57155 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
191 more TERMINATED
[36m(_train_fn pid=876958)[0m 	iters: 100, epoch: 4 | loss: 0.6347514
[36m(_train_fn pid=876958)[0m 	speed: 0.1229s/iter; left time: 137.7726s
[36m(_train_fn pid=876958)[0m 	iters: 200, epoch: 4 | loss: 0.6401630
[36m(_train_fn pid=876958)[0m 	speed: 0.0702s/iter; left time: 71.7078s
[36m(_train_fn pid=876958)[0m Updating learning rate to 0.0001592629931121368
[36m(_train_fn pid=876958)[0m saving checkpoint...
[36m(_train_fn pid=876958)[0m Validation loss decreased (1.5716 --> 1.5677).  Saving model state dict ...
[36m(_train_fn pid=876958)[0m Epoch: 4 cost time: 17.146544933319092
[36m(_train_fn pid=876958)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6154586 Vali Loss: 1.5677451 Best vali loss: 1.5677451
[36m(_train_fn pid=876958)[0m 	iters: 100, epoch: 5 | loss: 0.6062782
[36m(_train_fn pid=876958)[0m 	speed: 0.1230s/iter; left time: 107.8325s
Trial status: 196 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:51:59. Total running time: 3hr 30min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=876958)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e89050e2_197_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1845,e_layer_2024-08-24_10-50-27/checkpoint_000004)
[36m(_train_fn pid=876958)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e89050e2_197_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1845,e_layer_2024-08-24_10-50-27/checkpoint_000005)
[36m(_train_fn pid=877820)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ad9f9ee7_198_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1893,e_layers_2024-08-24_10-52-26/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e89050e2   RUNNING           4            77.8931       0.615459        1.56775             1.56775 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
191 more TERMINATED
[36m(_train_fn pid=876958)[0m 	iters: 200, epoch: 5 | loss: 0.5474437
[36m(_train_fn pid=876958)[0m 	speed: 0.0703s/iter; left time: 54.5998s
[36m(_train_fn pid=876958)[0m Updating learning rate to 7.96314965560684e-05
[36m(_train_fn pid=876958)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=876958)[0m saving checkpoint...
[36m(_train_fn pid=876958)[0m Epoch: 5 cost time: 17.16052770614624
[36m(_train_fn pid=876958)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6137037 Vali Loss: 1.5680482 Best vali loss: 1.5677451
[36m(_train_fn pid=876958)[0m 	iters: 100, epoch: 6 | loss: 0.5896114
[36m(_train_fn pid=876958)[0m 	speed: 0.1228s/iter; left time: 77.7409s
[36m(_train_fn pid=876958)[0m 	iters: 200, epoch: 6 | loss: 0.5989777
[36m(_train_fn pid=876958)[0m 	speed: 0.0703s/iter; left time: 37.4941s
[36m(_train_fn pid=876958)[0m Updating learning rate to 3.98157482780342e-05
[36m(_train_fn pid=876958)[0m saving checkpoint...
[36m(_train_fn pid=876958)[0m Validation loss decreased (1.5677 --> 1.5655).  Saving model state dict ...

Trial trial-e89050e2 completed after 6 iterations at 2024-08-24 10:52:26. Total running time: 3hr 31min 17s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e89050e2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.34331 â”‚
â”‚ time_total_s                            116.54046 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56555 â”‚
â”‚ train_loss                                0.61275 â”‚
â”‚ valid_loss                                1.56555 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-ad9f9ee7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ad9f9ee7 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18933 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                        0.001 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=877820)[0m configuration
[36m(_train_fn pid=877820)[0m {'batch_size': 32, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18933198384643188, 'e_layers': 1, 'learning_rate': 0.0009984560293170798, 'd_ff': 48}
[36m(_train_fn pid=877820)[0m Use GPU: cuda:0
[36m(_train_fn pid=877820)[0m train 7825
[36m(_train_fn pid=877820)[0m val 2161
[36m(_train_fn pid=877820)[0m start_epoch 0
[36m(_train_fn pid=877820)[0m max_epoch 8

Trial status: 197 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:52:29. Total running time: 3hr 31min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ad9f9ee7   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
192 more TERMINATED
[36m(_train_fn pid=877820)[0m 	iters: 100, epoch: 1 | loss: 1.0503621
[36m(_train_fn pid=877820)[0m 	speed: 0.0137s/iter; left time: 25.4061s
[36m(_train_fn pid=877820)[0m 	iters: 200, epoch: 1 | loss: 1.0582881
[36m(_train_fn pid=877820)[0m 	speed: 0.0066s/iter; left time: 11.6056s
[36m(_train_fn pid=877820)[0m Validation loss decreased (inf --> 2.3354).  Saving model state dict ...
[36m(_train_fn pid=877820)[0m Epoch: 1 cost time: 2.0629022121429443
2024-08-24 10:52:33,396	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=877820)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ad9f9ee7_198_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1893,e_layers_2024-08-24_10-52-26/checkpoint_000001)
2024-08-24 10:52:35,325	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=877820)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ad9f9ee7_198_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1893,e_layers_2024-08-24_10-52-26/checkpoint_000002)
2024-08-24 10:52:37,271	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=877820)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ad9f9ee7_198_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1893,e_layers_2024-08-24_10-52-26/checkpoint_000003)
2024-08-24 10:52:39,173	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=877820)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ad9f9ee7_198_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1893,e_layers_2024-08-24_10-52-26/checkpoint_000004)
[36m(_train_fn pid=877820)[0m Epoch: 1, Steps: 244 | Train Loss: 1.1216001 Vali Loss: 2.3354078 Best vali loss: 2.3354078
[36m(_train_fn pid=877820)[0m Updating learning rate to 0.0009984560293170798
[36m(_train_fn pid=877820)[0m saving checkpoint...
[36m(_train_fn pid=877820)[0m 	iters: 100, epoch: 2 | loss: 0.5582643
[36m(_train_fn pid=877820)[0m 	speed: 0.0126s/iter; left time: 20.2073s
[36m(_train_fn pid=877820)[0m 	iters: 200, epoch: 2 | loss: 0.5888193
[36m(_train_fn pid=877820)[0m 	speed: 0.0067s/iter; left time: 10.0396s
[36m(_train_fn pid=877820)[0m Updating learning rate to 0.0004992280146585399
[36m(_train_fn pid=877820)[0m saving checkpoint...
[36m(_train_fn pid=877820)[0m Validation loss decreased (2.3354 --> 1.5886).  Saving model state dict ...
[36m(_train_fn pid=877820)[0m Epoch: 2 cost time: 1.6677792072296143
[36m(_train_fn pid=877820)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6707075 Vali Loss: 1.5886241 Best vali loss: 1.5886241
[36m(_train_fn pid=877820)[0m 	iters: 100, epoch: 3 | loss: 0.6230242
[36m(_train_fn pid=877820)[0m 	speed: 0.0127s/iter; left time: 17.2789s
[36m(_train_fn pid=877820)[0m 	iters: 200, epoch: 3 | loss: 0.5957230
[36m(_train_fn pid=877820)[0m 	speed: 0.0068s/iter; left time: 8.5592s
[36m(_train_fn pid=877820)[0m Updating learning rate to 0.00024961400732926995
[36m(_train_fn pid=877820)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=877820)[0m saving checkpoint...
[36m(_train_fn pid=877820)[0m Epoch: 3 cost time: 1.674787998199463
[36m(_train_fn pid=877820)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6097054 Vali Loss: 1.5998641 Best vali loss: 1.5886241
[36m(_train_fn pid=877820)[0m 	iters: 100, epoch: 4 | loss: 0.6089454
[36m(_train_fn pid=877820)[0m 	speed: 0.0125s/iter; left time: 14.0528s
[36m(_train_fn pid=877820)[0m 	iters: 200, epoch: 4 | loss: 0.5238536
[36m(_train_fn pid=877820)[0m 	speed: 0.0067s/iter; left time: 6.8058s
[36m(_train_fn pid=877820)[0m Updating learning rate to 0.00012480700366463497
[36m(_train_fn pid=877820)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=877820)[0m saving checkpoint...
[36m(_train_fn pid=877820)[0m Epoch: 4 cost time: 1.6700904369354248
[36m(_train_fn pid=877820)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6001849 Vali Loss: 1.6132194 Best vali loss: 1.5886241
[36m(_train_fn pid=877820)[0m 	iters: 100, epoch: 5 | loss: 0.6464886
[36m(_train_fn pid=877820)[0m 	speed: 0.0127s/iter; left time: 11.1355s
[36m(_train_fn pid=877820)[0m 	iters: 200, epoch: 5 | loss: 0.5668603
[36m(_train_fn pid=877820)[0m 	speed: 0.0066s/iter; left time: 5.1369s

Trial trial-ad9f9ee7 completed after 5 iterations at 2024-08-24 10:52:39. Total running time: 3hr 31min 30s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ad9f9ee7 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.90548 â”‚
â”‚ time_total_s                             10.42279 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58862 â”‚
â”‚ train_loss                                 0.5956 â”‚
â”‚ valid_loss                                1.60945 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=877820)[0m Updating learning rate to 6.240350183231749e-05
[36m(_train_fn pid=877820)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=877820)[0m saving checkpoint...
[36m(_train_fn pid=877820)[0m Epoch: 5 cost time: 1.6539857387542725
[36m(_train_fn pid=877820)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5955970 Vali Loss: 1.6094485 Best vali loss: 1.5886241
[36m(_train_fn pid=877820)[0m Early stopping

Trial trial-a6ba4dfe started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a6ba4dfe config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19088 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00173 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=878298)[0m configuration
[36m(_train_fn pid=878298)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19088180577389038, 'e_layers': 1, 'learning_rate': 0.0017278268567660923, 'd_ff': 1536}
[36m(_train_fn pid=878298)[0m Use GPU: cuda:0
[36m(_train_fn pid=878298)[0m train 7825
[36m(_train_fn pid=878298)[0m val 2161
[36m(_train_fn pid=878298)[0m start_epoch 0
[36m(_train_fn pid=878298)[0m max_epoch 8
[36m(_train_fn pid=878298)[0m 	iters: 100, epoch: 1 | loss: 0.8197303
[36m(_train_fn pid=878298)[0m 	speed: 0.0765s/iter; left time: 141.6743s
[36m(_train_fn pid=878298)[0m 	iters: 200, epoch: 1 | loss: 0.6415743
[36m(_train_fn pid=878298)[0m 	speed: 0.0698s/iter; left time: 122.3992s

Trial status: 198 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:53:00. Total running time: 3hr 31min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a6ba4dfe   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
193 more TERMINATED
2024-08-24 10:53:01,768	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=878298)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a6ba4dfe_199_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1909,e_layer_2024-08-24_10-52-39/checkpoint_000000)
[36m(_train_fn pid=878298)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a6ba4dfe_199_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1909,e_layer_2024-08-24_10-52-39/checkpoint_000001)
[36m(_train_fn pid=878298)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a6ba4dfe_199_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1909,e_layer_2024-08-24_10-52-39/checkpoint_000002)
[36m(_train_fn pid=878298)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a6ba4dfe_199_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1909,e_layer_2024-08-24_10-52-39/checkpoint_000003)
[36m(_train_fn pid=878298)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a6ba4dfe_199_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1909,e_layer_2024-08-24_10-52-39/checkpoint_000004)
[36m(_train_fn pid=878298)[0m Updating learning rate to 0.0017278268567660923
[36m(_train_fn pid=878298)[0m saving checkpoint...
[36m(_train_fn pid=878298)[0m Validation loss decreased (inf --> 1.8310).  Saving model state dict ...
[36m(_train_fn pid=878298)[0m Epoch: 1 cost time: 17.44685649871826
[36m(_train_fn pid=878298)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7817409 Vali Loss: 1.8309519 Best vali loss: 1.8309519
[36m(_train_fn pid=878298)[0m 	iters: 100, epoch: 2 | loss: 0.7305996
[36m(_train_fn pid=878298)[0m 	speed: 0.1229s/iter; left time: 197.7837s
[36m(_train_fn pid=878298)[0m 	iters: 200, epoch: 2 | loss: 0.7303122
[36m(_train_fn pid=878298)[0m 	speed: 0.0703s/iter; left time: 106.0940s
[36m(_train_fn pid=878298)[0m Updating learning rate to 0.0008639134283830462
[36m(_train_fn pid=878298)[0m saving checkpoint...
[36m(_train_fn pid=878298)[0m Validation loss decreased (1.8310 --> 1.6476).  Saving model state dict ...
[36m(_train_fn pid=878298)[0m Epoch: 2 cost time: 17.168029308319092
[36m(_train_fn pid=878298)[0m Epoch: 2, Steps: 244 | Train Loss: 1.1938146 Vali Loss: 1.6475626 Best vali loss: 1.6475626
[36m(_train_fn pid=878298)[0m 	iters: 100, epoch: 3 | loss: 0.6989621
[36m(_train_fn pid=878298)[0m 	speed: 0.1231s/iter; left time: 168.0835s
Trial status: 198 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:53:30. Total running time: 3hr 32min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a6ba4dfe   RUNNING           2            39.3571       1.19381         1.64756             1.64756 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
193 more TERMINATED
[36m(_train_fn pid=878298)[0m 	iters: 200, epoch: 3 | loss: 0.6557301
[36m(_train_fn pid=878298)[0m 	speed: 0.0705s/iter; left time: 89.1228s
[36m(_train_fn pid=878298)[0m Updating learning rate to 0.0004319567141915231
[36m(_train_fn pid=878298)[0m saving checkpoint...
[36m(_train_fn pid=878298)[0m Validation loss decreased (1.6476 --> 1.6244).  Saving model state dict ...
[36m(_train_fn pid=878298)[0m Epoch: 3 cost time: 17.19861125946045
[36m(_train_fn pid=878298)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6453243 Vali Loss: 1.6243920 Best vali loss: 1.6243920
[36m(_train_fn pid=878298)[0m 	iters: 100, epoch: 4 | loss: 0.6391590
[36m(_train_fn pid=878298)[0m 	speed: 0.1234s/iter; left time: 138.3786s
[36m(_train_fn pid=878298)[0m 	iters: 200, epoch: 4 | loss: 0.6599514
[36m(_train_fn pid=878298)[0m 	speed: 0.0705s/iter; left time: 72.0103s
[36m(_train_fn pid=878298)[0m Updating learning rate to 0.00021597835709576154
[36m(_train_fn pid=878298)[0m saving checkpoint...
[36m(_train_fn pid=878298)[0m Validation loss decreased (1.6244 --> 1.6126).  Saving model state dict ...
[36m(_train_fn pid=878298)[0m Epoch: 4 cost time: 17.222296237945557
[36m(_train_fn pid=878298)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6371748 Vali Loss: 1.6125605 Best vali loss: 1.6125605
Trial status: 198 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:54:00. Total running time: 3hr 32min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a6ba4dfe   RUNNING           4            78.1244       0.637175        1.61256             1.61256 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
193 more TERMINATED
[36m(_train_fn pid=878298)[0m 	iters: 100, epoch: 5 | loss: 0.6228901
[36m(_train_fn pid=878298)[0m 	speed: 0.1236s/iter; left time: 108.3542s
[36m(_train_fn pid=878298)[0m 	iters: 200, epoch: 5 | loss: 0.5607066
[36m(_train_fn pid=878298)[0m 	speed: 0.0707s/iter; left time: 54.9302s
[36m(_train_fn pid=878298)[0m Updating learning rate to 0.00010798917854788077
[36m(_train_fn pid=878298)[0m saving checkpoint...
[36m(_train_fn pid=878298)[0m Validation loss decreased (1.6126 --> 1.6058).  Saving model state dict ...
[36m(_train_fn pid=878298)[0m Epoch: 5 cost time: 17.253140687942505
[36m(_train_fn pid=878298)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6325978 Vali Loss: 1.6058497 Best vali loss: 1.6058497
[36m(_train_fn pid=878298)[0m 	iters: 100, epoch: 6 | loss: 0.6062934
[36m(_train_fn pid=878298)[0m 	speed: 0.1237s/iter; left time: 78.3155s
Trial status: 198 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:54:30. Total running time: 3hr 33min 21s
[36m(_train_fn pid=878298)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-a6ba4dfe_199_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1909,e_layer_2024-08-24_10-52-39/checkpoint_000005)
2024-08-24 10:55:00,731	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=879155)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e9bab2a2_200_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1570,e_layer_2024-08-24_10-54-38/checkpoint_000000)
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-a6ba4dfe   RUNNING           5            97.5603       0.632598        1.60585             1.60585 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
193 more TERMINATED
[36m(_train_fn pid=878298)[0m 	iters: 200, epoch: 6 | loss: 0.6123663
[36m(_train_fn pid=878298)[0m 	speed: 0.0707s/iter; left time: 37.6619s

Trial trial-a6ba4dfe completed after 6 iterations at 2024-08-24 10:54:38. Total running time: 3hr 33min 29s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-a6ba4dfe result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.41937 â”‚
â”‚ time_total_s                            116.97971 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                            1.6016 â”‚
â”‚ train_loss                                0.63003 â”‚
â”‚ valid_loss                                 1.6016 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=878298)[0m Updating learning rate to 5.3994589273940385e-05
[36m(_train_fn pid=878298)[0m saving checkpoint...
[36m(_train_fn pid=878298)[0m Validation loss decreased (1.6058 --> 1.6016).  Saving model state dict ...

Trial trial-e9bab2a2 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e9bab2a2 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.15702 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00051 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=879155)[0m configuration
[36m(_train_fn pid=879155)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1570244443762689, 'e_layers': 1, 'learning_rate': 0.0005068876971067664, 'd_ff': 1536}
[36m(_train_fn pid=879155)[0m Use GPU: cuda:0
[36m(_train_fn pid=879155)[0m train 7825
[36m(_train_fn pid=879155)[0m val 2161
[36m(_train_fn pid=879155)[0m start_epoch 0
[36m(_train_fn pid=879155)[0m max_epoch 8
[36m(_train_fn pid=879155)[0m 	iters: 100, epoch: 1 | loss: 0.8500476
[36m(_train_fn pid=879155)[0m 	speed: 0.0764s/iter; left time: 141.6449s
[36m(_train_fn pid=879155)[0m 	iters: 200, epoch: 1 | loss: 0.6682107
[36m(_train_fn pid=879155)[0m 	speed: 0.0700s/iter; left time: 122.6957s

Trial status: 199 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:55:00. Total running time: 3hr 33min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e9bab2a2   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
194 more TERMINATED
[36m(_train_fn pid=879155)[0m Updating learning rate to 0.0005068876971067664
[36m(_train_fn pid=879155)[0m saving checkpoint...
[36m(_train_fn pid=879155)[0m Validation loss decreased (inf --> 1.9306).  Saving model state dict ...
[36m(_train_fn pid=879155)[0m Epoch: 1 cost time: 17.465999364852905
[36m(_train_fn pid=879155)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8093483 Vali Loss: 1.9306143 Best vali loss: 1.9306143
[36m(_train_fn pid=879155)[0m 	iters: 100, epoch: 2 | loss: 0.6450660
[36m(_train_fn pid=879155)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e9bab2a2_200_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1570,e_layer_2024-08-24_10-54-38/checkpoint_000001)
[36m(_train_fn pid=879155)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e9bab2a2_200_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1570,e_layer_2024-08-24_10-54-38/checkpoint_000002)
[36m(_train_fn pid=879155)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e9bab2a2_200_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1570,e_layer_2024-08-24_10-54-38/checkpoint_000003)
[36m(_train_fn pid=879155)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e9bab2a2_200_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1570,e_layer_2024-08-24_10-54-38/checkpoint_000004)
[36m(_train_fn pid=879155)[0m 	speed: 0.1228s/iter; left time: 197.5443s
[36m(_train_fn pid=879155)[0m 	iters: 200, epoch: 2 | loss: 0.6951712
[36m(_train_fn pid=879155)[0m 	speed: 0.0703s/iter; left time: 106.1372s
[36m(_train_fn pid=879155)[0m Updating learning rate to 0.0002534438485533832
[36m(_train_fn pid=879155)[0m saving checkpoint...
[36m(_train_fn pid=879155)[0m Validation loss decreased (1.9306 --> 1.5733).  Saving model state dict ...
[36m(_train_fn pid=879155)[0m Epoch: 2 cost time: 17.166675567626953
[36m(_train_fn pid=879155)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6563617 Vali Loss: 1.5732849 Best vali loss: 1.5732849
[36m(_train_fn pid=879155)[0m 	iters: 100, epoch: 3 | loss: 0.6678745
[36m(_train_fn pid=879155)[0m 	speed: 0.1230s/iter; left time: 167.9514s
Trial status: 199 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:55:30. Total running time: 3hr 34min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e9bab2a2   RUNNING           2            39.3577       0.656362        1.57328             1.57328 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
194 more TERMINATED
[36m(_train_fn pid=879155)[0m 	iters: 200, epoch: 3 | loss: 0.6285862
[36m(_train_fn pid=879155)[0m 	speed: 0.0703s/iter; left time: 88.9421s
[36m(_train_fn pid=879155)[0m Updating learning rate to 0.0001267219242766916
[36m(_train_fn pid=879155)[0m saving checkpoint...
[36m(_train_fn pid=879155)[0m Validation loss decreased (1.5733 --> 1.5671).  Saving model state dict ...
[36m(_train_fn pid=879155)[0m Epoch: 3 cost time: 17.161938190460205
[36m(_train_fn pid=879155)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6167545 Vali Loss: 1.5671089 Best vali loss: 1.5671089
[36m(_train_fn pid=879155)[0m 	iters: 100, epoch: 4 | loss: 0.6360846
[36m(_train_fn pid=879155)[0m 	speed: 0.1231s/iter; left time: 137.9863s
[36m(_train_fn pid=879155)[0m 	iters: 200, epoch: 4 | loss: 0.6362460
[36m(_train_fn pid=879155)[0m 	speed: 0.0703s/iter; left time: 71.7517s
[36m(_train_fn pid=879155)[0m Updating learning rate to 6.33609621383458e-05
[36m(_train_fn pid=879155)[0m saving checkpoint...
[36m(_train_fn pid=879155)[0m Validation loss decreased (1.5671 --> 1.5642).  Saving model state dict ...
[36m(_train_fn pid=879155)[0m Epoch: 4 cost time: 17.16284728050232
[36m(_train_fn pid=879155)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6124392 Vali Loss: 1.5641658 Best vali loss: 1.5641658
Trial status: 199 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:56:00. Total running time: 3hr 34min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e9bab2a2   RUNNING           4            78.014        0.612439        1.56417             1.56417 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
194 more TERMINATED
[36m(_train_fn pid=879155)[0m 	iters: 100, epoch: 5 | loss: 0.6059687
[36m(_train_fn pid=879155)[0m 	speed: 0.1230s/iter; left time: 107.8312s
[36m(_train_fn pid=879155)[0m 	iters: 200, epoch: 5 | loss: 0.5450723
[36m(_train_fn pid=879155)[0m 	speed: 0.0703s/iter; left time: 54.6436s
[36m(_train_fn pid=879155)[0m Updating learning rate to 3.16804810691729e-05
[36m(_train_fn pid=879155)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=879155)[0m saving checkpoint...
[36m(_train_fn pid=879155)[0m Epoch: 5 cost time: 17.163203239440918
[36m(_train_fn pid=879155)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6106218 Vali Loss: 1.5704876 Best vali loss: 1.5641658
[36m(_train_fn pid=879155)[0m 	iters: 100, epoch: 6 | loss: 0.5823525
[36m(_train_fn pid=879155)[0m 	speed: 0.1229s/iter; left time: 77.7989s
Trial status: 199 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:56:30. Total running time: 3hr 35min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=879155)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-e9bab2a2_200_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1570,e_layer_2024-08-24_10-54-38/checkpoint_000005)
2024-08-24 10:56:59,774	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=880016)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6011a59d_201_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1727,e_layer_2024-08-24_10-56-37/checkpoint_000000)
[36m(_train_fn pid=880016)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6011a59d_201_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1727,e_layer_2024-08-24_10-56-37/checkpoint_000001)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-e9bab2a2   RUNNING           5            97.3283       0.610622        1.57049             1.56417 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
194 more TERMINATED
[36m(_train_fn pid=879155)[0m 	iters: 200, epoch: 6 | loss: 0.5945110
[36m(_train_fn pid=879155)[0m 	speed: 0.0704s/iter; left time: 37.5212s

Trial trial-e9bab2a2 completed after 6 iterations at 2024-08-24 10:56:37. Total running time: 3hr 35min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-e9bab2a2 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.33438 â”‚
â”‚ time_total_s                             116.6627 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                            1.5614 â”‚
â”‚ train_loss                                0.60999 â”‚
â”‚ valid_loss                                 1.5614 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=879155)[0m Updating learning rate to 1.584024053458645e-05
[36m(_train_fn pid=879155)[0m saving checkpoint...
[36m(_train_fn pid=879155)[0m Validation loss decreased (1.5642 --> 1.5614).  Saving model state dict ...

Trial trial-6011a59d started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6011a59d config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17272 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00108 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=880016)[0m configuration
[36m(_train_fn pid=880016)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1727189243882303, 'e_layers': 1, 'learning_rate': 0.0010800833632857167, 'd_ff': 1536}
[36m(_train_fn pid=880016)[0m Use GPU: cuda:0
[36m(_train_fn pid=880016)[0m train 7825
[36m(_train_fn pid=880016)[0m val 2161
[36m(_train_fn pid=880016)[0m start_epoch 0
[36m(_train_fn pid=880016)[0m max_epoch 8
[36m(_train_fn pid=880016)[0m 	iters: 100, epoch: 1 | loss: 0.8322476
[36m(_train_fn pid=880016)[0m 	speed: 0.0765s/iter; left time: 141.7800s
[36m(_train_fn pid=880016)[0m 	iters: 200, epoch: 1 | loss: 0.6512192
[36m(_train_fn pid=880016)[0m 	speed: 0.0700s/iter; left time: 122.6589s
[36m(_train_fn pid=880016)[0m Updating learning rate to 0.0010800833632857167
[36m(_train_fn pid=880016)[0m saving checkpoint...
[36m(_train_fn pid=880016)[0m Validation loss decreased (inf --> 1.9032).  Saving model state dict ...
[36m(_train_fn pid=880016)[0m Epoch: 1 cost time: 17.46774458885193
[36m(_train_fn pid=880016)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7927371 Vali Loss: 1.9031688 Best vali loss: 1.9031688

Trial status: 200 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:57:00. Total running time: 3hr 35min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6011a59d   RUNNING           1            20.0331       0.792737        1.90317             1.90317 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
195 more TERMINATED
[36m(_train_fn pid=880016)[0m 	iters: 100, epoch: 2 | loss: 0.6699702
[36m(_train_fn pid=880016)[0m 	speed: 0.1230s/iter; left time: 197.8641s
[36m(_train_fn pid=880016)[0m 	iters: 200, epoch: 2 | loss: 0.7105482
[36m(_train_fn pid=880016)[0m 	speed: 0.0704s/iter; left time: 106.2751s
[36m(_train_fn pid=880016)[0m Updating learning rate to 0.0005400416816428584
[36m(_train_fn pid=880016)[0m saving checkpoint...
[36m(_train_fn pid=880016)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6011a59d_201_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1727,e_layer_2024-08-24_10-56-37/checkpoint_000002)
[36m(_train_fn pid=880016)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6011a59d_201_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1727,e_layer_2024-08-24_10-56-37/checkpoint_000003)
[36m(_train_fn pid=880016)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6011a59d_201_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1727,e_layer_2024-08-24_10-56-37/checkpoint_000004)
[36m(_train_fn pid=880016)[0m Validation loss decreased (1.9032 --> 1.5863).  Saving model state dict ...
[36m(_train_fn pid=880016)[0m Epoch: 2 cost time: 17.201308488845825
[36m(_train_fn pid=880016)[0m Epoch: 2, Steps: 244 | Train Loss: 0.7562748 Vali Loss: 1.5862821 Best vali loss: 1.5862821
[36m(_train_fn pid=880016)[0m 	iters: 100, epoch: 3 | loss: 0.6762623
[36m(_train_fn pid=880016)[0m 	speed: 0.1233s/iter; left time: 168.2645s
Trial status: 200 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:57:30. Total running time: 3hr 36min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6011a59d   RUNNING           2            39.3985       0.756275        1.58628             1.58628 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
195 more TERMINATED
[36m(_train_fn pid=880016)[0m 	iters: 200, epoch: 3 | loss: 0.6369550
[36m(_train_fn pid=880016)[0m 	speed: 0.0705s/iter; left time: 89.2023s
[36m(_train_fn pid=880016)[0m Updating learning rate to 0.0002700208408214292
[36m(_train_fn pid=880016)[0m saving checkpoint...
[36m(_train_fn pid=880016)[0m Validation loss decreased (1.5863 --> 1.5809).  Saving model state dict ...
[36m(_train_fn pid=880016)[0m Epoch: 3 cost time: 17.210375785827637
[36m(_train_fn pid=880016)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6200000 Vali Loss: 1.5809146 Best vali loss: 1.5809146
[36m(_train_fn pid=880016)[0m 	iters: 100, epoch: 4 | loss: 0.6338182
[36m(_train_fn pid=880016)[0m 	speed: 0.1235s/iter; left time: 138.4433s
[36m(_train_fn pid=880016)[0m 	iters: 200, epoch: 4 | loss: 0.6387206
[36m(_train_fn pid=880016)[0m 	speed: 0.0706s/iter; left time: 72.0337s
[36m(_train_fn pid=880016)[0m Updating learning rate to 0.0001350104204107146
[36m(_train_fn pid=880016)[0m saving checkpoint...
[36m(_train_fn pid=880016)[0m Validation loss decreased (1.5809 --> 1.5672).  Saving model state dict ...
[36m(_train_fn pid=880016)[0m Epoch: 4 cost time: 17.22626566886902
[36m(_train_fn pid=880016)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6149407 Vali Loss: 1.5672238 Best vali loss: 1.5672238
Trial status: 200 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:58:00. Total running time: 3hr 36min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6011a59d   RUNNING           4            78.1809       0.614941        1.56722             1.56722 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
195 more TERMINATED
[36m(_train_fn pid=880016)[0m 	iters: 100, epoch: 5 | loss: 0.6069767
[36m(_train_fn pid=880016)[0m 	speed: 0.1234s/iter; left time: 108.2501s
[36m(_train_fn pid=880016)[0m 	iters: 200, epoch: 5 | loss: 0.5481220
[36m(_train_fn pid=880016)[0m 	speed: 0.0705s/iter; left time: 54.8051s
[36m(_train_fn pid=880016)[0m Updating learning rate to 6.75052102053573e-05
[36m(_train_fn pid=880016)[0m saving checkpoint...
[36m(_train_fn pid=880016)[0m Validation loss decreased (1.5672 --> 1.5669).  Saving model state dict ...
[36m(_train_fn pid=880016)[0m Epoch: 5 cost time: 17.219858169555664
[36m(_train_fn pid=880016)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6131043 Vali Loss: 1.5668644 Best vali loss: 1.5668644
[36m(_train_fn pid=880016)[0m 	iters: 100, epoch: 6 | loss: 0.5900209
[36m(_train_fn pid=880016)[0m 	speed: 0.1233s/iter; left time: 78.0798s
Trial status: 200 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:58:30. Total running time: 3hr 37min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=880016)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-6011a59d_201_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1727,e_layer_2024-08-24_10-56-37/checkpoint_000005)
[36m(_train_fn pid=880876)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-200e6a60_202_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1816,e_layer_2024-08-24_10-58-36/checkpoint_000000)
2024-08-24 10:58:48,710	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=880876)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-200e6a60_202_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1816,e_layer_2024-08-24_10-58-36/checkpoint_000001)
[36m(_train_fn pid=880876)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-200e6a60_202_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1816,e_layer_2024-08-24_10-58-36/checkpoint_000002)
2024-08-24 10:58:53,318	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 10:58:57,919	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=880876)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-200e6a60_202_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1816,e_layer_2024-08-24_10-58-36/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-6011a59d   RUNNING           5            97.5713       0.613104        1.56686             1.56686 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
195 more TERMINATED
[36m(_train_fn pid=880016)[0m 	iters: 200, epoch: 6 | loss: 0.5992333
[36m(_train_fn pid=880016)[0m 	speed: 0.0705s/iter; left time: 37.5573s
[36m(_train_fn pid=880016)[0m Updating learning rate to 3.375260510267865e-05
[36m(_train_fn pid=880016)[0m saving checkpoint...
[36m(_train_fn pid=880016)[0m Validation loss decreased (1.5669 --> 1.5645).  Saving model state dict ...

Trial trial-6011a59d completed after 6 iterations at 2024-08-24 10:58:36. Total running time: 3hr 37min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-6011a59d result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.36936 â”‚
â”‚ time_total_s                             116.9407 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56445 â”‚
â”‚ train_loss                                0.61224 â”‚
â”‚ valid_loss                                1.56445 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-200e6a60 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-200e6a60 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18162 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00055 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=880876)[0m configuration
[36m(_train_fn pid=880876)[0m {'batch_size': 32, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1816175579210425, 'e_layers': 1, 'learning_rate': 0.0005537499065827792, 'd_ff': 384}
[36m(_train_fn pid=880876)[0m Use GPU: cuda:0
[36m(_train_fn pid=880876)[0m train 7825
[36m(_train_fn pid=880876)[0m val 2161
[36m(_train_fn pid=880876)[0m start_epoch 0
[36m(_train_fn pid=880876)[0m max_epoch 8
[36m(_train_fn pid=880876)[0m 	iters: 100, epoch: 1 | loss: 0.8521989
[36m(_train_fn pid=880876)[0m 	speed: 0.0230s/iter; left time: 42.6556s
[36m(_train_fn pid=880876)[0m 	iters: 200, epoch: 1 | loss: 0.8721591
[36m(_train_fn pid=880876)[0m 	speed: 0.0162s/iter; left time: 28.4215s
[36m(_train_fn pid=880876)[0m Updating learning rate to 0.0005537499065827792
[36m(_train_fn pid=880876)[0m saving checkpoint...
[36m(_train_fn pid=880876)[0m Validation loss decreased (inf --> 1.9413).  Saving model state dict ...
[36m(_train_fn pid=880876)[0m Epoch: 1 cost time: 4.375017166137695
[36m(_train_fn pid=880876)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8425934 Vali Loss: 1.9412890 Best vali loss: 1.9412890
[36m(_train_fn pid=880876)[0m 	iters: 100, epoch: 2 | loss: 0.6754907
[36m(_train_fn pid=880876)[0m 	speed: 0.0297s/iter; left time: 47.7838s
[36m(_train_fn pid=880876)[0m 	iters: 200, epoch: 2 | loss: 0.6960793
[36m(_train_fn pid=880876)[0m 	speed: 0.0162s/iter; left time: 24.4492s
[36m(_train_fn pid=880876)[0m Updating learning rate to 0.0002768749532913896
[36m(_train_fn pid=880876)[0m saving checkpoint...
[36m(_train_fn pid=880876)[0m Validation loss decreased (1.9413 --> 1.5760).  Saving model state dict ...
[36m(_train_fn pid=880876)[0m Epoch: 2 cost time: 3.992502450942993
[36m(_train_fn pid=880876)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6590872 Vali Loss: 1.5760204 Best vali loss: 1.5760204
[36m(_train_fn pid=880876)[0m 	iters: 100, epoch: 3 | loss: 0.5843399
[36m(_train_fn pid=880876)[0m 	speed: 0.0298s/iter; left time: 40.6955s
[36m(_train_fn pid=880876)[0m 	iters: 200, epoch: 3 | loss: 0.5360642
[36m(_train_fn pid=880876)[0m 	speed: 0.0162s/iter; left time: 20.5093s
[36m(_train_fn pid=880876)[0m Updating learning rate to 0.0001384374766456948
[36m(_train_fn pid=880876)[0m saving checkpoint...
[36m(_train_fn pid=880876)[0m Validation loss decreased (1.5760 --> 1.5723).  Saving model state dict ...
[36m(_train_fn pid=880876)[0m Epoch: 3 cost time: 4.003290891647339
[36m(_train_fn pid=880876)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6171299 Vali Loss: 1.5722720 Best vali loss: 1.5722720
[36m(_train_fn pid=880876)[0m 	iters: 100, epoch: 4 | loss: 0.6771346
[36m(_train_fn pid=880876)[0m 	speed: 0.0298s/iter; left time: 33.4129s
[36m(_train_fn pid=880876)[0m 	iters: 200, epoch: 4 | loss: 0.5469230
[36m(_train_fn pid=880876)[0m 	speed: 0.0162s/iter; left time: 16.5834s
[36m(_train_fn pid=880876)[0m Updating learning rate to 6.92187383228474e-05
[36m(_train_fn pid=880876)[0m saving checkpoint...
[36m(_train_fn pid=880876)[0m Validation loss decreased (1.5723 --> 1.5695).  Saving model state dict ...
[36m(_train_fn pid=880876)[0m Epoch: 4 cost time: 4.0074498653411865
[36m(_train_fn pid=880876)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6139431 Vali Loss: 1.5695205 Best vali loss: 1.5695205
[36m(_train_fn pid=880876)[0m 	iters: 100, epoch: 5 | loss: 0.5503089
[36m(_train_fn pid=880876)[0m 	speed: 0.0297s/iter; left time: 26.0220s

Trial status: 201 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:59:00. Total running time: 3hr 37min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 10:59:02,514	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=880876)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-200e6a60_202_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1816,e_layer_2024-08-24_10-58-36/checkpoint_000004)
[36m(_train_fn pid=880876)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-200e6a60_202_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1816,e_layer_2024-08-24_10-58-36/checkpoint_000005)
2024-08-24 10:59:07,113	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 10:59:11,740	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=880876)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-200e6a60_202_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1816,e_layer_2024-08-24_10-58-36/checkpoint_000006)
[36m(_train_fn pid=880876)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-200e6a60_202_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1816,e_layer_2024-08-24_10-58-36/checkpoint_000007)
2024-08-24 10:59:16,346	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-200e6a60   RUNNING           4            19.1619       0.613943        1.56952             1.56952 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
196 more TERMINATED
[36m(_train_fn pid=880876)[0m 	iters: 200, epoch: 5 | loss: 0.6743688
[36m(_train_fn pid=880876)[0m 	speed: 0.0162s/iter; left time: 12.5816s
[36m(_train_fn pid=880876)[0m Updating learning rate to 3.46093691614237e-05
[36m(_train_fn pid=880876)[0m saving checkpoint...
[36m(_train_fn pid=880876)[0m Validation loss decreased (1.5695 --> 1.5695).  Saving model state dict ...
[36m(_train_fn pid=880876)[0m Epoch: 5 cost time: 3.9953532218933105
[36m(_train_fn pid=880876)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6123087 Vali Loss: 1.5695078 Best vali loss: 1.5695078
[36m(_train_fn pid=880876)[0m 	iters: 100, epoch: 6 | loss: 0.6044722
[36m(_train_fn pid=880876)[0m 	speed: 0.0298s/iter; left time: 18.8503s
[36m(_train_fn pid=880876)[0m 	iters: 200, epoch: 6 | loss: 0.5718461
[36m(_train_fn pid=880876)[0m 	speed: 0.0162s/iter; left time: 8.6529s
[36m(_train_fn pid=880876)[0m Updating learning rate to 1.730468458071185e-05
[36m(_train_fn pid=880876)[0m saving checkpoint...
[36m(_train_fn pid=880876)[0m Validation loss decreased (1.5695 --> 1.5681).  Saving model state dict ...
[36m(_train_fn pid=880876)[0m Epoch: 6 cost time: 3.998241662979126
[36m(_train_fn pid=880876)[0m Epoch: 6, Steps: 244 | Train Loss: 0.6111722 Vali Loss: 1.5680575 Best vali loss: 1.5680575
[36m(_train_fn pid=880876)[0m 	iters: 100, epoch: 7 | loss: 0.6982240
[36m(_train_fn pid=880876)[0m 	speed: 0.0300s/iter; left time: 11.6582s
[36m(_train_fn pid=880876)[0m 	iters: 200, epoch: 7 | loss: 0.6254704
[36m(_train_fn pid=880876)[0m 	speed: 0.0163s/iter; left time: 4.7105s
[36m(_train_fn pid=880876)[0m Updating learning rate to 8.652342290355925e-06
[36m(_train_fn pid=880876)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=880876)[0m saving checkpoint...
[36m(_train_fn pid=880876)[0m Epoch: 7 cost time: 4.021375417709351
[36m(_train_fn pid=880876)[0m Epoch: 7, Steps: 244 | Train Loss: 0.6107025 Vali Loss: 1.5683573 Best vali loss: 1.5680575
[36m(_train_fn pid=880876)[0m 	iters: 100, epoch: 8 | loss: 0.6553405
[36m(_train_fn pid=880876)[0m 	speed: 0.0298s/iter; left time: 4.3247s
[36m(_train_fn pid=880876)[0m 	iters: 200, epoch: 8 | loss: 0.5944095
[36m(_train_fn pid=880876)[0m 	speed: 0.0163s/iter; left time: 0.7326s
[36m(_train_fn pid=880876)[0m Updating learning rate to 4.3261711451779625e-06
[36m(_train_fn pid=880876)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=880876)[0m saving checkpoint...
[36m(_train_fn pid=880876)[0m Epoch: 8 cost time: 4.011969804763794
[36m(_train_fn pid=880876)[0m Epoch: 8, Steps: 244 | Train Loss: 0.6100884 Vali Loss: 1.5691405 Best vali loss: 1.5680575

Trial trial-200e6a60 completed after 8 iterations at 2024-08-24 10:59:16. Total running time: 3hr 38min 7s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-200e6a60 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          4.60425 â”‚
â”‚ time_total_s                             37.57823 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.56806 â”‚
â”‚ train_loss                                0.61009 â”‚
â”‚ valid_loss                                1.56914 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-4b600fca started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4b600fca config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19328 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00092 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=881642)[0m configuration
[36m(_train_fn pid=881642)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19327951533013224, 'e_layers': 1, 'learning_rate': 0.0009224941015270803, 'd_ff': 1536}
[36m(_train_fn pid=881642)[0m Use GPU: cuda:0
[36m(_train_fn pid=881642)[0m train 7825
[36m(_train_fn pid=881642)[0m val 2161
[36m(_train_fn pid=881642)[0m start_epoch 0
[36m(_train_fn pid=881642)[0m max_epoch 8
[36m(_train_fn pid=881642)[0m 	iters: 100, epoch: 1 | loss: 0.8406072
[36m(_train_fn pid=881642)[0m 	speed: 0.0765s/iter; left time: 141.8247s

Trial status: 202 TERMINATED | 1 RUNNING
Current time: 2024-08-24 10:59:30. Total running time: 3hr 38min 21s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
2024-08-24 10:59:38,772	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=881642)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4b600fca_203_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1933,e_layer_2024-08-24_10-59-16/checkpoint_000000)
[36m(_train_fn pid=881642)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4b600fca_203_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1933,e_layer_2024-08-24_10-59-16/checkpoint_000001)
[36m(_train_fn pid=881642)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4b600fca_203_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1933,e_layer_2024-08-24_10-59-16/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4b600fca   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
197 more TERMINATED
[36m(_train_fn pid=881642)[0m 	iters: 200, epoch: 1 | loss: 0.6541252
[36m(_train_fn pid=881642)[0m 	speed: 0.0700s/iter; left time: 122.6599s
[36m(_train_fn pid=881642)[0m Updating learning rate to 0.0009224941015270803
[36m(_train_fn pid=881642)[0m saving checkpoint...
[36m(_train_fn pid=881642)[0m Validation loss decreased (inf --> 1.9150).  Saving model state dict ...
[36m(_train_fn pid=881642)[0m Epoch: 1 cost time: 17.473580598831177
[36m(_train_fn pid=881642)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7999063 Vali Loss: 1.9149715 Best vali loss: 1.9149715
[36m(_train_fn pid=881642)[0m 	iters: 100, epoch: 2 | loss: 0.6361285
[36m(_train_fn pid=881642)[0m 	speed: 0.1227s/iter; left time: 197.4616s
[36m(_train_fn pid=881642)[0m 	iters: 200, epoch: 2 | loss: 0.6946457
[36m(_train_fn pid=881642)[0m 	speed: 0.0703s/iter; left time: 106.0429s
[36m(_train_fn pid=881642)[0m Updating learning rate to 0.00046124705076354015
[36m(_train_fn pid=881642)[0m saving checkpoint...
[36m(_train_fn pid=881642)[0m Validation loss decreased (1.9150 --> 1.5691).  Saving model state dict ...
[36m(_train_fn pid=881642)[0m Epoch: 2 cost time: 17.15387988090515
[36m(_train_fn pid=881642)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6977142 Vali Loss: 1.5691151 Best vali loss: 1.5691151
Trial status: 202 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:00:00. Total running time: 3hr 38min 51s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4b600fca   RUNNING           2            39.3642       0.697714        1.56912             1.56912 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
197 more TERMINATED
[36m(_train_fn pid=881642)[0m 	iters: 100, epoch: 3 | loss: 0.6736172
[36m(_train_fn pid=881642)[0m 	speed: 0.1230s/iter; left time: 167.9526s
[36m(_train_fn pid=881642)[0m 	iters: 200, epoch: 3 | loss: 0.6291631
[36m(_train_fn pid=881642)[0m 	speed: 0.0704s/iter; left time: 89.0379s
[36m(_train_fn pid=881642)[0m Updating learning rate to 0.00023062352538177008
[36m(_train_fn pid=881642)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=881642)[0m saving checkpoint...
[36m(_train_fn pid=881642)[0m Epoch: 3 cost time: 17.18136978149414
[36m(_train_fn pid=881642)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6157336 Vali Loss: 1.5736267 Best vali loss: 1.5691151
[36m(_train_fn pid=881642)[0m 	iters: 100, epoch: 4 | loss: 0.6301351
[36m(_train_fn pid=881642)[0m 	speed: 0.1230s/iter; left time: 137.9159s
Trial status: 202 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:00:30. Total running time: 3hr 39min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=881642)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4b600fca_203_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1933,e_layer_2024-08-24_10-59-16/checkpoint_000003)
[36m(_train_fn pid=881642)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4b600fca_203_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1933,e_layer_2024-08-24_10-59-16/checkpoint_000004)
[36m(_train_fn pid=881642)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-4b600fca_203_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1933,e_layer_2024-08-24_10-59-16/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4b600fca   RUNNING           3            58.6917       0.615734        1.57363             1.56912 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
197 more TERMINATED
[36m(_train_fn pid=881642)[0m 	iters: 200, epoch: 4 | loss: 0.6370126
[36m(_train_fn pid=881642)[0m 	speed: 0.0704s/iter; left time: 71.9201s
[36m(_train_fn pid=881642)[0m Updating learning rate to 0.00011531176269088504
[36m(_train_fn pid=881642)[0m saving checkpoint...
[36m(_train_fn pid=881642)[0m Validation loss decreased (1.5691 --> 1.5645).  Saving model state dict ...
[36m(_train_fn pid=881642)[0m Epoch: 4 cost time: 17.20345640182495
[36m(_train_fn pid=881642)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6120057 Vali Loss: 1.5644528 Best vali loss: 1.5644528
[36m(_train_fn pid=881642)[0m 	iters: 100, epoch: 5 | loss: 0.6065664
[36m(_train_fn pid=881642)[0m 	speed: 0.1232s/iter; left time: 108.0681s
[36m(_train_fn pid=881642)[0m 	iters: 200, epoch: 5 | loss: 0.5444881
[36m(_train_fn pid=881642)[0m 	speed: 0.0703s/iter; left time: 54.6322s
[36m(_train_fn pid=881642)[0m Updating learning rate to 5.765588134544252e-05
[36m(_train_fn pid=881642)[0m saving checkpoint...
[36m(_train_fn pid=881642)[0m Validation loss decreased (1.5645 --> 1.5632).  Saving model state dict ...
[36m(_train_fn pid=881642)[0m Epoch: 5 cost time: 17.175053119659424
[36m(_train_fn pid=881642)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6100603 Vali Loss: 1.5631576 Best vali loss: 1.5631576
Trial status: 202 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:01:00. Total running time: 3hr 39min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4b600fca   RUNNING           5            97.4049       0.61006         1.56316             1.56316 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
197 more TERMINATED
[36m(_train_fn pid=881642)[0m 	iters: 100, epoch: 6 | loss: 0.5836360
[36m(_train_fn pid=881642)[0m 	speed: 0.1231s/iter; left time: 77.9526s
[36m(_train_fn pid=881642)[0m 	iters: 200, epoch: 6 | loss: 0.5935570
[36m(_train_fn pid=881642)[0m 	speed: 0.0703s/iter; left time: 37.4773s

Trial trial-4b600fca completed after 6 iterations at 2024-08-24 11:01:15. Total running time: 3hr 40min 6s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-4b600fca result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.33284 â”‚
â”‚ time_total_s                            116.73773 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56248 â”‚
â”‚ train_loss                                 0.6091 â”‚
â”‚ valid_loss                                1.56248 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=881642)[0m Updating learning rate to 2.882794067272126e-05
[36m(_train_fn pid=881642)[0m saving checkpoint...
[36m(_train_fn pid=881642)[0m Validation loss decreased (1.5632 --> 1.5625).  Saving model state dict ...

Trial trial-57a34c3f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-57a34c3f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.08095 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00071 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=882504)[0m configuration
[36m(_train_fn pid=882504)[0m {'batch_size': 32, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.08094664841435908, 'e_layers': 1, 'learning_rate': 0.0007078082011437947, 'd_ff': 48}
2024-08-24 11:01:22,429	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=882504)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-57a34c3f_204_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0809,e_layers_2024-08-24_11-01-15/checkpoint_000001)[32m [repeated 2x across cluster][0m
2024-08-24 11:01:24,266	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:01:26,089	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:01:27,908	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=882504)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-57a34c3f_204_alpha_d_ff=3,batch_size=32,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.0809,e_layers_2024-08-24_11-01-15/checkpoint_000004)[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=882504)[0m Use GPU: cuda:0
[36m(_train_fn pid=882504)[0m train 7825
[36m(_train_fn pid=882504)[0m val 2161
[36m(_train_fn pid=882504)[0m start_epoch 0
[36m(_train_fn pid=882504)[0m max_epoch 8
[36m(_train_fn pid=882504)[0m 	iters: 100, epoch: 1 | loss: 1.0279925
[36m(_train_fn pid=882504)[0m 	speed: 0.0139s/iter; left time: 25.7540s
[36m(_train_fn pid=882504)[0m 	iters: 200, epoch: 1 | loss: 1.0434623
[36m(_train_fn pid=882504)[0m 	speed: 0.0066s/iter; left time: 11.5924s
[36m(_train_fn pid=882504)[0m Validation loss decreased (inf --> 2.3984).  Saving model state dict ...
[36m(_train_fn pid=882504)[0m Epoch: 1 cost time: 2.092313766479492
[36m(_train_fn pid=882504)[0m Epoch: 1, Steps: 244 | Train Loss: 1.0968365 Vali Loss: 2.3983744 Best vali loss: 2.3983744
[36m(_train_fn pid=882504)[0m 	iters: 100, epoch: 2 | loss: 0.5767720
[36m(_train_fn pid=882504)[0m 	speed: 0.0128s/iter; left time: 20.6707s
[36m(_train_fn pid=882504)[0m Updating learning rate to 0.0007078082011437947
[36m(_train_fn pid=882504)[0m saving checkpoint...
[36m(_train_fn pid=882504)[0m 	iters: 200, epoch: 2 | loss: 0.6009296
[36m(_train_fn pid=882504)[0m 	speed: 0.0064s/iter; left time: 9.6157s
[36m(_train_fn pid=882504)[0m Updating learning rate to 0.00035390410057189737
[36m(_train_fn pid=882504)[0m saving checkpoint...
[36m(_train_fn pid=882504)[0m Validation loss decreased (2.3984 --> 1.5831).  Saving model state dict ...
[36m(_train_fn pid=882504)[0m Epoch: 2 cost time: 1.6298351287841797
[36m(_train_fn pid=882504)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6894916 Vali Loss: 1.5831208 Best vali loss: 1.5831208
[36m(_train_fn pid=882504)[0m 	iters: 100, epoch: 3 | loss: 0.6384102
[36m(_train_fn pid=882504)[0m 	speed: 0.0121s/iter; left time: 16.4958s
[36m(_train_fn pid=882504)[0m 	iters: 200, epoch: 3 | loss: 0.5999814
[36m(_train_fn pid=882504)[0m 	speed: 0.0063s/iter; left time: 7.9359s
[36m(_train_fn pid=882504)[0m Updating learning rate to 0.00017695205028594869
[36m(_train_fn pid=882504)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=882504)[0m saving checkpoint...
[36m(_train_fn pid=882504)[0m Epoch: 3 cost time: 1.576730728149414
[36m(_train_fn pid=882504)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6190641 Vali Loss: 1.5877043 Best vali loss: 1.5831208
[36m(_train_fn pid=882504)[0m 	iters: 100, epoch: 4 | loss: 0.6090805
[36m(_train_fn pid=882504)[0m 	speed: 0.0120s/iter; left time: 13.4644s
[36m(_train_fn pid=882504)[0m 	iters: 200, epoch: 4 | loss: 0.5272587
[36m(_train_fn pid=882504)[0m 	speed: 0.0062s/iter; left time: 6.3670s
[36m(_train_fn pid=882504)[0m Updating learning rate to 8.847602514297434e-05
[36m(_train_fn pid=882504)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=882504)[0m saving checkpoint...
[36m(_train_fn pid=882504)[0m Epoch: 4 cost time: 1.5651865005493164
[36m(_train_fn pid=882504)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6107829 Vali Loss: 1.5917184 Best vali loss: 1.5831208
[36m(_train_fn pid=882504)[0m 	iters: 100, epoch: 5 | loss: 0.6472272
[36m(_train_fn pid=882504)[0m 	speed: 0.0120s/iter; left time: 10.5546s
[36m(_train_fn pid=882504)[0m 	iters: 200, epoch: 5 | loss: 0.5775191
[36m(_train_fn pid=882504)[0m 	speed: 0.0062s/iter; left time: 4.8424s

Trial trial-57a34c3f completed after 5 iterations at 2024-08-24 11:01:27. Total running time: 3hr 40min 19s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-57a34c3f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.81668 â”‚
â”‚ time_total_s                             10.13138 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58312 â”‚
â”‚ train_loss                                0.60648 â”‚
â”‚ valid_loss                                1.59437 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=882504)[0m Updating learning rate to 4.423801257148717e-05
[36m(_train_fn pid=882504)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=882504)[0m saving checkpoint...
[36m(_train_fn pid=882504)[0m Epoch: 5 cost time: 1.5626826286315918
[36m(_train_fn pid=882504)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6064849 Vali Loss: 1.5943738 Best vali loss: 1.5831208
[36m(_train_fn pid=882504)[0m Early stopping

Trial trial-d0246aac started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d0246aac config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18362 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00272 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=882976)[0m configuration
[36m(_train_fn pid=882976)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18361716135597894, 'e_layers': 1, 'learning_rate': 0.002716064208212406, 'd_ff': 1536}
[36m(_train_fn pid=882976)[0m Use GPU: cuda:0
[36m(_train_fn pid=882976)[0m train 7825
[36m(_train_fn pid=882976)[0m val 2161
[36m(_train_fn pid=882976)[0m start_epoch 0
[36m(_train_fn pid=882976)[0m max_epoch 8

Trial status: 204 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:01:30. Total running time: 3hr 40min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
2024-08-24 11:01:49,715	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=882976)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d0246aac_205_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_11-01-27/checkpoint_000000)
[36m(_train_fn pid=882976)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d0246aac_205_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_11-01-27/checkpoint_000001)
[36m(_train_fn pid=882976)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d0246aac_205_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_11-01-27/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d0246aac   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
199 more TERMINATED
[36m(_train_fn pid=882976)[0m 	iters: 100, epoch: 1 | loss: 0.8076571
[36m(_train_fn pid=882976)[0m 	speed: 0.0762s/iter; left time: 141.1856s
[36m(_train_fn pid=882976)[0m 	iters: 200, epoch: 1 | loss: 0.6204481
[36m(_train_fn pid=882976)[0m 	speed: 0.0698s/iter; left time: 122.4178s
[36m(_train_fn pid=882976)[0m Updating learning rate to 0.002716064208212406
[36m(_train_fn pid=882976)[0m saving checkpoint...
[36m(_train_fn pid=882976)[0m Validation loss decreased (inf --> 1.7114).  Saving model state dict ...
[36m(_train_fn pid=882976)[0m Epoch: 1 cost time: 17.41809344291687
[36m(_train_fn pid=882976)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7631937 Vali Loss: 1.7113570 Best vali loss: 1.7113570
[36m(_train_fn pid=882976)[0m 	iters: 100, epoch: 2 | loss: 0.7727281
[36m(_train_fn pid=882976)[0m 	speed: 0.1222s/iter; left time: 196.5790s
Trial status: 204 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:02:00. Total running time: 3hr 40min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d0246aac   RUNNING           1            19.9694       0.763194        1.71136             1.71136 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
199 more TERMINATED
[36m(_train_fn pid=882976)[0m 	iters: 200, epoch: 2 | loss: 0.7542359
[36m(_train_fn pid=882976)[0m 	speed: 0.0696s/iter; left time: 105.0611s
[36m(_train_fn pid=882976)[0m Updating learning rate to 0.001358032104106203
[36m(_train_fn pid=882976)[0m saving checkpoint...
[36m(_train_fn pid=882976)[0m Validation loss decreased (1.7114 --> 1.6965).  Saving model state dict ...
[36m(_train_fn pid=882976)[0m Epoch: 2 cost time: 17.01507568359375
[36m(_train_fn pid=882976)[0m Epoch: 2, Steps: 244 | Train Loss: 1.8217488 Vali Loss: 1.6965399 Best vali loss: 1.6965399
[36m(_train_fn pid=882976)[0m 	iters: 100, epoch: 3 | loss: 0.7085835
[36m(_train_fn pid=882976)[0m 	speed: 0.1220s/iter; left time: 166.5378s
[36m(_train_fn pid=882976)[0m 	iters: 200, epoch: 3 | loss: 0.6615590
[36m(_train_fn pid=882976)[0m 	speed: 0.0699s/iter; left time: 88.3706s
[36m(_train_fn pid=882976)[0m Updating learning rate to 0.0006790160520531015
[36m(_train_fn pid=882976)[0m saving checkpoint...
[36m(_train_fn pid=882976)[0m Validation loss decreased (1.6965 --> 1.6435).  Saving model state dict ...
[36m(_train_fn pid=882976)[0m Epoch: 3 cost time: 17.045045852661133
[36m(_train_fn pid=882976)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6565222 Vali Loss: 1.6435257 Best vali loss: 1.6435257
Trial status: 204 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:02:31. Total running time: 3hr 41min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=882976)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d0246aac_205_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_11-01-27/checkpoint_000003)
[36m(_train_fn pid=882976)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d0246aac_205_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_11-01-27/checkpoint_000004)
[36m(_train_fn pid=882976)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d0246aac_205_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1836,e_layer_2024-08-24_11-01-27/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d0246aac   RUNNING           3            58.343        0.656522        1.64353             1.64353 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
199 more TERMINATED
[36m(_train_fn pid=882976)[0m 	iters: 100, epoch: 4 | loss: 0.6449582
[36m(_train_fn pid=882976)[0m 	speed: 0.1225s/iter; left time: 137.3457s
[36m(_train_fn pid=882976)[0m 	iters: 200, epoch: 4 | loss: 0.6637408
[36m(_train_fn pid=882976)[0m 	speed: 0.0700s/iter; left time: 71.4607s
[36m(_train_fn pid=882976)[0m Updating learning rate to 0.00033950802602655074
[36m(_train_fn pid=882976)[0m saving checkpoint...
[36m(_train_fn pid=882976)[0m Validation loss decreased (1.6435 --> 1.6299).  Saving model state dict ...
[36m(_train_fn pid=882976)[0m Epoch: 4 cost time: 17.08841586112976
[36m(_train_fn pid=882976)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6447759 Vali Loss: 1.6299123 Best vali loss: 1.6299123
[36m(_train_fn pid=882976)[0m 	iters: 100, epoch: 5 | loss: 0.6330619
[36m(_train_fn pid=882976)[0m 	speed: 0.1225s/iter; left time: 107.4055s
Trial status: 204 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:03:01. Total running time: 3hr 41min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d0246aac   RUNNING           4            77.5862       0.644776        1.62991             1.62991 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
199 more TERMINATED
[36m(_train_fn pid=882976)[0m 	iters: 200, epoch: 5 | loss: 0.5663370
[36m(_train_fn pid=882976)[0m 	speed: 0.0700s/iter; left time: 54.3714s
[36m(_train_fn pid=882976)[0m Updating learning rate to 0.00016975401301327537
[36m(_train_fn pid=882976)[0m saving checkpoint...
[36m(_train_fn pid=882976)[0m Validation loss decreased (1.6299 --> 1.6216).  Saving model state dict ...
[36m(_train_fn pid=882976)[0m Epoch: 5 cost time: 17.08590531349182
[36m(_train_fn pid=882976)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6400266 Vali Loss: 1.6216203 Best vali loss: 1.6216203
[36m(_train_fn pid=882976)[0m 	iters: 100, epoch: 6 | loss: 0.6121379
[36m(_train_fn pid=882976)[0m 	speed: 0.1226s/iter; left time: 77.5824s
[36m(_train_fn pid=882976)[0m 	iters: 200, epoch: 6 | loss: 0.6186760
[36m(_train_fn pid=882976)[0m 	speed: 0.0700s/iter; left time: 37.3019s

Trial trial-d0246aac completed after 6 iterations at 2024-08-24 11:03:25. Total running time: 3hr 42min 17s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d0246aac result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.24545 â”‚
â”‚ time_total_s                            116.07293 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.61715 â”‚
â”‚ train_loss                                0.63717 â”‚
â”‚ valid_loss                                1.61715 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=882976)[0m Updating learning rate to 8.487700650663768e-05
[36m(_train_fn pid=882976)[0m saving checkpoint...
[36m(_train_fn pid=882976)[0m Validation loss decreased (1.6216 --> 1.6172).  Saving model state dict ...

Trial trial-02865d3f started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-02865d3f config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19815 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00084 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=883834)[0m configuration
2024-08-24 11:03:30,374	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:03:32,166	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=883834)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02865d3f_206_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1981,e_layers=_2024-08-24_11-03-25/checkpoint_000001)[32m [repeated 2x across cluster][0m
2024-08-24 11:03:34,033	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:03:35,865	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:03:37,717	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=883834)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-02865d3f_206_alpha_d_ff=3,batch_size=32,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1981,e_layers=_2024-08-24_11-03-25/checkpoint_000004)[32m [repeated 3x across cluster][0m
[36m(_train_fn pid=883834)[0m {'batch_size': 32, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19814814651047163, 'e_layers': 1, 'learning_rate': 0.0008403228854311038, 'd_ff': 24}
[36m(_train_fn pid=883834)[0m Use GPU: cuda:0
[36m(_train_fn pid=883834)[0m train 7825
[36m(_train_fn pid=883834)[0m val 2161
[36m(_train_fn pid=883834)[0m start_epoch 0
[36m(_train_fn pid=883834)[0m max_epoch 8
[36m(_train_fn pid=883834)[0m 	iters: 100, epoch: 1 | loss: 1.0964334
[36m(_train_fn pid=883834)[0m 	speed: 0.0137s/iter; left time: 25.3813s
[36m(_train_fn pid=883834)[0m 	iters: 200, epoch: 1 | loss: 1.1292552
[36m(_train_fn pid=883834)[0m 	speed: 0.0062s/iter; left time: 10.8703s
[36m(_train_fn pid=883834)[0m Validation loss decreased (inf --> 2.2785).  Saving model state dict ...
[36m(_train_fn pid=883834)[0m Epoch: 1 cost time: 1.9894614219665527
[36m(_train_fn pid=883834)[0m Epoch: 1, Steps: 244 | Train Loss: 1.1031891 Vali Loss: 2.2785292 Best vali loss: 2.2785292
[36m(_train_fn pid=883834)[0m 	iters: 100, epoch: 2 | loss: 0.7149043
[36m(_train_fn pid=883834)[0m 	speed: 0.0117s/iter; left time: 18.8951s
[36m(_train_fn pid=883834)[0m Updating learning rate to 0.0008403228854311038
[36m(_train_fn pid=883834)[0m saving checkpoint...

Trial status: 205 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:03:31. Total running time: 3hr 42min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-02865d3f   RUNNING           1            2.62878       1.10319         2.27853             2.27853 â”‚
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
200 more TERMINATED
[36m(_train_fn pid=883834)[0m 	iters: 200, epoch: 2 | loss: 0.5822457
[36m(_train_fn pid=883834)[0m 	speed: 0.0061s/iter; left time: 9.1572s
[36m(_train_fn pid=883834)[0m Updating learning rate to 0.0004201614427155519
[36m(_train_fn pid=883834)[0m saving checkpoint...
[36m(_train_fn pid=883834)[0m Validation loss decreased (2.2785 --> 1.5898).  Saving model state dict ...
[36m(_train_fn pid=883834)[0m Epoch: 2 cost time: 1.5467703342437744
[36m(_train_fn pid=883834)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6944957 Vali Loss: 1.5898141 Best vali loss: 1.5898141
[36m(_train_fn pid=883834)[0m 	iters: 100, epoch: 3 | loss: 0.6586511
[36m(_train_fn pid=883834)[0m 	speed: 0.0122s/iter; left time: 16.5935s
[36m(_train_fn pid=883834)[0m 	iters: 200, epoch: 3 | loss: 0.6241847
[36m(_train_fn pid=883834)[0m 	speed: 0.0065s/iter; left time: 8.2102s
[36m(_train_fn pid=883834)[0m Updating learning rate to 0.00021008072135777594
[36m(_train_fn pid=883834)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=883834)[0m saving checkpoint...
[36m(_train_fn pid=883834)[0m Epoch: 3 cost time: 1.6291372776031494
[36m(_train_fn pid=883834)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6198990 Vali Loss: 1.5909196 Best vali loss: 1.5898141
[36m(_train_fn pid=883834)[0m 	iters: 100, epoch: 4 | loss: 0.5661324
[36m(_train_fn pid=883834)[0m 	speed: 0.0121s/iter; left time: 13.5683s
[36m(_train_fn pid=883834)[0m 	iters: 200, epoch: 4 | loss: 0.6119427
[36m(_train_fn pid=883834)[0m 	speed: 0.0063s/iter; left time: 6.4558s
[36m(_train_fn pid=883834)[0m Updating learning rate to 0.00010504036067888797
[36m(_train_fn pid=883834)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=883834)[0m saving checkpoint...
[36m(_train_fn pid=883834)[0m Epoch: 4 cost time: 1.5980286598205566
[36m(_train_fn pid=883834)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6116704 Vali Loss: 1.5932855 Best vali loss: 1.5898141
[36m(_train_fn pid=883834)[0m 	iters: 100, epoch: 5 | loss: 0.6398053
[36m(_train_fn pid=883834)[0m 	speed: 0.0120s/iter; left time: 10.5341s
[36m(_train_fn pid=883834)[0m 	iters: 200, epoch: 5 | loss: 0.7208246
[36m(_train_fn pid=883834)[0m 	speed: 0.0064s/iter; left time: 4.9735s

Trial trial-02865d3f completed after 5 iterations at 2024-08-24 11:03:37. Total running time: 3hr 42min 28s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-02865d3f result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.84878 â”‚
â”‚ time_total_s                              9.96041 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58981 â”‚
â”‚ train_loss                                0.60871 â”‚
â”‚ valid_loss                                1.59812 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=883834)[0m Updating learning rate to 5.2520180339443986e-05
[36m(_train_fn pid=883834)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=883834)[0m saving checkpoint...
[36m(_train_fn pid=883834)[0m Epoch: 5 cost time: 1.6209712028503418
[36m(_train_fn pid=883834)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6087072 Vali Loss: 1.5981191 Best vali loss: 1.5898141
[36m(_train_fn pid=883834)[0m Early stopping

Trial trial-b7d049c3 started with configuration:
2024-08-24 11:03:42,683	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:03:44,781	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=884306)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b7d049c3_207_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1865,e_layers_2024-08-24_11-03-37/checkpoint_000001)[32m [repeated 2x across cluster][0m
2024-08-24 11:03:46,795	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:03:48,770	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:03:50,771	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=884306)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-b7d049c3_207_alpha_d_ff=3,batch_size=32,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1865,e_layers_2024-08-24_11-03-37/checkpoint_000004)[32m [repeated 3x across cluster][0m
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b7d049c3 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18654 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00116 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=884306)[0m configuration
[36m(_train_fn pid=884306)[0m {'batch_size': 32, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18654113034104666, 'e_layers': 1, 'learning_rate': 0.001164681695894244, 'd_ff': 96}
[36m(_train_fn pid=884306)[0m Use GPU: cuda:0
[36m(_train_fn pid=884306)[0m train 7825
[36m(_train_fn pid=884306)[0m val 2161
[36m(_train_fn pid=884306)[0m start_epoch 0
[36m(_train_fn pid=884306)[0m max_epoch 8
[36m(_train_fn pid=884306)[0m 	iters: 100, epoch: 1 | loss: 1.0977955
[36m(_train_fn pid=884306)[0m 	speed: 0.0145s/iter; left time: 26.8901s
[36m(_train_fn pid=884306)[0m 	iters: 200, epoch: 1 | loss: 0.9198949
[36m(_train_fn pid=884306)[0m 	speed: 0.0072s/iter; left time: 12.6497s
[36m(_train_fn pid=884306)[0m Updating learning rate to 0.001164681695894244
[36m(_train_fn pid=884306)[0m saving checkpoint...
[36m(_train_fn pid=884306)[0m Validation loss decreased (inf --> 2.0427).  Saving model state dict ...
[36m(_train_fn pid=884306)[0m 	iters: 100, epoch: 2 | loss: 0.5544127
[36m(_train_fn pid=884306)[0m 	speed: 0.0138s/iter; left time: 22.2167s
[36m(_train_fn pid=884306)[0m Epoch: 1 cost time: 2.224609375
[36m(_train_fn pid=884306)[0m Epoch: 1, Steps: 244 | Train Loss: 1.1707867 Vali Loss: 2.0427329 Best vali loss: 2.0427329
[36m(_train_fn pid=884306)[0m 	iters: 200, epoch: 2 | loss: 0.5535575
[36m(_train_fn pid=884306)[0m 	speed: 0.0072s/iter; left time: 10.8414s
[36m(_train_fn pid=884306)[0m Updating learning rate to 0.000582340847947122
[36m(_train_fn pid=884306)[0m saving checkpoint...
[36m(_train_fn pid=884306)[0m Validation loss decreased (2.0427 --> 1.5793).  Saving model state dict ...
[36m(_train_fn pid=884306)[0m Epoch: 2 cost time: 1.8032793998718262
[36m(_train_fn pid=884306)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6699047 Vali Loss: 1.5793228 Best vali loss: 1.5793228
[36m(_train_fn pid=884306)[0m 	iters: 100, epoch: 3 | loss: 0.5885884
[36m(_train_fn pid=884306)[0m 	speed: 0.0135s/iter; left time: 18.4218s
[36m(_train_fn pid=884306)[0m 	iters: 200, epoch: 3 | loss: 0.6240751
[36m(_train_fn pid=884306)[0m 	speed: 0.0068s/iter; left time: 8.5815s
[36m(_train_fn pid=884306)[0m Updating learning rate to 0.000291170423973561
[36m(_train_fn pid=884306)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=884306)[0m saving checkpoint...
[36m(_train_fn pid=884306)[0m Epoch: 3 cost time: 1.7053186893463135
[36m(_train_fn pid=884306)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6161123 Vali Loss: 1.5802720 Best vali loss: 1.5793228
[36m(_train_fn pid=884306)[0m 	iters: 100, epoch: 4 | loss: 0.6605653
[36m(_train_fn pid=884306)[0m 	speed: 0.0133s/iter; left time: 14.9112s
[36m(_train_fn pid=884306)[0m 	iters: 200, epoch: 4 | loss: 0.5983346
[36m(_train_fn pid=884306)[0m 	speed: 0.0066s/iter; left time: 6.7660s
[36m(_train_fn pid=884306)[0m Updating learning rate to 0.0001455852119867805
[36m(_train_fn pid=884306)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=884306)[0m saving checkpoint...
[36m(_train_fn pid=884306)[0m Epoch: 4 cost time: 1.68351411819458
[36m(_train_fn pid=884306)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6106179 Vali Loss: 1.5859509 Best vali loss: 1.5793228
[36m(_train_fn pid=884306)[0m 	iters: 100, epoch: 5 | loss: 0.5594981
[36m(_train_fn pid=884306)[0m 	speed: 0.0130s/iter; left time: 11.4355s
[36m(_train_fn pid=884306)[0m 	iters: 200, epoch: 5 | loss: 0.5810494
[36m(_train_fn pid=884306)[0m 	speed: 0.0068s/iter; left time: 5.2709s

Trial trial-b7d049c3 completed after 5 iterations at 2024-08-24 11:03:50. Total running time: 3hr 42min 42s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-b7d049c3 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          1.99034 â”‚
â”‚ time_total_s                             11.00051 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.57932 â”‚
â”‚ train_loss                                0.60868 â”‚
â”‚ valid_loss                                1.58616 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=884306)[0m Updating learning rate to 7.279260599339025e-05
[36m(_train_fn pid=884306)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=884306)[0m saving checkpoint...
[36m(_train_fn pid=884306)[0m Epoch: 5 cost time: 1.6938128471374512
[36m(_train_fn pid=884306)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6086843 Vali Loss: 1.5861603 Best vali loss: 1.5793228
[36m(_train_fn pid=884306)[0m Early stopping

Trial trial-c51ecaa3 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c51ecaa3 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                             0.1955 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0006 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=884784)[0m configuration
[36m(_train_fn pid=884784)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1954953746219174, 'e_layers': 1, 'learning_rate': 0.0005951851971070625, 'd_ff': 1536}
[36m(_train_fn pid=884784)[0m Use GPU: cuda:0
[36m(_train_fn pid=884784)[0m train 7825
[36m(_train_fn pid=884784)[0m val 2161
[36m(_train_fn pid=884784)[0m start_epoch 0
[36m(_train_fn pid=884784)[0m max_epoch 8
[36m(_train_fn pid=884784)[0m 	iters: 100, epoch: 1 | loss: 0.7951576
[36m(_train_fn pid=884784)[0m 	speed: 0.0432s/iter; left time: 164.8722s
[36m(_train_fn pid=884784)[0m 	iters: 200, epoch: 1 | loss: 0.7985792
[36m(_train_fn pid=884784)[0m 	speed: 0.0365s/iter; left time: 135.6063s

Trial status: 207 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:04:01. Total running time: 3hr 42min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=884784)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c51ecaa3_208_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1955,e_layer_2024-08-24_11-03-50/checkpoint_000000)
2024-08-24 11:04:13,738	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=884784)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c51ecaa3_208_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1955,e_layer_2024-08-24_11-03-50/checkpoint_000001)
2024-08-24 11:04:33,939	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:04:54,184	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=884784)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c51ecaa3_208_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1955,e_layer_2024-08-24_11-03-50/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c51ecaa3   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
202 more TERMINATED
[36m(_train_fn pid=884784)[0m 	iters: 300, epoch: 1 | loss: 0.7234375
[36m(_train_fn pid=884784)[0m 	speed: 0.0365s/iter; left time: 132.0043s
[36m(_train_fn pid=884784)[0m 	iters: 400, epoch: 1 | loss: 0.6295574
[36m(_train_fn pid=884784)[0m 	speed: 0.0366s/iter; left time: 128.5315s
[36m(_train_fn pid=884784)[0m Updating learning rate to 0.0005951851971070625
[36m(_train_fn pid=884784)[0m saving checkpoint...
[36m(_train_fn pid=884784)[0m Validation loss decreased (inf --> 1.8994).  Saving model state dict ...
[36m(_train_fn pid=884784)[0m Epoch: 1 cost time: 18.28533697128296
[36m(_train_fn pid=884784)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7875602 Vali Loss: 1.8994205 Best vali loss: 1.8994205
[36m(_train_fn pid=884784)[0m 	iters: 100, epoch: 2 | loss: 0.7397906
[36m(_train_fn pid=884784)[0m 	speed: 0.0921s/iter; left time: 306.0070s
[36m(_train_fn pid=884784)[0m 	iters: 200, epoch: 2 | loss: 0.6326554
[36m(_train_fn pid=884784)[0m 	speed: 0.0366s/iter; left time: 118.0824s
[36m(_train_fn pid=884784)[0m 	iters: 300, epoch: 2 | loss: 0.6698461
[36m(_train_fn pid=884784)[0m 	speed: 0.0366s/iter; left time: 114.4684s
[36m(_train_fn pid=884784)[0m 	iters: 400, epoch: 2 | loss: 0.6509153
[36m(_train_fn pid=884784)[0m 	speed: 0.0367s/iter; left time: 110.8727s
Trial status: 207 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:04:31. Total running time: 3hr 43min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c51ecaa3   RUNNING           1            20.9609       0.78756         1.89942             1.89942 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
202 more TERMINATED
[36m(_train_fn pid=884784)[0m Updating learning rate to 0.00029759259855353124
[36m(_train_fn pid=884784)[0m saving checkpoint...
[36m(_train_fn pid=884784)[0m Validation loss decreased (1.8994 --> 1.5651).  Saving model state dict ...
[36m(_train_fn pid=884784)[0m Epoch: 2 cost time: 17.952119827270508
[36m(_train_fn pid=884784)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6515252 Vali Loss: 1.5651490 Best vali loss: 1.5651490
[36m(_train_fn pid=884784)[0m 	iters: 100, epoch: 3 | loss: 0.6511068
[36m(_train_fn pid=884784)[0m 	speed: 0.0922s/iter; left time: 261.3724s
[36m(_train_fn pid=884784)[0m 	iters: 200, epoch: 3 | loss: 0.6791296
[36m(_train_fn pid=884784)[0m 	speed: 0.0367s/iter; left time: 100.4480s
[36m(_train_fn pid=884784)[0m 	iters: 300, epoch: 3 | loss: 0.5885705
[36m(_train_fn pid=884784)[0m 	speed: 0.0367s/iter; left time: 96.7356s
[36m(_train_fn pid=884784)[0m 	iters: 400, epoch: 3 | loss: 0.6691614
[36m(_train_fn pid=884784)[0m 	speed: 0.0368s/iter; left time: 93.1639s
[36m(_train_fn pid=884784)[0m Updating learning rate to 0.00014879629927676562
[36m(_train_fn pid=884784)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=884784)[0m saving checkpoint...
[36m(_train_fn pid=884784)[0m Epoch: 3 cost time: 17.98500633239746
[36m(_train_fn pid=884784)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6120617 Vali Loss: 1.5690109 Best vali loss: 1.5651490
[36m(_train_fn pid=884784)[0m 	iters: 100, epoch: 4 | loss: 0.5848008
[36m(_train_fn pid=884784)[0m 	speed: 0.0922s/iter; left time: 216.2746s
Trial status: 207 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:05:01. Total running time: 3hr 43min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
2024-08-24 11:05:14,459	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=884784)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c51ecaa3_208_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1955,e_layer_2024-08-24_11-03-50/checkpoint_000003)
2024-08-24 11:05:34,743	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=884784)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c51ecaa3_208_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1955,e_layer_2024-08-24_11-03-50/checkpoint_000004)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c51ecaa3   RUNNING           3            61.3984       0.612062        1.56901             1.56515 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
202 more TERMINATED
[36m(_train_fn pid=884784)[0m 	iters: 200, epoch: 4 | loss: 0.5794806
[36m(_train_fn pid=884784)[0m 	speed: 0.0368s/iter; left time: 82.6196s
[36m(_train_fn pid=884784)[0m 	iters: 300, epoch: 4 | loss: 0.6933781
[36m(_train_fn pid=884784)[0m 	speed: 0.0367s/iter; left time: 78.8400s
[36m(_train_fn pid=884784)[0m 	iters: 400, epoch: 4 | loss: 0.6408072
[36m(_train_fn pid=884784)[0m 	speed: 0.0368s/iter; left time: 75.2105s
[36m(_train_fn pid=884784)[0m Updating learning rate to 7.439814963838281e-05
[36m(_train_fn pid=884784)[0m saving checkpoint...
[36m(_train_fn pid=884784)[0m Validation loss decreased (1.5651 --> 1.5633).  Saving model state dict ...
[36m(_train_fn pid=884784)[0m Epoch: 4 cost time: 17.998347759246826
[36m(_train_fn pid=884784)[0m Epoch: 4, Steps: 489 | Train Loss: 0.6087602 Vali Loss: 1.5633194 Best vali loss: 1.5633194
[36m(_train_fn pid=884784)[0m 	iters: 100, epoch: 5 | loss: 0.5015929
[36m(_train_fn pid=884784)[0m 	speed: 0.0926s/iter; left time: 171.9033s
[36m(_train_fn pid=884784)[0m 	iters: 200, epoch: 5 | loss: 0.5983955
[36m(_train_fn pid=884784)[0m 	speed: 0.0368s/iter; left time: 64.5747s
[36m(_train_fn pid=884784)[0m 	iters: 300, epoch: 5 | loss: 0.5669187
[36m(_train_fn pid=884784)[0m 	speed: 0.0368s/iter; left time: 60.9523s
[36m(_train_fn pid=884784)[0m 	iters: 400, epoch: 5 | loss: 0.4327445
[36m(_train_fn pid=884784)[0m 	speed: 0.0368s/iter; left time: 57.2519s
Trial status: 207 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:05:31. Total running time: 3hr 44min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c51ecaa3   RUNNING           4            81.6693       0.60876         1.56332             1.56332 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
202 more TERMINATED
[36m(_train_fn pid=884784)[0m Updating learning rate to 3.7199074819191404e-05
[36m(_train_fn pid=884784)[0m saving checkpoint...
[36m(_train_fn pid=884784)[0m Validation loss decreased (1.5633 --> 1.5616).  Saving model state dict ...

Trial trial-c51ecaa3 completed after 5 iterations at 2024-08-24 11:05:34. Total running time: 3hr 44min 25s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c51ecaa3 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         20.28719 â”‚
â”‚ time_total_s                            101.95652 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56159 â”‚
â”‚ train_loss                                0.60672 â”‚
â”‚ valid_loss                                1.56159 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-357752e6 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-357752e6 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19442 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00064 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=885531)[0m configuration
[36m(_train_fn pid=885531)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19442213265854993, 'e_layers': 1, 'learning_rate': 0.0006398194364175005, 'd_ff': 1536}
[36m(_train_fn pid=885531)[0m Use GPU: cuda:0
[36m(_train_fn pid=885531)[0m train 7825
[36m(_train_fn pid=885531)[0m val 2161
2024-08-24 11:05:56,868	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=885531)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-357752e6_209_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1944,e_layer_2024-08-24_11-05-34/checkpoint_000000)
[36m(_train_fn pid=885531)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-357752e6_209_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1944,e_layer_2024-08-24_11-05-34/checkpoint_000001)
[36m(_train_fn pid=885531)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-357752e6_209_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1944,e_layer_2024-08-24_11-05-34/checkpoint_000002)
[36m(_train_fn pid=885531)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-357752e6_209_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1944,e_layer_2024-08-24_11-05-34/checkpoint_000003)
[36m(_train_fn pid=885531)[0m start_epoch 0
[36m(_train_fn pid=885531)[0m max_epoch 8
[36m(_train_fn pid=885531)[0m 	iters: 100, epoch: 1 | loss: 0.8534586
[36m(_train_fn pid=885531)[0m 	speed: 0.0767s/iter; left time: 142.1033s
[36m(_train_fn pid=885531)[0m 	iters: 200, epoch: 1 | loss: 0.6625567
[36m(_train_fn pid=885531)[0m 	speed: 0.0703s/iter; left time: 123.1678s
[36m(_train_fn pid=885531)[0m Updating learning rate to 0.0006398194364175005
[36m(_train_fn pid=885531)[0m saving checkpoint...
[36m(_train_fn pid=885531)[0m Validation loss decreased (inf --> 1.9267).  Saving model state dict ...
[36m(_train_fn pid=885531)[0m Epoch: 1 cost time: 17.532113313674927
[36m(_train_fn pid=885531)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8109344 Vali Loss: 1.9267194 Best vali loss: 1.9267194

Trial status: 208 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:06:01. Total running time: 3hr 44min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-357752e6   RUNNING           1            20.1229       0.810934        1.92672             1.92672 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
203 more TERMINATED
[36m(_train_fn pid=885531)[0m 	iters: 100, epoch: 2 | loss: 0.6366339
[36m(_train_fn pid=885531)[0m 	speed: 0.1229s/iter; left time: 197.6827s
[36m(_train_fn pid=885531)[0m 	iters: 200, epoch: 2 | loss: 0.6942570
[36m(_train_fn pid=885531)[0m 	speed: 0.0702s/iter; left time: 105.9047s
[36m(_train_fn pid=885531)[0m Updating learning rate to 0.00031990971820875023
[36m(_train_fn pid=885531)[0m saving checkpoint...
[36m(_train_fn pid=885531)[0m Validation loss decreased (1.9267 --> 1.5688).  Saving model state dict ...
[36m(_train_fn pid=885531)[0m Epoch: 2 cost time: 17.126579999923706
[36m(_train_fn pid=885531)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6737268 Vali Loss: 1.5688268 Best vali loss: 1.5688268
[36m(_train_fn pid=885531)[0m 	iters: 100, epoch: 3 | loss: 0.6696890
[36m(_train_fn pid=885531)[0m 	speed: 0.1229s/iter; left time: 167.7799s
[36m(_train_fn pid=885531)[0m 	iters: 200, epoch: 3 | loss: 0.6287891
[36m(_train_fn pid=885531)[0m 	speed: 0.0703s/iter; left time: 88.8867s
Trial status: 208 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:06:31. Total running time: 3hr 45min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-357752e6   RUNNING           2            39.4138       0.673727        1.56883             1.56883 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
203 more TERMINATED
[36m(_train_fn pid=885531)[0m Updating learning rate to 0.00015995485910437512
[36m(_train_fn pid=885531)[0m saving checkpoint...
[36m(_train_fn pid=885531)[0m Validation loss decreased (1.5688 --> 1.5683).  Saving model state dict ...
[36m(_train_fn pid=885531)[0m Epoch: 3 cost time: 17.15556812286377
[36m(_train_fn pid=885531)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6159952 Vali Loss: 1.5682830 Best vali loss: 1.5682830
[36m(_train_fn pid=885531)[0m 	iters: 100, epoch: 4 | loss: 0.6366085
[36m(_train_fn pid=885531)[0m 	speed: 0.1229s/iter; left time: 137.7786s
[36m(_train_fn pid=885531)[0m 	iters: 200, epoch: 4 | loss: 0.6360348
[36m(_train_fn pid=885531)[0m 	speed: 0.0703s/iter; left time: 71.7316s
[36m(_train_fn pid=885531)[0m Updating learning rate to 7.997742955218756e-05
[36m(_train_fn pid=885531)[0m saving checkpoint...
[36m(_train_fn pid=885531)[0m Validation loss decreased (1.5683 --> 1.5649).  Saving model state dict ...
[36m(_train_fn pid=885531)[0m Epoch: 4 cost time: 17.14431405067444
[36m(_train_fn pid=885531)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6119067 Vali Loss: 1.5648679 Best vali loss: 1.5648679
Trial status: 208 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:07:01. Total running time: 3hr 45min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=885531)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-357752e6_209_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1944,e_layer_2024-08-24_11-05-34/checkpoint_000004)
[36m(_train_fn pid=885531)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-357752e6_209_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1944,e_layer_2024-08-24_11-05-34/checkpoint_000005)
2024-08-24 11:07:45,604	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=886391)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c133f168_210_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1925,e_layer_2024-08-24_11-07-33/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-357752e6   RUNNING           4            78.0384       0.611907        1.56487             1.56487 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
203 more TERMINATED
[36m(_train_fn pid=885531)[0m 	iters: 100, epoch: 5 | loss: 0.6056973
[36m(_train_fn pid=885531)[0m 	speed: 0.1229s/iter; left time: 107.7920s
[36m(_train_fn pid=885531)[0m 	iters: 200, epoch: 5 | loss: 0.5444072
[36m(_train_fn pid=885531)[0m 	speed: 0.0702s/iter; left time: 54.5240s
[36m(_train_fn pid=885531)[0m Updating learning rate to 3.998871477609378e-05
[36m(_train_fn pid=885531)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=885531)[0m saving checkpoint...
[36m(_train_fn pid=885531)[0m Epoch: 5 cost time: 17.137553691864014
[36m(_train_fn pid=885531)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6099008 Vali Loss: 1.5713709 Best vali loss: 1.5648679
[36m(_train_fn pid=885531)[0m 	iters: 100, epoch: 6 | loss: 0.5823594
[36m(_train_fn pid=885531)[0m 	speed: 0.1224s/iter; left time: 77.5044s
[36m(_train_fn pid=885531)[0m 	iters: 200, epoch: 6 | loss: 0.5946827
[36m(_train_fn pid=885531)[0m 	speed: 0.0700s/iter; left time: 37.3193s
Trial status: 208 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:07:31. Total running time: 3hr 46min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-357752e6   RUNNING           5            97.316        0.609901        1.57137             1.56487 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
203 more TERMINATED

Trial trial-357752e6 completed after 6 iterations at 2024-08-24 11:07:33. Total running time: 3hr 46min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-357752e6 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.26897 â”‚
â”‚ time_total_s                            116.58492 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56183 â”‚
â”‚ train_loss                                0.60916 â”‚
â”‚ valid_loss                                1.56183 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=885531)[0m Updating learning rate to 1.999435738804689e-05
[36m(_train_fn pid=885531)[0m saving checkpoint...
[36m(_train_fn pid=885531)[0m Validation loss decreased (1.5649 --> 1.5618).  Saving model state dict ...

Trial trial-c133f168 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c133f168 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.19248 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                       0.0005 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=886391)[0m configuration
[36m(_train_fn pid=886391)[0m {'batch_size': 32, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.19247712909575532, 'e_layers': 1, 'learning_rate': 0.0005035578520545156, 'd_ff': 768}
[36m(_train_fn pid=886391)[0m Use GPU: cuda:0
[36m(_train_fn pid=886391)[0m train 7825
[36m(_train_fn pid=886391)[0m val 2161
[36m(_train_fn pid=886391)[0m start_epoch 0
[36m(_train_fn pid=886391)[0m max_epoch 8
[36m(_train_fn pid=886391)[0m 	iters: 100, epoch: 1 | loss: 0.7684157
[36m(_train_fn pid=886391)[0m 	speed: 0.0394s/iter; left time: 72.9447s
[36m(_train_fn pid=886391)[0m 	iters: 200, epoch: 1 | loss: 0.8043583
[36m(_train_fn pid=886391)[0m 	speed: 0.0324s/iter; left time: 56.7216s
[36m(_train_fn pid=886391)[0m Updating learning rate to 0.0005035578520545156
[36m(_train_fn pid=886391)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c133f168_210_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1925,e_layer_2024-08-24_11-07-33/checkpoint_000001)
[36m(_train_fn pid=886391)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c133f168_210_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1925,e_layer_2024-08-24_11-07-33/checkpoint_000002)
[36m(_train_fn pid=886391)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c133f168_210_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1925,e_layer_2024-08-24_11-07-33/checkpoint_000003)
[36m(_train_fn pid=886391)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c133f168_210_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1925,e_layer_2024-08-24_11-07-33/checkpoint_000004)
[36m(_train_fn pid=886391)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c133f168_210_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1925,e_layer_2024-08-24_11-07-33/checkpoint_000005)
[36m(_train_fn pid=886391)[0m saving checkpoint...
[36m(_train_fn pid=886391)[0m Validation loss decreased (inf --> 1.9710).  Saving model state dict ...
[36m(_train_fn pid=886391)[0m Epoch: 1 cost time: 8.338762044906616
[36m(_train_fn pid=886391)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8453848 Vali Loss: 1.9709932 Best vali loss: 1.9709932
[36m(_train_fn pid=886391)[0m 	iters: 100, epoch: 2 | loss: 0.6738947
[36m(_train_fn pid=886391)[0m 	speed: 0.0579s/iter; left time: 93.1358s
[36m(_train_fn pid=886391)[0m 	iters: 200, epoch: 2 | loss: 0.5926793
[36m(_train_fn pid=886391)[0m 	speed: 0.0324s/iter; left time: 48.9169s
[36m(_train_fn pid=886391)[0m Updating learning rate to 0.0002517789260272578
[36m(_train_fn pid=886391)[0m saving checkpoint...
[36m(_train_fn pid=886391)[0m Validation loss decreased (1.9710 --> 1.5768).  Saving model state dict ...
[36m(_train_fn pid=886391)[0m Epoch: 2 cost time: 7.946345567703247
[36m(_train_fn pid=886391)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6671427 Vali Loss: 1.5768457 Best vali loss: 1.5768457
[36m(_train_fn pid=886391)[0m 	iters: 100, epoch: 3 | loss: 0.5621173
[36m(_train_fn pid=886391)[0m 	speed: 0.0579s/iter; left time: 79.0137s
[36m(_train_fn pid=886391)[0m 	iters: 200, epoch: 3 | loss: 0.5650196
[36m(_train_fn pid=886391)[0m 	speed: 0.0325s/iter; left time: 41.1001s

Trial status: 209 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:08:01. Total running time: 3hr 46min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c133f168   RUNNING           2            18.8553       0.667143        1.57685             1.57685 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
204 more TERMINATED
[36m(_train_fn pid=886391)[0m Updating learning rate to 0.0001258894630136289
[36m(_train_fn pid=886391)[0m saving checkpoint...
[36m(_train_fn pid=886391)[0m Validation loss decreased (1.5768 --> 1.5717).  Saving model state dict ...
[36m(_train_fn pid=886391)[0m Epoch: 3 cost time: 7.963721990585327
[36m(_train_fn pid=886391)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6189566 Vali Loss: 1.5717209 Best vali loss: 1.5717209
[36m(_train_fn pid=886391)[0m 	iters: 100, epoch: 4 | loss: 0.6594841
[36m(_train_fn pid=886391)[0m 	speed: 0.0581s/iter; left time: 65.1570s
[36m(_train_fn pid=886391)[0m 	iters: 200, epoch: 4 | loss: 0.5953332
[36m(_train_fn pid=886391)[0m 	speed: 0.0325s/iter; left time: 33.1767s
[36m(_train_fn pid=886391)[0m Updating learning rate to 6.294473150681444e-05
[36m(_train_fn pid=886391)[0m saving checkpoint...
[36m(_train_fn pid=886391)[0m Validation loss decreased (1.5717 --> 1.5686).  Saving model state dict ...
[36m(_train_fn pid=886391)[0m Epoch: 4 cost time: 7.966667175292969
[36m(_train_fn pid=886391)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6161502 Vali Loss: 1.5686442 Best vali loss: 1.5686442
[36m(_train_fn pid=886391)[0m 	iters: 100, epoch: 5 | loss: 0.5373073
[36m(_train_fn pid=886391)[0m 	speed: 0.0580s/iter; left time: 50.8980s
[36m(_train_fn pid=886391)[0m 	iters: 200, epoch: 5 | loss: 0.5477715
[36m(_train_fn pid=886391)[0m 	speed: 0.0326s/iter; left time: 25.2938s
[36m(_train_fn pid=886391)[0m Updating learning rate to 3.147236575340722e-05
[36m(_train_fn pid=886391)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=886391)[0m saving checkpoint...
[36m(_train_fn pid=886391)[0m Epoch: 5 cost time: 7.962981224060059
[36m(_train_fn pid=886391)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6144793 Vali Loss: 1.5687367 Best vali loss: 1.5686442
[36m(_train_fn pid=886391)[0m 	iters: 100, epoch: 6 | loss: 0.6225719
[36m(_train_fn pid=886391)[0m 	speed: 0.0579s/iter; left time: 36.6427s
[36m(_train_fn pid=886391)[0m 	iters: 200, epoch: 6 | loss: 0.6426061
[36m(_train_fn pid=886391)[0m 	speed: 0.0326s/iter; left time: 17.3836s
[36m(_train_fn pid=886391)[0m Updating learning rate to 1.573618287670361e-05
[36m(_train_fn pid=886391)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=886391)[0m saving checkpoint...
[36m(_train_fn pid=886391)[0m Epoch: 6 cost time: 7.981418132781982
[36m(_train_fn pid=886391)[0m Epoch: 6, Steps: 244 | Train Loss: 0.6139022 Vali Loss: 1.5712930 Best vali loss: 1.5686442
Trial status: 209 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:08:31. Total running time: 3hr 47min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=886391)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-c133f168_210_alpha_d_ff=3,batch_size=32,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1925,e_layer_2024-08-24_11-07-33/checkpoint_000006)
[36m(_train_fn pid=887163)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-900a3892_211_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1726,e_layer_2024-08-24_11-08-39/checkpoint_000000)
[36m(_train_fn pid=887163)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-900a3892_211_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1726,e_layer_2024-08-24_11-08-39/checkpoint_000001)
2024-08-24 11:08:51,748	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:08:56,362	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=887163)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-900a3892_211_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1726,e_layer_2024-08-24_11-08-39/checkpoint_000002)
2024-08-24 11:09:00,965	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=887163)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-900a3892_211_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1726,e_layer_2024-08-24_11-08-39/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-c133f168   RUNNING           6            55.0491       0.613902        1.57129             1.56864 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
204 more TERMINATED
[36m(_train_fn pid=886391)[0m 	iters: 100, epoch: 7 | loss: 0.5233487
[36m(_train_fn pid=886391)[0m 	speed: 0.0580s/iter; left time: 22.5454s
[36m(_train_fn pid=886391)[0m 	iters: 200, epoch: 7 | loss: 0.6407568
[36m(_train_fn pid=886391)[0m 	speed: 0.0326s/iter; left time: 9.4293s

Trial trial-c133f168 completed after 7 iterations at 2024-08-24 11:08:39. Total running time: 3hr 47min 31s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c133f168 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000006 â”‚
â”‚ time_this_iter_s                          9.07536 â”‚
â”‚ time_total_s                             64.12444 â”‚
â”‚ training_iteration                              7 â”‚
â”‚ best_valid_loss                           1.56864 â”‚
â”‚ train_loss                                0.61348 â”‚
â”‚ valid_loss                                1.56973 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=886391)[0m Updating learning rate to 7.868091438351806e-06
[36m(_train_fn pid=886391)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=886391)[0m saving checkpoint...
[36m(_train_fn pid=886391)[0m Epoch: 7 cost time: 7.98501181602478
[36m(_train_fn pid=886391)[0m Epoch: 7, Steps: 244 | Train Loss: 0.6134807 Vali Loss: 1.5697281 Best vali loss: 1.5686442
[36m(_train_fn pid=886391)[0m Early stopping

Trial trial-900a3892 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-900a3892 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.17261 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00242 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=887163)[0m configuration
[36m(_train_fn pid=887163)[0m {'batch_size': 32, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.1726124274522731, 'e_layers': 1, 'learning_rate': 0.0024243021300306587, 'd_ff': 384}
[36m(_train_fn pid=887163)[0m Use GPU: cuda:0
[36m(_train_fn pid=887163)[0m train 7825
[36m(_train_fn pid=887163)[0m val 2161
[36m(_train_fn pid=887163)[0m start_epoch 0
[36m(_train_fn pid=887163)[0m max_epoch 8
[36m(_train_fn pid=887163)[0m 	iters: 100, epoch: 1 | loss: 0.7973882
[36m(_train_fn pid=887163)[0m 	speed: 0.0232s/iter; left time: 43.0582s
[36m(_train_fn pid=887163)[0m 	iters: 200, epoch: 1 | loss: 0.7918940
[36m(_train_fn pid=887163)[0m 	speed: 0.0162s/iter; left time: 28.4061s
[36m(_train_fn pid=887163)[0m Updating learning rate to 0.0024243021300306587
[36m(_train_fn pid=887163)[0m saving checkpoint...
[36m(_train_fn pid=887163)[0m Validation loss decreased (inf --> 1.7768).  Saving model state dict ...
[36m(_train_fn pid=887163)[0m Epoch: 1 cost time: 4.400330066680908
[36m(_train_fn pid=887163)[0m Epoch: 1, Steps: 244 | Train Loss: 0.7800321 Vali Loss: 1.7768070 Best vali loss: 1.7768070
[36m(_train_fn pid=887163)[0m 	iters: 100, epoch: 2 | loss: 0.6345193
[36m(_train_fn pid=887163)[0m 	speed: 0.0298s/iter; left time: 47.9402s
[36m(_train_fn pid=887163)[0m 	iters: 200, epoch: 2 | loss: 0.6832867
[36m(_train_fn pid=887163)[0m 	speed: 0.0162s/iter; left time: 24.4580s
[36m(_train_fn pid=887163)[0m Updating learning rate to 0.0012121510650153293
[36m(_train_fn pid=887163)[0m saving checkpoint...
[36m(_train_fn pid=887163)[0m Validation loss decreased (1.7768 --> 1.5761).  Saving model state dict ...
[36m(_train_fn pid=887163)[0m Epoch: 2 cost time: 3.9989991188049316
[36m(_train_fn pid=887163)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6248505 Vali Loss: 1.5760541 Best vali loss: 1.5760541
[36m(_train_fn pid=887163)[0m 	iters: 100, epoch: 3 | loss: 0.5690278
[36m(_train_fn pid=887163)[0m 	speed: 0.0298s/iter; left time: 40.6790s
[36m(_train_fn pid=887163)[0m 	iters: 200, epoch: 3 | loss: 0.5198296
[36m(_train_fn pid=887163)[0m 	speed: 0.0163s/iter; left time: 20.6063s
[36m(_train_fn pid=887163)[0m Updating learning rate to 0.0006060755325076647
[36m(_train_fn pid=887163)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=887163)[0m saving checkpoint...
[36m(_train_fn pid=887163)[0m Epoch: 3 cost time: 4.014307498931885
[36m(_train_fn pid=887163)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6007993 Vali Loss: 1.5917153 Best vali loss: 1.5760541
[36m(_train_fn pid=887163)[0m 	iters: 100, epoch: 4 | loss: 0.6485016
[36m(_train_fn pid=887163)[0m 	speed: 0.0299s/iter; left time: 33.4994s
[36m(_train_fn pid=887163)[0m 	iters: 200, epoch: 4 | loss: 0.5196611
[36m(_train_fn pid=887163)[0m 	speed: 0.0162s/iter; left time: 16.5583s
[36m(_train_fn pid=887163)[0m Updating learning rate to 0.00030303776625383234
[36m(_train_fn pid=887163)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=887163)[0m saving checkpoint...
[36m(_train_fn pid=887163)[0m Epoch: 4 cost time: 3.999732255935669
[36m(_train_fn pid=887163)[0m Epoch: 4, Steps: 244 | Train Loss: 0.5832393 Vali Loss: 1.5984086 Best vali loss: 1.5760541

Trial status: 210 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:09:01. Total running time: 3hr 47min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
[36m(_train_fn pid=887163)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-900a3892_211_alpha_d_ff=3,batch_size=32,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1726,e_layer_2024-08-24_11-08-39/checkpoint_000004)
2024-08-24 11:09:05,569	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=887677)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-53826d9b_212_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1871,e_layer_2024-08-24_11-09-05/checkpoint_000000)
2024-08-24 11:09:27,807	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-900a3892   RUNNING           4            19.2153       0.583239        1.59841             1.57605 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
205 more TERMINATED
[36m(_train_fn pid=887163)[0m 	iters: 100, epoch: 5 | loss: 0.5138083
[36m(_train_fn pid=887163)[0m 	speed: 0.0299s/iter; left time: 26.1928s
[36m(_train_fn pid=887163)[0m 	iters: 200, epoch: 5 | loss: 0.5795499
[36m(_train_fn pid=887163)[0m 	speed: 0.0162s/iter; left time: 12.6228s
[36m(_train_fn pid=887163)[0m Updating learning rate to 0.00015151888312691617
[36m(_train_fn pid=887163)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=887163)[0m saving checkpoint...
[36m(_train_fn pid=887163)[0m Epoch: 5 cost time: 3.9995172023773193
[36m(_train_fn pid=887163)[0m Epoch: 5, Steps: 244 | Train Loss: 0.5707626 Vali Loss: 1.6063484 Best vali loss: 1.5760541
[36m(_train_fn pid=887163)[0m Early stopping

Trial trial-900a3892 completed after 5 iterations at 2024-08-24 11:09:05. Total running time: 3hr 47min 56s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-900a3892 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          4.59584 â”‚
â”‚ time_total_s                             23.81111 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.57605 â”‚
â”‚ train_loss                                0.57076 â”‚
â”‚ valid_loss                                1.60635 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-53826d9b started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-53826d9b config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              32 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.18714 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00078 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=887677)[0m configuration
[36m(_train_fn pid=887677)[0m {'batch_size': 32, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.18714202844144545, 'e_layers': 1, 'learning_rate': 0.0007785114135469471, 'd_ff': 1536}
[36m(_train_fn pid=887677)[0m Use GPU: cuda:0
[36m(_train_fn pid=887677)[0m train 7825
[36m(_train_fn pid=887677)[0m val 2161
[36m(_train_fn pid=887677)[0m start_epoch 0
[36m(_train_fn pid=887677)[0m max_epoch 8
[36m(_train_fn pid=887677)[0m 	iters: 100, epoch: 1 | loss: 0.8448717
[36m(_train_fn pid=887677)[0m 	speed: 0.0765s/iter; left time: 141.8328s
[36m(_train_fn pid=887677)[0m 	iters: 200, epoch: 1 | loss: 0.6574989
[36m(_train_fn pid=887677)[0m 	speed: 0.0701s/iter; left time: 122.8575s
[36m(_train_fn pid=887677)[0m Updating learning rate to 0.0007785114135469471
[36m(_train_fn pid=887677)[0m saving checkpoint...
[36m(_train_fn pid=887677)[0m Validation loss decreased (inf --> 1.9210).  Saving model state dict ...
[36m(_train_fn pid=887677)[0m Epoch: 1 cost time: 17.48245334625244
[36m(_train_fn pid=887677)[0m Epoch: 1, Steps: 244 | Train Loss: 0.8037004 Vali Loss: 1.9209534 Best vali loss: 1.9209534

Trial status: 211 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:09:31. Total running time: 3hr 48min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=887677)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-53826d9b_212_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1871,e_layer_2024-08-24_11-09-05/checkpoint_000001)
[36m(_train_fn pid=887677)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-53826d9b_212_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1871,e_layer_2024-08-24_11-09-05/checkpoint_000002)
[36m(_train_fn pid=887677)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-53826d9b_212_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1871,e_layer_2024-08-24_11-09-05/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-53826d9b   RUNNING           1            20.0581       0.8037          1.92095             1.92095 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
206 more TERMINATED
[36m(_train_fn pid=887677)[0m 	iters: 100, epoch: 2 | loss: 0.6360984
[36m(_train_fn pid=887677)[0m 	speed: 0.1228s/iter; left time: 197.6506s
[36m(_train_fn pid=887677)[0m 	iters: 200, epoch: 2 | loss: 0.6906300
[36m(_train_fn pid=887677)[0m 	speed: 0.0701s/iter; left time: 105.8394s
[36m(_train_fn pid=887677)[0m Updating learning rate to 0.00038925570677347354
[36m(_train_fn pid=887677)[0m saving checkpoint...
[36m(_train_fn pid=887677)[0m Validation loss decreased (1.9210 --> 1.5843).  Saving model state dict ...
[36m(_train_fn pid=887677)[0m Epoch: 2 cost time: 17.136411905288696
[36m(_train_fn pid=887677)[0m Epoch: 2, Steps: 244 | Train Loss: 0.6888057 Vali Loss: 1.5842652 Best vali loss: 1.5842652
[36m(_train_fn pid=887677)[0m 	iters: 100, epoch: 3 | loss: 0.6670632
[36m(_train_fn pid=887677)[0m 	speed: 0.1230s/iter; left time: 167.9170s
[36m(_train_fn pid=887677)[0m 	iters: 200, epoch: 3 | loss: 0.6299309
[36m(_train_fn pid=887677)[0m 	speed: 0.0703s/iter; left time: 88.9486s
Trial status: 211 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:10:01. Total running time: 3hr 48min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-53826d9b   RUNNING           2            39.3633       0.688806        1.58427             1.58427 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
206 more TERMINATED
[36m(_train_fn pid=887677)[0m Updating learning rate to 0.00019462785338673677
[36m(_train_fn pid=887677)[0m saving checkpoint...
[36m(_train_fn pid=887677)[0m Validation loss decreased (1.5843 --> 1.5656).  Saving model state dict ...
[36m(_train_fn pid=887677)[0m Epoch: 3 cost time: 17.161041021347046
[36m(_train_fn pid=887677)[0m Epoch: 3, Steps: 244 | Train Loss: 0.6154829 Vali Loss: 1.5656435 Best vali loss: 1.5656435
[36m(_train_fn pid=887677)[0m 	iters: 100, epoch: 4 | loss: 0.6310571
[36m(_train_fn pid=887677)[0m 	speed: 0.1230s/iter; left time: 137.8899s
[36m(_train_fn pid=887677)[0m 	iters: 200, epoch: 4 | loss: 0.6352189
[36m(_train_fn pid=887677)[0m 	speed: 0.0703s/iter; left time: 71.7256s
[36m(_train_fn pid=887677)[0m Updating learning rate to 9.731392669336839e-05
[36m(_train_fn pid=887677)[0m saving checkpoint...
[36m(_train_fn pid=887677)[0m Validation loss decreased (1.5656 --> 1.5644).  Saving model state dict ...
[36m(_train_fn pid=887677)[0m Epoch: 4 cost time: 17.15722370147705
[36m(_train_fn pid=887677)[0m Epoch: 4, Steps: 244 | Train Loss: 0.6115675 Vali Loss: 1.5643891 Best vali loss: 1.5643891
Trial status: 211 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:10:31. Total running time: 3hr 49min 22s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
[36m(_train_fn pid=887677)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-53826d9b_212_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1871,e_layer_2024-08-24_11-09-05/checkpoint_000004)
[36m(_train_fn pid=887677)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-53826d9b_212_alpha_d_ff=3,batch_size=32,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1871,e_layer_2024-08-24_11-09-05/checkpoint_000005)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-53826d9b   RUNNING           4            78.0039       0.611568        1.56439             1.56439 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
206 more TERMINATED
[36m(_train_fn pid=887677)[0m 	iters: 100, epoch: 5 | loss: 0.6057615
[36m(_train_fn pid=887677)[0m 	speed: 0.1230s/iter; left time: 107.8548s
[36m(_train_fn pid=887677)[0m 	iters: 200, epoch: 5 | loss: 0.5449014
[36m(_train_fn pid=887677)[0m 	speed: 0.0702s/iter; left time: 54.5566s
[36m(_train_fn pid=887677)[0m Updating learning rate to 4.865696334668419e-05
[36m(_train_fn pid=887677)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=887677)[0m saving checkpoint...
[36m(_train_fn pid=887677)[0m Epoch: 5 cost time: 17.152297973632812
[36m(_train_fn pid=887677)[0m Epoch: 5, Steps: 244 | Train Loss: 0.6100946 Vali Loss: 1.5709309 Best vali loss: 1.5643891
[36m(_train_fn pid=887677)[0m 	iters: 100, epoch: 6 | loss: 0.5824100
[36m(_train_fn pid=887677)[0m 	speed: 0.1226s/iter; left time: 77.6370s
[36m(_train_fn pid=887677)[0m 	iters: 200, epoch: 6 | loss: 0.5944241
[36m(_train_fn pid=887677)[0m 	speed: 0.0702s/iter; left time: 37.3991s
Trial status: 211 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:11:01. Total running time: 3hr 49min 52s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-53826d9b   RUNNING           5            97.3013       0.610095        1.57093             1.56439 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
206 more TERMINATED

Trial trial-53826d9b completed after 6 iterations at 2024-08-24 11:11:04. Total running time: 3hr 49min 55s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-53826d9b result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000005 â”‚
â”‚ time_this_iter_s                         19.29102 â”‚
â”‚ time_total_s                            116.59228 â”‚
â”‚ training_iteration                              6 â”‚
â”‚ best_valid_loss                           1.56236 â”‚
â”‚ train_loss                                0.60928 â”‚
â”‚ valid_loss                                1.56236 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=887677)[0m Updating learning rate to 2.4328481673342096e-05
[36m(_train_fn pid=887677)[0m saving checkpoint...
[36m(_train_fn pid=887677)[0m Validation loss decreased (1.5644 --> 1.5624).  Saving model state dict ...

Trial trial-3a1d2a04 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3a1d2a04 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.20706 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00098 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=888538)[0m configuration
[36m(_train_fn pid=888538)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.2070595555423195, 'e_layers': 1, 'learning_rate': 0.0009798998493740878, 'd_ff': 1536}
[36m(_train_fn pid=888538)[0m Use GPU: cuda:0
[36m(_train_fn pid=888538)[0m train 7825
[36m(_train_fn pid=888538)[0m val 2161
[36m(_train_fn pid=888538)[0m start_epoch 0
[36m(_train_fn pid=888538)[0m max_epoch 8
[36m(_train_fn pid=888538)[0m 	iters: 100, epoch: 1 | loss: 0.7783341
[36m(_train_fn pid=888538)[0m 	speed: 0.0434s/iter; left time: 165.4078s
[36m(_train_fn pid=888538)[0m 	iters: 200, epoch: 1 | loss: 0.7816110
[36m(_train_fn pid=888538)[0m 	speed: 0.0365s/iter; left time: 135.5326s
[36m(_train_fn pid=888538)[0m 	iters: 300, epoch: 1 | loss: 0.7158687
2024-08-24 11:11:27,707	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=888538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a1d2a04_213_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2071,e_layer_2024-08-24_11-11-04/checkpoint_000000)
2024-08-24 11:11:47,860	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=888538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a1d2a04_213_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2071,e_layer_2024-08-24_11-11-04/checkpoint_000001)
2024-08-24 11:12:08,053	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=888538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a1d2a04_213_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2071,e_layer_2024-08-24_11-11-04/checkpoint_000002)
[36m(_train_fn pid=888538)[0m 	speed: 0.0365s/iter; left time: 131.8118s
[36m(_train_fn pid=888538)[0m 	iters: 400, epoch: 1 | loss: 0.6189374
[36m(_train_fn pid=888538)[0m 	speed: 0.0365s/iter; left time: 128.3702s
[36m(_train_fn pid=888538)[0m Updating learning rate to 0.0009798998493740878
[36m(_train_fn pid=888538)[0m saving checkpoint...
[36m(_train_fn pid=888538)[0m Validation loss decreased (inf --> 1.8045).  Saving model state dict ...
[36m(_train_fn pid=888538)[0m Epoch: 1 cost time: 18.281172275543213
[36m(_train_fn pid=888538)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7726134 Vali Loss: 1.8044696 Best vali loss: 1.8044696
[36m(_train_fn pid=888538)[0m 	iters: 100, epoch: 2 | loss: 0.7524473
[36m(_train_fn pid=888538)[0m 	speed: 0.0918s/iter; left time: 305.2454s

Trial status: 212 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:11:31. Total running time: 3hr 50min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3a1d2a04   RUNNING           1            20.9481       0.772613        1.80447             1.80447 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
207 more TERMINATED
[36m(_train_fn pid=888538)[0m 	iters: 200, epoch: 2 | loss: 0.6344790
[36m(_train_fn pid=888538)[0m 	speed: 0.0366s/iter; left time: 117.8860s
[36m(_train_fn pid=888538)[0m 	iters: 300, epoch: 2 | loss: 0.6711385
[36m(_train_fn pid=888538)[0m 	speed: 0.0365s/iter; left time: 114.1334s
[36m(_train_fn pid=888538)[0m 	iters: 400, epoch: 2 | loss: 0.6554952
[36m(_train_fn pid=888538)[0m 	speed: 0.0366s/iter; left time: 110.6485s
[36m(_train_fn pid=888538)[0m Updating learning rate to 0.0004899499246870439
[36m(_train_fn pid=888538)[0m saving checkpoint...
[36m(_train_fn pid=888538)[0m Validation loss decreased (1.8045 --> 1.5695).  Saving model state dict ...
[36m(_train_fn pid=888538)[0m Epoch: 2 cost time: 17.90321922302246
[36m(_train_fn pid=888538)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6880685 Vali Loss: 1.5695309 Best vali loss: 1.5695309
[36m(_train_fn pid=888538)[0m 	iters: 100, epoch: 3 | loss: 0.6580171
[36m(_train_fn pid=888538)[0m 	speed: 0.0920s/iter; left time: 260.7819s
[36m(_train_fn pid=888538)[0m 	iters: 200, epoch: 3 | loss: 0.6860784
[36m(_train_fn pid=888538)[0m 	speed: 0.0366s/iter; left time: 100.1063s
[36m(_train_fn pid=888538)[0m 	iters: 300, epoch: 3 | loss: 0.5921855
[36m(_train_fn pid=888538)[0m 	speed: 0.0366s/iter; left time: 96.4697s
Trial status: 212 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:12:01. Total running time: 3hr 50min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3a1d2a04   RUNNING           2            41.1064       0.688068        1.56953             1.56953 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
207 more TERMINATED
[36m(_train_fn pid=888538)[0m 	iters: 400, epoch: 3 | loss: 0.6762396
[36m(_train_fn pid=888538)[0m 	speed: 0.0366s/iter; left time: 92.7593s
[36m(_train_fn pid=888538)[0m Updating learning rate to 0.00024497496234352194
[36m(_train_fn pid=888538)[0m saving checkpoint...
[36m(_train_fn pid=888538)[0m Validation loss decreased (1.5695 --> 1.5689).  Saving model state dict ...
[36m(_train_fn pid=888538)[0m Epoch: 3 cost time: 17.92186665534973
[36m(_train_fn pid=888538)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6164737 Vali Loss: 1.5688933 Best vali loss: 1.5688933
[36m(_train_fn pid=888538)[0m 	iters: 100, epoch: 4 | loss: 0.5799150
[36m(_train_fn pid=888538)[0m 	speed: 0.0922s/iter; left time: 216.2674s
[36m(_train_fn pid=888538)[0m 	iters: 200, epoch: 4 | loss: 0.5808607
[36m(_train_fn pid=888538)[0m 	speed: 0.0366s/iter; left time: 82.1505s
[36m(_train_fn pid=888538)[0m 	iters: 300, epoch: 4 | loss: 0.6972049
[36m(_train_fn pid=888538)[0m 	speed: 0.0367s/iter; left time: 78.6590s
[36m(_train_fn pid=888538)[0m 	iters: 400, epoch: 4 | loss: 0.6423486
[36m(_train_fn pid=888538)[0m 	speed: 0.0366s/iter; left time: 74.9097s
[36m(_train_fn pid=888538)[0m Updating learning rate to 0.00012248748117176097
[36m(_train_fn pid=888538)[0m saving checkpoint...
[36m(_train_fn pid=888538)[0m Validation loss decreased (1.5689 --> 1.5643).  Saving model state dict ...
[36m(_train_fn pid=888538)[0m Epoch: 4 cost time: 17.936630487442017
[36m(_train_fn pid=888538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a1d2a04_213_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2071,e_layer_2024-08-24_11-11-04/checkpoint_000003)
2024-08-24 11:12:28,257	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=888538)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-3a1d2a04_213_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2071,e_layer_2024-08-24_11-11-04/checkpoint_000004)
2024-08-24 11:12:48,478	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=889285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-edfffb25_214_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2114,e_layers_2024-08-24_11-12-48/checkpoint_000000)
2024-08-24 11:13:00,442	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=889285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-edfffb25_214_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2114,e_layers_2024-08-24_11-12-48/checkpoint_000001)
[36m(_train_fn pid=888538)[0m Epoch: 4, Steps: 489 | Train Loss: 0.6123098 Vali Loss: 1.5643454 Best vali loss: 1.5643454
Trial status: 212 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:12:31. Total running time: 3hr 51min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-3a1d2a04   RUNNING           4            81.4942       0.61231         1.56435             1.56435 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
207 more TERMINATED
[36m(_train_fn pid=888538)[0m 	iters: 100, epoch: 5 | loss: 0.5027724
[36m(_train_fn pid=888538)[0m 	speed: 0.0922s/iter; left time: 171.2080s
[36m(_train_fn pid=888538)[0m 	iters: 200, epoch: 5 | loss: 0.6014658
[36m(_train_fn pid=888538)[0m 	speed: 0.0367s/iter; left time: 64.4202s
[36m(_train_fn pid=888538)[0m 	iters: 300, epoch: 5 | loss: 0.5677047
[36m(_train_fn pid=888538)[0m 	speed: 0.0367s/iter; left time: 60.7589s
[36m(_train_fn pid=888538)[0m 	iters: 400, epoch: 5 | loss: 0.4385521
[36m(_train_fn pid=888538)[0m 	speed: 0.0366s/iter; left time: 57.0408s
[36m(_train_fn pid=888538)[0m Updating learning rate to 6.124374058588049e-05
[36m(_train_fn pid=888538)[0m saving checkpoint...
[36m(_train_fn pid=888538)[0m Validation loss decreased (1.5643 --> 1.5601).  Saving model state dict ...

Trial trial-3a1d2a04 completed after 5 iterations at 2024-08-24 11:12:48. Total running time: 3hr 51min 39s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-3a1d2a04 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         20.21517 â”‚
â”‚ time_total_s                             101.7094 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56014 â”‚
â”‚ train_loss                                0.60949 â”‚
â”‚ valid_loss                                1.56014 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-edfffb25 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-edfffb25 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 16 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.21139 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                       0.0018 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=889285)[0m configuration
[36m(_train_fn pid=889285)[0m {'batch_size': 16, 'd_model': 16, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.21139169993416249, 'e_layers': 2, 'learning_rate': 0.001797359274460965, 'd_ff': 48}
[36m(_train_fn pid=889285)[0m Use GPU: cuda:0
[36m(_train_fn pid=889285)[0m train 7825
[36m(_train_fn pid=889285)[0m val 2161
[36m(_train_fn pid=889285)[0m start_epoch 0
[36m(_train_fn pid=889285)[0m max_epoch 8
[36m(_train_fn pid=889285)[0m 	iters: 100, epoch: 1 | loss: 0.9823396
[36m(_train_fn pid=889285)[0m 	speed: 0.0153s/iter; left time: 58.4154s
[36m(_train_fn pid=889285)[0m 	iters: 200, epoch: 1 | loss: 1.0120108
[36m(_train_fn pid=889285)[0m 	speed: 0.0081s/iter; left time: 29.8986s
[36m(_train_fn pid=889285)[0m 	iters: 300, epoch: 1 | loss: 0.8551419
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 28.1297s
[36m(_train_fn pid=889285)[0m 	iters: 400, epoch: 1 | loss: 0.7927830
[36m(_train_fn pid=889285)[0m 	speed: 0.0077s/iter; left time: 27.1525s
[36m(_train_fn pid=889285)[0m Updating learning rate to 0.001797359274460965
[36m(_train_fn pid=889285)[0m saving checkpoint...
[36m(_train_fn pid=889285)[0m Validation loss decreased (inf --> 1.7865).  Saving model state dict ...
[36m(_train_fn pid=889285)[0m Epoch: 1 cost time: 4.3228678703308105
[36m(_train_fn pid=889285)[0m Epoch: 1, Steps: 489 | Train Loss: 0.9176451 Vali Loss: 1.7864510 Best vali loss: 1.7864510
[36m(_train_fn pid=889285)[0m 	iters: 100, epoch: 2 | loss: 0.6784807
[36m(_train_fn pid=889285)[0m 	speed: 0.0206s/iter; left time: 68.6353s
[36m(_train_fn pid=889285)[0m 	iters: 200, epoch: 2 | loss: 0.8266408
[36m(_train_fn pid=889285)[0m 	speed: 0.0083s/iter; left time: 26.8387s
[36m(_train_fn pid=889285)[0m 	iters: 300, epoch: 2 | loss: 0.6598713
[36m(_train_fn pid=889285)[0m 	speed: 0.0079s/iter; left time: 24.7275s
[36m(_train_fn pid=889285)[0m 	iters: 400, epoch: 2 | loss: 0.6523323
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 23.6760s
[36m(_train_fn pid=889285)[0m Updating learning rate to 0.0008986796372304825
[36m(_train_fn pid=889285)[0m saving checkpoint...
[36m(_train_fn pid=889285)[0m Validation loss decreased (1.7865 --> 1.6264).  Saving model state dict ...
[36m(_train_fn pid=889285)[0m Epoch: 2 cost time: 3.9812467098236084
[36m(_train_fn pid=889285)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6197441 Vali Loss: 1.6264339 Best vali loss: 1.6264339
[36m(_train_fn pid=889285)[0m 	iters: 100, epoch: 3 | loss: 0.5705893
[36m(_train_fn pid=889285)[0m 	speed: 0.0200s/iter; left time: 56.5991s

Trial status: 213 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:13:01. Total running time: 3hr 51min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 11:13:04,770	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=889285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-edfffb25_214_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2114,e_layers_2024-08-24_11-12-48/checkpoint_000002)
2024-08-24 11:13:09,075	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=889285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-edfffb25_214_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2114,e_layers_2024-08-24_11-12-48/checkpoint_000003)
2024-08-24 11:13:13,748	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=889285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-edfffb25_214_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2114,e_layers_2024-08-24_11-12-48/checkpoint_000004)
[36m(_train_fn pid=889285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-edfffb25_214_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2114,e_layers_2024-08-24_11-12-48/checkpoint_000005)
2024-08-24 11:13:18,074	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:13:22,406	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=889285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-edfffb25_214_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2114,e_layers_2024-08-24_11-12-48/checkpoint_000006)
2024-08-24 11:13:27,101	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-edfffb25   RUNNING           2             9.6786       0.619744        1.62643             1.62643 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
208 more TERMINATED
[36m(_train_fn pid=889285)[0m 	iters: 200, epoch: 3 | loss: 0.6398642
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 21.2364s
[36m(_train_fn pid=889285)[0m 	iters: 300, epoch: 3 | loss: 0.5001820
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 20.5074s
[36m(_train_fn pid=889285)[0m 	iters: 400, epoch: 3 | loss: 0.6184819
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 19.7182s
[36m(_train_fn pid=889285)[0m Updating learning rate to 0.00044933981861524123
[36m(_train_fn pid=889285)[0m saving checkpoint...
[36m(_train_fn pid=889285)[0m Validation loss decreased (1.6264 --> 1.6179).  Saving model state dict ...
[36m(_train_fn pid=889285)[0m Epoch: 3 cost time: 3.8439714908599854
[36m(_train_fn pid=889285)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5864889 Vali Loss: 1.6178692 Best vali loss: 1.6178692
[36m(_train_fn pid=889285)[0m 	iters: 100, epoch: 4 | loss: 0.5247509
[36m(_train_fn pid=889285)[0m 	speed: 0.0199s/iter; left time: 46.7635s
[36m(_train_fn pid=889285)[0m 	iters: 200, epoch: 4 | loss: 0.5733383
[36m(_train_fn pid=889285)[0m 	speed: 0.0077s/iter; left time: 17.3629s
[36m(_train_fn pid=889285)[0m 	iters: 300, epoch: 4 | loss: 0.5602608
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 16.7221s
[36m(_train_fn pid=889285)[0m 	iters: 400, epoch: 4 | loss: 0.6509762
[36m(_train_fn pid=889285)[0m 	speed: 0.0077s/iter; left time: 15.7912s
[36m(_train_fn pid=889285)[0m Updating learning rate to 0.00022466990930762061
[36m(_train_fn pid=889285)[0m saving checkpoint...
[36m(_train_fn pid=889285)[0m Validation loss decreased (1.6179 --> 1.6073).  Saving model state dict ...
[36m(_train_fn pid=889285)[0m Epoch: 4 cost time: 3.825347423553467
[36m(_train_fn pid=889285)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5751205 Vali Loss: 1.6072742 Best vali loss: 1.6072742
[36m(_train_fn pid=889285)[0m 	iters: 100, epoch: 5 | loss: 0.4918277
[36m(_train_fn pid=889285)[0m 	speed: 0.0205s/iter; left time: 38.0827s
[36m(_train_fn pid=889285)[0m 	iters: 200, epoch: 5 | loss: 0.6333156
[36m(_train_fn pid=889285)[0m 	speed: 0.0084s/iter; left time: 14.8461s
[36m(_train_fn pid=889285)[0m 	iters: 300, epoch: 5 | loss: 0.4926656
[36m(_train_fn pid=889285)[0m 	speed: 0.0085s/iter; left time: 14.0219s
[36m(_train_fn pid=889285)[0m 	iters: 400, epoch: 5 | loss: 0.4433911
[36m(_train_fn pid=889285)[0m 	speed: 0.0085s/iter; left time: 13.2116s
[36m(_train_fn pid=889285)[0m Updating learning rate to 0.00011233495465381031
[36m(_train_fn pid=889285)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=889285)[0m saving checkpoint...
[36m(_train_fn pid=889285)[0m Epoch: 5 cost time: 4.180094957351685
[36m(_train_fn pid=889285)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5673479 Vali Loss: 1.6104947 Best vali loss: 1.6072742
[36m(_train_fn pid=889285)[0m 	iters: 100, epoch: 6 | loss: 0.4848855
[36m(_train_fn pid=889285)[0m 	speed: 0.0207s/iter; left time: 28.3081s
[36m(_train_fn pid=889285)[0m 	iters: 200, epoch: 6 | loss: 0.6921320
[36m(_train_fn pid=889285)[0m 	speed: 0.0077s/iter; left time: 9.7562s
[36m(_train_fn pid=889285)[0m 	iters: 300, epoch: 6 | loss: 0.6444649
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 9.0900s
[36m(_train_fn pid=889285)[0m 	iters: 400, epoch: 6 | loss: 0.6443900
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 8.3284s
[36m(_train_fn pid=889285)[0m Updating learning rate to 5.6167477326905154e-05
[36m(_train_fn pid=889285)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=889285)[0m saving checkpoint...
[36m(_train_fn pid=889285)[0m Epoch: 6 cost time: 3.840900182723999
[36m(_train_fn pid=889285)[0m Epoch: 6, Steps: 489 | Train Loss: 0.5627965 Vali Loss: 1.6074066 Best vali loss: 1.6072742
[36m(_train_fn pid=889285)[0m 	iters: 100, epoch: 7 | loss: 0.5094159
[36m(_train_fn pid=889285)[0m 	speed: 0.0200s/iter; left time: 17.6172s
[36m(_train_fn pid=889285)[0m 	iters: 200, epoch: 7 | loss: 0.5926415
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 6.0418s
[36m(_train_fn pid=889285)[0m 	iters: 300, epoch: 7 | loss: 0.5202907
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 5.3086s
[36m(_train_fn pid=889285)[0m 	iters: 400, epoch: 7 | loss: 0.4655451
[36m(_train_fn pid=889285)[0m 	speed: 0.0078s/iter; left time: 4.5055s
[36m(_train_fn pid=889285)[0m Updating learning rate to 2.8083738663452577e-05
[36m(_train_fn pid=889285)[0m saving checkpoint...
[36m(_train_fn pid=889285)[0m Validation loss decreased (1.6073 --> 1.5999).  Saving model state dict ...
[36m(_train_fn pid=889285)[0m Epoch: 7 cost time: 3.8573598861694336
[36m(_train_fn pid=889285)[0m Epoch: 7, Steps: 489 | Train Loss: 0.5602773 Vali Loss: 1.5998813 Best vali loss: 1.5998813
[36m(_train_fn pid=889285)[0m 	iters: 100, epoch: 8 | loss: 0.5459446
[36m(_train_fn pid=889285)[0m 	speed: 0.0207s/iter; left time: 8.0830s
[36m(_train_fn pid=889285)[0m 	iters: 200, epoch: 8 | loss: 0.5317184
[36m(_train_fn pid=889285)[0m 	speed: 0.0085s/iter; left time: 2.4661s
[36m(_train_fn pid=889285)[0m 	iters: 300, epoch: 8 | loss: 0.6421750
[36m(_train_fn pid=889285)[0m 	speed: 0.0085s/iter; left time: 1.6125s
[36m(_train_fn pid=889285)[0m 	iters: 400, epoch: 8 | loss: 0.5541691
[36m(_train_fn pid=889285)[0m 	speed: 0.0086s/iter; left time: 0.7698s

Trial trial-edfffb25 completed after 8 iterations at 2024-08-24 11:13:27. Total running time: 3hr 52min 18s
[36m(_train_fn pid=889285)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-edfffb25_214_alpha_d_ff=3,batch_size=16,d_model=16,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2114,e_layers_2024-08-24_11-12-48/checkpoint_000007)
[36m(_train_fn pid=890045)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d2417067_215_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2073,e_layers=_2024-08-24_11-13-27/checkpoint_000000)
[36m(_train_fn pid=890045)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d2417067_215_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2073,e_layers=_2024-08-24_11-13-27/checkpoint_000001)
2024-08-24 11:13:36,293	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:13:39,428	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=890045)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d2417067_215_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2073,e_layers=_2024-08-24_11-13-27/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-edfffb25 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000007 â”‚
â”‚ time_this_iter_s                          4.68694 â”‚
â”‚ time_total_s                             36.32241 â”‚
â”‚ training_iteration                              8 â”‚
â”‚ best_valid_loss                           1.59988 â”‚
â”‚ train_loss                                0.55888 â”‚
â”‚ valid_loss                                1.61068 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=889285)[0m Updating learning rate to 1.4041869331726288e-05
[36m(_train_fn pid=889285)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=889285)[0m saving checkpoint...
[36m(_train_fn pid=889285)[0m Epoch: 8 cost time: 4.2117369174957275
[36m(_train_fn pid=889285)[0m Epoch: 8, Steps: 489 | Train Loss: 0.5588833 Vali Loss: 1.6106846 Best vali loss: 1.5998813

Trial trial-d2417067 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d2417067 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                  8 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.20727 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00157 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=890045)[0m configuration
[36m(_train_fn pid=890045)[0m {'batch_size': 16, 'd_model': 8, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.20726846840543509, 'e_layers': 1, 'learning_rate': 0.0015722569937220926, 'd_ff': 24}
[36m(_train_fn pid=890045)[0m Use GPU: cuda:0
[36m(_train_fn pid=890045)[0m train 7825
[36m(_train_fn pid=890045)[0m val 2161
[36m(_train_fn pid=890045)[0m start_epoch 0
[36m(_train_fn pid=890045)[0m max_epoch 8
[36m(_train_fn pid=890045)[0m 	iters: 100, epoch: 1 | loss: 1.1218821
[36m(_train_fn pid=890045)[0m 	speed: 0.0132s/iter; left time: 50.2551s
[36m(_train_fn pid=890045)[0m 	iters: 200, epoch: 1 | loss: 0.8576846
[36m(_train_fn pid=890045)[0m 	speed: 0.0060s/iter; left time: 22.4398s
[36m(_train_fn pid=890045)[0m 	iters: 300, epoch: 1 | loss: 0.9931138
[36m(_train_fn pid=890045)[0m 	speed: 0.0057s/iter; left time: 20.4539s

Trial status: 214 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:13:31. Total running time: 3hr 52min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-d2417067   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
209 more TERMINATED
[36m(_train_fn pid=890045)[0m 	iters: 400, epoch: 1 | loss: 0.9602035
[36m(_train_fn pid=890045)[0m 	speed: 0.0057s/iter; left time: 19.9843s
[36m(_train_fn pid=890045)[0m Updating learning rate to 0.0015722569937220926
[36m(_train_fn pid=890045)[0m saving checkpoint...
[36m(_train_fn pid=890045)[0m Validation loss decreased (inf --> 1.9388).  Saving model state dict ...
[36m(_train_fn pid=890045)[0m Epoch: 1 cost time: 3.301159143447876
[36m(_train_fn pid=890045)[0m Epoch: 1, Steps: 489 | Train Loss: 0.9749583 Vali Loss: 1.9388302 Best vali loss: 1.9388302
[36m(_train_fn pid=890045)[0m 	iters: 100, epoch: 2 | loss: 0.5768194
[36m(_train_fn pid=890045)[0m 	speed: 0.0157s/iter; left time: 52.1439s
[36m(_train_fn pid=890045)[0m 	iters: 200, epoch: 2 | loss: 0.5747817
[36m(_train_fn pid=890045)[0m 	speed: 0.0061s/iter; left time: 19.7619s
[36m(_train_fn pid=890045)[0m 	iters: 300, epoch: 2 | loss: 0.6313060
[36m(_train_fn pid=890045)[0m 	speed: 0.0061s/iter; left time: 19.1661s
[36m(_train_fn pid=890045)[0m 	iters: 400, epoch: 2 | loss: 0.5081871
[36m(_train_fn pid=890045)[0m 	speed: 0.0062s/iter; left time: 18.6928s
[36m(_train_fn pid=890045)[0m Updating learning rate to 0.0007861284968610463
[36m(_train_fn pid=890045)[0m saving checkpoint...
[36m(_train_fn pid=890045)[0m Validation loss decreased (1.9388 --> 1.5839).  Saving model state dict ...
[36m(_train_fn pid=890045)[0m Epoch: 2 cost time: 3.024012565612793
[36m(_train_fn pid=890045)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6314984 Vali Loss: 1.5839208 Best vali loss: 1.5839208
[36m(_train_fn pid=890045)[0m 	iters: 100, epoch: 3 | loss: 0.6029240
[36m(_train_fn pid=890045)[0m 	speed: 0.0151s/iter; left time: 42.9452s
[36m(_train_fn pid=890045)[0m 	iters: 200, epoch: 3 | loss: 0.6666260
[36m(_train_fn pid=890045)[0m 	speed: 0.0056s/iter; left time: 15.1960s
[36m(_train_fn pid=890045)[0m 	iters: 300, epoch: 3 | loss: 0.5292807
[36m(_train_fn pid=890045)[0m 	speed: 0.0055s/iter; left time: 14.6025s
[36m(_train_fn pid=890045)[0m 	iters: 400, epoch: 3 | loss: 0.6279438
[36m(_train_fn pid=890045)[0m 	speed: 0.0056s/iter; left time: 14.0867s
[36m(_train_fn pid=890045)[0m Updating learning rate to 0.00039306424843052316
[36m(_train_fn pid=890045)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=890045)[0m saving checkpoint...
[36m(_train_fn pid=890045)[0m Epoch: 3 cost time: 2.7605538368225098
[36m(_train_fn pid=890045)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5982097 Vali Loss: 1.5942573 Best vali loss: 1.5839208
[36m(_train_fn pid=890045)[0m 	iters: 100, epoch: 4 | loss: 0.5627765
2024-08-24 11:13:42,839	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=890045)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d2417067_215_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2073,e_layers=_2024-08-24_11-13-27/checkpoint_000003)
[36m(_train_fn pid=890045)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-d2417067_215_alpha_d_ff=3,batch_size=16,d_model=8,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2073,e_layers=_2024-08-24_11-13-27/checkpoint_000004)
2024-08-24 11:13:46,257	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:14:09,498	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=890541)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7e214e37_216_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2240,e_layer_2024-08-24_11-13-46/checkpoint_000000)
[36m(_train_fn pid=890045)[0m 	speed: 0.0152s/iter; left time: 35.6994s
[36m(_train_fn pid=890045)[0m 	iters: 200, epoch: 4 | loss: 0.6085024
[36m(_train_fn pid=890045)[0m 	speed: 0.0061s/iter; left time: 13.7921s
[36m(_train_fn pid=890045)[0m 	iters: 300, epoch: 4 | loss: 0.6703081
[36m(_train_fn pid=890045)[0m 	speed: 0.0061s/iter; left time: 13.1883s
[36m(_train_fn pid=890045)[0m 	iters: 400, epoch: 4 | loss: 0.5070436
[36m(_train_fn pid=890045)[0m 	speed: 0.0061s/iter; left time: 12.4832s
[36m(_train_fn pid=890045)[0m Updating learning rate to 0.00019653212421526158
[36m(_train_fn pid=890045)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=890045)[0m saving checkpoint...
[36m(_train_fn pid=890045)[0m Epoch: 4 cost time: 3.0388433933258057
[36m(_train_fn pid=890045)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5872634 Vali Loss: 1.6054084 Best vali loss: 1.5839208
[36m(_train_fn pid=890045)[0m 	iters: 100, epoch: 5 | loss: 0.6433346
[36m(_train_fn pid=890045)[0m 	speed: 0.0158s/iter; left time: 29.2676s
[36m(_train_fn pid=890045)[0m 	iters: 200, epoch: 5 | loss: 0.6447893
[36m(_train_fn pid=890045)[0m 	speed: 0.0061s/iter; left time: 10.7392s
[36m(_train_fn pid=890045)[0m 	iters: 300, epoch: 5 | loss: 0.6569200
[36m(_train_fn pid=890045)[0m 	speed: 0.0062s/iter; left time: 10.2043s
[36m(_train_fn pid=890045)[0m 	iters: 400, epoch: 5 | loss: 0.7923842
[36m(_train_fn pid=890045)[0m 	speed: 0.0062s/iter; left time: 9.5780s
[36m(_train_fn pid=890045)[0m Updating learning rate to 9.826606210763079e-05
[36m(_train_fn pid=890045)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=890045)[0m saving checkpoint...
[36m(_train_fn pid=890045)[0m Epoch: 5 cost time: 3.0502500534057617
[36m(_train_fn pid=890045)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5819066 Vali Loss: 1.6149514 Best vali loss: 1.5839208
[36m(_train_fn pid=890045)[0m Early stopping

Trial trial-d2417067 completed after 5 iterations at 2024-08-24 11:13:46. Total running time: 3hr 52min 37s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-d2417067 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.41571 â”‚
â”‚ time_total_s                             17.46772 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.58392 â”‚
â”‚ train_loss                                0.58191 â”‚
â”‚ valid_loss                                1.61495 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-7e214e37 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7e214e37 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                              0.224 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00132 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=890541)[0m configuration
[36m(_train_fn pid=890541)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.22399946400647813, 'e_layers': 1, 'learning_rate': 0.001322076645534857, 'd_ff': 1536}
[36m(_train_fn pid=890541)[0m Use GPU: cuda:0
[36m(_train_fn pid=890541)[0m train 7825
[36m(_train_fn pid=890541)[0m val 2161
[36m(_train_fn pid=890541)[0m start_epoch 0
[36m(_train_fn pid=890541)[0m max_epoch 8
[36m(_train_fn pid=890541)[0m 	iters: 100, epoch: 1 | loss: 0.7670508
[36m(_train_fn pid=890541)[0m 	speed: 0.0428s/iter; left time: 163.1835s
[36m(_train_fn pid=890541)[0m 	iters: 200, epoch: 1 | loss: 0.7732073
[36m(_train_fn pid=890541)[0m 	speed: 0.0360s/iter; left time: 133.8505s
[36m(_train_fn pid=890541)[0m 	iters: 300, epoch: 1 | loss: 0.7088012
[36m(_train_fn pid=890541)[0m 	speed: 0.0361s/iter; left time: 130.5284s

Trial status: 215 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:14:01. Total running time: 3hr 52min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7e214e37   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
210 more TERMINATED
[36m(_train_fn pid=890541)[0m 	iters: 400, epoch: 1 | loss: 0.6069483
[36m(_train_fn pid=890541)[0m 	speed: 0.0362s/iter; left time: 127.3332s
[36m(_train_fn pid=890541)[0m Updating learning rate to 0.001322076645534857
[36m(_train_fn pid=890541)[0m saving checkpoint...
[36m(_train_fn pid=890541)[0m Validation loss decreased (inf --> 1.7159).  Saving model state dict ...
[36m(_train_fn pid=890541)[0m Epoch: 1 cost time: 18.086031913757324
[36m(_train_fn pid=890541)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7594457 Vali Loss: 1.7159119 Best vali loss: 1.7159119
[36m(_train_fn pid=890541)[0m 	iters: 100, epoch: 2 | loss: 0.7755557
[36m(_train_fn pid=890541)[0m 	speed: 0.0914s/iter; left time: 303.8554s
[36m(_train_fn pid=890541)[0m 	iters: 200, epoch: 2 | loss: 0.6474878
[36m(_train_fn pid=890541)[0m 	speed: 0.0364s/iter; left time: 117.4245s
[36m(_train_fn pid=890541)[0m 	iters: 300, epoch: 2 | loss: 0.6778032
[36m(_train_fn pid=890541)[0m 	speed: 0.0364s/iter; left time: 113.7434s
2024-08-24 11:14:29,618	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=890541)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7e214e37_216_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2240,e_layer_2024-08-24_11-13-46/checkpoint_000001)
[36m(_train_fn pid=890541)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7e214e37_216_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2240,e_layer_2024-08-24_11-13-46/checkpoint_000002)
2024-08-24 11:14:49,761	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:15:09,958	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=890541)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7e214e37_216_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2240,e_layer_2024-08-24_11-13-46/checkpoint_000003)
[36m(_train_fn pid=890541)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-7e214e37_216_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2240,e_layer_2024-08-24_11-13-46/checkpoint_000004)
[36m(_train_fn pid=890541)[0m 	iters: 400, epoch: 2 | loss: 0.6546752
[36m(_train_fn pid=890541)[0m 	speed: 0.0364s/iter; left time: 110.1609s
[36m(_train_fn pid=890541)[0m Updating learning rate to 0.0006610383227674285
[36m(_train_fn pid=890541)[0m saving checkpoint...
[36m(_train_fn pid=890541)[0m Validation loss decreased (1.7159 --> 1.5715).  Saving model state dict ...
[36m(_train_fn pid=890541)[0m Epoch: 2 cost time: 17.84131932258606
[36m(_train_fn pid=890541)[0m Epoch: 2, Steps: 489 | Train Loss: 0.7711280 Vali Loss: 1.5715301 Best vali loss: 1.5715301
Trial status: 215 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:14:32. Total running time: 3hr 53min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7e214e37   RUNNING           2            40.8442       0.771128        1.57153             1.57153 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
210 more TERMINATED
[36m(_train_fn pid=890541)[0m 	iters: 100, epoch: 3 | loss: 0.6577359
[36m(_train_fn pid=890541)[0m 	speed: 0.0922s/iter; left time: 261.4099s
[36m(_train_fn pid=890541)[0m 	iters: 200, epoch: 3 | loss: 0.6873955
[36m(_train_fn pid=890541)[0m 	speed: 0.0366s/iter; left time: 100.0684s
[36m(_train_fn pid=890541)[0m 	iters: 300, epoch: 3 | loss: 0.5924600
[36m(_train_fn pid=890541)[0m 	speed: 0.0366s/iter; left time: 96.3429s
[36m(_train_fn pid=890541)[0m 	iters: 400, epoch: 3 | loss: 0.6732859
[36m(_train_fn pid=890541)[0m 	speed: 0.0365s/iter; left time: 92.6422s
[36m(_train_fn pid=890541)[0m Updating learning rate to 0.00033051916138371426
[36m(_train_fn pid=890541)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=890541)[0m saving checkpoint...
[36m(_train_fn pid=890541)[0m Epoch: 3 cost time: 17.905402421951294
[36m(_train_fn pid=890541)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6177171 Vali Loss: 1.5763680 Best vali loss: 1.5715301
[36m(_train_fn pid=890541)[0m 	iters: 100, epoch: 4 | loss: 0.5896699
[36m(_train_fn pid=890541)[0m 	speed: 0.0917s/iter; left time: 215.1691s
[36m(_train_fn pid=890541)[0m 	iters: 200, epoch: 4 | loss: 0.5806481
[36m(_train_fn pid=890541)[0m 	speed: 0.0366s/iter; left time: 82.2630s
[36m(_train_fn pid=890541)[0m 	iters: 300, epoch: 4 | loss: 0.7016668
[36m(_train_fn pid=890541)[0m 	speed: 0.0366s/iter; left time: 78.6111s
Trial status: 215 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:15:02. Total running time: 3hr 53min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-7e214e37   RUNNING           3            60.9804       0.617717        1.57637             1.57153 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
210 more TERMINATED
[36m(_train_fn pid=890541)[0m 	iters: 400, epoch: 4 | loss: 0.6482615
[36m(_train_fn pid=890541)[0m 	speed: 0.0366s/iter; left time: 74.9458s
[36m(_train_fn pid=890541)[0m Updating learning rate to 0.00016525958069185713
[36m(_train_fn pid=890541)[0m saving checkpoint...
[36m(_train_fn pid=890541)[0m Validation loss decreased (1.5715 --> 1.5660).  Saving model state dict ...
[36m(_train_fn pid=890541)[0m Epoch: 4 cost time: 17.939013242721558
[36m(_train_fn pid=890541)[0m Epoch: 4, Steps: 489 | Train Loss: 0.6144941 Vali Loss: 1.5660313 Best vali loss: 1.5660313
[36m(_train_fn pid=890541)[0m 	iters: 100, epoch: 5 | loss: 0.5062894
[36m(_train_fn pid=890541)[0m 	speed: 0.0922s/iter; left time: 171.2278s
[36m(_train_fn pid=890541)[0m 	iters: 200, epoch: 5 | loss: 0.6033974
[36m(_train_fn pid=890541)[0m 	speed: 0.0366s/iter; left time: 64.3597s
[36m(_train_fn pid=890541)[0m 	iters: 300, epoch: 5 | loss: 0.5716208
[36m(_train_fn pid=890541)[0m 	speed: 0.0367s/iter; left time: 60.7413s
[36m(_train_fn pid=890541)[0m 	iters: 400, epoch: 5 | loss: 0.4366866
[36m(_train_fn pid=890541)[0m 	speed: 0.0367s/iter; left time: 57.1340s
[36m(_train_fn pid=890541)[0m Updating learning rate to 8.262979034592857e-05
[36m(_train_fn pid=890541)[0m saving checkpoint...
[36m(_train_fn pid=890541)[0m Validation loss decreased (1.5660 --> 1.5607).  Saving model state dict ...

Trial trial-7e214e37 completed after 5 iterations at 2024-08-24 11:15:30. Total running time: 3hr 54min 21s
2024-08-24 11:15:30,191	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=891290)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2522db72_217_alpha_d_ff=3,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2128,e_layers_2024-08-24_11-15-30/checkpoint_000000)
[36m(_train_fn pid=891290)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2522db72_217_alpha_d_ff=3,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2128,e_layers_2024-08-24_11-15-30/checkpoint_000001)
2024-08-24 11:15:40,560	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=891290)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2522db72_217_alpha_d_ff=3,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2128,e_layers_2024-08-24_11-15-30/checkpoint_000002)
2024-08-24 11:15:44,122	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-7e214e37 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         20.22701 â”‚
â”‚ time_total_s                            101.40487 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56075 â”‚
â”‚ train_loss                                0.61231 â”‚
â”‚ valid_loss                                1.56075 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial status: 216 TERMINATED | 1 PENDING
Current time: 2024-08-24 11:15:32. Total running time: 3hr 54min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â”‚ trial-2522db72   PENDING                                                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
211 more TERMINATED

Trial trial-2522db72 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2522db72 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                 32 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.21282 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00103 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=891290)[0m configuration
[36m(_train_fn pid=891290)[0m {'batch_size': 16, 'd_model': 32, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.21281611670469136, 'e_layers': 1, 'learning_rate': 0.0010287728950526093, 'd_ff': 96}
[36m(_train_fn pid=891290)[0m Use GPU: cuda:0
[36m(_train_fn pid=891290)[0m train 7825
[36m(_train_fn pid=891290)[0m val 2161
[36m(_train_fn pid=891290)[0m start_epoch 0
[36m(_train_fn pid=891290)[0m max_epoch 8
[36m(_train_fn pid=891290)[0m 	iters: 100, epoch: 1 | loss: 1.2821794
[36m(_train_fn pid=891290)[0m 	speed: 0.0133s/iter; left time: 50.7290s
[36m(_train_fn pid=891290)[0m 	iters: 200, epoch: 1 | loss: 0.9355249
[36m(_train_fn pid=891290)[0m 	speed: 0.0063s/iter; left time: 23.4724s
[36m(_train_fn pid=891290)[0m 	iters: 300, epoch: 1 | loss: 0.8802425
[36m(_train_fn pid=891290)[0m 	speed: 0.0063s/iter; left time: 22.8787s
[36m(_train_fn pid=891290)[0m 	iters: 400, epoch: 1 | loss: 0.7941946
[36m(_train_fn pid=891290)[0m 	speed: 0.0065s/iter; left time: 22.6889s
[36m(_train_fn pid=891290)[0m Updating learning rate to 0.0010287728950526093
[36m(_train_fn pid=891290)[0m saving checkpoint...
[36m(_train_fn pid=891290)[0m Validation loss decreased (inf --> 1.9653).  Saving model state dict ...
[36m(_train_fn pid=891290)[0m Epoch: 1 cost time: 3.5531556606292725
[36m(_train_fn pid=891290)[0m Epoch: 1, Steps: 489 | Train Loss: 1.0576491 Vali Loss: 1.9652622 Best vali loss: 1.9652622
[36m(_train_fn pid=891290)[0m 	iters: 100, epoch: 2 | loss: 0.6651642
[36m(_train_fn pid=891290)[0m 	speed: 0.0168s/iter; left time: 55.7081s
[36m(_train_fn pid=891290)[0m 	iters: 200, epoch: 2 | loss: 0.5242024
[36m(_train_fn pid=891290)[0m 	speed: 0.0060s/iter; left time: 19.3504s
[36m(_train_fn pid=891290)[0m 	iters: 300, epoch: 2 | loss: 0.6816839
[36m(_train_fn pid=891290)[0m 	speed: 0.0059s/iter; left time: 18.5394s
[36m(_train_fn pid=891290)[0m 	iters: 400, epoch: 2 | loss: 0.5032749
[36m(_train_fn pid=891290)[0m 	speed: 0.0059s/iter; left time: 17.9055s
[36m(_train_fn pid=891290)[0m Updating learning rate to 0.0005143864475263047
[36m(_train_fn pid=891290)[0m saving checkpoint...
[36m(_train_fn pid=891290)[0m Validation loss decreased (1.9653 --> 1.5686).  Saving model state dict ...
[36m(_train_fn pid=891290)[0m Epoch: 2 cost time: 2.9939022064208984
[36m(_train_fn pid=891290)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6431005 Vali Loss: 1.5685587 Best vali loss: 1.5685587
[36m(_train_fn pid=891290)[0m 	iters: 100, epoch: 3 | loss: 0.7592313
[36m(_train_fn pid=891290)[0m 	speed: 0.0164s/iter; left time: 46.4389s
[36m(_train_fn pid=891290)[0m 	iters: 200, epoch: 3 | loss: 0.5152286
[36m(_train_fn pid=891290)[0m 	speed: 0.0063s/iter; left time: 17.2033s
[36m(_train_fn pid=891290)[0m 	iters: 300, epoch: 3 | loss: 0.5796235
[36m(_train_fn pid=891290)[0m 	speed: 0.0063s/iter; left time: 16.7193s
[36m(_train_fn pid=891290)[0m 	iters: 400, epoch: 3 | loss: 0.7275717
[36m(_train_fn pid=891290)[0m 	speed: 0.0063s/iter; left time: 16.0107s
[36m(_train_fn pid=891290)[0m Updating learning rate to 0.00025719322376315234
[36m(_train_fn pid=891290)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=891290)[0m saving checkpoint...
[36m(_train_fn pid=891290)[0m Epoch: 3 cost time: 3.137646198272705
[36m(_train_fn pid=891290)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6113394 Vali Loss: 1.5755462 Best vali loss: 1.5685587
[36m(_train_fn pid=891290)[0m 	iters: 100, epoch: 4 | loss: 0.4641248
[36m(_train_fn pid=891290)[0m 	speed: 0.0166s/iter; left time: 38.9522s
[36m(_train_fn pid=891290)[0m 	iters: 200, epoch: 4 | loss: 0.6157234
[36m(_train_fn pid=891290)[0m 	speed: 0.0063s/iter; left time: 14.2249s
[36m(_train_fn pid=891290)[0m 	iters: 300, epoch: 4 | loss: 0.6546654
[36m(_train_fn pid=891290)[0m 	speed: 0.0063s/iter; left time: 13.4770s
[36m(_train_fn pid=891290)[0m 	iters: 400, epoch: 4 | loss: 0.5609898
2024-08-24 11:15:47,664	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=891290)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2522db72_217_alpha_d_ff=3,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2128,e_layers_2024-08-24_11-15-30/checkpoint_000003)
[36m(_train_fn pid=891290)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-2522db72_217_alpha_d_ff=3,batch_size=16,d_model=32,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2128,e_layers_2024-08-24_11-15-30/checkpoint_000004)
2024-08-24 11:15:51,062	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=891786)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1056450c_218_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2222,e_layer_2024-08-24_11-15-51/checkpoint_000000)
2024-08-24 11:16:13,718	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=891290)[0m 	speed: 0.0063s/iter; left time: 12.8215s
[36m(_train_fn pid=891290)[0m Updating learning rate to 0.00012859661188157617
[36m(_train_fn pid=891290)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=891290)[0m saving checkpoint...
[36m(_train_fn pid=891290)[0m Epoch: 4 cost time: 3.117436170578003
[36m(_train_fn pid=891290)[0m Epoch: 4, Steps: 489 | Train Loss: 0.6060224 Vali Loss: 1.5868042 Best vali loss: 1.5685587
[36m(_train_fn pid=891290)[0m 	iters: 100, epoch: 5 | loss: 0.5784130
[36m(_train_fn pid=891290)[0m 	speed: 0.0161s/iter; left time: 29.9347s
[36m(_train_fn pid=891290)[0m 	iters: 200, epoch: 5 | loss: 0.5333969
[36m(_train_fn pid=891290)[0m 	speed: 0.0060s/iter; left time: 10.5393s
[36m(_train_fn pid=891290)[0m 	iters: 300, epoch: 5 | loss: 0.5473366
[36m(_train_fn pid=891290)[0m 	speed: 0.0060s/iter; left time: 9.9095s
[36m(_train_fn pid=891290)[0m 	iters: 400, epoch: 5 | loss: 0.4832239
[36m(_train_fn pid=891290)[0m 	speed: 0.0060s/iter; left time: 9.3721s
[36m(_train_fn pid=891290)[0m Updating learning rate to 6.429830594078808e-05
[36m(_train_fn pid=891290)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=891290)[0m saving checkpoint...
[36m(_train_fn pid=891290)[0m Epoch: 5 cost time: 2.97471022605896
[36m(_train_fn pid=891290)[0m Epoch: 5, Steps: 489 | Train Loss: 0.6033039 Vali Loss: 1.5823608 Best vali loss: 1.5685587
[36m(_train_fn pid=891290)[0m Early stopping

Trial trial-2522db72 completed after 5 iterations at 2024-08-24 11:15:51. Total running time: 3hr 54min 42s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-2522db72 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          3.39631 â”‚
â”‚ time_total_s                             18.28611 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56856 â”‚
â”‚ train_loss                                 0.6033 â”‚
â”‚ valid_loss                                1.58236 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial trial-1056450c started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1056450c config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.22221 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00088 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=891786)[0m configuration
[36m(_train_fn pid=891786)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.22220666562177543, 'e_layers': 1, 'learning_rate': 0.000882675214462919, 'd_ff': 1536}
[36m(_train_fn pid=891786)[0m Use GPU: cuda:0
[36m(_train_fn pid=891786)[0m train 7825
[36m(_train_fn pid=891786)[0m val 2161
[36m(_train_fn pid=891786)[0m start_epoch 0
[36m(_train_fn pid=891786)[0m max_epoch 8
[36m(_train_fn pid=891786)[0m 	iters: 100, epoch: 1 | loss: 0.7847666
[36m(_train_fn pid=891786)[0m 	speed: 0.0433s/iter; left time: 164.9996s
[36m(_train_fn pid=891786)[0m 	iters: 200, epoch: 1 | loss: 0.7855471
[36m(_train_fn pid=891786)[0m 	speed: 0.0365s/iter; left time: 135.6819s

Trial status: 217 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:16:02. Total running time: 3hr 54min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1056450c   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
212 more TERMINATED
[36m(_train_fn pid=891786)[0m 	iters: 300, epoch: 1 | loss: 0.7186595
[36m(_train_fn pid=891786)[0m 	speed: 0.0365s/iter; left time: 131.9685s
[36m(_train_fn pid=891786)[0m 	iters: 400, epoch: 1 | loss: 0.6224614
[36m(_train_fn pid=891786)[0m 	speed: 0.0365s/iter; left time: 128.3634s
[36m(_train_fn pid=891786)[0m Updating learning rate to 0.000882675214462919
[36m(_train_fn pid=891786)[0m saving checkpoint...
[36m(_train_fn pid=891786)[0m Validation loss decreased (inf --> 1.8383).  Saving model state dict ...
[36m(_train_fn pid=891786)[0m Epoch: 1 cost time: 18.284231424331665
[36m(_train_fn pid=891786)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7785255 Vali Loss: 1.8383458 Best vali loss: 1.8383458
[36m(_train_fn pid=891786)[0m 	iters: 100, epoch: 2 | loss: 0.7419226
[36m(_train_fn pid=891786)[0m 	speed: 0.0920s/iter; left time: 305.8916s
[36m(_train_fn pid=891786)[0m 	iters: 200, epoch: 2 | loss: 0.6348860
[36m(_train_fn pid=891786)[0m 	speed: 0.0365s/iter; left time: 117.8189s
[36m(_train_fn pid=891786)[0m 	iters: 300, epoch: 2 | loss: 0.6680369
[36m(_train_fn pid=891786)[0m 	speed: 0.0366s/iter; left time: 114.3179s
[36m(_train_fn pid=891786)[0m 	iters: 400, epoch: 2 | loss: 0.6509202
[36m(_train_fn pid=891786)[0m 	speed: 0.0365s/iter; left time: 110.5041s
Trial status: 217 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:16:32. Total running time: 3hr 55min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
2024-08-24 11:16:33,879	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=891786)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1056450c_218_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2222,e_layer_2024-08-24_11-15-51/checkpoint_000001)
2024-08-24 11:16:54,739	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=891786)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1056450c_218_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2222,e_layer_2024-08-24_11-15-51/checkpoint_000002)
[36m(_train_fn pid=891786)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1056450c_218_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2222,e_layer_2024-08-24_11-15-51/checkpoint_000003)
2024-08-24 11:17:15,181	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1056450c   RUNNING           1            20.958        0.778526        1.83835             1.83835 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
212 more TERMINATED
[36m(_train_fn pid=891786)[0m Updating learning rate to 0.0004413376072314595
[36m(_train_fn pid=891786)[0m saving checkpoint...
[36m(_train_fn pid=891786)[0m Validation loss decreased (1.8383 --> 1.5633).  Saving model state dict ...
[36m(_train_fn pid=891786)[0m Epoch: 2 cost time: 17.910419702529907
[36m(_train_fn pid=891786)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6630272 Vali Loss: 1.5633034 Best vali loss: 1.5633034
[36m(_train_fn pid=891786)[0m 	iters: 100, epoch: 3 | loss: 0.6501007
[36m(_train_fn pid=891786)[0m 	speed: 0.0921s/iter; left time: 261.2192s
[36m(_train_fn pid=891786)[0m 	iters: 200, epoch: 3 | loss: 0.6716496
[36m(_train_fn pid=891786)[0m 	speed: 0.0373s/iter; left time: 101.9738s
[36m(_train_fn pid=891786)[0m 	iters: 300, epoch: 3 | loss: 0.5849611
[36m(_train_fn pid=891786)[0m 	speed: 0.0390s/iter; left time: 102.6593s
[36m(_train_fn pid=891786)[0m 	iters: 400, epoch: 3 | loss: 0.6642314
[36m(_train_fn pid=891786)[0m 	speed: 0.0385s/iter; left time: 97.6944s
[36m(_train_fn pid=891786)[0m Updating learning rate to 0.00022066880361572974
[36m(_train_fn pid=891786)[0m saving checkpoint...
[36m(_train_fn pid=891786)[0m Validation loss decreased (1.5633 --> 1.5616).  Saving model state dict ...
[36m(_train_fn pid=891786)[0m Epoch: 3 cost time: 18.5816593170166
[36m(_train_fn pid=891786)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6108587 Vali Loss: 1.5615661 Best vali loss: 1.5615661
[36m(_train_fn pid=891786)[0m 	iters: 100, epoch: 4 | loss: 0.5748188
[36m(_train_fn pid=891786)[0m 	speed: 0.0938s/iter; left time: 220.1128s
[36m(_train_fn pid=891786)[0m 	iters: 200, epoch: 4 | loss: 0.5795777
[36m(_train_fn pid=891786)[0m 	speed: 0.0368s/iter; left time: 82.5624s
Trial status: 217 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:17:02. Total running time: 3hr 55min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1056450c   RUNNING           3            61.9677       0.610859        1.56157             1.56157 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
212 more TERMINATED
[36m(_train_fn pid=891786)[0m 	iters: 300, epoch: 4 | loss: 0.6896108
[36m(_train_fn pid=891786)[0m 	speed: 0.0373s/iter; left time: 80.1317s
[36m(_train_fn pid=891786)[0m 	iters: 400, epoch: 4 | loss: 0.6383125
[36m(_train_fn pid=891786)[0m 	speed: 0.0371s/iter; left time: 75.9233s
[36m(_train_fn pid=891786)[0m Updating learning rate to 0.00011033440180786487
[36m(_train_fn pid=891786)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=891786)[0m saving checkpoint...
[36m(_train_fn pid=891786)[0m Epoch: 4 cost time: 18.197364568710327
[36m(_train_fn pid=891786)[0m Epoch: 4, Steps: 489 | Train Loss: 0.6058897 Vali Loss: 1.5626317 Best vali loss: 1.5615661
[36m(_train_fn pid=891786)[0m 	iters: 100, epoch: 5 | loss: 0.4996772
[36m(_train_fn pid=891786)[0m 	speed: 0.0939s/iter; left time: 174.3621s
[36m(_train_fn pid=891786)[0m 	iters: 200, epoch: 5 | loss: 0.5966243
[36m(_train_fn pid=891786)[0m 	speed: 0.0379s/iter; left time: 66.5269s
[36m(_train_fn pid=891786)[0m 	iters: 300, epoch: 5 | loss: 0.5592309
[36m(_train_fn pid=891786)[0m 	speed: 0.0374s/iter; left time: 61.9932s
[36m(_train_fn pid=891786)[0m 	iters: 400, epoch: 5 | loss: 0.4307096
[36m(_train_fn pid=891786)[0m 	speed: 0.0386s/iter; left time: 60.1406s
Trial status: 217 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:17:32. Total running time: 3hr 56min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
2024-08-24 11:17:35,969	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=891786)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-1056450c_218_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2222,e_layer_2024-08-24_11-15-51/checkpoint_000004)
[36m(_train_fn pid=892569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ff9d8cef_219_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2332,e_layer_2024-08-24_11-17-35/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-1056450c   RUNNING           4            82.4154       0.60589         1.56263             1.56157 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
212 more TERMINATED

Trial trial-1056450c completed after 5 iterations at 2024-08-24 11:17:35. Total running time: 3hr 56min 27s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-1056450c result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         20.77514 â”‚
â”‚ time_total_s                            103.19055 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56157 â”‚
â”‚ train_loss                                0.60266 â”‚
â”‚ valid_loss                                1.56612 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=891786)[0m Updating learning rate to 5.5167200903932436e-05
[36m(_train_fn pid=891786)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=891786)[0m saving checkpoint...

Trial trial-ff9d8cef started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ff9d8cef config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                256 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.23324 â”‚
â”‚ e_layers                                 2 â”‚
â”‚ learning_rate                      0.00124 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=892569)[0m configuration
[36m(_train_fn pid=892569)[0m {'batch_size': 16, 'd_model': 256, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.2332379877260029, 'e_layers': 2, 'learning_rate': 0.0012449576382368075, 'd_ff': 768}
[36m(_train_fn pid=892569)[0m Use GPU: cuda:0
[36m(_train_fn pid=892569)[0m train 7825
[36m(_train_fn pid=892569)[0m val 2161
[36m(_train_fn pid=892569)[0m start_epoch 0
[36m(_train_fn pid=892569)[0m max_epoch 8
[36m(_train_fn pid=892569)[0m 	iters: 100, epoch: 1 | loss: 0.7211989
[36m(_train_fn pid=892569)[0m 	speed: 0.0328s/iter; left time: 125.0428s
[36m(_train_fn pid=892569)[0m 	iters: 200, epoch: 1 | loss: 0.7732765
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 95.3351s
[36m(_train_fn pid=892569)[0m 	iters: 300, epoch: 1 | loss: 0.6321552
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 92.8866s
[36m(_train_fn pid=892569)[0m 	iters: 400, epoch: 1 | loss: 0.6607168
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 90.1978s
[36m(_train_fn pid=892569)[0m Updating learning rate to 0.0012449576382368075
[36m(_train_fn pid=892569)[0m saving checkpoint...
[36m(_train_fn pid=892569)[0m Validation loss decreased (inf --> 1.7246).  Saving model state dict ...
[36m(_train_fn pid=892569)[0m Epoch: 1 cost time: 13.012325763702393
[36m(_train_fn pid=892569)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7532305 Vali Loss: 1.7246320 Best vali loss: 1.7246320
[36m(_train_fn pid=892569)[0m 	iters: 100, epoch: 2 | loss: 0.5887548
[36m(_train_fn pid=892569)[0m 	speed: 0.0657s/iter; left time: 218.3668s
[36m(_train_fn pid=892569)[0m 	iters: 200, epoch: 2 | loss: 0.7313935
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 82.8985s
[36m(_train_fn pid=892569)[0m 	iters: 300, epoch: 2 | loss: 0.6118528
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 80.3223s

Trial status: 218 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:18:02. Total running time: 3hr 56min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
2024-08-24 11:18:07,139	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=892569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ff9d8cef_219_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2332,e_layer_2024-08-24_11-17-35/checkpoint_000001)
2024-08-24 11:18:21,407	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=892569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ff9d8cef_219_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2332,e_layer_2024-08-24_11-17-35/checkpoint_000002)
[36m(_train_fn pid=892569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ff9d8cef_219_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2332,e_layer_2024-08-24_11-17-35/checkpoint_000003)
2024-08-24 11:18:35,679	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:18:49,933	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ff9d8cef   RUNNING           1            15.0808       0.75323         1.72463             1.72463 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
213 more TERMINATED
[36m(_train_fn pid=892569)[0m 	iters: 400, epoch: 2 | loss: 0.6419212
[36m(_train_fn pid=892569)[0m 	speed: 0.0258s/iter; left time: 77.8811s
[36m(_train_fn pid=892569)[0m Updating learning rate to 0.0006224788191184037
[36m(_train_fn pid=892569)[0m saving checkpoint...
[36m(_train_fn pid=892569)[0m Validation loss decreased (1.7246 --> 1.5679).  Saving model state dict ...
[36m(_train_fn pid=892569)[0m Epoch: 2 cost time: 12.619386672973633
[36m(_train_fn pid=892569)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6581021 Vali Loss: 1.5678731 Best vali loss: 1.5678731
[36m(_train_fn pid=892569)[0m 	iters: 100, epoch: 3 | loss: 0.6341990
[36m(_train_fn pid=892569)[0m 	speed: 0.0657s/iter; left time: 186.3049s
[36m(_train_fn pid=892569)[0m 	iters: 200, epoch: 3 | loss: 0.6404678
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 70.3577s
[36m(_train_fn pid=892569)[0m 	iters: 300, epoch: 3 | loss: 0.5616658
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 67.7801s
[36m(_train_fn pid=892569)[0m 	iters: 400, epoch: 3 | loss: 0.5622689
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 65.1748s
[36m(_train_fn pid=892569)[0m Updating learning rate to 0.00031123940955920187
[36m(_train_fn pid=892569)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=892569)[0m saving checkpoint...
[36m(_train_fn pid=892569)[0m Epoch: 3 cost time: 12.610527038574219
[36m(_train_fn pid=892569)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6052163 Vali Loss: 1.5795398 Best vali loss: 1.5678731
[36m(_train_fn pid=892569)[0m 	iters: 100, epoch: 4 | loss: 0.5168434
[36m(_train_fn pid=892569)[0m 	speed: 0.0655s/iter; left time: 153.7683s
[36m(_train_fn pid=892569)[0m 	iters: 200, epoch: 4 | loss: 0.5333768
[36m(_train_fn pid=892569)[0m 	speed: 0.0258s/iter; left time: 57.8496s
[36m(_train_fn pid=892569)[0m 	iters: 300, epoch: 4 | loss: 0.6266027
[36m(_train_fn pid=892569)[0m 	speed: 0.0258s/iter; left time: 55.3068s
[36m(_train_fn pid=892569)[0m 	iters: 400, epoch: 4 | loss: 0.5562391
[36m(_train_fn pid=892569)[0m 	speed: 0.0258s/iter; left time: 52.7717s
Trial status: 218 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:18:32. Total running time: 3hr 57min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-ff9d8cef   RUNNING           3            43.6387       0.605216        1.57954             1.56787 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
213 more TERMINATED
[36m(_train_fn pid=892569)[0m Updating learning rate to 0.00015561970477960093
[36m(_train_fn pid=892569)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=892569)[0m saving checkpoint...
[36m(_train_fn pid=892569)[0m Epoch: 4 cost time: 12.623047351837158
[36m(_train_fn pid=892569)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5922373 Vali Loss: 1.5820919 Best vali loss: 1.5678731
[36m(_train_fn pid=892569)[0m 	iters: 100, epoch: 5 | loss: 0.5898006
[36m(_train_fn pid=892569)[0m 	speed: 0.0654s/iter; left time: 121.3872s
[36m(_train_fn pid=892569)[0m 	iters: 200, epoch: 5 | loss: 0.5591432
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 45.1836s
[36m(_train_fn pid=892569)[0m 	iters: 300, epoch: 5 | loss: 0.6257017
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 42.5886s
[36m(_train_fn pid=892569)[0m 	iters: 400, epoch: 5 | loss: 0.6978945
[36m(_train_fn pid=892569)[0m 	speed: 0.0257s/iter; left time: 40.0159s

Trial trial-ff9d8cef completed after 5 iterations at 2024-08-24 11:18:49. Total running time: 3hr 57min 41s
[36m(_train_fn pid=892569)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-ff9d8cef_219_alpha_d_ff=3,batch_size=16,d_model=256,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2332,e_layer_2024-08-24_11-17-35/checkpoint_000004)
2024-08-24 11:19:12,818	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=893228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0e61f2c7_220_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2078,e_layer_2024-08-24_11-18-49/checkpoint_000000)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-ff9d8cef result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         14.25271 â”‚
â”‚ time_total_s                             72.16016 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56787 â”‚
â”‚ train_loss                                0.58176 â”‚
â”‚ valid_loss                                1.58643 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=892569)[0m Updating learning rate to 7.780985238980047e-05
[36m(_train_fn pid=892569)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=892569)[0m saving checkpoint...
[36m(_train_fn pid=892569)[0m Epoch: 5 cost time: 12.601828575134277
[36m(_train_fn pid=892569)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5817646 Vali Loss: 1.5864309 Best vali loss: 1.5678731
[36m(_train_fn pid=892569)[0m Early stopping

Trial trial-0e61f2c7 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0e61f2c7 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.20777 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00144 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=893228)[0m configuration
[36m(_train_fn pid=893228)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.20777341530998944, 'e_layers': 1, 'learning_rate': 0.0014428627245130362, 'd_ff': 1536}
[36m(_train_fn pid=893228)[0m Use GPU: cuda:0
[36m(_train_fn pid=893228)[0m train 7825
[36m(_train_fn pid=893228)[0m val 2161
[36m(_train_fn pid=893228)[0m start_epoch 0
[36m(_train_fn pid=893228)[0m max_epoch 8
[36m(_train_fn pid=893228)[0m 	iters: 100, epoch: 1 | loss: 0.7630336
[36m(_train_fn pid=893228)[0m 	speed: 0.0436s/iter; left time: 166.3710s
[36m(_train_fn pid=893228)[0m 	iters: 200, epoch: 1 | loss: 0.7698224
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 136.1796s

Trial status: 219 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:19:02. Total running time: 3hr 57min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0e61f2c7   RUNNING                                                                                  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
214 more TERMINATED
[36m(_train_fn pid=893228)[0m 	iters: 300, epoch: 1 | loss: 0.7038345
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 132.5997s
[36m(_train_fn pid=893228)[0m 	iters: 400, epoch: 1 | loss: 0.6019645
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 129.0074s
[36m(_train_fn pid=893228)[0m Updating learning rate to 0.0014428627245130362
[36m(_train_fn pid=893228)[0m saving checkpoint...
[36m(_train_fn pid=893228)[0m Validation loss decreased (inf --> 1.6892).  Saving model state dict ...
[36m(_train_fn pid=893228)[0m Epoch: 1 cost time: 18.37604808807373
[36m(_train_fn pid=893228)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7524371 Vali Loss: 1.6892217 Best vali loss: 1.6892217
[36m(_train_fn pid=893228)[0m 	iters: 100, epoch: 2 | loss: 0.7597340
[36m(_train_fn pid=893228)[0m 	speed: 0.0923s/iter; left time: 306.8935s
[36m(_train_fn pid=893228)[0m 	iters: 200, epoch: 2 | loss: 0.6353831
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 118.4192s
[36m(_train_fn pid=893228)[0m 	iters: 300, epoch: 2 | loss: 0.6710581
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 114.6915s
[36m(_train_fn pid=893228)[0m 	iters: 400, epoch: 2 | loss: 0.6517535
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 111.0190s
Trial status: 219 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:19:32. Total running time: 3hr 58min 23s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
2024-08-24 11:19:33,059	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=893228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0e61f2c7_220_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2078,e_layer_2024-08-24_11-18-49/checkpoint_000001)
[36m(_train_fn pid=893228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0e61f2c7_220_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2078,e_layer_2024-08-24_11-18-49/checkpoint_000002)
2024-08-24 11:19:53,304	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
2024-08-24 11:20:13,514	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=893228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0e61f2c7_220_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2078,e_layer_2024-08-24_11-18-49/checkpoint_000003)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0e61f2c7   RUNNING           1            21.0506       0.752437        1.68922             1.68922 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
214 more TERMINATED
[36m(_train_fn pid=893228)[0m Updating learning rate to 0.0007214313622565181
[36m(_train_fn pid=893228)[0m saving checkpoint...
[36m(_train_fn pid=893228)[0m Validation loss decreased (1.6892 --> 1.5738).  Saving model state dict ...
[36m(_train_fn pid=893228)[0m Epoch: 2 cost time: 17.982372760772705
[36m(_train_fn pid=893228)[0m Epoch: 2, Steps: 489 | Train Loss: 0.7463798 Vali Loss: 1.5738494 Best vali loss: 1.5738494
[36m(_train_fn pid=893228)[0m 	iters: 100, epoch: 3 | loss: 0.6585796
[36m(_train_fn pid=893228)[0m 	speed: 0.0924s/iter; left time: 261.8767s
[36m(_train_fn pid=893228)[0m 	iters: 200, epoch: 3 | loss: 0.6725268
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 100.2986s
[36m(_train_fn pid=893228)[0m 	iters: 300, epoch: 3 | loss: 0.5896081
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 96.6343s
[36m(_train_fn pid=893228)[0m 	iters: 400, epoch: 3 | loss: 0.6717021
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 93.1406s
[36m(_train_fn pid=893228)[0m Updating learning rate to 0.00036071568112825905
[36m(_train_fn pid=893228)[0m saving checkpoint...
[36m(_train_fn pid=893228)[0m Validation loss decreased (1.5738 --> 1.5695).  Saving model state dict ...
[36m(_train_fn pid=893228)[0m Epoch: 3 cost time: 17.972453832626343
[36m(_train_fn pid=893228)[0m Epoch: 3, Steps: 489 | Train Loss: 0.6147475 Vali Loss: 1.5695017 Best vali loss: 1.5695017
[36m(_train_fn pid=893228)[0m 	iters: 100, epoch: 4 | loss: 0.5811286
[36m(_train_fn pid=893228)[0m 	speed: 0.0923s/iter; left time: 216.4983s
[36m(_train_fn pid=893228)[0m 	iters: 200, epoch: 4 | loss: 0.5821720
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 82.3943s
Trial status: 219 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:20:02. Total running time: 3hr 58min 53s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0e61f2c7   RUNNING           3            61.5251       0.614748        1.5695              1.5695  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
214 more TERMINATED
[36m(_train_fn pid=893228)[0m 	iters: 300, epoch: 4 | loss: 0.6984180
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 78.7531s
[36m(_train_fn pid=893228)[0m 	iters: 400, epoch: 4 | loss: 0.6418293
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 75.0393s
[36m(_train_fn pid=893228)[0m Updating learning rate to 0.00018035784056412953
[36m(_train_fn pid=893228)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=893228)[0m saving checkpoint...
[36m(_train_fn pid=893228)[0m Epoch: 4 cost time: 17.97782039642334
[36m(_train_fn pid=893228)[0m Epoch: 4, Steps: 489 | Train Loss: 0.6101205 Vali Loss: 1.5717505 Best vali loss: 1.5695017
[36m(_train_fn pid=893228)[0m 	iters: 100, epoch: 5 | loss: 0.5039418
[36m(_train_fn pid=893228)[0m 	speed: 0.0920s/iter; left time: 170.9192s
[36m(_train_fn pid=893228)[0m 	iters: 200, epoch: 5 | loss: 0.6046121
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 64.4064s
[36m(_train_fn pid=893228)[0m 	iters: 300, epoch: 5 | loss: 0.5703641
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 60.7646s
[36m(_train_fn pid=893228)[0m 	iters: 400, epoch: 5 | loss: 0.4327705
[36m(_train_fn pid=893228)[0m 	speed: 0.0367s/iter; left time: 57.1065s
Trial status: 219 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:20:32. Total running time: 3hr 59min 24s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
2024-08-24 11:20:33,707	WARNING experiment_state.py:206 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds and may become a bottleneck. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.
You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.
You can suppress this warning by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0). Set it to 0 to completely suppress this warning.
[36m(_train_fn pid=893228)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-0e61f2c7_220_alpha_d_ff=3,batch_size=16,d_model=512,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.2078,e_layer_2024-08-24_11-18-49/checkpoint_000004)
[36m(_train_fn pid=893975)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-38db6a71_221_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1658,e_layer_2024-08-24_11-20-33/checkpoint_000000)
[36m(_train_fn pid=893975)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-38db6a71_221_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1658,e_layer_2024-08-24_11-20-33/checkpoint_000001)
[36m(_train_fn pid=893975)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-38db6a71_221_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1658,e_layer_2024-08-24_11-20-33/checkpoint_000002)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-0e61f2c7   RUNNING           4            81.7376       0.61012         1.57175             1.5695  â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
214 more TERMINATED

Trial trial-0e61f2c7 completed after 5 iterations at 2024-08-24 11:20:33. Total running time: 3hr 59min 24s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-0e61f2c7 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                         20.19398 â”‚
â”‚ time_total_s                            101.93153 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                            1.5695 â”‚
â”‚ train_loss                                0.60756 â”‚
â”‚ valid_loss                                1.57339 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=893228)[0m Updating learning rate to 9.017892028206476e-05
[36m(_train_fn pid=893228)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=893228)[0m saving checkpoint...

Trial trial-38db6a71 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-38db6a71 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                128 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.16579 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00194 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=893975)[0m configuration
[36m(_train_fn pid=893975)[0m {'batch_size': 16, 'd_model': 128, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.16578890227708196, 'e_layers': 1, 'learning_rate': 0.0019403492095861606, 'd_ff': 384}
[36m(_train_fn pid=893975)[0m Use GPU: cuda:0
[36m(_train_fn pid=893975)[0m train 7825
[36m(_train_fn pid=893975)[0m val 2161
[36m(_train_fn pid=893975)[0m start_epoch 0
[36m(_train_fn pid=893975)[0m max_epoch 8
[36m(_train_fn pid=893975)[0m 	iters: 100, epoch: 1 | loss: 0.7243859
[36m(_train_fn pid=893975)[0m 	speed: 0.0166s/iter; left time: 63.1286s
[36m(_train_fn pid=893975)[0m 	iters: 200, epoch: 1 | loss: 0.8150370
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 34.6836s
[36m(_train_fn pid=893975)[0m 	iters: 300, epoch: 1 | loss: 0.6698067
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 33.6723s
[36m(_train_fn pid=893975)[0m 	iters: 400, epoch: 1 | loss: 0.8444353
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 32.8168s
[36m(_train_fn pid=893975)[0m Updating learning rate to 0.0019403492095861606
[36m(_train_fn pid=893975)[0m saving checkpoint...
[36m(_train_fn pid=893975)[0m Validation loss decreased (inf --> 1.6707).  Saving model state dict ...
[36m(_train_fn pid=893975)[0m Epoch: 1 cost time: 5.026465177536011
[36m(_train_fn pid=893975)[0m Epoch: 1, Steps: 489 | Train Loss: 0.7469329 Vali Loss: 1.6707237 Best vali loss: 1.6707237
[36m(_train_fn pid=893975)[0m 	iters: 100, epoch: 2 | loss: 0.6284085
[36m(_train_fn pid=893975)[0m 	speed: 0.0250s/iter; left time: 83.2431s
[36m(_train_fn pid=893975)[0m 	iters: 200, epoch: 2 | loss: 0.5618076
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 30.0159s
[36m(_train_fn pid=893975)[0m 	iters: 300, epoch: 2 | loss: 0.6140186
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 29.1396s
[36m(_train_fn pid=893975)[0m 	iters: 400, epoch: 2 | loss: 0.6419749
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 28.2280s
[36m(_train_fn pid=893975)[0m Updating learning rate to 0.0009701746047930803
[36m(_train_fn pid=893975)[0m saving checkpoint...
[36m(_train_fn pid=893975)[0m Validation loss decreased (1.6707 --> 1.5680).  Saving model state dict ...
[36m(_train_fn pid=893975)[0m Epoch: 2 cost time: 4.608660697937012
[36m(_train_fn pid=893975)[0m Epoch: 2, Steps: 489 | Train Loss: 0.6194761 Vali Loss: 1.5680441 Best vali loss: 1.5680441
[36m(_train_fn pid=893975)[0m 	iters: 100, epoch: 3 | loss: 0.5356766
[36m(_train_fn pid=893975)[0m 	speed: 0.0250s/iter; left time: 70.8989s
[36m(_train_fn pid=893975)[0m 	iters: 200, epoch: 3 | loss: 0.5074808
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 25.5677s
[36m(_train_fn pid=893975)[0m 	iters: 300, epoch: 3 | loss: 0.5214809
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 24.6047s
[36m(_train_fn pid=893975)[0m 	iters: 400, epoch: 3 | loss: 0.4334570
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 23.6540s
[36m(_train_fn pid=893975)[0m Updating learning rate to 0.00048508730239654014
[36m(_train_fn pid=893975)[0m EarlyStopping counter: 1 out of 3
[36m(_train_fn pid=893975)[0m saving checkpoint...
[36m(_train_fn pid=893975)[0m Epoch: 3 cost time: 4.605967044830322
[36m(_train_fn pid=893975)[0m Epoch: 3, Steps: 489 | Train Loss: 0.5903527 Vali Loss: 1.6425162 Best vali loss: 1.5680441
[36m(_train_fn pid=893975)[0m 	iters: 100, epoch: 4 | loss: 0.6239723
[36m(_train_fn pid=893975)[0m 	speed: 0.0249s/iter; left time: 58.4412s
[36m(_train_fn pid=893975)[0m 	iters: 200, epoch: 4 | loss: 0.6847728
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 20.8767s
[36m(_train_fn pid=893975)[0m 	iters: 300, epoch: 4 | loss: 0.5749845
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 19.9602s
[36m(_train_fn pid=893975)[0m 	iters: 400, epoch: 4 | loss: 0.4667999
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 19.0438s
[36m(_train_fn pid=893975)[0m Updating learning rate to 0.00024254365119827007
[36m(_train_fn pid=893975)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-38db6a71_221_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1658,e_layer_2024-08-24_11-20-33/checkpoint_000003)
[36m(_train_fn pid=893975)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720/trial-38db6a71_221_alpha_d_ff=3,batch_size=16,d_model=128,decomp_method=dft_decomp,down_sampling_method=avg,dropout=0.1658,e_layer_2024-08-24_11-20-33/checkpoint_000004)
2024-08-24 11:21:09,048	INFO timeout.py:54 -- Reached timeout of 14400 seconds. Stopping all trials.
2024-08-24 11:21:09,087	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/antonio/Documents/tfm/neuralforecast/DEF/TimeMixer/checkpoints/hptunning/hyperopt_tpe/ETTh1_96_720' in 0.0383s.
[36m(_train_fn pid=893975)[0m EarlyStopping counter: 2 out of 3
[36m(_train_fn pid=893975)[0m saving checkpoint...
[36m(_train_fn pid=893975)[0m Epoch: 4 cost time: 4.58676552772522
[36m(_train_fn pid=893975)[0m Epoch: 4, Steps: 489 | Train Loss: 0.5711506 Vali Loss: 1.6018643 Best vali loss: 1.5680441
[36m(_train_fn pid=893975)[0m 	iters: 100, epoch: 5 | loss: 0.5163414
[36m(_train_fn pid=893975)[0m 	speed: 0.0249s/iter; left time: 46.2695s
[36m(_train_fn pid=893975)[0m 	iters: 200, epoch: 5 | loss: 0.4997756
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 16.2668s
[36m(_train_fn pid=893975)[0m 	iters: 300, epoch: 5 | loss: 0.5985420
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 15.3903s
[36m(_train_fn pid=893975)[0m 	iters: 400, epoch: 5 | loss: 0.5464832
[36m(_train_fn pid=893975)[0m 	speed: 0.0093s/iter; left time: 14.4763s

Trial status: 220 TERMINATED | 1 RUNNING
Current time: 2024-08-24 11:21:02. Total running time: 3hr 59min 54s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)     train_loss     valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-38db6a71   RUNNING           4            21.995        0.571151        1.60186             1.56804 â”‚
â”‚ trial-4138d74d   TERMINATED        6            13.6009       0.593321        1.59962             1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5            24.2127       0.510234        1.62942             1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7            43.9511       0.570752        1.58113             1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5           101.635        0.600472        1.56828             1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7            13.0884       0.512451        1.683               1.61687 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
215 more TERMINATED

Trial trial-38db6a71 completed after 5 iterations at 2024-08-24 11:21:03. Total running time: 3hr 59min 54s
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-38db6a71 result                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ checkpoint_dir_name             checkpoint_000004 â”‚
â”‚ time_this_iter_s                          5.27409 â”‚
â”‚ time_total_s                             27.26905 â”‚
â”‚ training_iteration                              5 â”‚
â”‚ best_valid_loss                           1.56804 â”‚
â”‚ train_loss                                0.55818 â”‚
â”‚ valid_loss                                1.62643 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=893975)[0m Updating learning rate to 0.00012127182559913503
[36m(_train_fn pid=893975)[0m EarlyStopping counter: 3 out of 3
[36m(_train_fn pid=893975)[0m saving checkpoint...
[36m(_train_fn pid=893975)[0m Epoch: 5 cost time: 4.58112359046936
[36m(_train_fn pid=893975)[0m Epoch: 5, Steps: 489 | Train Loss: 0.5581806 Vali Loss: 1.6264332 Best vali loss: 1.5680441
[36m(_train_fn pid=893975)[0m Early stopping

Trial trial-c1c4d578 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial trial-c1c4d578 config                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ alpha_d_ff                               3 â”‚
â”‚ batch_size                              16 â”‚
â”‚ d_model                                512 â”‚
â”‚ decomp_method/decomp_method     dft_decomp â”‚
â”‚ down_sampling_method                   avg â”‚
â”‚ dropout                            0.20523 â”‚
â”‚ e_layers                                 1 â”‚
â”‚ learning_rate                      0.00097 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=894501)[0m configuration
[36m(_train_fn pid=894501)[0m {'batch_size': 16, 'd_model': 512, 'decomp_method': 'dft_decomp', 'down_sampling_method': 'avg', 'dropout': 0.20522639934728137, 'e_layers': 1, 'learning_rate': 0.000970912634210684, 'd_ff': 1536}
[36m(_train_fn pid=894501)[0m Use GPU: cuda:0
[36m(_train_fn pid=894501)[0m train 7825
[36m(_train_fn pid=894501)[0m val 2161
[36m(_train_fn pid=894501)[0m start_epoch 0
[36m(_train_fn pid=894501)[0m max_epoch 8

Trial status: 222 TERMINATED
Current time: 2024-08-24 11:21:09. Total running time: 4hr 0min 0s
Logical resource usage: 1.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Current best trial: fbb451de with best_valid_loss=1.5601323318125597 and params={'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name       status         iter     total time (s)        train_loss        valid_loss     best_valid_loss â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trial-4138d74d   TERMINATED        6           13.6009        0.593321          1.59962                 1.59035 â”‚
â”‚ trial-dcb4d3d5   TERMINATED        5           24.2127        0.510234          1.62942                 1.58169 â”‚
â”‚ trial-d7816b5e   TERMINATED        7           43.9511        0.570752          1.58113                 1.57201 â”‚
â”‚ trial-0a718da3   TERMINATED        5          101.635         0.600472          1.56828                 1.56397 â”‚
â”‚ trial-0b9eea2a   TERMINATED        7           13.0884        0.512451          1.683                   1.61687 â”‚
â”‚ trial-9492fa28   TERMINATED        5           24.136         0.559138          1.631                   1.59984 â”‚
â”‚ trial-2284a318   TERMINATED        7            9.85526       0.607496          1.60426                 1.60058 â”‚
â”‚ trial-11c7eacb   TERMINATED        7           12.0173        0.51809           1.61431                 1.60412 â”‚
â”‚ trial-8ab49a95   TERMINATED        4           91.6686        0.785399          1.97416                 1.62049 â”‚
â”‚ trial-49dc9ea1   TERMINATED        5           24.409         0.567482          1.70109                 1.61398 â”‚
â”‚ trial-1954e8ad   TERMINATED        5           46.593         0.502781          1.63017                 1.62071 â”‚
â”‚ trial-743b5daa   TERMINATED        6           41.9831        0.501552          1.63098                 1.59842 â”‚
â”‚ trial-ddc42f98   TERMINATED        7           25.2552        0.484829          1.66408                 1.58972 â”‚
â”‚ trial-5ad2934c   TERMINATED        5          124.518         0.60563           1.58949                 1.58949 â”‚
â”‚ trial-2aff9e60   TERMINATED        8           62.1421        0.631143          1.62851                 1.62851 â”‚
â”‚ trial-c515a439   TERMINATED        8           16.7843        0.614096          1.59012                 1.58937 â”‚
â”‚ trial-eff11b3a   TERMINATED        4          105.348         0.58908           1.60903                 1.59461 â”‚
â”‚ trial-ce680db1   TERMINATED        5           46.2896        0.561379          1.58649                 1.5698  â”‚
â”‚ trial-3e25555f   TERMINATED        8           15.0816        0.648012          1.63981                 1.63981 â”‚
â”‚ trial-85234c81   TERMINATED        5           35.193         0.550072          1.68666                 1.59797 â”‚
â”‚ trial-f4eb6174   TERMINATED        5           33.4889        0.538467          1.61271                 1.5831  â”‚
â”‚ trial-c0ae4bfd   TERMINATED        7           44.9702        0.558755          1.58657                 1.57858 â”‚
â”‚ trial-fccc4bc0   TERMINATED        5           17.5468        0.544558          1.63227                 1.58569 â”‚
â”‚ trial-e1dd9d13   TERMINATED        5          115.221         0.619304          1.58017                 1.58017 â”‚
â”‚ trial-d4e87f4a   TERMINATED        5            9.35826       0.589352          1.63067                 1.59827 â”‚
â”‚ trial-0adcf665   TERMINATED        7           55.4906        0.611138          1.58944                 1.58879 â”‚
â”‚ trial-bcc1b404   TERMINATED        5           18.8739        0.537969          1.62631                 1.60216 â”‚
â”‚ trial-28369f7f   TERMINATED        4          120.02          0.623031          1.58275                 1.58275 â”‚
â”‚ trial-a4b0dce8   TERMINATED        5           57.9042        0.433476          1.63452                 1.57162 â”‚
â”‚ trial-71c3c524   TERMINATED        7          101.885         0.607795          1.60335                 1.60233 â”‚
â”‚ trial-4424e324   TERMINATED        6           27.616         0.540599          1.60361                 1.57395 â”‚
â”‚ trial-fce1ff29   TERMINATED        5           90.6985        0.55006           1.69071                 1.59263 â”‚
â”‚ trial-422fc89d   TERMINATED        3          136.298     44497.3           48560.1                     1.85785 â”‚
â”‚ trial-c6eb872b   TERMINATED        7           20.5203        0.525356          1.61599                 1.59886 â”‚
â”‚ trial-5d4622b7   TERMINATED        5           25.2           0.587533          1.59506                 1.5728  â”‚
â”‚ trial-bcb9971a   TERMINATED        5           50.1838        0.398286          1.58401                 1.57731 â”‚
â”‚ trial-302d000c   TERMINATED        6           55.6192        0.550074          1.63072                 1.62074 â”‚
â”‚ trial-5e4c3658   TERMINATED        7           21.3596        0.563073          1.59562                 1.57755 â”‚
â”‚ trial-587538db   TERMINATED        4           89.625         0.720901          1.81349                 1.67084 â”‚
â”‚ trial-ba979bd7   TERMINATED        8           13.3257        0.654541          1.66541                 1.66541 â”‚
â”‚ trial-87b712b1   TERMINATED        4           28.6305        0.475037          1.71375                 1.56591 â”‚
â”‚ trial-2291caba   TERMINATED        6            7.8728        0.582227          1.64002                 1.60968 â”‚
â”‚ trial-8415ef6e   TERMINATED        5           17.0908        0.596985          1.61509                 1.59683 â”‚
â”‚ trial-8e78993d   TERMINATED        7           48.2562        0.605335          1.62206                 1.61345 â”‚
â”‚ trial-3ee4276a   TERMINATED        5           43.3534        0.564992          1.70166                 1.59514 â”‚
â”‚ trial-64278b87   TERMINATED        8            8.98098       0.662075          1.69203                 1.69203 â”‚
â”‚ trial-529c47d2   TERMINATED        8           22.3375        0.611979          1.57635                 1.57542 â”‚
â”‚ trial-56cff665   TERMINATED        5           35.9759        0.48001           1.64127                 1.56766 â”‚
â”‚ trial-723e5131   TERMINATED        8           12.4593        0.640104          1.65431                 1.65431 â”‚
â”‚ trial-8f94cc69   TERMINATED        6           55.0064        0.608293          1.59562                 1.5924  â”‚
â”‚ trial-c910a0da   TERMINATED        5           34.0157        0.589839          1.58705                 1.57407 â”‚
â”‚ trial-0ed8cfa0   TERMINATED        7           34.005         0.609228          1.5834                  1.58282 â”‚
â”‚ trial-17cf266d   TERMINATED        6          114.495         0.609825          1.56429                 1.56429 â”‚
â”‚ trial-d6f53a96   TERMINATED        5           34.5397        0.491889          1.5887                  1.58418 â”‚
â”‚ trial-7080bbc2   TERMINATED        5          123.811         0.621278          1.61895                 1.61895 â”‚
â”‚ trial-c53a2728   TERMINATED        5           25.4867        0.556389          1.58752                 1.5819  â”‚
â”‚ trial-5f401ec3   TERMINATED        6           79.6761        0.5864            1.60236                 1.58868 â”‚
â”‚ trial-44221150   TERMINATED        3          124.401      1474.95           1683.75                    1.6272  â”‚
â”‚ trial-5f8779e9   TERMINATED        7           17.9347        0.551986          1.60024                 1.58887 â”‚
â”‚ trial-2d72a19b   TERMINATED        5           16.5167        0.485371          1.70875                 1.61384 â”‚
â”‚ trial-c0ddc678   TERMINATED        3          115.194         4.64109e+11       2.87947e+10             1.92609 â”‚
â”‚ trial-28d3b87f   TERMINATED        6            9.59222       0.572091          1.60717                 1.60367 â”‚
â”‚ trial-59a195b8   TERMINATED        7           26.7112        0.527535          1.61848                 1.59667 â”‚
â”‚ trial-2d77ed42   TERMINATED        6          116.37          0.61065           1.56512                 1.56512 â”‚
â”‚ trial-51af8c6c   TERMINATED        5           32.1146        0.585119          1.61114                 1.56449 â”‚
â”‚ trial-24c877e8   TERMINATED        5           34.8918        0.570735          1.61785                 1.58436 â”‚
â”‚ trial-b1cf6dc9   TERMINATED        4           52.8826        1.30921           2.78008                 1.62603 â”‚
â”‚ trial-18d7d013   TERMINATED        6           12.7676        0.586256          1.60413                 1.60176 â”‚
â”‚ trial-0dfdff43   TERMINATED        4          109.511         0.761772          1.93262                 1.62338 â”‚
â”‚ trial-6cf6ed84   TERMINATED        5           81.7447        0.572801          1.6976                  1.59488 â”‚
â”‚ trial-3eebd77e   TERMINATED        7           31.1651        0.60849           1.59547                 1.59424 â”‚
â”‚ trial-3a704acd   TERMINATED        8           37.0287        0.608562          1.57537                 1.57537 â”‚
â”‚ trial-661f88f0   TERMINATED        5          111.07          0.577442          1.64349                 1.60281 â”‚
â”‚ trial-955594c2   TERMINATED        5           19.3301        0.528841          1.61844                 1.59089 â”‚
â”‚ trial-12948899   TERMINATED        5            9.71221       0.540164          1.63548                 1.59573 â”‚
â”‚ trial-a7e77534   TERMINATED        7          107.864         0.610246          1.57655                 1.57541 â”‚
â”‚ trial-29bec89e   TERMINATED        5           93.9451        0.528941          1.67805                 1.61507 â”‚
â”‚ trial-c310e66c   TERMINATED        7           34.2985        0.467506          1.64164                 1.58957 â”‚
â”‚ trial-54067546   TERMINATED        8            7.08236       0.648341          1.62001                 1.62001 â”‚
â”‚ trial-56f9ecfb   TERMINATED        5           84.9197        0.565634          1.63296                 1.58134 â”‚
â”‚ trial-1a61e553   TERMINATED        8           21.2639        0.623084          1.60138                 1.60138 â”‚
â”‚ trial-894051e7   TERMINATED        6            8.12102       0.566886          1.64767                 1.59748 â”‚
â”‚ trial-6e9c3025   TERMINATED        5            9.96499       0.560955          1.63151                 1.59935 â”‚
â”‚ trial-4ce91de3   TERMINATED        7           29.5778        0.611802          1.57817                 1.57728 â”‚
â”‚ trial-ca404878   TERMINATED        5          107.417         0.570431          1.57004                 1.57004 â”‚
â”‚ trial-3dae9915   TERMINATED        5           10.2391        0.590777          1.62003                 1.60344 â”‚
â”‚ trial-da8c1684   TERMINATED        5           17.8898        0.583128          1.58246                 1.56744 â”‚
â”‚ trial-b8c443a6   TERMINATED        7           21.8852        0.582123          1.5913                  1.58972 â”‚
â”‚ trial-6f6d7e6d   TERMINATED        3          130.087       170.557           426.946                   1.84478 â”‚
â”‚ trial-062edc2f   TERMINATED        4           13.2177        0.511498          1.62473                 1.60422 â”‚
â”‚ trial-394da6a5   TERMINATED        8           10.4349        0.635073          1.63374                 1.63374 â”‚
â”‚ trial-8eb45462   TERMINATED        4          125.995         4.47283e+08       2.06837e+09             1.61131 â”‚
â”‚ trial-59b61781   TERMINATED        7           14.7638        0.606409          1.58963                 1.58902 â”‚
â”‚ trial-89b09162   TERMINATED        5            5.96169       0.572707          1.61251                 1.58595 â”‚
â”‚ trial-91ee4d56   TERMINATED        7           33.4491        0.432823          1.62733                 1.58109 â”‚
â”‚ trial-8dd63f0d   TERMINATED        7           23.6727        0.599592          1.58256                 1.58033 â”‚
â”‚ trial-73041521   TERMINATED        5           49.641         0.563801          1.61605                 1.59082 â”‚
â”‚ trial-8e4fa3c2   TERMINATED        8           76.5665        0.514755          1.61419                 1.57813 â”‚
â”‚ trial-fdfebfbc   TERMINATED        5           57.1828        0.524731          1.62222                 1.59059 â”‚
â”‚ trial-2f1c5109   TERMINATED        5           98.0647        0.54514           1.64417                 1.56969 â”‚
â”‚ trial-f99d2acd   TERMINATED        4          124.877         1.0998e+10        2.9966e+10              1.59996 â”‚
â”‚ trial-90a1a1f3   TERMINATED        5           28.8587        0.579588          1.5853                  1.57148 â”‚
â”‚ trial-5b764f93   TERMINATED        7          116.362         0.616431          1.59582                 1.59582 â”‚
â”‚ trial-e7fa1c44   TERMINATED        6           52.7791        0.567604          1.60089                 1.56898 â”‚
â”‚ trial-d536d72f   TERMINATED        5           33.2545        0.579409          1.59009                 1.58239 â”‚
â”‚ trial-6ccf7050   TERMINATED        3          131.528         0.645209          1.64092                 1.64092 â”‚
â”‚ trial-b96c443f   TERMINATED        6           88.6688        0.589057          1.6151                  1.60025 â”‚
â”‚ trial-45bd3b8d   TERMINATED        6            8.86618       0.593954          1.59201                 1.58695 â”‚
â”‚ trial-e1aa52b5   TERMINATED        8           20.1674        0.633629          1.60914                 1.60914 â”‚
â”‚ trial-55bf5705   TERMINATED        5          114.63          0.58884           1.64511                 1.60519 â”‚
â”‚ trial-af10e011   TERMINATED        8           90.3199        0.610951          1.59453                 1.59277 â”‚
â”‚ trial-f702e741   TERMINATED        6            6.17819       0.619215          1.61148                 1.60613 â”‚
â”‚ trial-553c7619   TERMINATED        5           18.6686        0.588231          1.59858                 1.59704 â”‚
â”‚ trial-69363883   TERMINATED        5           55.9608        0.590192          1.63875                 1.58372 â”‚
â”‚ trial-5ea956f6   TERMINATED        6           30.8843        0.488056          1.61111                 1.58337 â”‚
â”‚ trial-f38f2860   TERMINATED        8           73.0139        0.632502          1.60556                 1.60556 â”‚
â”‚ trial-1c202e21   TERMINATED        6           23.1123        0.502243          1.63187                 1.5778  â”‚
â”‚ trial-1d2f0fd2   TERMINATED        4           95.6807        5.02262           8.09344                 1.62459 â”‚
â”‚ trial-9ec3bfee   TERMINATED        4           75.8336        8.82266e+09       2.15172e+10             1.72028 â”‚
â”‚ trial-66587373   TERMINATED        4           28.7332        0.529545          1.67561                 1.65131 â”‚
â”‚ trial-dc2fbe9a   TERMINATED        6          104.083         0.565298          1.70988                 1.61769 â”‚
â”‚ trial-1e117675   TERMINATED        5           21.0842        0.556982          1.65706                 1.60213 â”‚
â”‚ trial-7d3a60f7   TERMINATED        5            9.83042       0.551532          1.62054                 1.59636 â”‚
â”‚ trial-df45f4a1   TERMINATED        8           25.8573        0.60689           1.58927                 1.5881  â”‚
â”‚ trial-d43e9672   TERMINATED        7            5.83327       0.596333          1.60125                 1.59917 â”‚
â”‚ trial-fea50374   TERMINATED        8           17.2372        0.611678          1.59624                 1.59624 â”‚
â”‚ trial-263ebd2d   TERMINATED        5           17.6178        0.554778          1.64756                 1.59713 â”‚
â”‚ trial-ef22361c   TERMINATED        5           12.6667        0.521328          1.62564                 1.58091 â”‚
â”‚ trial-606a6b82   TERMINATED        5            9.46695       0.598669          1.60279                 1.59855 â”‚
â”‚ trial-168e79a1   TERMINATED        5            8.16005       0.57096           1.63321                 1.5828  â”‚
â”‚ trial-01d0249a   TERMINATED        5           40.4179        0.560228          1.64626                 1.61305 â”‚
â”‚ trial-5e319399   TERMINATED        5           20.7106        0.526706          1.6715                  1.57233 â”‚
â”‚ trial-e8b2bdf5   TERMINATED        8           16.9707        0.631382          1.60147                 1.60147 â”‚
â”‚ trial-eec3f6b9   TERMINATED        8           35.7599        0.610701          1.58502                 1.58467 â”‚
â”‚ trial-e384540e   TERMINATED        5           20.5272        0.546794          1.62528                 1.59435 â”‚
â”‚ trial-9c638090   TERMINATED        6           60.5053        0.542576          1.62863                 1.58019 â”‚
â”‚ trial-e3a8ea16   TERMINATED        8           54.654         0.605801          1.59941                 1.59925 â”‚
â”‚ trial-d010648f   TERMINATED        5           26.3903        0.577772          1.65521                 1.61103 â”‚
â”‚ trial-02531bea   TERMINATED        7           14.9957        0.609351          1.60104                 1.59936 â”‚
â”‚ trial-0185ffd0   TERMINATED        8            9.91619       0.618269          1.58605                 1.58605 â”‚
â”‚ trial-40735eca   TERMINATED        5            8.35274       0.557729          1.61038                 1.58558 â”‚
â”‚ trial-305c6745   TERMINATED        4           12.2063        0.541399          1.63593                 1.58882 â”‚
â”‚ trial-7d59398b   TERMINATED        4          105.048         0.611633          1.56937                 1.56937 â”‚
â”‚ trial-97342513   TERMINATED        7           15.1872        0.604379          1.59061                 1.58947 â”‚
â”‚ trial-282fda45   TERMINATED        8           18.2218        0.501997          1.62604                 1.58499 â”‚
â”‚ trial-d4e2d060   TERMINATED        8           22.7543        0.551376          1.61252                 1.59395 â”‚
â”‚ trial-32e12be8   TERMINATED        5           23.5175        0.545423          1.65537                 1.63762 â”‚
â”‚ trial-c60ba4aa   TERMINATED        5           41.3025        0.576941          1.58868                 1.56805 â”‚
â”‚ trial-a0eb3a40   TERMINATED        8           18.9744        0.665293          1.69202                 1.69202 â”‚
â”‚ trial-33052edc   TERMINATED        6           26.7478        0.602112          1.59962                 1.59386 â”‚
â”‚ trial-76f44654   TERMINATED        6          116.451         0.611341          1.56437                 1.56437 â”‚
â”‚ trial-113d5626   TERMINATED        6          116.298         0.608433          1.56236                 1.56236 â”‚
â”‚ trial-33f85791   TERMINATED        6          116.416         0.611793          1.56569                 1.56569 â”‚
â”‚ trial-5a3162da   TERMINATED        6          116.32          0.608097          1.56185                 1.56185 â”‚
â”‚ trial-4d6541d2   TERMINATED        6          116.412         0.608191          1.56048                 1.56048 â”‚
â”‚ trial-d9e723f0   TERMINATED        6          116.476         0.608604          1.56156                 1.56156 â”‚
â”‚ trial-18e6cfa9   TERMINATED        6          116.308         0.60817           1.56359                 1.56359 â”‚
â”‚ trial-fbb451de   TERMINATED        6          116.338         0.608111          1.56013                 1.56013 â”‚
â”‚ trial-b58a1502   TERMINATED        6          116.39          0.612678          1.56614                 1.56614 â”‚
â”‚ trial-4637ccbe   TERMINATED        6          116.282         0.609028          1.56151                 1.56151 â”‚
â”‚ trial-1de22ba4   TERMINATED        6          116.306         0.608761          1.56179                 1.56179 â”‚
â”‚ trial-c936880f   TERMINATED        6          116.418         0.614957          1.56809                 1.56809 â”‚
â”‚ trial-ce2f2357   TERMINATED        6          116.481         0.609259          1.56397                 1.56397 â”‚
â”‚ trial-76f4b60d   TERMINATED        6          116.386         0.608125          1.56025                 1.56025 â”‚
â”‚ trial-10b98384   TERMINATED        6          116.298         0.609526          1.56074                 1.56074 â”‚
â”‚ trial-c26f3ddf   TERMINATED        6          116.372         0.609561          1.5607                  1.5607  â”‚
â”‚ trial-7292344b   TERMINATED        6          116.369         0.61266           1.56643                 1.56643 â”‚
â”‚ trial-be5f29e9   TERMINATED        6          116.305         0.627336          1.59556                 1.59556 â”‚
â”‚ trial-16aa2a55   TERMINATED        6          116.272         0.610699          1.56149                 1.56149 â”‚
â”‚ trial-994d84e0   TERMINATED        6          116.388         0.608644          1.56089                 1.56089 â”‚
â”‚ trial-dcf07010   TERMINATED        6          116.498         0.610056          1.56216                 1.56216 â”‚
â”‚ trial-19caa7f2   TERMINATED        6          116.673         0.612898          1.56608                 1.56608 â”‚
â”‚ trial-86cfced8   TERMINATED        6          116.567         0.608616          1.56077                 1.56077 â”‚
â”‚ trial-f641d2d1   TERMINATED        6          116.504         0.609272          1.56164                 1.56164 â”‚
â”‚ trial-e90c3939   TERMINATED        6          116.337         0.608501          1.56271                 1.56271 â”‚
â”‚ trial-26da4402   TERMINATED        6          116.468         0.610617          1.56153                 1.56153 â”‚
â”‚ trial-991da5f6   TERMINATED        4           77.2366        0.72874           1.82518                 1.64937 â”‚
â”‚ trial-807ab17f   TERMINATED        6          116.783         0.608914          1.56097                 1.56097 â”‚
â”‚ trial-fba640ce   TERMINATED        6          116.867         0.612732          1.56541                 1.56541 â”‚
â”‚ trial-b4e9ba3a   TERMINATED        6          116.774         0.615136          1.56923                 1.56923 â”‚
â”‚ trial-1d704276   TERMINATED        6          116.959         0.60952           1.56224                 1.56224 â”‚
â”‚ trial-3e36d9f5   TERMINATED        6          116.767         0.610297          1.56225                 1.56225 â”‚
â”‚ trial-a0ac7b70   TERMINATED        6          116.846         0.6121            1.56607                 1.56607 â”‚
â”‚ trial-d20c25bb   TERMINATED        6          116.781         0.613097          1.56596                 1.56596 â”‚
â”‚ trial-51ad3077   TERMINATED        6          116.787         0.608372          1.56199                 1.56199 â”‚
â”‚ trial-95c70997   TERMINATED        6          116.901         0.609747          1.5638                  1.5638  â”‚
â”‚ trial-db830771   TERMINATED        6          116.727         0.608891          1.56139                 1.56139 â”‚
â”‚ trial-09541a32   TERMINATED        6          116.476         0.613002          1.56639                 1.56639 â”‚
â”‚ trial-f33279dc   TERMINATED        6          116.763         0.610132          1.56232                 1.56232 â”‚
â”‚ trial-1cd0aa88   TERMINATED        6          116.775         0.608437          1.56094                 1.56094 â”‚
â”‚ trial-5329edda   TERMINATED        6          116.825         0.617111          1.57335                 1.57335 â”‚
â”‚ trial-67e82c1c   TERMINATED        6          116.683         0.609104          1.56149                 1.56149 â”‚
â”‚ trial-39ca9fa6   TERMINATED        6          116.827         0.615365          1.57002                 1.57002 â”‚
â”‚ trial-3e89bf2d   TERMINATED        6          116.767         0.613599          1.56882                 1.56882 â”‚
â”‚ trial-c67079c3   TERMINATED        8           37.6771        0.605855          1.57423                 1.57186 â”‚
â”‚ trial-ce472cf0   TERMINATED        6          116.975         0.608691          1.56084                 1.56084 â”‚
â”‚ trial-e89050e2   TERMINATED        6          116.54          0.612748          1.56555                 1.56555 â”‚
â”‚ trial-ad9f9ee7   TERMINATED        5           10.4228        0.595597          1.60945                 1.58862 â”‚
â”‚ trial-a6ba4dfe   TERMINATED        6          116.98          0.630026          1.6016                  1.6016  â”‚
â”‚ trial-e9bab2a2   TERMINATED        6          116.663         0.609995          1.5614                  1.5614  â”‚
â”‚ trial-6011a59d   TERMINATED        6          116.941         0.61224           1.56445                 1.56445 â”‚
â”‚ trial-200e6a60   TERMINATED        8           37.5782        0.610088          1.56914                 1.56806 â”‚
â”‚ trial-4b600fca   TERMINATED        6          116.738         0.6091            1.56248                 1.56248 â”‚
â”‚ trial-57a34c3f   TERMINATED        5           10.1314        0.606485          1.59437                 1.58312 â”‚
â”‚ trial-d0246aac   TERMINATED        6          116.073         0.637166          1.61715                 1.61715 â”‚
â”‚ trial-02865d3f   TERMINATED        5            9.96041       0.608707          1.59812                 1.58981 â”‚
â”‚ trial-b7d049c3   TERMINATED        5           11.0005        0.608684          1.58616                 1.57932 â”‚
â”‚ trial-c51ecaa3   TERMINATED        5          101.957         0.606722          1.56159                 1.56159 â”‚
â”‚ trial-357752e6   TERMINATED        6          116.585         0.60916           1.56183                 1.56183 â”‚
â”‚ trial-c133f168   TERMINATED        7           64.1244        0.613481          1.56973                 1.56864 â”‚
â”‚ trial-900a3892   TERMINATED        5           23.8111        0.570763          1.60635                 1.57605 â”‚
â”‚ trial-53826d9b   TERMINATED        6          116.592         0.609281          1.56236                 1.56236 â”‚
â”‚ trial-3a1d2a04   TERMINATED        5          101.709         0.609493          1.56014                 1.56014 â”‚
â”‚ trial-edfffb25   TERMINATED        8           36.3224        0.558883          1.61068                 1.59988 â”‚
â”‚ trial-d2417067   TERMINATED        5           17.4677        0.581907          1.61495                 1.58392 â”‚
â”‚ trial-7e214e37   TERMINATED        5          101.405         0.612312          1.56075                 1.56075 â”‚
â”‚ trial-2522db72   TERMINATED        5           18.2861        0.603304          1.58236                 1.56856 â”‚
â”‚ trial-1056450c   TERMINATED        5          103.191         0.602665          1.56612                 1.56157 â”‚
â”‚ trial-ff9d8cef   TERMINATED        5           72.1602        0.581765          1.58643                 1.56787 â”‚
â”‚ trial-0e61f2c7   TERMINATED        5          101.932         0.607564          1.57339                 1.5695  â”‚
â”‚ trial-38db6a71   TERMINATED        5           27.269         0.558181          1.62643                 1.56804 â”‚
â”‚ trial-c1c4d578   TERMINATED                                                                                     â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[36m(_train_fn pid=894501)[0m 	iters: 100, epoch: 1 | loss: 0.7783097
[36m(_train_fn pid=894501)[0m 	speed: 0.0433s/iter; left time: 165.0964s
[36m(_train_fn pid=894501)[0m 	iters: 200, epoch: 1 | loss: 0.7817225
[36m(_train_fn pid=894501)[0m 	speed: 0.0365s/iter; left time: 135.6066s
[36m(_train_fn pid=894501)[0m 	iters: 300, epoch: 1 | loss: 0.7160085
[36m(_train_fn pid=894501)[0m 	speed: 0.0365s/iter; left time: 131.9700s

Best hyperparameters found were:  {'alpha_d_ff': 3, 'batch_size': 32, 'd_model': 512, 'decomp_method': {'decomp_method': 'dft_decomp'}, 'down_sampling_method': 'avg', 'dropout': 0.19237397793931257, 'e_layers': 1, 'learning_rate': 0.0008450451542293993}


Time taken (1 parallel trials): 14415 seconds


